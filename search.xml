<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>dubbo框架知识</title>
    <url>/posts/2661b4f7/</url>
    <content><![CDATA[<h2 id="一、Dubbo架构和实战"><a href="#一、Dubbo架构和实战" class="headerlink" title="一、Dubbo架构和实战"></a>一、Dubbo架构和实战</h2><h3 id="架构演变过程"><a href="#架构演变过程" class="headerlink" title="架构演变过程"></a>架构演变过程</h3><p><strong>单体架构</strong></p>
<p>单体架构所有模块和功能都集中在一个项目中 ，部署时也是将项目所有功能整体部署到服务器中。</p>
<p><strong>垂直架构</strong></p>
<p>根据业务把项目垂直切割成多个项目。</p>
<p><strong>分布式架构（SOA）</strong></p>
<p>在垂直划分的基础上,将每个项目拆分出多个具备松耦合的服务,一个服务通常以独立的形式存在于操作系统进程中。</p>
<p>Dubbo三大核心能力：面向接口的远程方法调用，智能容错和负载均衡，以及服务自动注册和发现。</p>
<p>基于垂直结构进行分层：</p>
<p>应用层: 距离用户最近的一层也称之为接入层，使用tomcat作为web容器接收用户请求使用下游的dubbo提供的接口来返回数据并且该层禁止访问数据库。</p>
<p>业务服务层：根据具体的业务场景 演变而来的模块 比如 简历投递 职位搜索 职位推荐等。</p>
<p>基础业务层：招聘业务的核心 账号 简历 公司 职位。</p>
<p>基础服务层：这一层是与业务无关的模块是一些通用的服务，比如发短信，发邮件等等，这类服务请求量大但是逻辑简单。</p>
<p>存储层:不同的存储类型Mysql、Mongodb。</p>
<p>分级：二八定律，80%的流量在核心功能上，优先保证核心服务的稳定。</p>
<p>隔离：不同性质、不同重要业务要进行隔离，比如各种中间件。</p>
<p>优点：服务以接口为粒度，屏蔽远程调用底层细节，只关心结果，而且采用此业务分层架构清晰，模块职责单一，扩展性强，保证系统稳定且安全。</p>
<p>缺点：粒度控制复杂，模块越多可能引发超时，分布式事务问题，可能引发接口爆炸，版本升级兼容困难，调用链路长。</p>
<p><strong>微服务架构</strong></p>
<p>将单个应用程序作为一套小型服务开发的方法，每种应用程序都在其自己的进程中独立运行，并使用轻量级机制(通常是HTTP资源的API)进行通信。这些服务的集中化管理非常少，它们可以用不同的编程语言编写，并使用不同的数据存储技术。微服务是在SOA上做的升华 , 粒度更加细致，微服务架构强调的一个重点是业务需要彻底的组件化和服务化。</p>
<h3 id="Dubbo基础知识"><a href="#Dubbo基础知识" class="headerlink" title="Dubbo基础知识"></a>Dubbo基础知识</h3><p>Apache Dubbo是一款高性能的Java RPC框架。</p>
<p><img src="/posts/2661b4f7/asset/v2-4ae9ce5468c78e02b18cc8a500e6c05c_720w.webp" alt="img"></p>
<p>面向接口的远程方法调用：提供高性能的基于代理的远程调用能力，服务以接口为粒度，为开发者屏蔽远程调用底层细节。</p>
<p>智能容错和负载均衡：内置多种负载均衡策略，智能感知下游节点健康状况，显著减少调用延迟，提高系统吞吐量。</p>
<p>服务自动注册和发现：支持多种注册中心服务，服务实例上下线实时感知。</p>
<p>Dubbo服务治理：，企业为了确保项目顺利完成而实施的过程，包括最佳实践、架构原则、治理规程、规律以及其他决定性的因素。</p>
<p><strong>Dubbo处理流程</strong></p>
<p><img src="/posts/2661b4f7/asset/v2-a5bc0cd9d0c2dceba033af1deffb0010_720w.webp" alt="img"></p>
<p><img src="/posts/2661b4f7/asset/v2-96a9e1c2484f3820750ca1e117436510_720w.webp" alt="img"></p>
<p>调用过程：</p>
<p>\1. 服务提供者在服务容器启动时向注册中心注册自己提供的服务。</p>
<p>\2. 服务消费者在启动时向注册中心订阅自己所需的服务。</p>
<p>\3. 注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心会基于长连接推送数据给消费者。</p>
<p>\4. 服务消费者从提供者地址列表中，基于软负载均衡算法选一台提供者进行调用，如果调用失败，重新选择。</p>
<p>\5. 服务提供者和服务消费者在内存中的调用次数和时间，定时每分钟发送给监控中心。</p>
<h3 id="Dubbo配置方式"><a href="#Dubbo配置方式" class="headerlink" title="Dubbo配置方式"></a>Dubbo配置方式</h3><p>1.注解: 基于注解可以快速的将程序配置，无需多余的配置信息，包含提供者和消费者。弊端是根据配置信息无法快速定位。</p>
<p>\2. XML:和Spring做结合，相关的Service和Reference均使用Spring集成后的。通过这样的方式可以很方便的通过几个文件进行管理整个集群配置。可以快速定位也可以快速更改。</p>
<p>3.基于代码方式: 基于代码方式的对上述配置进行配置。</p>
<h3 id="dubbo-application配置"><a href="#dubbo-application配置" class="headerlink" title="dubbo:application配置"></a>dubbo:application配置</h3><p>代表当前应用的信息</p>
<p>\1. name: 当前应用程序的名称，在dubbo-admin中我们也可以看到，这个代表这个应用名称。我们在真正时是时也会根据这个参数来进行聚合应用请求。</p>
<p>\2. owner: 当前应用程序的负责人，可以通过这个负责人找到其相关的应用列表，用于快速定位到责任人。</p>
<p>\3. qosEnable : 是否启动QoS 默认true</p>
<p>\4. qosPort : 启动QoS绑定的端口 默认22222</p>
<p>\5. qosAcceptForeignIp: 是否允许远程访问 默认是false</p>
<p>注解方式</p>
<p><img src="https://pic2.zhimg.com/80/v2-1acff69e625ede63ce08ef174fefec65_720w.webp" alt="img"></p>
<p>XML方式</p>
<p><img src="https://pic3.zhimg.com/80/v2-3dc3de900d5b2e0d6ea12f46b45f3caa_720w.webp" alt="img"></p>
<h3 id="dubbo-registry配置"><a href="#dubbo-registry配置" class="headerlink" title="dubbo:registry配置"></a>dubbo:registry配置</h3><p>代表该模块所使用的注册中心</p>
<p>\1. id : 当前服务中provider或者consumer中存在多个注册中心时，则使用需要增加该配置。在一 些公司，会通过业务线的不同选择不同的注册中心，所以一般都会配置该值。</p>
<p>\2. address : 当前注册中心的访问地址。</p>
<p>\3. protocol : 当前注册中心所使用的协议是什么。也可以直接在 address 中写入，比如使用 zookeeper，就可以写成 zookeeper:&#x2F;&#x2F;xx.xx.xx.xx:2181</p>
<p>\4. timeout : 当与注册中心不再同一个机房时，大多会把该参数延长。</p>
<h3 id="dubbo-protocol配置"><a href="#dubbo-protocol配置" class="headerlink" title="dubbo:protocol配置"></a>dubbo:protocol配置</h3><p>指定服务在进行数据传输所使用的协议</p>
<p>\1. id : 在大公司，可能因为各个部门技术栈不同，所以可能会选择使用不同的协议进行交互。这里 在多个协议使用时，需要指定。</p>
<p>\2. name : 指定协议名称。默认使用 dubbo 。</p>
<h3 id="dubbo-service配置"><a href="#dubbo-service配置" class="headerlink" title="dubbo:service配置"></a>dubbo:service配置</h3><p>指定当前需要对外暴露的服务信息</p>
<p>\1. interface : 指定当前需要进行对外暴露的接口是什么。</p>
<p>\2. ref : 具体实现对象的引用，一般我们在生产级别都是使用Spring去进行Bean托管的，所以这里面 一般也指的是Spring中的BeanId。</p>
<p>\3. version : 对外暴露的版本号。不同的版本号，消费者在消费的时候只会根据固定的版本号进行消 费。</p>
<h3 id="dubbo-reference配置"><a href="#dubbo-reference配置" class="headerlink" title="dubbo:reference配置"></a>dubbo:reference配置</h3><p>消费者的配置</p>
<p>\1. id : 指定该Bean在注册到Spring中的id。</p>
<p>\2. interface: 服务接口名</p>
<p>\3. version : 指定当前服务版本，与服务提供者的版本一致。</p>
<p>\4. registry : 指定所具体使用的注册中心地址。这里面也就是使用上面在dubbo:registry中所声明的id。</p>
<h3 id="dubbo-consumer设置"><a href="#dubbo-consumer设置" class="headerlink" title="dubbo:consumer设置"></a>dubbo:consumer设置</h3><p>\1. mock: 用于在方法调用出现错误时，当做服务降级来统一对外返回结果，后面我们也会对这个方 法做更多的介绍。</p>
<p>\2. timeout: 用于指定当前方法或者接口中所有方法的超时时间。我们一般都会根据提供者的时长来 具体规定。比如我们在进行第三方服务依赖时可能会对接口的时长做放宽，防止第三方服务不稳定 导致服务受损。</p>
<p>\3. check: 用于在启动时，检查生产者是否有该服务。我们一般都会将这个值设置为false，不让其进 行检查。因为如果出现模块之间循环引用的话，那么则可能会出现相互依赖，都进行check的话， 那么这两个服务永远也启动不起来。</p>
<p>\4. retries: 用于指定当前服务在执行时出现错误或者超时时的重试机制，重试次数。</p>
<p>\1. 注意提供者是否有幂等，否则可能出现数据一致性问题</p>
<p>\2. 注意提供者是否有类似缓存机制，如出现大面积错误时，可能因为不停重试导致雪崩</p>
<p>\5. executes: 用于在提供者做配置，来确保最大的并行度，熔断处理。</p>
<p>\1. 可能导致集群功能无法充分利用或者堵塞</p>
<p>\2. 但是也可以启动部分对应用的保护功能</p>
<p>\3. 可以不做配置，结合后面的熔断限流使用</p>
<h3 id="dubbo-method配置"><a href="#dubbo-method配置" class="headerlink" title="dubbo:method配置"></a>dubbo:method配置</h3><p>XML中独有，指定具体方法级别在进行RPC操作时候的配置。</p>
<p>\1. name : 指定方法名称，用于对这个方法名称的RPC调用进行特殊配置。</p>
<p>\2. async: 是否异步 默认false</p>
<h2 id="二、Dubbo高级应用"><a href="#二、Dubbo高级应用" class="headerlink" title="二、Dubbo高级应用"></a>二、Dubbo高级应用</h2><h3 id="SPI"><a href="#SPI" class="headerlink" title="SPI"></a>SPI</h3><p>JDK内置的一种服务提供发现机制，使用SPI机制的优势是实现解耦， 使得第三方服务模块的装配控制逻辑与调用者的业务代码分离。</p>
<p><img src="https://pic3.zhimg.com/80/v2-7e6ad2826337df99bfc91a38212d7536_720w.webp" alt="img"></p>
<p><strong>SPI约定</strong></p>
<p>1） 当服务提供者提供了接口的一种具体实现后，在META-INF&#x2F;services目录下创建一个以“接口全 限定名”为命名的文件，内容为实现类的全限定名。</p>
<p>2） 接口实现类所在的jar包放在主程序的classpath中。</p>
<p>3） 主程序通过java.util.ServiceLoader动态装载实现模块，它通过扫描META-INF&#x2F;services目录下 的配置文件找到实现类的全限定名，把类加载到JVM。</p>
<p>4） SPI的实现类必须携带一个无参构造方法。</p>
<p><strong>Dubbo中的SPI</strong></p>
<p>dubbo中大量的使用了SPI来作为扩展点，通过实现同一接口的前提下，可以进行定制自己的实现类。 比如比较常见的协议，负载均衡，都可以通过SPI的方式进行定制化，自己扩展。</p>
<p>优点：</p>
<p>\1. JDK 标准的 SPI 会一次性实例化扩展点所有实现，如果有扩展实现初始化很耗时，但如果没用上也加载，会很浪费资源。</p>
<p>\2. 如果有扩展点加载失败，则所有扩展点无法使用。</p>
<p>\3. 提供了对扩展点包装的功能(Adaptive)，并且还支持通过set的方式对其他的扩展点进行注入。</p>
<p><strong>Adaptive功能</strong></p>
<p>Dubbo中的Adaptive功能，主要解决的问题是如何动态的选择具体的扩展点。通过 getAdaptiveExtension 统一对指定接口对应的所有扩展点进行封装，通过URL的方式对扩展点来进行 动态选择。</p>
<p><img src="/posts/2661b4f7/asset/v2-9ebe297abb9ffb4cd9ae42abb3883680_720w.webp" alt="img"></p>
<p><strong>Dubbo过滤器</strong></p>
<p>Dubbo的Filter机制，是专门为服务提供方和服务消费方调用过程进行拦截设计的，每次远程方法执行，该拦截都会被执行。这样就为开发者提供了非常方便的扩展性，比如为dubbo接口实现ip白名单功 能、监控功能 、日志记录等。</p>
<p><img src="/posts/2661b4f7/asset/v2-49dc6db2ce773a88323ec7744165c1fe_720w.webp" alt="img"></p>
<h3 id="负载均衡策略"><a href="#负载均衡策略" class="headerlink" title="负载均衡策略"></a>负载均衡策略</h3><p>负载均衡（Load Balance）, 其实就是将请求分摊到多个操作单元上进行执行，从而共同完成工作任务。负载均衡策略主要用于客户端存在多个提供者时进行选择某个提供者。在集群负载均衡时，Dubbo 提供了多种均衡策略（包括随机、轮询、最少活跃调用数、一致性 Hash），dubbo默认为随机调用。</p>
<p><img src="https://pic3.zhimg.com/80/v2-83806ef061b1d2930e45612f0e1300f6_720w.webp" alt="img"></p>
<p><strong>自定义负载均衡器开发</strong></p>
<p>1） 自定义负载均衡器</p>
<p>2） 配置负载均衡器 META-INF&#x2F;dubbo</p>
<p>3） 在服务提供者工程实现类中编写用于测试负载均衡效果的方法，启动不同端口时，方法返回的信息不同。</p>
<p>4） 启动多个服务 要求他们使用同一个接口注册到同一个注册中心 但是他们的dubbo通信端口不同</p>
<p>5） 在服务消费方指定自定义负载均衡器</p>
<h3 id="异步调用"><a href="#异步调用" class="headerlink" title="异步调用"></a>异步调用</h3><p>Dubbo不只提供了堵塞式的的同步调用，同时提供了异步调用的方式。这种方式主要应用于提供者接口</p>
<p>响应耗时明显，消费者端可以利用调用接口的时间去做一些其他的接口调用,利用 Future 模式来异步等待和获取结果即可。</p>
<p><img src="https://pic2.zhimg.com/80/v2-4a8a66ba39d42150125f8998f1950e69_720w.webp" alt="img"></p>
<h3 id="线程池"><a href="#线程池" class="headerlink" title="线程池"></a>线程池</h3><p>Dubbo两种线程池</p>
<p>1） fix: 表示创建固定大小的线程池。Dubbo默认的使用方式，默认创建的执行线程数为200，并且是没有任何等待队列的。大量操作同步执行可能阻塞。</p>
<p>2） cache: 创建非固定大小的线程池，当线程不足时，会自动创建新的线程。高TPS（每秒请求数）请求下，对系统CPU和负载压力大。</p>
<p>自定义线程池</p>
<p>真实的使用过程中可能会因为使用fix模式的线程池，导致具体某些业务场景因为线程池中的线程数量不足而产生错误，而很多业务研发是对这些无感知的，只有当出现错误的时候才会去查看告警或者通过客户反馈出现严重的问题才去查看，结果发现是线程池满了。所以可以在创建线程池的时，通过某些手段对这个线程池进行监控，这样就可以进行及时的扩缩容机器或者告警。</p>
<p><img src="/posts/2661b4f7/asset/v2-12fac06f2555b36e6e70627b2bd0fed0_720w.webp" alt="img"></p>
<p><img src="/posts/2661b4f7/asset/v2-8e625e430a5de8a219fad20089ecb1d8_720w.webp" alt="img"></p>
<h3 id="路由规则"><a href="#路由规则" class="headerlink" title="路由规则"></a>路由规则</h3><p>路由是决定一次请求中需要发往目标机器的重要判断，通过对其控制可以决定请求的目标机器。我们可以通过创建这样的规则来决定一个请求会交给哪些服务器去处理。</p>
<p><img src="/posts/2661b4f7/asset/v2-5ecffd910c975b61d29b565a0e6df524_720w.webp" alt="img"></p>
<p>规则详解：</p>
<p>route:&#x2F;&#x2F; 表示路由规则的类型，支持条件路由规则和脚本路由规则，可扩展，必填。</p>
<p>0.0.0.0 表示对所有 IP 地址生效，如果只想对某个 IP 的生效，请填入具体 IP，必填。</p>
<p>com.lagou.service.HelloService 表示只对指定服务生效，必填。</p>
<p>category&#x3D;routers 表示该数据为动态配置类型，必填。</p>
<p>dynamic : 是否为持久数据，当指定服务重启时是否继续生效。必填。</p>
<p>runtime : 是否在设置规则时自动缓存规则，如果设置为true则会影响部分性能。</p>
<p>… &#x3D;&gt; … 在这里 &#x3D;&gt; 前面的就是表示消费者方的匹配规则，可以不填(代表全部)。 &#x3D;&gt; 后方则必 须填写，表示当请求过来时，如果选择提供者的配置。</p>
<h3 id="服务降级"><a href="#服务降级" class="headerlink" title="服务降级"></a>服务降级</h3><p>服务降级，当服务器压力剧增的情况下，根据当前业务情况及流量对一些服务有策略的降低服务级别， 以释放服务器资源，保证核心任务的正常运行。使用服务降级，这是防止分布式服务发生雪崩效应，当一个请求发生超时，一直等待着服务响应，那么在高并发情况下，很多请求都是因为这样一直等着响应，直到服务资源耗尽产生宕机，而宕机之后会导致分布式其他服务调用该宕机的服务也会出现资源耗尽宕机， 这样下去将导致整个分布式服务都瘫痪，这就是雪崩。</p>
<p>降级方式：</p>
<p>1） 在 dubbo 管理控制台配置服务降级，屏蔽和容错。</p>
<p>2） 指定返回简单值或者null</p>
<p>3） 使用java代码 动态写入配置中心</p>
<p>4） 整合hystrix</p>
<h3 id="三、Dubbo源码剖析"><a href="#三、Dubbo源码剖析" class="headerlink" title="三、Dubbo源码剖析"></a>三、Dubbo源码剖析</h3><h3 id="Dubbo调用过程"><a href="#Dubbo调用过程" class="headerlink" title="Dubbo调用过程"></a>Dubbo调用过程</h3><p><img src="/posts/2661b4f7/asset/v2-4e50eefdbc51c5001c3c13479aa0bfe4_720w.webp" alt="img"></p>
<p>调用四部分</p>
<p>1）Provider: 暴露服务的服务提供方</p>
<p>Protocol 负责提供者和消费者之间协议交互数据</p>
<p>Service 真实的业务服务信息 可以理解成接口 和 实现</p>
<p>Container Dubbo的运行环境</p>
<p>2）Consumer: 调用远程服务的服务消费方</p>
<p>Protocol 负责提供者和消费者之间协议交互数据</p>
<p>Cluster 感知提供者端的列表信息</p>
<p>Proxy 可以理解成 提供者的服务调用代理类 由它接管 Consumer中的接口调用逻辑</p>
<p>3）Registry: 注册中心，用于作为服务发现和路由配置等工作，提供者和消费者都会在这里进行注册</p>
<p>4）Monitor: 用于提供者和消费者中的数据统计，比如调用频次，成功失败次数等信息。</p>
<p>启动和执行流程</p>
<p>1）提供者端启动 容器负责把Service信息加载 并通过Protocol 注册到注册中心</p>
<p>2）消费者端启动 通过监听提供者列表来感知提供者信息 并在提供者发生改变时 通过注册中心及时通知消费端</p>
<p>3）消费方发起 请求 通过Proxy模块</p>
<p>4）利用Cluster模块 来选择真实的要发送给的提供者信息</p>
<p>5）交由Consumer中的Protocol 把信息发送给提供者</p>
<p>6）提供者同样需要通过 Protocol 模块来处理消费者的信息</p>
<p>7）最后由真正的服务提供者 Service 来进行处理</p>
<h3 id="整体调用链路"><a href="#整体调用链路" class="headerlink" title="整体调用链路"></a>整体调用链路</h3><p><img src="/posts/2661b4f7/asset/v2-ec19e0a13ca14a1c0fce121b198fc812_720w.webp" alt="img"></p>
<p>1）消费者通过Interface进行方法调用 统一交由消费者端的 Proxy 通过ProxyFactory 来进行代理 对象的创建 使用到了 jdk javassist技术</p>
<p>2）交给Filter 这个模块 做一个统一的过滤请求 在SPI案例中涉及过</p>
<p>3）接下来会进入最主要的Invoker调用逻辑</p>
<p>通过Directory 去配置中新读取信息 最终通过list方法获取所有的Invoker</p>
<p>通过Cluster模块 根据选择的具体路由规则 来选取Invoker列表</p>
<p>通过LoadBalance模块 根据负载均衡策略 选择一个具体的Invoker 来处理我们的请求</p>
<p>如果执行中出现错误 并且Consumer阶段配置了重试机制 则会重新尝试执行</p>
<p>4） 继续经过Filter进行执行功能的前后封装 Invoker 选择具体的执行协议 、</p>
<p>5） 客户端 进行编码和序列化然后发送数据</p>
<p>6） 到达Consumer中的Server在这里进行反编码和反序列化的接收数据</p>
<p>7） 使用Exporter选择执行器</p>
<p>8） 交给Filter 进行一个提供者端的过滤到达 Invoker 执行器</p>
<p>9） 通过Invoker 调用接口的具体实现然后返回</p>
<h3 id="URL规则和服务本地缓存"><a href="#URL规则和服务本地缓存" class="headerlink" title="URL规则和服务本地缓存"></a>URL规则和服务本地缓存</h3><p>Dubbo中的URL与java中的URL差异</p>
<p>1） 这里提供了针对于参数的 parameter 的增加和减少(支持动态更改)</p>
<p>2） 提供缓存功能，对一些基础的数据做缓存</p>
<p>服务本地缓存</p>
<p>频繁往从ZK获取信息，肯定会存在单点故障问题，所以dubbo提供了将提供者信息缓存在本地的方法，主要实现就是创建一个properties文件，通过构造方法从远程一拿到配置信息就存储到本地进行缓存。</p>
<h3 id="Dubbo服务消费过程"><a href="#Dubbo服务消费过程" class="headerlink" title="Dubbo服务消费过程"></a>Dubbo服务消费过程</h3><p><img src="https://pic3.zhimg.com/80/v2-9916b50dd80c1fe5226288ad2da843f6_720w.webp" alt="img"></p>
<p>1）通过ReferenceConfig 类的Protocol 调用 refer 方法让远程对象生成 Invoker 实例。</p>
<p>2）接着通过ProxyFactory的getProxy方法生成ref代理对象对远程服务进行处理。</p>
<h3 id="Adaptive功能实现原理"><a href="#Adaptive功能实现原理" class="headerlink" title="Adaptive功能实现原理"></a>Adaptive功能实现原理</h3><p>Adaptive的主要功能是对所有的扩展点进行封装为一个类，通过URL传入参数的时动态选择需要使用的扩展点。其底层的实现原理就是动态代理。</p>
<h3 id="集群容错分析"><a href="#集群容错分析" class="headerlink" title="集群容错分析"></a>集群容错分析</h3><p><img src="https://pic3.zhimg.com/80/v2-9d8219c67027330bc038ac2dd92e1bfa_720w.webp" alt="img"></p>
<p>Dubbo 主要提供了这样几种容错方式</p>
<p>Failover Cluster - 失败自动切换 失败时会重试其它服务器</p>
<p>Failfast Cluster - 快速失败请求失败后快速返回异常结果不重试</p>
<p>Failsafe Cluster - 失败安全出现异常 直接忽略 会对请求做负载均衡</p>
<p>Failback Cluster - 失败自动恢复请求失败后 会自动记录请求到失败队列中</p>
<p>Forking Cluster - 并行调用多个服务提供者 其中有一个返回则立即返回结果</p>
<h3 id="信息缓存接口Directory"><a href="#信息缓存接口Directory" class="headerlink" title="信息缓存接口Directory"></a>信息缓存接口Directory</h3><p>Directory是Dubbo中的一个接口，主要用于缓存当前可以被调用的提供者列表信息。我们在消费者进 行调用时都会通过这个接口来获取所有的提供者列表，再进行后续处理。</p>
<h3 id="负载均衡实现原理"><a href="#负载均衡实现原理" class="headerlink" title="负载均衡实现原理"></a>负载均衡实现原理</h3><p>通过LoadBalance 接口进行定义，默认使用的是随机算法，这随机算法的负载，其内部的实现其实就是一个权重概念，通过不同权重来选取不同机器。权重相同直接随机，权重不同通过总工权重来随机分配。</p>
<h3 id="网络通信原理剖析"><a href="#网络通信原理剖析" class="headerlink" title="网络通信原理剖析"></a>网络通信原理剖析</h3><p>dubbo协议采用固定长度的消息头和不定长度的消息体来进行数据传输。请求、响应的 header 一致。</p>
]]></content>
      <categories>
        <category>基础知识</category>
        <category>dubbo</category>
      </categories>
      <tags>
        <tag>基础知识</tag>
        <tag>dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title>jvm参数配置</title>
    <url>/posts/7828/</url>
    <content><![CDATA[<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-XX:MetaspaceSize=128M -XX:MaxMetaspaceSize=256M -Xms256m -Xmx256m</span><br></pre></td></tr></table></figure>

<p> 文章看下来上面这段配置的意思很简单，设置元空间的初始值和最大值，设置堆空间的初始值和最大值。 </p>
<p> 为什么MetaspaceSize要设置为128M？为什么堆内存初始值Xms设置为256M而不是512M？ </p>
<p> 按照Java官方的指导： </p>
<p> <img src="/posts/7828/asset/20210518100720453.png" alt="img"> </p>
<p>Java堆大小设置，Xms 和 Xmx设置为老年代存活对象的3-4倍，即Full GC之后的老年代内存占用的3-4倍。</p>
<p>②、永久代 PermSize和MaxPermSize(元空间)设置为老年代存活对象的1.2-1.5倍。</p>
<p>③、年轻代Xmn的设置为老年代存活对象的1-1.5倍。</p>
<p>④、老年代的内存大小设置为老年代存活对象的2-3倍。</p>
<p>使用一个模仿生成环境进行测试运行一段时间后，获取JVM参数数据。然后再进行设置实际的JVM参数；如下用jstat工具查看jvm的情况：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">jstat -gc 12345</span><br><span class="line">###</span><br><span class="line"> S0C    S1C    S0U    S1U      EC       EU        OC         OU       MC     MU    CCSC   CCSU   YGC     YGCT    FGC    FGCT     GCT   </span><br><span class="line">13824.0 22528.0 13377.0  0.0   548864.0 535257.2  113152.0   46189.3   73984.0 71119.8 9728.0 9196.2     14    0.259   3      0.287    0.546</span><br></pre></td></tr></table></figure>

<p>OU表示老年代所占用的内存为 46189.3 K（大约45M）；那么jvm相应的配置参数应该做如下修改：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-XX:MetaspaceSize=64M -XX:MaxMetaspaceSize=64M -Xms180m -Xmx180m</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>基础知识</category>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>基础知识</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title>多线程并发编程基础</title>
    <url>/posts/35288/</url>
    <content><![CDATA[<h3 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h3><p>Java是支持多线程的开发语言，意思就是可以在多CPU核心的机子上同时处理不同的任务，优化资源的使用率，提升程序的效率。</p>
<p>1） 并发编程三要素：</p>
<p>原子性：一个或者多个操作要么全部执行成功要么全部执行失败。</p>
<p>有序性：程序执行顺序按照代码顺序先后执行，但是CPU可能会对指令进行重排序。</p>
<p>可见性：当多个线程访问同一个变量时，如果一个线程修改了变量，其他线程立即获取最新的值。</p>
<p>2） 线程的五大状态：</p>
<p>创建状态：当用new操作符创建一个线程的时候。</p>
<p>就绪状态：调用start方法，处于就绪状态的线程并不一定马上就执行run方法，还需要等待CPU的调度。</p>
<p>运行状态：CPU开始调度线程，并开始执行Run方法。</p>
<p>阻塞状态：线程的执行过程中可能因为一些原因进入阻塞状态，比如调用sleep方法，获取尝试得到一个锁等等。、</p>
<p>死亡状态：Run方法执行完或者执行中遇到异常。</p>
<p>3） 悲观锁和乐观锁</p>
<p>悲观锁：认为一定会有其他线程来改变他，所以每次操作就会加锁，会造成线程阻塞。</p>
<p>乐观锁：认为不会有线程来改变他，每次操作不会加锁，但是如果因为其他线程来改变了值，造成了冲突，会因为冲突而操作失败，但是他又会继续重试，直到成功为止，不会造成线程阻塞。</p>
<p>4） 线程之间的协作</p>
<p>线程之间的协作有：wait、notify、notifyAll等</p>
<p>5） Synchronized关键字（同步锁）</p>
<p>修饰一个代码块：被修饰的代码块称为同步语句块，作用范围是大括号{}括起来的代码，作用的对象是调用这个代码块的对象。</p>
<p>修饰一个方法：被修饰的方法称为同步方法，作用范围是整个方法，作用的对象是调用这个方法的对象。</p>
<p>修饰一个静态的方法：作用范围是整个静态方法，所用的对象是这个类中的所有对象。</p>
<p>修饰一个类：作用范围是synchronized后面括起来的部分，作用的对象是这个类中的所有对象</p>
<p>6） CAS</p>
<p>比较替换，是实现并发应用的一种技术，主要用于不想使线程进入阻塞的一种方式，操作包含三个操作数-内存位置V、预期原值A、新值B，如果内存位置和预期原值相匹配，处理器自动将该位置的值改为新值，否则就不做处理。</p>
<p>CAS三大问题：ABA问题、循环时间长开销大、只能保证一个共享变量的原子操作，即一个CAS只能处理一个。</p>
<p>7） 线程池</p>
<p>如果使用一个线程就创建一个，存在如果并发的线程量大，且每个线程执行一个任务就结束了，这样频繁的创建线程就会给系统带来很大的开销，导致系统效率大大降低，因为频繁创建线程和销毁线程是需要时间的，而线程池可以对线程进行复用，大大减少线程创建和销毁所带来的性能消耗。</p>
<h3 id="Thread和Runnable概念"><a href="#Thread和Runnable概念" class="headerlink" title="Thread和Runnable概念"></a>Thread和Runnable概念</h3><p>创建执行线程的两种方法：扩展Thread类以及实现Runnable接口重写Run方法</p>
<p>线程的特征和状态：</p>
<p>1） 不管是否并发，都有一个主线程的Thread对象，执行该程序时，java虚拟机会创建一个新的Thread并在该线程中执行main方法，这是非并发应用程序的唯一线程，也是并发应用程序中的第一个线程。</p>
<p>2） Java线程共享应用程序中所有资源，包括内存和打开的文件，快速简单共享信息，但是需要使用同步，也就是加锁来避免数据竞争。</p>
<p>3） Java线程的优先级，介于Thread.MAX_PRIORITY(10)和Thread.MIN_PRIORITY(1)之间，默认是5，通常较高优先级的线程会先于较低优先级的线程之前执行，但不是绝对，CPU可能会进行指令重排。</p>
<p>4） Java的两种线程：守护线程和非守护线程，我们常用的多线程都是非守护线程。</p>
<p>Java程序结束执行的两种情形：</p>
<p><strong>第一种，通过执行Runtime类的exit()方法，用户具有可主动调用权力。</strong></p>
<p><strong>第二种，所有非守护线程执行完毕，JVM进程会自动退出，不会考虑守护线程运行情况。</strong></p>
<p>守护线程主要用于垃圾收集器或缓存管理器中，在start方法执行前通过isDaemon方法检查线程是否为守护线程，也可以通过setDaemon方法将某个线程指定为守护线程。</p>
<p>5） Thread.States枚举类中定义的线程状态</p>
<p>New: Thread对象已经创建还未执行</p>
<p>Runnable: Thread对象已经在java虚拟机中运行</p>
<p>Blocked：Thread对象正在等待锁定</p>
<p>Waiting: Thread对象正在等待另一个线程的动作</p>
<p>Time_Waiting: Thread对象正在等待另一个线程的动作,但是有时间限制</p>
<p>Terminated: Thread对象已经完成了执行</p>
<p>getState方法可以获取Thread对象的状态，并且修改，但是在给定时间内一个线程只能有一个状态。</p>
<h3 id="Thread和Runnable应用"><a href="#Thread和Runnable应用" class="headerlink" title="Thread和Runnable应用"></a>Thread和Runnable应用</h3><p>Runnable接口只定义了一种可实现的方法，即run方法，和继承Thread类是不一样的，当执行start方法启动新线程就会调用run方法。</p>
<p>Thread类常用方法：</p>
<p>1） 获取和设置Thread对象信息的方法：</p>
<p>getId：返回Thread对象的标识符，他是线程创建分配的一个正整数，整个生命周期唯一且不能修改。</p>
<p>getName&#x2F;setName：获取或设置Thread对象的名称。</p>
<p>getPriority&#x2F;setPriority：获取或设置Thread对象的优先级。</p>
<p>isDaemon&#x2F;setDeamon：获取或者建立Threa对象的守护条件。</p>
<p>getState：返回Thread对象的状态。</p>
<p>2） Interrupt：中断目标线程，比如该线程处于sleep休眠中，使用它就可以直接唤醒，并给线程打上中断标记</p>
<p>3） Interrupted：判断目标线程是否被中断，并清除该线程中断标记。</p>
<p>4） Isinterrupted：判断目标线程是否被中断，但是不会清楚线程中断标记。</p>
<p>5） Sleep(long ms)：线程执行暂停、休眠的时间。</p>
<p>6） Join：暂停线程执行，直到调用该方法的线程执行结束为止，就是A B两个线程，B线程通过join方法切入到A线程中，那么A线程需要等待B线程执行完毕，他才能继续执行。</p>
<p>7） setUncaughtExceptionHandler：用于建立未校验的异常处理器。</p>
<p>8） currentThread：Thread类静态方法，返回实际执行该代码的Thread对象。</p>
<h3 id="Callable接口"><a href="#Callable接口" class="headerlink" title="Callable接口"></a>Callable接口</h3><p>与Runnable接口相似，主要用在filter模式，比如mq消息的处理，但是：</p>
<p>1） Callable接口声明call方法，具有参数和返回值，并且入参和返回值是相对应的。</p>
<p>2） 声明了call方法，必须返回声明中指定对象的返回值</p>
<p>3） Call方法可以抛出任何一种校验异常，可以实现自己的处理器重载afterExecute方法处理异常</p>
<p> <img src="https://pic2.zhimg.com/80/v2-7c79f59124536e3be8ed1c57f436ae65_720w.webp" alt="img"> </p>
<p> <img src="/posts/35288/asset/v2-c37452e128790f835543d0ad341e2690_720w.webp" alt="img"> </p>
<h3 id="Synchronized关键字"><a href="#Synchronized关键字" class="headerlink" title="Synchronized关键字"></a>Synchronized关键字</h3><p>Synchronized一般用在同步代码块里面给某个对象加锁，就是多线程想要干某件事时判断你是否获取了这个对象锁，类似于门票机制。加锁的方式有多种，可以给方法或者类或者创建的一个obj对象，但是本质都是面向对象加锁，需要操作这个对象的时候你就要获取到对象的锁才能进行下一步。</p>
<p> <img src="/posts/35288/asset/v2-4ae6da3587b42425152c5a37eab34378_720w.webp" alt="img"> </p>
<p><strong>对象锁、方法锁、类锁理解：</strong></p>
<p>静态方法只能加类锁 加在方法上也是类锁 和其他非静态方法锁是不互斥的 可以同步执行 只会和相同类锁互斥</p>
<p>分三种情况 对象锁 非静态方法锁 和静态类锁</p>
<p>创建一个类对象多线程共用：</p>
<p>方法锁之间互斥</p>
<p>类锁之间互斥</p>
<p>对象锁互斥</p>
<p>而类锁 和方法锁 和对象锁之间都不互斥</p>
<p>创建多个类对象多线程独用：</p>
<p>方法锁之间不互斥</p>
<p>类锁之间互斥</p>
<p>对象锁之间不互斥</p>
<p>而类锁 和方法锁 和对象锁之间都不互斥</p>
<p><strong>锁是一个对象：</strong></p>
<p>这个对象内部有一个标志位，记录自己有没有被某个线程占用，以0和1标记。</p>
<p>如果这个对象被某个线程占用，记录这个线程的thread ID</p>
<p>这个对象维护一个thread id list，记录其他所有阻塞的、等待获取这个锁的线程。当前线程释放这个锁之后从thread id list里面取一个线程唤醒。</p>
<p><strong>锁的实现原理：</strong></p>
<p>在对象里面，有一块数据叫mark word，以64位windows系统为准，里面有两个重要字段锁标志位和占用该锁的thread id，不同系统结构不同。</p>
<h3 id="Wait方法和Notify方法"><a href="#Wait方法和Notify方法" class="headerlink" title="Wait方法和Notify方法"></a>Wait方法和Notify方法</h3><p>常见多线程编程模型之生产者消费者模型</p>
<p> <img src="https://pic2.zhimg.com/80/v2-8d8a44b3c9de22903b08881b41042801_720w.webp" alt="img"> </p>
<p>一个内存队列，生产者往里面放，消费者从里面取。</p>
<ol>
<li><p>内存队列加锁实现线程安全</p>
</li>
<li><p>阻塞，当内存队列满了生产者放不进去东西阻塞，内存队列空了消费者取不到东西也会阻塞。</p>
</li>
<li><p>双向通知，当内存队列满了，生产者阻塞，通知消费者取，当内存队列空了，消费者阻塞，通知生产者生产。</p>
</li>
</ol>
<p>阻塞的实现</p>
<p>1） 生产者、消费者线程调用自己的wait和notify方法，自己阻塞自己</p>
<p>2） 用一个阻塞队列，当取不到数据或者放不进数据时，表明已被阻塞</p>
<p>双向通知的实现</p>
<p>1） wait和notify机制</p>
<p>2） condition机制</p>
<p><strong>wait方法和notify方法为什么必须要和synchronized关键字一起使用？</strong></p>
<p>因为对于同一个对象，一个线程调用了该对象的wait进行等待，另一个线程调用了对象的notify进行唤醒，两个线程之间要通信，为了达到他们之间的协作，就必须要使用synchronized关键字同步给对象，也就是给对象加锁，等唤醒之后两个线程在争抢对象锁。任何对象都可以被synchronized修饰成为锁，所以notify和wait只能放在Object类中。</p>
<p><strong>为什么wait的时候必须释放锁？</strong></p>
<p>假设A线程B线程，如果A线程wait却不释放锁，那么B线程就永远没有机会进入同步块中来唤醒A线程，就发生了死锁，所以wait的机制就是先释放锁，等其他线程争抢，自己进入休眠状态中，等待其他线程唤醒重新获取锁</p>
<p>wait和notify存在的问题：</p>
<p>生产者在通知消费者的同时也通知了其他生产者，消费者在通知生产者的同时也通知了其他消费者，因为wait、notify以及synchronized所作用的对象都是同一个，一个对象是没办法区分队列空还是队列满的两个条件，于是要引入condition来解决此问题。</p>
<h3 id="Interrupt方法"><a href="#Interrupt方法" class="headerlink" title="Interrupt方法"></a>Interrupt方法</h3><p>Interrupt异常：</p>
<p>必须要是声明了会抛出InterruptedExeception的函数才会抛出异常，异常抛出取消状态，也就是sleep、join和wait</p>
<p>轻量级阻塞和重量级阻塞：</p>
<p>轻量级阻塞，能被中断的阻塞，通过wait进行阻塞等待，可以被interrupt唤醒；而不能被中断的阻塞被称为重量级阻塞，比如synchronized修饰的同步块，状态为blocked。</p>
<p><img src="https://pic4.zhimg.com/80/v2-1693b4d10339c14539f5e10fd3404e8b_720w.webp" alt="img"></p>
<p>初始线程处于new状态，调用start执行，进入runnable和ready状态，如果没有调用任何的阻塞函数，线程就会在这两种状态之间切换，也就是系统的时间片调度，两种状态的切换是操作系统完成的，除非手动调用yield函数，放弃CPU的占用。</p>
<p>一旦调用图中的任何阻塞函数，线程就会进入waiting和waiting_time状态，前者无限期阻塞，后者根据设定时间阻塞，如果使用了synchronized关键字或者块，则会进入blocked状态。因此thread.interrupted中断线程的精确含义是唤醒的是轻量级阻塞线程。</p>
<p>Thread.Interrupted和Thread.isinterrupted的区别：</p>
<p>这两个方法都是用来判断自己是否收到过中断信号，前者是实例方法后者是静态方法，前者只是读取中断状态，不做任何操作，而后者不仅读取还要重置中断标志位。</p>
<h3 id="线程优雅的关闭"><a href="#线程优雅的关闭" class="headerlink" title="线程优雅的关闭"></a>线程优雅的关闭</h3><p>在java中有stop、destory等方法强制杀死线程，但是这样操作也会带来线程中的资源如网络连接、文件描述符等无法正常关闭，不推荐使用，因此一个线程运行应该让他执行完毕释放所有资源再退出，不断循环的多线程可以通过线程之间的通信机制，让主线程通知退出。</p>
<p><strong>守护线程</strong></p>
<p><img src="https://pic4.zhimg.com/80/v2-f7c1a32a72dbfb3792e804c06768a637_720w.webp" alt="img"></p>
<p>当一个jvm进程里面有多个线程，这些线程被分为两类：守护线程和非守护线程，默认都是非守护线程，当所有非守护线程退出后，整个jvm进程都会退出，，守护线程不影响jvm进程的退出，比如垃圾回收线程就是守护线程，他们默默在后台工作，当开发者的所有前台线程即非守护线程退出之后，整个JVM进程也退出了。</p>
<p><strong>设置标志位来优雅关闭线程</strong></p>
<p>也就是设置一个布尔变量，初始值是true，在线程run方法中通过while循环执行，当线程运行到一定地步，我把这个变量重置为false，那run方法执行不下去了就自动退出。</p>
<p><img src="/posts/35288/asset/v2-9427c0165e4fb7024b5d4c3247b45aec_720w.webp" alt="img"></p>
<p>如果在while中被阻塞了，就会无法退出循环，这时候可以通过interruptedExecption异常和interrupt函数来处理</p>
<h3 id="并发核心概念"><a href="#并发核心概念" class="headerlink" title="并发核心概念"></a>并发核心概念</h3><p>并发：系统同时运行多个不同的任务，比如单核CPU，他同时只能干一件事，但是他可以通过时间分片来切换同时让多个线程运行，这就是并发。</p>
<p>并行：系统同时运行两个以上线程，线程之间互相不争抢资源，如多核CPU，每个核心可以自己干自己的事，互相不受影响。</p>
<p>比如nginx，他启动之后有一个master和多个worker，master负责监听，worker负责处理请求，worker的数量和系统的cpu核心数量是一样的，这样每个核心就只运行一个worker核心，不需要上下文切换，效率就会有很高提升。所以worker就是并行运行</p>
<p><strong>并发同步问题</strong></p>
<p>并发同步是为协调两个或者更多任务获取预期结果的机制。</p>
<p>实现的两种方式：</p>
<p>1） 控制同步：A任务依赖于B任务的结束，A任务不能在B任务还没结束之前就开始，串行处理，按顺序来。</p>
<p>2） 数据访问同步：当两个或者更多任务访问共享变量时，任意时间只有一个任务可以访问该变量，比如锁机制</p>
<p>临界段:他是一段代码，用来访问共享变量，互斥是保证这一要求的机制，在任意时间只能被一个任务执行。</p>
<p><strong>并发系统实现同步机制</strong></p>
<p>信号量：一种用于控制对一个或者多个单位资源进行访问的机制，他有一个用于存放可用资源数量的变量。互斥就是一种特殊的信号量，他只有两种状态忙和空闲，当空闲就可以被争抢，当忙就只能被持有线程释放，通过保护临界段避免条件竞争。</p>
<p>监视器：一种在共享资源上实现互斥的机制，他有一个互斥、一个条件变量、两种操作即等待条件和通报条件，一旦你通报了该条件，在等待他的任务中只有一个会继续执行。</p>
<p>如果共享数据受同步机制保护，那么代码就是线程安全的。</p>
<p><strong>不可变对象</strong></p>
<p>初始化之后就不可以修改，如果想要修改就必须创建一个新的对象，所以他是线程安全的，在并发编程中使用不会出现任何问题，比如我们常用的String类，当给他赋值的时候，他其实是重新创建了一个新的对象，他底层是final修饰的。</p>
<p><strong>原子操作和原子变量</strong></p>
<p>原子操作：我这个操作要么成功要么失败，通过临界段来实现原子操作，以便于对整个操作实现同步机制。</p>
<p>原子变量：通过原子操作来设置或获取的变量，通过同步机制或者CAS来实现，CAS是乐观锁的实现方式之一，先拿到值，不加锁，最后修改的时候再获取当前值与之前值比较来判断是否能同步。</p>
<p><strong>共享内存和消息传递</strong></p>
<p>并发多线程之间的两种通信方式</p>
<p>共享内存：同一台计算机运行多个任务，在相同的内存区域读或写，对该内存区域访问采用同步机制的保护临界段</p>
<p>消息传递，比如生产者消费者队列，在一个内存区域共享。</p>
<p>消息传递：不同计算机运行多个任务，多任务之间执行消息传递，需要遵循预定义的协议，而且分两种情况同步和异步，发送方发送消息后阻塞并等待响应就是同步，发送方发送消息后继续执行自己流程就是异步。比如分布式集群，在不同机器部署，又需要互相之间消息通讯。</p>
<h3 id="并发编程的问题"><a href="#并发编程的问题" class="headerlink" title="并发编程的问题"></a>并发编程的问题</h3><p><strong>数据竞争</strong></p>
<p>多个任务在临界段之外对共享变量进行写入，且没有任何同步机制就会存在数据竞争。多个任务执行同一个方法，因为执行顺序不同最终结果也会不同。</p>
<p><strong>死锁</strong></p>
<p>多个任务正在等待必须由另一线程释放的某个共享变量才能继续运行，比如A线程、B线程、C线程形成A等B、B等C、C等A，造成闭环死锁。</p>
<p>形成死锁必须满足的四种条件，也称为Coffman条件：</p>
<p>1） 互斥：死锁中涉及的资源必须是不可共享的，一次只能有一个任务可以使用该资源。</p>
<p>2） 占有并等待条件：一个任务在占有某一互斥资源时又请求另一互斥资源，且他在等待时不会释放任何资源。</p>
<p>3） 不可剥夺：资源只能被持有他的任务释放</p>
<p>4） 循环等待：任务1等待任务2所占用资源。。。任务n等待任务1所占用资源形成循环等待。</p>
<p>避免死锁的方式：</p>
<p>1） 忽略：发生死锁重新执行</p>
<p>2） 检测：检测程序是否有死锁，如jconsole</p>
<p>3） 预防：根据Coffman条件进行预防，让他不能达到四个满足条件</p>
<p>4） 规避：任务执行前，对空闲资源和任务需要的资源进行分析，是否会形成死锁来判断任务是否可以执行。</p>
<p><strong>活锁</strong></p>
<p>任务1和任务2两个并发线程执行需要两个资源，任务1执行先对资源1进行了加锁，任务2执行先对资源2进行了加锁，当任务1需要用资源2，因为被任务2持有，没法获取，于是他就释放了资源1，任务2也是一样，互换人质，然后下一步执行又发现任务1获取不到资源1咯，一直循环下去就形成了活锁。活锁占CPU且占内存，因为他们是一直运行下去的，而且存在资源交换，而死锁只占内存，不占用CPU，因为他们已经没法继续执行下去了。</p>
<p><strong>资源不足</strong></p>
<p>某个任务在系统无法获取维持其继续执行下去的资源，就会发生资源不足问题。通过公平原则可以解决此问题，通过算法实现类似于排队原则，避免大家争抢出现资源都没抢够资源不足无法继续运行的问题，但是公平原则会导致效率降低。</p>
<p><strong>优先权反转</strong></p>
<p>低优先权任务持有了高优先权任务所需的资源，就会发生优先权反转，低优先任务会先执行，然后释放资源，高优先权任务才能继续执行。</p>
<h3 id="JMM内存模型"><a href="#JMM内存模型" class="headerlink" title="JMM内存模型"></a>JMM内存模型</h3><p>JMM内存模型为了解决一些问题而诞生的。</p>
<p><strong>内存可见性问题</strong></p>
<p>比如一个4核的CPU，分三级缓存，一级二级分数每个核心，三级横跨所有核心，负责和内存条同步，基于缓存一致性协议，多核缓存之间进行同步的，诞生缓存一致性协议对性能消耗过大，于是在单核里面加入了两个读loadBuffer和写的storeBuffer，先写到buffer中，再进行同步，把同步变成异步。但是这样就会出现缓存不一致问题即内存可见性问题。在Java中就是多线程之间线程缓存与共享内存不一致问题。</p>
<p><img src="/posts/35288/asset/v2-5cf2ccd9131feadf6bb1d0fa75dddd58_720w.webp" alt="img"></p>
<p><strong>重排序和内存可见性关系</strong></p>
<p>比如两个线程通过Store buffer延迟写入到共享内存实现缓存同步，但是如果读线程先于写线程执行，就会出现读取不到数据情况。</p>
<p>重排序类型：</p>
<p>1） 编译器重排序。没有依赖关系的语句，编译器可以调整顺序。</p>
<p>2） CPU指令重排序。指令级别执行，两条指令依赖关系就可以不按顺序执行。</p>
<p>3） CPU内存重排序。指令执行顺序与写入执行顺序不一致，比如通过异步调用，造成缓存不一致就是内存重排序</p>
<p><strong>内存屏障</strong></p>
<p>为了禁止编译器重排序和CPU指令重排序，在编译器和CPU层面都有相应指令防止重排序，也就是内存屏障。他是JMM和happen-before规则的底层实现原理。</p>
<p>编译器的内存屏障是告诉编译器在编译过程中不要进行指令重排，而CPU的内存屏障是指令，给开发者调用，比如volatile关键字。</p>
<p>JDK8提供了一个Unsafe类提供三个内存屏障函数</p>
<p><img src="https://pic3.zhimg.com/80/v2-da40f51263a28fee5a5b6e2ada04c9f2_720w.webp" alt="img"></p>
<p>CPU内存屏障分为四种：</p>
<p>1） LoadLoad：禁止读和读的重排序</p>
<p>2） StoreStore：禁止写和写的重排序</p>
<p>3） LoadStore：禁止读和写的重排序</p>
<p>4） StoreLoad：禁止写和读的重排序</p>
<p>Unsale类的三个内存屏障函数范围：</p>
<p>1）loadFence：LoadLoad+ LoadStore</p>
<p>2）storeFence：StoreStore+ LoadStore</p>
<p>3）fullFence：loadFence+ storeFence+ StoreLoad</p>
<p><strong>重排序的原则即as-if-serial</strong></p>
<p>单线程程序重排序规则</p>
<p>单线程只要操作之间没有数据依赖，就可以进行CPU指令重排序，因为执行的结果是不受影响的。</p>
<p>多线程程序重排序规则</p>
<p>多线程之间数据依赖太复杂，就会出现内存可见性问题，编译器和CPU没有办法根据依赖关系作出优化，他只能保证单线程遵循重排序原则，而上层要告知编译器和CPU在多线程情况下什么时候可以重排序什么时候不可以。</p>
<h3 id="Happen-before"><a href="#Happen-before" class="headerlink" title="Happen-before"></a>Happen-before</h3><p>他是JMM内存模型的规范，从字面理解就得到结果了先行发生，用于描述两个操作之间的内存可见性。</p>
<p>主要干两个事，</p>
<p>第一：编译器和CPU可以灵活重排序</p>
<p>第二：开发者能知道的那些重排序和不应该知道的重排序，比如开发者知道可以用volitile和synchronized等线程同步机制来禁止重排序。</p>
<p>比如A happen-before B，那么A执行结果必须对B可见，保证跨线程之间的内存可见性。</p>
<p><strong>Happen-before的传递性</strong></p>
<p>除了基本规则之外，它还具有传递性，即A happen-before B、B happen-before C。。。</p>
<p>比如在同一个线程中两个方法且有一个公共变量a初始值是0,set方法把值设置为了5，set方法在get方法之前执行，调用get就获取到的值就是5，就算公共变量没有用volitile修饰，因为set方法和get方法是遵循了happen-before的传递性的。</p>
<h3 id="Volatile关键字"><a href="#Volatile关键字" class="headerlink" title="Volatile关键字"></a>Volatile关键字</h3><p>三个作用：64位写入的原子性、内存可见性、禁止指令重排序</p>
<p>基于上面那个例子，如果是多线程情况并发执行下，不加volitile关键字，那么get方法得到的值就不一定是5了。</p>
<p>重排序：DCL问题即双重校验锁</p>
<p><img src="https://pic2.zhimg.com/80/v2-5fb7ddf608badef988b9a63a8ca2d02d_720w.webp" alt="img"></p>
<p>如果不加volatile关键字，这个单例就会存在问题，他的执行顺序如下:</p>
<ol>
<li><p>分配一块内存</p>
</li>
<li><p>在内存上初始化成员变量</p>
</li>
<li><p>把instance引用指向内存</p>
</li>
</ol>
<p>犹豫2和3没有依赖关系，所以他们就可能发生指令重排序，即先把instance引用指向内存再初始化成员变量就会造成构造方法溢出的问题。</p>
<p><strong>Volatile的实现原理</strong></p>
<p>1） 在volatile写操作前插入一个storestore(禁止写和写)内存屏障保证volatile写操作和之前写操作不会重排序</p>
<p>2） 在volatile写操作后插入一个storeload(禁止写和读)内存屏障保证volatile写操作和之后读操作不会重排序</p>
<p>3） 在volatile读操作后插入一个loadloadl(禁止写和写)屏障和loadstore(禁止写和读)屏障，保证volatile读操作不会和之后的读操作、写操作重排序。</p>
<p><strong>JSR-133对volatile的增强</strong></p>
<p>JDK5开始，只允许把一个64位的long&#x2F;double类型变量写操作拆分成两个32位写操作来执行，而读不允许了，任意读操作都必须具有原子性，不可拆分。</p>
<h3 id="Final关键字"><a href="#Final关键字" class="headerlink" title="Final关键字"></a>Final关键字</h3><p>Final关键字也可以解决构造方法溢出问题，因为他有遵循happen-before原则，通过final关键字修饰，可以保证值在构造方法之前完成，不会出现另一个线程取值的时候还未完成对象变量初始化。</p>
<p>Happen-before规则总结，也就是JMM的规范承诺：</p>
<p>1） 单线程的每个操作,happen-before在该线程中任意后续操作。</p>
<p>2） 对volatile变量的写，happen-before在后续进行这个变量的读。</p>
<p>3） 对synchronized的解锁，happen-before在后续对这个锁加锁。</p>
<p>4） 对final变量的写，happen-before在后续对finale变量的读。</p>
<p><img src="/posts/35288/asset/v2-0cc21197aaf0462aa5f7cbdb7bf4808d_720w.webp" alt="img"></p>
<h3 id="二、JUC之并发容器"><a href="#二、JUC之并发容器" class="headerlink" title="二、JUC之并发容器"></a>二、JUC之并发容器</h3><h3 id="BlockingQueue"><a href="#BlockingQueue" class="headerlink" title="BlockingQueue"></a>BlockingQueue</h3><p>在所有并发容器中最常用的一种，他是一个阻塞队列，当入队列时，如果队列已满，则阻塞调用者，当出队列时，如果队列为空，则阻塞调用者。</p>
<p>他定义的是一个接口，有多个不同的实现类以不同方式来实现这个阻塞队列。</p>
<p><img src="https://pic2.zhimg.com/80/v2-ff3ff41f2dad86b67795e1674ed9d6bd_720w.webp" alt="img"></p>
<p><img src="https://pic3.zhimg.com/80/v2-7575818801437856d51a9e3f43faef3e_720w.webp" alt="img"></p>
<p>只需要关注里面重要的方法，如add、offer、put方法都是添加值，只是返回类型不同且put会阻塞并抛出异常，而add和offer是非阻塞的，remove移除、take获取、poll获取。不过remove是非阻塞式的，而take和poll是阻塞式的。</p>
<h3 id="ArrayBlockingQueue"><a href="#ArrayBlockingQueue" class="headerlink" title="ArrayBlockingQueue"></a>ArrayBlockingQueue</h3><p>数组实现的环形队列，在自己的构造函数中传入数组的容量。</p>
<p>他的核心结构就是两个队头队尾指针以及核心的一个锁加上对应的两个condition条件，这里就用到了前面说的wait、notify以及synchronized所作用的对象都是同一个，没办法判断队列是空还是满的情况，增加condition来解决此问题。</p>
<p><img src="https://pic3.zhimg.com/80/v2-cac66f64ea6f5258383d0a39241723f6_720w.webp" alt="img"></p>
<p>各种阻塞队列的实现方式都大同小异，以ArrayBlockingQueue源码解读实现原理来讲：</p>
<p>Put方法：先获取锁然后锁上，接着判断当前队列的元素个数是否已经等于数组长度相等，说明队列已满，就await阻塞等待，否则进入放数据的处理方法，获取数据并放入，并且判断队列长度是否已经达到了数组长度，达到了就把队列长度值初始化为0，进行重新下一轮塞值循环，接着把数据放入队列之后就可以通知非空条件。通过他来告知消费者里面已经有数据了，可以来获取。</p>
<p><img src="/posts/35288/asset/v2-82a658ed85b8c6cf1907a67549be23d4_720w.webp" alt="img"></p>
<p><img src="https://pic3.zhimg.com/80/v2-88fc2ff62a957da2dc35d1407e9dadea_720w.webp" alt="img"></p>
<p>Take方法：跟get方法一样，也是先获取锁，然后加锁，判断队列是否是空，如果为空获取不到数据，进入阻塞状态，如果count不等于0了证明有值就进入获取值方法，在里面直接拿到数组对象，通过下标拿到对应的值，拿到值之后这个值就设置为null,代表值已经获取了，同时判断队列获取数据的下标长度是否已经达到了数组的长度，即已经拿到了最后一个值，那么就初始化下标长度变量，进入下一轮取值循环，等拿到值之后就可以通过非满条件，也就是队列里面的值不是满的来通知生产者生产数据放入队列中，最后返回拿到的值并释放锁。</p>
<p><img src="https://pic4.zhimg.com/80/v2-c4690999c2063afb5502f7c26dae49fb_720w.webp" alt="img"></p>
<p><img src="/posts/35288/asset/v2-b84b6f5ddf74553dac6cd99c0bfdf34c_720w.webp" alt="img"></p>
<h3 id="LinkedBlockingQueue"><a href="#LinkedBlockingQueue" class="headerlink" title="LinkedBlockingQueue"></a>LinkedBlockingQueue</h3><p>基于单向链表的阻塞队列，因为他的队头和队尾是两个指针双向操作，因此用了两把锁（分别是写入锁和读取锁）和两个条件（非空条件对应写入锁，非满条件对应读取锁）及一个原子变量记录count数量，可以进行一边追加一边消费，先入后出原则，效率更高。</p>
<p><img src="https://pic2.zhimg.com/80/v2-1585e43a6687a89c82c481817224a5e1_720w.webp" alt="img"></p>
<p>LinkedBlockingQueue和ArrayBlockingQueue的差异</p>
<p>1）LinkedBlockingQueue为了提高并发读，用了两把锁分别控制队头队尾，代表put和put、take和take之间是互斥的，但是put和take之间不互斥，而ArrayBlockingQueue只有一把锁，put和take之间是互斥的，不能同时又读又写。但是他们也有相同点，对于count变量，都需要操作，必须是原子类型。</p>
<p>2）LinkedBlockingQueue因为各自拿了一把锁，所以当需要调用对方的condition和signal,还必须的加上对方的锁，不然就会成我们前面说到的活锁情况发生。</p>
<h3 id="PriorityBlockingQueue"><a href="#PriorityBlockingQueue" class="headerlink" title="PriorityBlockingQueue"></a>PriorityBlockingQueue</h3><p>队列通常是先进先出，而priorityBlockingQueue按照元素优先级从小到大出队列，也称为优先级队列，通过compareto比较大小，元素自己有带有比较功能，他与前面的队列最大差异就是内部有一个数组实现的二叉堆，以及一个锁和一个非空条件构成，没有非满条件，因为他这个堆是可扩容的，默认值是11，超出11之后就会自动扩容,所以永远没有阻塞。因为是二叉堆，所以出的第一个元素永远是堆顶那个，取出堆顶元素之后又重新构建，和ArrayBlockingQueue相似，但是没有非满条件。</p>
<p><img src="https://pic2.zhimg.com/80/v2-efeec6fa0ac8460ca4f09437fac87d41_720w.webp" alt="img"></p>
<h3 id="DelayQueue"><a href="#DelayQueue" class="headerlink" title="DelayQueue"></a>DelayQueue</h3><p>DelayQueue延迟队列，按延迟时间从小到大出队的PriorityQueue，所谓延迟时间，就是未来将要执行的时间减去当前时间，他是一个接口，继承comparable，重写getDelay方法，如果getDelay返回值小于等于0，说明该元素到期，需要从队列中拿出来执行，他通过getDelay返回值来比较大小。他由一把锁一个非空条件以及优先级队列构成，优先级队列是由二叉堆构成。</p>
<p><img src="https://pic3.zhimg.com/80/v2-b702302621f78b37d796d54437446316_720w.webp" alt="img"></p>
<p>注意：</p>
<p>关于取元素：他不同于一般的阻塞队列，只有队列为空时才阻塞，如果堆顶元素延迟时间没到也会阻塞，无法从堆顶取出。通过Thread leader变量可以记录等待堆顶元素的第一个线程，因为这样可以通过getDelay方法获取到期时间，不用无限期等待，通过condition条件设定到期时间，时间到了就获取出来了。</p>
<p>关于放元素：不是每一个元素进入都需要通知等待的线程，因为线程取的是堆顶元素，除非堆顶元素的等待时间大于当前放入元素的等待时间，即当前放入的元素需要更先被取出来，才需要通知等待的线程。</p>
<h3 id="SynchronousQueue"><a href="#SynchronousQueue" class="headerlink" title="SynchronousQueue"></a>SynchronousQueue</h3><p>他是一种特殊的阻塞队列，本身是没有容量的，他是一个链表，可以挂多个元素，但是不存储，调用put挂值就会阻塞，等另一个线程调用了take获取，两个线程同时解锁，他就相当于中介，处理一手交钱一手交货的那个中间人。而且他支持多线程同时放取操作。他也有公平和非公平模式，公平是先进先出，不公平就是先进后出，即后到线程先配对。通过栈来实现，下图中的三目表达式就根据是否公平来决定是队列结构还是栈结构。这两种结构内部其实还是一个单向的链表，只是执行顺序不一样而已。</p>
<p><img src="https://pic4.zhimg.com/80/v2-db0a271b519fa6fe976a2ecd310fbb67_720w.webp" alt="img"></p>
<h3 id="BlockingDeque"><a href="#BlockingDeque" class="headerlink" title="BlockingDeque"></a>BlockingDeque</h3><p>可以理解为double and queue，阻塞的双端队列接口，他的有一个且只有一个实现类LinkedBlockingDeque,是一个双向链表。他只有一把锁，所以只能干一件事，要么生产要么消费。其优点是查找定位速度快，可以从两边开始。</p>
<p><img src="/posts/35288/asset/v2-d114ccfc145084c42f5af56e18ac6a5c_720w.webp" alt="img"></p>
<h3 id="CopyOnWrite"><a href="#CopyOnWrite" class="headerlink" title="CopyOnWrite"></a>CopyOnWrite</h3><p>从名字就可以得到结果了，复制写，就是写的时候不操作源数据，而且拷贝一份来修改，在通过悲观锁或者乐观锁进行回写，这样操作的目的就是在读的时候就不用加锁了，不加锁就可以提高读取效率，而且我根本就没有操作源数据，加锁无意义。他是以空间换时间的典型策略。</p>
<p>重要的集合：CopyOnWriteArrayList集合、CopyOnWriteArraySet集合</p>
<h3 id="ConcurrentLinkedQueue-x2F-Deque"><a href="#ConcurrentLinkedQueue-x2F-Deque" class="headerlink" title="ConcurrentLinkedQueue&#x2F;Deque"></a>ConcurrentLinkedQueue&#x2F;Deque</h3><p>他们的原理是相同的，AQS阻塞队列基于双向链表，通过对head&#x2F;tail进行CAS操作，实现入队和出队。ConcurrentLinkedQueue是一个单向链表，与AQS类似，同样基于CAS，同样通过head&#x2F;tail指针记录队列头部和尾部，他通过CAS来实现阻塞，而不是wait直接阻塞。Head、tail在初始的时候都是指向null，在AQS阻塞队列中，每次入队，tail一定后移一个位置，每次出队，head一定后移一个位置，保证head指向队列头部，tail指向队列尾部。但是在ConcurrentLinkedQueue中head&#x2F;tail的更新可能就落后节点的入队、出队，因为他不是直接对head&#x2F;tail指针进行的CAS操作，而是对节点node的数组item操作的。</p>
<p>入队列的时候P的next指针只要进行了CAS操作就算入队成功，因为next已经把关系建立，不需要同步移动tail指针，所以他追加两次才移动一次指针，一次移动两个位置，和AQS同步移动完全不同。</p>
<p>出队列的时候并非根据tail指针进行判断，而是依赖于head指针后续节点是否为空，只要对节点的数据执行CAS成功，置为NULL，则出队成功，head指针没有移动可以由下一个线程来操作。</p>
<p><img src="https://pic4.zhimg.com/80/v2-632da8229d3c26ef823157609569600f_720w.webp" alt="img"></p>
<h3 id="ConcurrentHashMap"><a href="#ConcurrentHashMap" class="headerlink" title="ConcurrentHashMap"></a>ConcurrentHashMap</h3><p>HashMap的实现方式是数组加链表，被称为拉链法，而ConcurrentHashMap是在hashMap的基础上应对多线程的各种优化，首先所有数据都放在一个大hashmap中，其次引入了红黑树，注意JDK8之后hashMap也引入了红黑树进行优化。</p>
<p><img src="https://pic2.zhimg.com/80/v2-6142479d7c312ed5a8bf6ae88c44a879_720w.webp" alt="img"></p>
<p>由原理图可分析得到，他是竖向数组加横向链表或者树构成，如果他是一个普通的节点，那么就是一个链表结构，如果是一个树结构节点，那么他就是一个红黑树结构，链表和红黑树之间是可以转换的，初始都是链表，当链表数据元素达到某个阀值时，就会转化成红黑树，优化数据结构。如果小于这个阀值，就会转化成链表。</p>
<p>设计的目的：</p>
<p>1） 元素越多，使用红黑树查询更新效率更高，链表结构元素越多越容易产生hash冲突，而红黑树能够解决冲突问题。</p>
<p>2） 加锁不是对整个concurrentHashMap加锁，而是对数组每个头节点加锁，随着数组的长度的增加，并发度就会越来越高，初始长度是16。</p>
<p>3） 支持并发扩容，也就是超过了初始长度16了。</p>
<p><img src="/posts/35288/asset/v2-564a53cc336649513078226c9831df3c_720w.webp" alt="img"></p>
<p>整个结构里面最重要的数据就是cap,他就是node数组的长度，为2的整数次方，通过传入初始容量计算得到，并且控制sizeCtl在初始化或并发扩容时候的线程数初始值也是他，。</p>
<p><strong>初始化</strong></p>
<p>多线程的竞争是通过对sizeCtl进行CAS操作实现的，如果某个线程成功把sizeCtl设置为-1，他就拥有了初始化的权利，等到初始化完成，再把sizeCtl设置回去，而且由于初始化工作量小，其他线程在没有争抢到初始化资格的时候并不是放弃了CPU，而是自旋等待。</p>
<p><strong>Put方法</strong></p>
<p>可分为四个分支，也可以称为四步，因为他是一个循环的过程，整个循环结束，也就是完成四个分支总元素加1：</p>
<p>1） 整个数组初始化</p>
<p>2） 每个元素的初始化，也就是所在槽为空，得到该元素为该槽第一个元素，新建一个头结点并返回</p>
<p>3） 扩容，链表转红黑树的规则：链表元素阀值为8，并且整个数组的长度超过64。当数组长度没有达到64，那么链表只会进行普通扩容，并不会转化成红黑树。</p>
<p>4） 放入元素，在加锁后往链表或者红黑树添加元素，通过头节点类型判断是node还是treenode</p>
<p><strong>扩容原理</strong></p>
<p>新建一个hashMap，其数组长度是旧数组长度两倍，然后把旧数组元素逐个迁移，多线程情况下为了避免产生条件竞争，ConcurrentHashMap把整个数组扩容进度分片，也就是根据有多少个CPU核心得到最大并发处理的线程数，然后分工，每个线程干一点，最后完成整个数组扩容，他的内部有一个变量记录扩容进度，通过CAS进行操作，所以不仅提高扩容效率，还能保证并发下线程安全。</p>
<p>1）扩容过程中的数据访问处理？</p>
<p>如果在扩容中有线程访问node1节点数据，但是node1节点已经到新ConcurrentHashMap中了，就数组node1已经没有值，这个时候会有一个转发节点，记录新ConcurrentHashMap的引用，通过转发节点获取迁移的数据并返回</p>
<p>2）初始值为16，扩容设计成2倍，扩容阀值0.75的原则？</p>
<p><img src="https://pic4.zhimg.com/80/v2-d7326eef821646f94ef557c7e02972bb_720w.webp" alt="img"></p>
<p><strong>sizeCtl不同值的含义</strong></p>
<p>-1：正在初始化</p>
<p>其他负数：多线程正在做并发扩容</p>
<p>Cap:未初始化之前的初始容量</p>
<p>扩容成功之后sizeCtl存储的是下一次扩容的阀值，也就是0.75</p>
<h3 id="ConcurrentSkipListMap-x2F-Set"><a href="#ConcurrentSkipListMap-x2F-Set" class="headerlink" title="ConcurrentSkipListMap&#x2F;Set"></a>ConcurrentSkipListMap&#x2F;Set</h3><p>ConcurrentHashMap是一种key无序的hashmap，ConcurrentSkipListMap则是有序的。</p>
<p><strong>使用场景</strong></p>
<p>在util包中，非线程安全的Treemap也是key有序的，基于红黑树实现。</p>
<p>在concurrent包中，key有序的hashmap就是ConcurrentSkipListMap，不过他不是基于红黑树，他是基于SkipList跳表实现的。因为目前还没有能够高效对树结构实现无锁，删除添加节点的办法，因此跳表就出来了，他可以满足无锁的进行高效删除、添加节点。</p>
<p><strong>无锁链表的问题</strong></p>
<p>前面blockqueue讲了很多无锁队列，其实现也是链表，但是在队头队尾通过CAS实现操作，如果在中间插入就会出现问题。因为多线程情况下中间操作数据，删除和插入，即使通过CAS操作，你不能确定当前拿到的元素是否还是有效元素，比如有1、10、30三个节点，现在两个线程同时操作，A线程要在增加20节点，B线程要删除10节点，A线程执行的时候，通过CAS先把20节点指向30，然后把10节点指向当前20，这是原子性的，接着呢B线程要删除10节点，于是他就拿到了1节点，并指向30，两个CAS操作分开来看是没问题的，但是合并在一起就出问题了，因为实际操作的时候，都是拿的前驱节点，即1节点，而A线程操作的时候并不知道10节点已经被删除了，最后遍历重组的时候就会出现1节点指向了30，而20就被忽略了，连同10节点一并被干掉了。</p>
<p>解决办法：</p>
<p>通过新增一个marker节点，让当前被操作元素next指向他，这样在当前操作元素后面添加元素就可以判断当前操作元素的next节点是否指向了marker节点，以上面例子，A线程插入20节点，10节点指向marker，B线程如果删除了10节点，那么10节点的marker指向就被破坏了，而A线程在插入的时候就会发现问题，因为他拿到不是10这个节点了，就算10在哪里也和他没有关系，他CAS的是10节点指向的marker。</p>
<p><strong>跳表</strong></p>
<p>上面无锁链表的问题被解决了，对于跳表而言，就可以进行高效的删除、添加操作了，因为跳表是多层链表叠加起来的，也就可以通过指定下一个marker节点来实现CAS操作。</p>
<p><img src="https://pic3.zhimg.com/80/v2-4d2d75562af5c07be17ff5b0d06ede52_720w.webp" alt="img"></p>
<p>比如上面的跳表，我要查找元素19，或者是要在19节点后面插入一个20节点，通过头元素跳跃比较，将会直接过滤掉很多不需要查询的节点，找到所在位置，性能提升非常高，跳表的增删查效率和红黑树不相上下，他是以空间换取时间的一种设计，应用非常广泛，比如Redis。</p>
<p><img src="/posts/35288/asset/v2-a4930525a113b4591d559876e4321a32_720w.webp" alt="img"></p>
<p>ConcurrentSkipListMap底层通过跳表来实现，因此他就只需要记录头部元素head节点即可。查找、删除、添加就先从头部节点开始找，因为他最底层下面肯定是有序排列的，只需要通过头部节点一层层往下找，快速定位到所在节点位置。</p>
<h3 id="三、JUC之同步工具类"><a href="#三、JUC之同步工具类" class="headerlink" title="三、JUC之同步工具类"></a>三、JUC之同步工具类</h3><h3 id="Semaphore"><a href="#Semaphore" class="headerlink" title="Semaphore"></a>Semaphore</h3><p>Semaphore也就是信号量，提供了资源数量的并发访问控制。其实就是对共享资源争抢方式的控制，N个线程来竞争限制多少线程可以拿到，是否公平竞争。当初始的资源个数为1的时候，Semaphore退化为排他锁。正因为如此，Semaphone的实现原理和锁十分类似，是基于AQS，有公平和非公平之分。</p>
<p>举个例子，一个只有两个2座位，然后有5个同学要写作业，怎么办呢，抢座位啊，通过代码如下：</p>
<p><img src="https://pic3.zhimg.com/80/v2-3c40a8f78860c94f4a004da6c005e7de_720w.webp" alt="img"></p>
<p><img src="https://pic4.zhimg.com/80/v2-6237d72e1386cdf7af5a8a35abf7bbbb_720w.webp" alt="img"></p>
<h3 id="CountDownLatch"><a href="#CountDownLatch" class="headerlink" title="CountDownLatch"></a>CountDownLatch</h3><p>使用频率较高，主要作用是通过CountDownLatch来实现让主线程来等待其他worker线程，也就是子线程执行完才能退出。</p>
<p><img src="/posts/35288/asset/v2-ec5e82cdcbd2f48866d4a17d0bd3d3d8_720w.webp" alt="img"></p>
<p><img src="https://pic4.zhimg.com/80/v2-f208450cea241ae1051b3f6f08cd2da7_720w.webp" alt="img"></p>
<p>CountDownLatch原理和Semaphore原理类似，同样是基于AQS，不过没有公平和非公平之分。</p>
<p>阻塞实现：通过state状态来判断，只要不为0调用await()方法的线程就会被放入阻塞队列。</p>
<p>唤醒实现：基于AQS阻塞队列来实现的，所以可以让多个线程都阻塞在state&#x3D;0条件上，通过countDown()一直减state，减到0后一次性唤醒所有线程。</p>
<p><img src="https://pic4.zhimg.com/80/v2-a1d30bb3651ef1b82d7bfe43a61933c7_720w.webp" alt="img"></p>
<h3 id="CyclicBarrier"><a href="#CyclicBarrier" class="headerlink" title="CyclicBarrier"></a>CyclicBarrier</h3><p>应用场景：用于协调多个线程同步执行操作的场合。比如面试分笔试和面试，笔试需要等人齐了一起开始，而面试就单独进行，而来面试的人就可以看做一个个单独的线程，需要协调一起做笔试题。</p>
<p><img src="https://pic4.zhimg.com/80/v2-9f2bd69bc25aebed5bd80ecacf8ff167_720w.webp" alt="img"></p>
<p><img src="https://pic3.zhimg.com/80/v2-21ff9f4013dc359a46c276ffa4241142_720w.webp" alt="img"></p>
<p>实现原理：CyclicBarrier基于ReentrantLock(重入锁)+Condition(条件)实现。</p>
<p>注意：</p>
<p>1） CyclicBarrier是可以被重用的</p>
<p>2） CyclicBarrier 会响应中断。再等待过程中收到中断信号，所有阻塞线程都会被唤醒，然后重新开始。</p>
<p>3） 回调方法只会被执行一次，而不是每个线程都执行一次。</p>
<h3 id="Exchanger"><a href="#Exchanger" class="headerlink" title="Exchanger"></a>Exchanger</h3><p>Exchanger用于线程之间交换数据。多线程之间并发调用exchange方法，会两两互相交换数据，如果是单线程的话就会进入阻塞状态，分即时等待和永久等待。</p>
<p><img src="https://pic2.zhimg.com/80/v2-dd636d3f68dafe3ec1aaad599bf6bd61_720w.webp" alt="img"></p>
<p>实现原理：Exchanger的核心机制和Lock一样，也是CAS+park&#x2F;unpark。每个线程在调用exchange(…)方法交换数据的时候，会先创建一个Node对象。这个Node对象就是对该线程的包装，里面包含了3个重要字段：第一个是该线程要交互的数据，第二个是对方线程交换来的数据，最后一个是该线程自身。如果多个线程就通过内部的多个node节点。</p>
<h3 id="Phaser"><a href="#Phaser" class="headerlink" title="Phaser"></a>Phaser</h3><p>JDK7开始，新增了一个同步工具类Phaser，他可以替代CyclicBarrier和CountDownLatch，并且功能更丰富。</p>
<p><strong>Phaser替代CountDownLatch</strong></p>
<p>CountDownLatch时讲到它可以实现让主线程等待所有子线程执行完毕再执行，涉及到两个方法await和countDown，在Phaser中相对应的方法是awaitAdance和arrive。</p>
<p><img src="https://pic4.zhimg.com/80/v2-cd649477aabe631e81cca3910d064d9f_720w.webp" alt="img"></p>
<p><strong>Phaser替代CyclicBarrier</strong></p>
<p>CyclicBarrier时讲到它可以协调多个线程一起开始干同一件事，涉及到一个方法await，在Phaser中向对应的方法是arriveAndAwaitAdvance)，他就是 arrive()与 awaitAdvance()的组合。表示我已经到达同步点，等待所有人到达再继续执行。</p>
<p><img src="/posts/35288/asset/v2-042674ed87fc81fa1d1252922d0ad414_720w.webp" alt="img"></p>
<p><strong>Phaser新特性</strong></p>
<p>1）动态调整线程个数：CyclicBarrier 所要同步的线程个数是在构造方法中指定的，之后不能更改，而 Phaser 可以在运行 期间动态地调整要同步的线程个数，比如笔记过程中插入了一个新面试者进来和大家一起笔试。</p>
<p>2）层次Phaser：多个Phaser可以组成一个树状结构，可以通过在构造方法中传入父Phaser来实现。</p>
<p>Phaser没有基于AQS来实现，但是具备AQS的核心特性：state变量、CAS操作、阻塞队列。</p>
<p>arrive()方法：根据设置的总数，与到达的线程数相减，到0之后唤醒队列线程并重置state,同时phase累加与线程总数一致。</p>
<p>awaitAdvance()方法：通过while循环的4个分支进行阻塞判断，当4个分支都走完进行唤醒，主线程执行。</p>
<h3 id="四、JUC之Atomic类-原子变量类"><a href="#四、JUC之Atomic类-原子变量类" class="headerlink" title="四、JUC之Atomic类(原子变量类)"></a>四、JUC之Atomic类(原子变量类)</h3><h3 id="AtomicInteger和AtomicLong"><a href="#AtomicInteger和AtomicLong" class="headerlink" title="AtomicInteger和AtomicLong"></a>AtomicInteger和AtomicLong</h3><p>两者原理相同，假设一个类中有个int类型变量count，类里面有两个方法，A方法++；B方法–;多线程情况下为了保证数据安全有效，我们的常规办法就是在A、B方法上加synchronized关键字进行加锁，其实还可以通过把这个count变量声明成AtomicInteger类，这样不需要加锁在并发情况下也是原子性操作，线程安全的。他的内部是通过自旋进行CAS操作实现。</p>
<p><strong>悲观锁和乐观锁</strong></p>
<p>悲观锁：认为数据发生并发冲突的概率很大，读操作之前就上锁。synchronized关键字， ReentrantLock都是悲观锁的典型。</p>
<p>乐观锁（CAS）：认为数据发生并发冲突的概率比较小，读操作之前不上锁。等到写操作的时候，再判断数据在此期间是否被其他线程修改了。如果被其他线程修改了，就把数据重新读出来，重复该过程；如果没有被修改，就写回去。判断数据是否被修改，同时写回新值，这两个操作要合成一个原子操作，也就是CAS。</p>
<p><strong>CAS的实现</strong></p>
<p>所有调用CAS的地方，比如前面Unsafe类以及现在的AtomicInteger类，都会先通过这个方法把成员变量转换成一个Offset。而这个Offset不是原本value了，而是他的偏移量，所以CAS操作的是偏移量。</p>
<p><strong>自旋和阻塞</strong></p>
<p>阻塞：当一个线程拿不到锁放弃CPU，进入阻塞状态，等待后续被唤醒，再重新被操作系统调度。</p>
<p>自旋：当一个线程拿不到锁不放弃CPU，空转，不断重试，也就是所谓的自旋。</p>
<p>注意：单核CPU只能阻塞，多核CPU才能自旋，因为单核CPU自旋，其他线程就卡死没办法运行了。两种可以结合使用，比如设定一定自旋时间等待，时间到了还没获取锁就切换成阻塞，放弃CPU。Synchronized关键字就是这种实现策略。</p>
<h3 id="AtomicBoolean和AtomicReference"><a href="#AtomicBoolean和AtomicReference" class="headerlink" title="AtomicBoolean和AtomicReference"></a>AtomicBoolean和AtomicReference</h3><p><strong>AtomicBoolean</strong></p>
<p>比如一个布尔变量，在逻辑代码中，如果为false就取反，设置为true，但是只限于单线程，并发情况下就要用AtomicBoolean，结合他的乐观锁机制，在多线程并发情况下保证线程安全。</p>
<p><strong>AtomicReference</strong></p>
<p>原子引用类，其实就是一个对象两个线程共用，比如一个线程负责读另一个线程负责更新，如果不保证线程安全的情况下，那数据将会出现问题，如读到过期数据，类似于Mysql中的脏读，使用AtomicReference类就可以避免这个问题。</p>
<p><strong>如何支持boolean和double类型</strong></p>
<p>在Unsafe类中，只提供了三种类型的CAS操作：int、long、Object（也就是引用类型）即compareAndSetInt、compareAndSetLong、compareAndSetObject，在jdk的实现中，这三种CAS操作都是由底层实现的，其他类型的CAS操作都要转换为这三种之一进行操作。Int类型根据0和1就可以转化成boolean类型，double的话则是依赖于和Long类型互转。</p>
<h3 id="AtomicStampedReference和AtomicMarkableReference"><a href="#AtomicStampedReference和AtomicMarkableReference" class="headerlink" title="AtomicStampedReference和AtomicMarkableReference"></a>AtomicStampedReference和AtomicMarkableReference</h3><p><strong>ABA问题与解决办法</strong></p>
<p>ABA问题：比如A、B、C三个线程，A线程根据约定在等待B线程释放共享资源给他然后继续运行，但是B线程释放共享资源这个事C线程也知道，并且也在约定的多线程之内，当B线程释放的资源了，放入了对象中，C线程跑去拿走并消耗了,A线程回来发现对象中还是没有这个资源，又跑去找B线程要。</p>
<p>解决办法：CAS增强，对这个对象增加版本号，不仅比较值，还比较版本号，虽然前后都是为空，但是他中间有段时间是有值的，可以证明B线程确实释放了资源给他。</p>
<p>因此在AtomicStampedReference中，他的compareAndSet方法，即CAS操作就不是只有新值，旧值两个参数，还有版本号的新值和旧值，这四个对象都是装在一个叫Pair的内部类里面。Integer型或者Long型的CAS没有办法同时比较两个变量，他就是一个值，没有引用。</p>
<p>AtomicMarkableReference与AtomicStampedReference原理相似，不过他的Pair内部类版本号是一个布尔变量，没办法完全避免ABA问题，只能降低发生概率。</p>
<h3 id="AtomicIntegerFieldUpdater、AtomicLongFieldUpdater和AtomicReferenceFieldUpdater"><a href="#AtomicIntegerFieldUpdater、AtomicLongFieldUpdater和AtomicReferenceFieldUpdater" class="headerlink" title="AtomicIntegerFieldUpdater、AtomicLongFieldUpdater和AtomicReferenceFieldUpdater"></a>AtomicIntegerFieldUpdater、AtomicLongFieldUpdater和AtomicReferenceFieldUpdater</h3><p>AtomicIntegerFieldUpdater：原子integer类型属性更新类</p>
<p>AtomicLongFieldUpdater：原子Long类型属性更新类</p>
<p>AtomicReferenceFieldUpdater：原子引用类型属性更新类</p>
<p>他们都是一个基于反射的工具类，能对指定类的指定的volatile字段进行原子更新。</p>
<p>但是使用具有一定约束条件：</p>
<p>1） 对于AtomicIntegerFieldUpdater和AtomicLongFieldUpdater只能修改int&#x2F;long类型的字段，不能修改其包装类型（Integer&#x2F;Long）。如果要修改包装类型就需要使用AtomicReferenceFieldUpdater。</p>
<p>2） 字段必须是volatile类型的，在线程之间共享变量时保证立即可见。</p>
<p>3） 只能是可修改变量，不能使final变量，因为final的语义就是不可修改。实际上final的语义和volatile是有冲突的，这两个关键字不能同时存在。</p>
<h3 id="AtomicIntergerArray、AtomicInLongArray和AtomicReferenceArray"><a href="#AtomicIntergerArray、AtomicInLongArray和AtomicReferenceArray" class="headerlink" title="AtomicIntergerArray、AtomicInLongArray和AtomicReferenceArray"></a>AtomicIntergerArray、AtomicInLongArray和AtomicReferenceArray</h3><p>三个数组元素的原子操作。这里并不是说对整个数组的操作是原子的，而是针对数组中一个元素的原子操作。</p>
<p>其实他向比较与第一个AtomicInterger类，就多了一个下标而已，因为他是数组类型的，底层也是CAS操作实现，通过下标结合操作元素。</p>
<h3 id="Striped64和LongAdder"><a href="#Striped64和LongAdder" class="headerlink" title="Striped64和LongAdder"></a>Striped64和LongAdder</h3><p>JDK 8，针对Long型的原子操作，java新增了LongAdder、LongAccumulator类；针对Double型的原子操作，新增了DoubleAdder、DoubleAccumulator类，他们都是属于Striped64的继承类。</p>
<p><img src="https://pic1.zhimg.com/80/v2-ef84fb1b7dd90bca4e85643fcd080c2c_720w.webp" alt="img"></p>
<p><strong>LongAdder原理</strong></p>
<p>AtomicLong内部是一个volatile long型变量，由多个线程对这个变量进行CAS操作，在高并发情况下就不够高效了，因此LongAdder创造了另外一种设计，把一个Long变量拆分成一个base和多个cell，都是对Long型变量做的包装，类似于ConcurrentHashMap的分段锁，在多线程并发下，如果并发低，就使用主base，如果并发高，就分摊到节点cell上，最后取值的时候累加，类似于负载均衡原理。</p>
<p><img src="/posts/35288/asset/v2-998d72d78234cf46745430fb755fdad4_720w.webp" alt="img"></p>
<p>基础类Striped64，也可以称为分片64位的类，无论是long，还是double，都是64位的。但因为没有double型的CAS操作，所以是通过把double型转化成long型来实现的。</p>
<p><strong>最终一致性</strong></p>
<p>在sum求和方法中，并没有对cells[]数组加锁。也就是说，一边有线程对其执行求和操作，一边还有线程修改数组里的值，也就是最终一致性，而不是强一致性。这也类似于ConcurrentHashMap 中的clear()方法，一边执行清空操作，一边还有线程放入数据，clear()方法调用完毕后再读取，hash map里面可能还有元素。因此，在LongAdder适合高并发的统计场景，而不适合要对某个 Long 型变量进行严格同步的场景。</p>
<p><strong>@jdk.internal.vm.annotation.Contended注解</strong></p>
<p>JDK8之后新增，他的作用是做优化，称之为伪共享与缓存行填充。</p>
<p>存在问题：如果在以前，主内存中有A\B\C三个Long型变量，他被CPU1和CPU2分别读入了自己的缓存中，放在了同一行cache中，这时候CPU1要修改A的值，那么他就要失效整行cache，并通知CPU2也要整行cache失效，这时候B\C就遭了无妄之灾，他们俩也被失效咯，本来B\C不应该被失效，应该是可以继续读取共享的，现在不行了，所以被称为伪共享问题。</p>
<p><img src="/posts/35288/asset/v2-f0d50e0d2bbed7c4c5719ca060841264_720w.webp" alt="img"></p>
<p>解决办法：声明一个@jdk.internal.vm.annotation.Contended即可实现缓存行的填充。之所以这个地方要用缓存行填充，是为了不让Cell[]数组中相邻的元素落到同一个缓存行里。</p>
<p><img src="/posts/35288/asset/v2-e2186741313b4e374f8b4b470580b590_720w.webp" alt="img"></p>
<p>LongAccumulator类是LongAdder类的增强，他们的原理是相同的，LongAdder只能进行累加操作，并且初始值默认为0；LongAccumulator可以自己定义一个二元操作符，并且可以传入一个初始值。而double的那两个类只不过是Long类的转换罢了。</p>
<h3 id="五、JUC之Lock与Condition"><a href="#五、JUC之Lock与Condition" class="headerlink" title="五、JUC之Lock与Condition"></a>五、JUC之Lock与Condition</h3><h3 id="互斥锁（ReentrantLock）"><a href="#互斥锁（ReentrantLock）" class="headerlink" title="互斥锁（ReentrantLock）"></a>互斥锁（ReentrantLock）</h3><p>可重入锁：指当一个线程调用 object.lock()获取到锁，进入临界区后，再次调用object.lock()，仍然可以获取到该锁。显然，通常的锁都要设计成可重入的，否则就会发生死锁，比如synchronized关键字。</p>
<p><img src="https://pic3.zhimg.com/80/v2-055e5f44966f2e68e4cda7d69881a3ba_720w.webp" alt="img"></p>
<p>他继承Lock接口，Lock中常用的方法就是lock()获取锁\unlock()释放锁，继承Lock的这两个方法但是本身没有逻辑，他的实现都在内部类sync中。</p>
<p><img src="https://pic2.zhimg.com/80/v2-364f3d99f90bb2d44177d5477a293795_720w.webp" alt="img"></p>
<p><strong>公平锁和非公平锁</strong></p>
<p>Sync是一个抽象类，它有两个子类FairSync与NonfairSync，分别对应公平锁和非公平锁，通过传入一个布尔变量来确定，公平锁按顺序排队，非公平锁无论先后都可以抢，为了提高效率，大部分锁类默认都是非公平锁。</p>
<p><strong>锁的基本实现原理</strong></p>
<p>锁必须具备的四个核心要素：</p>
<p>1）需要一个state变量，标记该锁的状态。state变量至少有两个值：0、1。对state变量的操作，使用CAS保证线程安全。</p>
<p>2）需要记录当前是哪个线程持有锁。</p>
<p>3）需要底层支持对一个线程进行阻塞或唤醒操作。</p>
<p>4.）需要有一个队列维护所有阻塞的线程。这个队列也必须是线程安全的无锁队列，也需要使用CAS。</p>
<p>Sync的父类AbstractQueuedSynchronizer经常被称作队列同步器（AQS），他就是锁功能实现的关键。他的父类AOS记录持有锁的线程，他自身具有state变量记录锁的状态，并且state是累加的，0无锁、1持有锁、&gt;1重入锁，满足1，2要素；接着通过LockSupport工具类对Unsafe类的park方法阻塞和unpark方法唤醒做了封装，引入到AQS类中，满足3要素。最后在AQS类里面基于双向链表和CAS实现了一个阻塞队列。head指向双向链表头部，tail指向双向链表尾部。入队就是把新的Node加到tail后面，然后对tail进行CAS操作；出队就是对head进行CAS操作，把head向后移一个位置，如果head和tail相等，也就是都为null说明队列为空，满足4要素，达到具备一个锁的功能。</p>
<p><strong>AQS阻塞队列与唤醒机制</strong></p>
<p>通过addWaiter(…)方法生成一个node节点把Thread对象加入阻塞队列，线程一旦进入acquireQueued(…)就会被无限期阻塞，即使有其他线程调用interrupt()方法也不能将其唤醒，除非有其他线程释放了锁，并且该线程拿到了锁，才会从accquireQueued(…)返回，返回值是一个布尔变量。在该方法返回的一刻，就是拿到锁的那一刻，进行唤醒，唤醒也分两种情况，是否是中断唤醒。如果是中断唤醒acquireQueued会死循环直到拿到锁为止。</p>
<p><strong>Lock类常用方法解析</strong></p>
<p>lock()：获取锁，阻塞。</p>
<p>unlock()：释放锁，唤醒。</p>
<p>lockInterruptibly()：Lock类中的lock方法调用后不能被中断，但是lockInterruptibly方法可以被中断，当有人给他发送中断信号它就抛出InterruptedException异常跳出循环，不再阻塞。</p>
<p>tryLock()：基于调用非公平锁的tryAcquire(…)，对state进行CAS操作，如果操作成功就拿到锁；如果操作不成功则直接返回false，不阻塞。</p>
<h3 id="读写锁（ReentrantReadWriteLock）"><a href="#读写锁（ReentrantReadWriteLock）" class="headerlink" title="读写锁（ReentrantReadWriteLock）"></a>读写锁（ReentrantReadWriteLock）</h3><p>读写锁就是读线程和读线程之间不互斥，它分为读锁和写锁，也称为共享锁和排它锁。</p>
<p>这个类实现了ReadWriteLock接口，顶级接口仍然还是Lock，ReentrantReadWriteLock通过实现ReadWriteLock的writeLock方法和readLock方法进行读写操作，也就是说，当使用 ReadWriteLock 的时候，并不是直接使用，而是获得其内部的读锁和写锁，然后分别调用lock&#x2F;unlock。</p>
<p><img src="/posts/35288/asset/v2-282cac9ada5d4113333ed521229f7b7b_720w.webp" alt="img"></p>
<p><strong>读写锁实现的基本原理</strong></p>
<p>ReadLock和WriteLock是两把锁，实际上它只是同一把锁的两个视图而已，线程分成两类：读线程和写线程。读线程和写线程之间不互斥（可以同时拿到这把锁），读线程之间不互斥，写线程之间互斥。同互斥锁一样，读写锁也是用state变量来表示锁状态的。只是state变量在这里的含义和互斥锁完全不同。在内部类Sync中，对state变量进行了重新定义，因为在读写锁里面，他有两种状态，读锁状态和写锁状态，而无法用一次CAS 同时操作两个int变量，因此这个state就被拆成了两半，用了一个int型的高16位和低16位分别表示读锁和写锁的状态。当state&#x3D;0时，说明没有线程持有读锁，也没有线程持有写锁；当state !&#x3D; 0时，要么有线程持有读锁，要么有线程持有写锁，两者不能同时成立，因为读和写互斥。这时再进一步通过sharedCount(state)和exclusiveCount(state)判断到底是读线程还是写线程持有了该锁，所以读写锁是读读不互斥，读写互斥，写写互斥。</p>
<p><strong>AQS的两对模板方法</strong></p>
<p>acquire&#x2F;release、acquireShared&#x2F;releaseShared 是AQS里面的两对模板方法。互斥锁和读写锁的写锁都是基于acquire&#x2F;release模板方法来实现的。读写锁的读锁是基于acquireShared&#x2F;releaseShared这对模板方法来实现的。</p>
<p>读写锁也有公平和分公平之分</p>
<p>公平，不论是读锁，还是写锁，只要队列中有其他线程在排队（排队等读锁，或者排队等写锁），就不能直接去抢锁，要排在队列尾部。</p>
<p>非公平(读锁)：读锁是共享锁，多个线程会同时持有读锁，所以读线程就不是直接抢了，有一个约束，如果队列的第1个元素是写线程的时候，读线程也要阻塞，不能直接去抢。即偏向写线程。因为如果当前读锁被一个读线程持有，其他读线程又在抢，那么可能写锁永远都没机会拿到锁了，无法写入。</p>
<p>非公平(写锁)：写锁是排他锁，写线程能抢锁，前提是state&#x3D;0，只有在没有其他线程持有读锁或写锁的情况下，它才有机会去抢锁。或者state !&#x3D; 0，但那个持有写锁的线程是它自己，再次重入。</p>
<h3 id="Condition"><a href="#Condition" class="headerlink" title="Condition"></a>Condition</h3><p>常用于同步锁，Condition本身是一个接口，其功能和wait&#x2F;notify类似。wait()&#x2F;notify()必须和synchronized一起使用，Condition也必须和Lock一起使用。</p>
<p><img src="/posts/35288/asset/v2-a559d81a5ac4caa9810dbb5447bc8e28_720w.webp" alt="img"></p>
<p><img src="https://pic2.zhimg.com/80/v2-88dd40428587b9586901bd0de19f48d9_720w.webp" alt="img"></p>
<p><strong>Condition应用场景及实现原理</strong></p>
<p>比如前面讲到了ArrayBlockingQueue阻塞队列，他有一把锁和两个condition条件，即非空条件和非满条件，而这个condition条件就是通过构造器先创建一把锁，再通过这个锁创造出来两个条件。</p>
<p><img src="/posts/35288/asset/v2-723fe463e4cb821dd8713bc6e2fdd38c_720w.webp" alt="img"></p>
<p>Condition避免了wait&#x2F;notify的生产者通知生产者、消费者通知消费者的问题。</p>
<p>读写锁中的 ReadLock 是不支持 Condition 的，读写锁的写锁和互斥锁都支持Condition。</p>
<p><strong>await()实现分析</strong></p>
<p>每一个Condition对象上面，都阻塞了多个线程。因此，在ConditionObject内部也有一个双向链表</p>
<p>组成的队列，通过这个Condition调用await方法先把线程加到Condition的等待队列中，在调用await方法时已经是拿到锁的线程，所以在把线程加到Condition等待队列时不需要CAS操作，接着释放掉锁，进入阻塞状态，如果不释放锁会造成死锁，并且他是可以响应中断的，响应中断抛出异常，中断阻塞，如果被中断唤醒就必须要重新拿锁。awaitUninterruptibly方法不会响应中断。</p>
<p><strong>notify()实现分析</strong></p>
<p>持有锁的线程调用signal方法才有资格进行唤醒，没有锁的线程直接抛异常，通过通知唤醒队列中第一个线程。</p>
<h3 id="读写锁（StampedLock）"><a href="#读写锁（StampedLock）" class="headerlink" title="读写锁（StampedLock）"></a>读写锁（StampedLock）</h3><p>JDK8中新增了StampedLock，他也是一个读写锁，只不过他的并发量更高，因为他在上一代的设计上做了改动，即读写不互斥。</p>
<p><img src="https://pic3.zhimg.com/80/v2-6bb6c6be6464400a10bdfe491938cebe_720w.webp" alt="img"></p>
<p>ReentrantReadWriteLock采用的是“悲观读”的策略，就算有非公平约束，也可能导致读线程一直持有锁，写线程拿不到锁无法写入的情况。而StampedLock引入了“乐观读”策略，读的时候不加读锁，读出来发现数据被修改了，再升级为“悲观读”，相当于降低了“读”的地位，把抢锁的天平往“写”的一方倾斜了一下，避免写线程被饿死。</p>
<p>官方使用实例剖析：</p>
<p>有一个Point类，多个线程调用move()方法，修改坐标；还有多个线程调用distanceFromOrigin()方法，求距离。首先，执行move操作的时候，要加写锁，因为写操作和写操作是互斥的，接着调用distenceFromOrigin方法，这个方法就是读的逻辑，他首先默认使用乐观读，不加锁，然后读之前对数据做了一个快照，拷贝存储内存中，读完之后会再比较一下版本号，发现如果有其他线程在读期间修改了数据，就把读的数据废弃，重新读，但是这次读就不是乐观读了，他升级成了悲观读，进行加锁，重新读取数据。</p>
<p><strong>乐观读实现原理</strong></p>
<p>StampedLock是一个读写锁，和前面的读写锁一样，需要一个state表示读锁和写锁，不仅这样，他还要有一个版本号需要记录，因此对于这个32位的int类型state划分又不一样了，第8位表示写锁，写锁只需要一位，因为写锁是不可重入锁，前7位表示读锁，然后里面还有一个初始值state,且不是为0的，通过state&amp;WBIT !&#x3D; 0来确定是否被修改过，一旦线程被写锁持有，或者释放了，state都不会是0了，也就是版本号的变动记录，因此只通过一个变量，既实现了读锁、写锁的状态记录，还实现了数据的版本号的记录。</p>
<p><strong>悲观读实现原理</strong></p>
<p>同ReadWriteLock一样，StampedLock也要进行悲观的读锁和写锁操作。不过，它不是基于AQS实现的，而是内部重新实现了一个阻塞队列。在AQS里面，当一个线程CAS state失败之后，会立即加入阻塞队列，并且进入阻塞状态。但在StampedLock中，CAS state失败之后，会不断自旋，自旋足够多的次数之后，如果还拿不到锁，才进入阻塞状态。根据CPU的核数，定义了自旋次数的常量值。如果是单核的CPU，肯定不能自旋，在多核情况下，才采用自旋策略。</p>
<h3 id="六、线程池"><a href="#六、线程池" class="headerlink" title="六、线程池"></a>六、线程池</h3><h3 id="线程池的实现原理及继承体系"><a href="#线程池的实现原理及继承体系" class="headerlink" title="线程池的实现原理及继承体系"></a>线程池的实现原理及继承体系</h3><p>线程池就是调用方不断地向线程池中提交任务；线程池中有一组线程，不断地从队列中取任务。</p>
<p>线程池实现的基本问题：</p>
<p>1） 队列长度，无限度导致内存耗尽，有限满了之后解决方案。</p>
<p>2） 线程池线程个数，固定还是动态。</p>
<p>3） 新提交任务如何处理，新开线程还是放入队列。</p>
<p>4） 没有任务休眠还是阻塞，阻塞就需要有唤醒机制。</p>
<p>如果是休眠一段时间，就需要通过轮询反复检查是否有新任务到来，而通过使用阻塞队列即可解决问题4也可以解决问题1，所以ThreadPoolExector&#x2F;ScheduledThreadPoolExecutor都是基于阻塞队列实现的。</p>
<p><img src="/posts/35288/asset/v2-0354e928693d5b9cdb1a7197e082be8c_720w.webp" alt="img"></p>
<p>Executer类是一个顶级接口，他有两个核心实现类： ThreadPoolExector 和 ScheduledThreadPoolExecutor，这两个类就是实现线程池的，他们都具有执行某个任务的功能，并且ScheduledThreadPoolExecutor还可以周期性执行。</p>
<p><img src="https://pic2.zhimg.com/80/v2-6869fd9b082f23cc70f20ca8757325ed_720w.webp" alt="img"></p>
<h3 id="ThreadPoolExector"><a href="#ThreadPoolExector" class="headerlink" title="ThreadPoolExector"></a>ThreadPoolExector</h3><p><strong>核心数据结构</strong></p>
<p>记录线程池的状态和线程池里线程的个数的原子变量类AtomicInteger</p>
<p>存放任务的阻塞队列BlockingQueue</p>
<p>线程池内部各种变量进行互斥访问控制的重入锁ReentrantLock</p>
<p>放worker(也就是封装线程的一个内部类,一个线程对应一个worker)的hashset集合，而且Worker继承于AQS，也就是说Worker本身就是一把锁。</p>
<p><img src="https://pic3.zhimg.com/80/v2-bb260274a4a3107c1df08a84c925991e_720w.webp" alt="img"></p>
<p><strong>核心配置参数详解</strong></p>
<p><img src="https://pic2.zhimg.com/80/v2-573610f97665dbcbb271e50f1923482d_720w.webp" alt="img"></p>
<p>1）corePoolSize：在线程池中始终维护的线程个数。</p>
<p>2）maxPoolSize：在corePooSize已满、队列也满的情况下，扩充线程至此值。</p>
<p>3）keepAliveTime&#x2F;TimeUnit：maxPoolSize 中的空闲线程，销毁所需要的时间，总线程数收缩回corePoolSize。</p>
<p>4）blockingQueue：线程池所用的队列类型。</p>
<p>5）threadFactory：线程创建工厂，可以自定义，有默认值Executors.defaultThreadFactory() 。</p>
<p>6）RejectedExecutionHandler：corePoolSize已满，队列已满，maxPoolSize 已满，最后的拒绝策略。</p>
<p>配置参数在任务中的提交过程：</p>
<p>步骤一：判断当前线程数是否大于或等于corePoolSize。如果小于，则新建线程执行；如果大于，则进入步骤二。</p>
<p>步骤二：判断队列是否已满。如未满，则放入；如已满，则进入步骤三。</p>
<p>步骤三：判断当前线程数是否大于或等于maxPoolSize。如果小于，则新建线程执行；如果大于，则进入步骤四。</p>
<p>步骤四：根据拒绝策略，拒绝任务。</p>
<p>总结：首先判断corePoolSize，其次判断blockingQueue是否已满，接着判断maxPoolSize，最后使用拒绝策略。</p>
<p><strong>线程池的优雅关闭</strong></p>
<p>线程池的关闭也线程不同，因为一个线程池里面有多个线程在运行，因此进行关闭就需要一个策略，进行安全关闭线程池，也就是线程池的生命周期。</p>
<p>JDK7中有一个ctl变量，他组合了线程数量（workerCount）和线程池状态（runState），最高的3位存储线程池状态，其余29位存储线程个数，在之前是分开储存的。</p>
<p>ctl变量被拆成两半，最高的3位用来表示线程池的状态，低的29位表示线程的个数。</p>
<p><img src="/posts/35288/asset/v2-e5e440749892905bb058e2aa75d5e2c3_720w.webp" alt="img"></p>
<p>由上图源码得知线程池的状态有五种，分别是RUNNING、SHUTDOWN、STOP、TIDYING和TERMINATED，这五种状态是一个迁移的过程，从小到大迁移，-1，0，1，2，3，只会从小的状态值往大的状态值迁移，不会逆向迁移。</p>
<p>通过shutdown()和shutdownNow()进行关闭，但是他不是真正的关闭，只是切换了状态，只有最后调用了钩子方法terminated()，进入TERMINATED状态，线程池才真正关闭。</p>
<p><img src="/posts/35288/asset/v2-1aa45b7b4a4783b07ded8ad38996f214_720w.webp" alt="img"></p>
<p><strong>线程池关闭的实现</strong></p>
<p>先调用shutdown()或shutdownNow()方法，接着设定一个轮询，隔一段时间进行检查，通过调用awaitTermination()方法返回布尔变量来确定线程池是否关闭，而awaitTermination的内部实现其实就是不断循环判断线程池是否到达了最终状态TERMINATED，未达到就阻塞一段时间又来，直到获取自己的预期结果为止。</p>
<p><img src="https://pic3.zhimg.com/80/v2-d1d4faf56f1310e4e3188f96eb5f4ef6_720w.webp" alt="img"></p>
<p>shutdown()不会清空任务队列，会等所有任务执行完成，shutdownNow()清空任务队列，也就是活没干完也不干了。</p>
<p>shutdown()只会中断空闲的线程，shutdownNow()会中断所有线程，到了时间直接强制中断，但是要注意，中断只能中断轻量级锁，也就是阻塞等待，执行代码逻辑中并不能中断。shutdown() 和shutdownNow()都调用了tryTerminate()方法，tryTerminate()不会强行终止线程池，只是做了一下检测：当workerCount为0，workerQueue为空时，先把状态切换到TIDYING，然后调用钩子方法terminated()。当钩子方法执行完成时，把状态从TIDYING 改为 TERMINATED，接着调用termination.sinaglAll()，通知前面阻塞在awaitTermination的所有调用者线程。所以，TIDYING和TREMINATED的区别是在二者之间执行了一个钩子方法terminated()。</p>
<p><strong>任务的提交过程</strong></p>
<p>如果当前线程数小于corePoolSize，则启动新线程，添加worker，调用开启新线程方法addworker。如果大于或等于corePoolSize，则调用workQueue.offer放入队列，如果发现线程池正在停止，启动拒绝策略，不再接受这个任务否则就放入队列，放入后没有线程执行，就调用开启新线程方法addworker。如果线程数大于maxPoolSize，并且队列已满，调用拒绝策略。</p>
<p><strong>任务的执行过程</strong></p>
<p>上面的任务提交可能会开启一个worker，也就是调用addworker方法。而且他封装了线程，这个方法不单是只执行一个任务，而是源源不断地从队列中取任务执行，这是一个不断循环的过程，它内部有一个runworker方法，先拿到当前线程，再拿到第一个任务，接着中断封装的线程，也就是唤醒，线程就可以执行任务咯，执行完毕释放锁，当前worker就可以继续干其他事了。</p>
<p><strong>shutdown()与任务执行过程综合分析</strong></p>
<ol>
<li>当调用shutdown()的时候，所有线程都处于空闲状态</li>
</ol>
<p>这意味着任务队列一定是空的。此时，所有线程都会阻塞在 getTask()方法的地方。然后，所有线程都会收到interruptIdleWorkers()发来的中断信号，getTask()返回null，所有Worker都 会退出while循环，之后执行processWorkerExit。</p>
<ol start="2">
<li>当调用shutdown()的时候，所有线程都处于忙碌状态</li>
</ol>
<p>此时，队列可能是空的，也可能是非空的。interruptIdleWorkers()内部的tryLock调用失败，什么都不会做，所有线程会继续执行自己当前的任务。之后所有线程会执行完队列中的任务，直到队列为空，getTask()才会返回null。之后，就和场景1一样了，退出while循环。</p>
<ol start="3">
<li>当调用shutdown()的时候，部分线程忙碌，部分线程空闲</li>
</ol>
<p>有部分线程空闲，说明队列一定是空的，这些线程肯定阻塞在 getTask()方法的地方。空闲的 这些线程会和场景1一样处理，不空闲的线程会和场景2一样处理。</p>
<p><strong>shutdownNow() 与任务执行过程综合分析</strong></p>
<p>和上面的 shutdown()类似，只是多了一个环节，即清空任务队列。如果一个线程正在执行某个业务代码，即使向它发送中断信号，也没有用，只能等它把代码执行完成。因此，中断空闲线程和中断所有线程的区别并不是很大，除非线程当前刚好阻塞在某个地方。</p>
<p><strong>线程池的4种拒绝策略</strong></p>
<p>RejectedExecutionHandler 是一个接口，定义了四种实现，分别对应四种不同的拒绝策略，默认是AbortPolicy。</p>
<p>策略1(CallerRunsPolicy)：调用者直接在自己的线程里执行，线程池不处理，比如到医院打点滴，医院没地方了，到你家自己操作吧。</p>
<p>策略2(AbortPolicy)：线程池抛异常。</p>
<p>策略3(DiscardPolicy)：线程池直接丢掉任务，神不知鬼不觉。</p>
<p>策略4(DiscardOldestPolicy)：删除队列中最早的任务，将当前任务入队列。</p>
<h3 id="Executors工具类"><a href="#Executors工具类" class="headerlink" title="Executors工具类"></a>Executors工具类</h3><p>concurrent包提供了Executors工具类，利用它可以创建各种不同类型的线程池。</p>
<p>分五种：单线程的线程池、固定数目线程的线程池、每接收一个请求，就创建一个线程来执行、单线程具有周期调度功能的线程池、多线程，有调度功能的线程池。</p>
<p>《阿里巴巴Java开发手册》中，明确禁止使用Executors创建线程池，以规避因使用不当而造成资源耗尽的风险。</p>
<p>ScheduledThreadPoolExecutor</p>
<p>他实现了按时间调度来执行任务，分延迟执行任务和周期执行任务</p>
<p>延迟执行任务</p>
<p><img src="https://pic2.zhimg.com/80/v2-5ebe4b6692a133476486ee1ca3efedc9_720w.webp" alt="img"></p>
<p>周期执行任务</p>
<p><img src="/posts/35288/asset/v2-068aed111b47d6e07ce4f6b68dd5a39b_720w.webp" alt="img"></p>
<p>AtFixedRate：按固定频率执行，与任务本身执行时间无关。但有个前提条件，任务执行时间必须小于间隔时间，例如间隔时间是5s，每5s执行一次任务，任务的执行时间必须小于5s。</p>
<p>WithFixedDelay：按固定间隔执行，与任务本身执行时间有关。例如，任务本身执行时间是10s，间隔2s，则下一次开始执行的时间就是12s。</p>
<p><strong>延迟执行和周期性执行的原理</strong></p>
<p>ScheduledThreadPoolExecutor继承了ThreadPoolExecutor，内部结构基本一致，内部实现了一个特定的DelayQueue，称之为DelayWorkQueue来实现延迟执行任务。而周期性执行任务是执行完一个任务之后，再把该任务扔回到任务队列中，如此就可以对一个任务反复执行。</p>
<p><strong>延迟执行</strong></p>
<p>就是把提交的Runnable任务加上delay时间，转换成ScheduledFutureTask对象，放入DelayedWorkerQueue中，通过实现Delayed接口完成延迟执行。</p>
<p><strong>周期性执行</strong></p>
<p>包装一个ScheduledFutureTask对象，只是在延迟时间参数之外多了一个周期参数，然后放入DelayedWorkerQueue。不过他有两个方法，一个传入负数一个传入正数在内部实现是按间隔还是按频率的一种算法，也就是上面说的AtFixedRate和WithFixedDelay。</p>
<p> <img src="https://pic2.zhimg.com/80/v2-46990c4ccad4ab603fe62cccbde19c71_720w.webp" alt="img"> </p>
]]></content>
      <categories>
        <category>基础知识</category>
        <category>java并发编程</category>
      </categories>
      <tags>
        <tag>基础知识</tag>
        <tag>java并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title>jvm基础</title>
    <url>/posts/23682/</url>
    <content><![CDATA[<h3 id="JVM概念与操作系统关系"><a href="#JVM概念与操作系统关系" class="headerlink" title="JVM概念与操作系统关系"></a>JVM概念与操作系统关系</h3><p>JVM就是Java虚拟机，是一种用于计算设备的规范。</p>
<p> <img src="/posts/23682/asset/v2-aed3ede4e521dc832587b40e680643c0_720w.webp" alt="img"> </p>
<p> <img src="https://pic1.zhimg.com/80/v2-65a490534b0a548b61de8e7d603236a8_720w.webp" alt="img"> </p>
<p>HostSport是Java使用的虚拟机，在JDK8，Oracle公司将JRockit融合了进来。性能进一步提升。</p>
<p>Java 是一门抽象程度特别高的语言，提供了自动内存管理等一系列的特性。这些特性直接在操作系统上实现是不太</p>
<p>可能的，所以就需要 JVM进行转换。</p>
<p> <img src="https://pic2.zhimg.com/80/v2-920b2efdb39f3388ae0c45e5966740b1_720w.webp" alt="img"> </p>
<p> 通过JVM实现Java语言的跨平台，比如Maven仓库的jar包，不需要在平台再编译一次，并且实现自动管理内存，JVM有一块初始内存，当程序需要更多内存时，JVM就会向服务器申请内存，拿到服务器分配的内存后再向程序进行分配。 </p>
<h3 id="JRE、JDK、JVM关系"><a href="#JRE、JDK、JVM关系" class="headerlink" title="JRE、JDK、JVM关系"></a>JRE、JDK、JVM关系</h3><p>JVM是Java程序能够运行的核心，只需要给他提供class文件即可，而实际运行需要一个基本的类库，JVM 标准加上实现的一大堆基础类库，就组成Java 的运行时环境，即JRE。而JDK包括了JRE和JVM。</p>
<h3 id="Java虚拟机规范和Java语言规范关系"><a href="#Java虚拟机规范和Java语言规范关系" class="headerlink" title="Java虚拟机规范和Java语言规范关系"></a>Java虚拟机规范和Java语言规范关系</h3><p>Java 虚拟机规范，其实就是为输入和执行字节码提供一个运行环境，Java 语法规范，比如 switch、for、泛型、lambda 等相关的程序，最终都会编译成字节码，通过Java编译的字节码class文件连接在一起。</p>
<p> <img src="https://pic4.zhimg.com/80/v2-b940bc8619fb2ed01152435f46e6c9ff_720w.webp" alt="img"> </p>
<p> 执行过程：先编译成class文件，然后通过类加载器进行加载到JVM的内存空间里，再通过执行引擎来执行对应class文件翻译成二进制文件，接着调用操作系统接口进行解释执行，还有一种是JIT方式，根据条件即时执行。Java 虚拟机是基于栈的架构，指令由操作码和操作数组成，这些字节码指令 ，称为opcode。JVM靠他完成程序的执行。 </p>
<p> <img src="/posts/23682/asset/v2-4c3ebe7e95740cf2f1868caaa2d4b76d_720w.webp" alt="img"> </p>
<h3 id="二、Java虚拟机的内存管理"><a href="#二、Java虚拟机的内存管理" class="headerlink" title="二、Java虚拟机的内存管理"></a>二、Java虚拟机的内存管理</h3><h3 id="JVM整体架构"><a href="#JVM整体架构" class="headerlink" title="JVM整体架构"></a>JVM整体架构</h3><p>根据 JVM 规范，JVM 内存共分为虚拟机栈、堆、方法区、程序计数器、本地方法栈五个部分。</p>
<p> <img src="/posts/23682/asset/v2-f8ea427ec812429d4128775b3d3850f8_720w.webp" alt="img"> </p>
<p> <img src="/posts/23682/asset/v2-cb3e67121a734fba7ef41625a1c55826_720w.webp" alt="img"> </p>
<p> JVM分为五大模块： 类装载器子系统 、 运行时数据区 、 执行引擎 、 本地方法接口 和 垃圾收集模块 。 </p>
<p> <img src="/posts/23682/asset/v2-b2a2c22ea72b7df4b53a5aac5bca39d5_720w.webp" alt="img"> </p>
<h3 id="JVM运行时内存管理"><a href="#JVM运行时内存管理" class="headerlink" title="JVM运行时内存管理"></a>JVM运行时内存管理</h3><p>Java 虚拟机有自动内存管理机制，可以通过他排查错误，比如内存溢出等等。</p>
<p> <img src="https://pic4.zhimg.com/80/v2-1a986ec46435877f400ab3a464c04dc3_720w.webp" alt="img"> </p>
<p> 运行时数据区就是方法区、栈区、堆区、PC寄存器（程序计数器）、本地方法栈存在的区域。 </p>
<p><strong>Java7和Java8内存结构的不同</strong></p>
<p>前面说了Java的虚拟机融合JRockit，所以导致与8之前的版本出现了差异，而他们最大的区别就是方法区的实现，Java7中的方法区在Java8中被移除运行时数据区了，到了直接内存中，被称为元空间，但是Java8也是有方法区的，元空间就是方法区，只是实现方式变了。元空间不再与堆连续，而且是存在于本地内存（Native memory）。方法区也被称为永久代。</p>
<p> <img src="/posts/23682/asset/v2-c0fa84d2d858a37703a35246654a4912_720w.webp" alt="img"> </p>
<p>Java8为什么要将永久代替换成元空间</p>
<p>1） 字符串存在永久代中，容易出现性能问题和内存溢出。</p>
<p>2） 类及方法的信息等比较难确定其大小，因此对于永久代的大小指定比较困难，太小容易出现永久代溢出，太大则容易导致老年代溢出。</p>
<p>3） 永久代会为 GC 带来不必要的复杂度，并且回收效率偏低。</p>
<p>4） Oracle 将HotSpot与JRockit合二为一，JRockit没有所谓的永久代。</p>
<p> <img src="/posts/23682/asset/v2-d04cc33c759658692955254e7b3e3c3e_720w.webp" alt="img"> </p>
<h3 id="程序计数器"><a href="#程序计数器" class="headerlink" title="程序计数器"></a>程序计数器</h3><p>程序计数器也被称为PC寄存器，是一块较小的内存空间，它可以看做是当前线程所执行的字节码的行号指示器，因为JVM是多线程运行的，为了满足高效运行就要实现并发运行，而并发运行就涉及到线程之前的切换，这个程序计数器就是为了实现在线程之前切换找到原来需要继续运行的线程，不仅如此，分支、循环、跳转、异常处理等等基础功能都需要依赖这个计数器来完成。</p>
<p><strong>程序计数器的特点</strong></p>
<p>1） 计算机硬件的PC寄存器用于存放伪指令或地址，而虚拟机的PC寄存器用于存放将要执行指令的地址。</p>
<p>2） 当虚拟机正在执行的方法是一个本地（native）方法的时候，Jvm的pc寄存器存储的值是undefined。</p>
<p>3） 程序计数器是线程私有的，它的生命周期与线程相同，每个线程都有一个。</p>
<p>4） 程序计数器所占据内存区域是唯一一个在Java虚拟机规范中没有规定任何OutOfMemoryError情况的区域。</p>
<p> <img src="https://pic2.zhimg.com/80/v2-f6181cd1f5323b01bc27896788582dfd_720w.webp" alt="img"> </p>
<p> Java虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，在任何一个确定的时刻，一个处  理器只会执行一条线程中的指令。因此，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各条线程之间的计数器互不影响，独立存储，我们称这类内存区域为“线程私有”的内存。 </p>
<h3 id="虚拟机栈"><a href="#虚拟机栈" class="headerlink" title="虚拟机栈"></a>虚拟机栈</h3><p>Java虚拟机栈(Java Virtual Machine Stacks)也是线程私有的，即生命周期和线程相同。Java虚拟机栈和线程同时创建，用于存储栈帧。每个方法在执行时都会创建一个栈帧(Stack Frame)，用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每一个方法从调用直到执行完成的过程就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。</p>
<p> <img src="/posts/23682/asset/v2-e5e4aa49d13022fa1c9567841c2d5b5c_720w.webp" alt="img"> </p>
<p><strong>栈针的含义</strong></p>
<p>栈帧(Stack Frame)是用于支持虚拟机进行方法调用和方法执行的数据结构。栈帧存储了方法的局部变量表、操作数栈、动态连接和方法返回地址等信息。每一个方法从调用至执行完成的过程，都对应着一个栈帧在虚拟机栈里从入栈到出栈的过程。</p>
<p> <img src="/posts/23682/asset/v2-a23727a299074883f70b895bcb23647e_720w.webp" alt="img"> </p>
<p><strong>设置虚拟机栈的大小</strong></p>
<p>-Xss 为jvm启动的每个线程分配的内存大小，默认JDK1.4中是256K，JDK1.5+中是1M，通过-Xss设置大小</p>
<h3 id="栈针结构"><a href="#栈针结构" class="headerlink" title="栈针结构"></a>栈针结构</h3><p>栈帧存储了方法的局部变量、操作数栈、动态连接和方法返回地址等信息。</p>
<p> <img src="/posts/23682/asset/v2-a9279735d8bbaceb90c3d5a30ba47a24_720w.webp" alt="img"> </p>
<p><strong>局部变量</strong></p>
<p>局部变量表(Local Variable Table)是一组变量值存储空间，用于存放方法参数和方法内定义的局部变量。包括8种基</p>
<p> 本数据类型、对象引用（reference类型）和returnAddress类型（指向一条字节码指令的地址）。其中64位长度的long和double类型的数据会占用2个局部变量空间（Slot），其余的数据类型只占用1个。 </p>
<p> <img src="/posts/23682/asset/v2-ee48c11801ef6cc0763a547da8400b20_720w.webp" alt="img"> </p>
<p> <img src="/posts/23682/asset/v2-6c706477ecac6c11b66ca46d165bcfb0_720w.webp" alt="img"> </p>
<p><strong>操作数栈</strong></p>
<p>操作数栈(Operand Stack)也称作操作栈，是一个后入先出栈(LIFO)。随着方法执行和字节码指令的执行，会从局部</p>
<p>变量表或对象实例的字段中复制常量或变量写入到操作数栈，再随着计算的进行将栈中元素出栈到局部变量表或者</p>
<p>返回给方法调用者，也就是出栈&#x2F;入栈操作。</p>
<p><strong>动态链接</strong></p>
<p>把符号引用转换为直接引用，Java虚拟机栈中，每个栈帧都包含一个指向运行时常量池中该栈所属方法的符号引用，持有这个引用的目的是为了支持方法调用过程中的动态链接(Dynamic Linking)。</p>
<p> <img src="/posts/23682/asset/v2-4ff123647bf6fb262b0da2b3004bd016_720w.webp" alt="img"> </p>
<p><strong>方法返回地址</strong></p>
<p>方法返回地址存放调用该方法的PC寄存器的值，其实就是程序计数器保存了多个方法的调用地址，比如两个方法之间的切换，要通过程序计数器来实现切换或者调转，而方法返回地址就是通过程序计数器存储的方法之间调转的地址。无论方法是否正常完成，即无论是否抛出异常，都需要返回到方法被调用的位置，程序才能继续进行。</p>
<h3 id="本地方法栈"><a href="#本地方法栈" class="headerlink" title="本地方法栈"></a>本地方法栈</h3><p>本地方法栈（Native Method Stacks） 与虚拟机栈所发挥的作用是非常相似的，其区别是虚拟机栈为虚拟机执行</p>
<p>Java方法（也就是字节码）服务，而本地方法栈则是为虚拟机使用到的本地（Native） 方法服务。</p>
<p>1）本地方法栈加载native的方法, native类方法存在的意义当然是填补java代码不方便实现的缺陷而提出的，比如驱动程序，用C来写执行会更快。</p>
<p>2）虚拟机栈为虚拟机执行Java方法服务，而本地方法栈则是为虚拟机使用到的Native方法服务。</p>
<p>3）都线程私有的，它的生命周期与线程相同，每个线程都有一个。</p>
<p>两种异常：StackOverFlowError :线程请求的栈深度&gt;所允许的深度；OutOfMemoryError：本地方法栈扩展时无法申请到足够的内存。</p>
<h3 id="堆空间"><a href="#堆空间" class="headerlink" title="堆空间"></a>堆空间</h3><p><strong>Java 堆概念</strong></p>
<p>对于Java应用程序来说， Java堆（Java Heap） 是虚拟机所管理的内存中最大的一块。 Java堆是被所有线程共享</p>
<p>的一块内存区域， 在虚拟机启动时创建，存储除特殊外所有对象的地方。</p>
<p> <img src="https://pic2.zhimg.com/80/v2-d145d86babb8f1e6f31846c890dea97d_720w.webp" alt="img"> </p>
<p><strong>堆的特点</strong></p>
<p>1） Java虚拟机所管理的内存中最大的一块。</p>
<p>2） 堆是jvm所有线程共享的(也包含私有的线程缓冲区)。</p>
<p>3） 在虚拟机启动的时候创建。</p>
<p>4） 作用是存放对象实例，几乎所有的对象实例以及数组都要在这里分配内存。</p>
<p>5） 是垃圾收集器管理的主要区域，所以也被称为GC堆，并且对堆空间进行了分代划分。</p>
<p>6） 堆的大小可调节，通过-Xms和-Xmx控制。</p>
<p>7） 方法结束后,堆中对象不会马上移出仅仅在垃圾回收的时候时候才移除。</p>
<p>8） 如果在堆中没有内存完成实例的分配，并且堆也无法再扩展时，将会抛出OutOfMemoryError异常。</p>
<p>设置堆空间大小：如示例: -Xmx20m -Xms5m表示Java应用最大可用内存为20M， 最小内存为5M。</p>
<p>设置了最大内存和最小内存，分配给程序的内存并不是按最大值来，也就是贪婪算法，而是一个一个尽可能低的层面，更贴近于最小值，通过JVM动态按需分配添加，超出最大内存报内存溢出错误。</p>
<p><strong>堆的分类</strong></p>
<p>Java7 Hotspot虚拟机中Java堆内存划分</p>
<p> <img src="https://pic4.zhimg.com/80/v2-f1b8d32d3886e3dbe26a7c3d723ad10b_720w.webp" alt="img"> </p>
<p> Java8 Hotspot虚拟机中Java堆内存划分 </p>
<p> <img src="https://pic2.zhimg.com/80/v2-c12ebdc2706858888b2e5498c753de89_720w.webp" alt="img"> </p>
<p> 通过设置VM参数-XX:+PrintGCDetails可以在控制台打印堆空间各代分配内存信息 </p>
<p> <img src="/posts/23682/asset/v2-80008789099556267530083d271e4362_720w.webp" alt="img"> </p>
<p><strong>年轻代和老年代</strong></p>
<p>年轻代(Young Gen)：年轻代主要存放新创建的对象，内存大小相对会比较小，垃圾回收会比较频繁。年轻代分</p>
<p>成1个Eden Space和2个SurvivorSpace（from 和to）。</p>
<p>年老代(Tenured Gen)：年老代主要存放JVM认为生命周期比较长的对象（经过几次的Young Gen的垃圾回收后仍然存在），内存大小相对会比较大，垃圾回收也相对没有那么频繁。</p>
<p> 年老代(Tenured Gen)：年老代主要存放JVM认为生命周期比较长的对象（经过几次的Young Gen的垃圾回收后仍然存在），内存大小相对会比较大，垃圾回收也相对没有那么频繁。 </p>
<p> <img src="https://pic3.zhimg.com/80/v2-e2ce0b71054465043aff928c296d8f5a_720w.webp" alt="img"> </p>
<p> 默认 -XX:NewRatio&#x3D;2 , 即新生代占1 , 老年代占2 ,新生代占整个堆的1&#x2F;3。Eden空间和另外两个Survivor空间占比分别为8:1:1，通过-XX:SurvivorRatio&#x3D;8调整。 </p>
<p> <img src="https://pic2.zhimg.com/80/v2-e8e6f9317d54014475f8fddd033ce5ad_720w.webp" alt="img"> </p>
<p> 堆大小 &#x3D; 新生代 + 老年代。堆的大小可以通过参数 –Xms、-Xmx 来指定。 </p>
<p> <strong>通过JDK自带jvisualvm工具查看堆空间</strong> </p>
<p>安装Visual VM，把默认地址改为<a href="https://link.zhihu.com/?target=https://visualvm.github.io/pluginscenters.html">https://visualvm.github.io/pluginscenters.html</a>，再安装。</p>
<p>Idea中配置VM参数 –Xmx300m -Xms300m -XX:NewRatio&#x3D;4 -XX:SurvivorRatio&#x3D;8 即最大最小堆空间300m，年轻代年老代1:4，年轻代eden区和from，to区8:1:1。</p>
<p> <img src="/posts/23682/asset/v2-4ba55da25975a975d21958be013bc326_720w.webp" alt="img"> </p>
<p><strong>对象分配过程</strong></p>
<p>1） new的对象先放在Eden区。该区域有大小限制。</p>
<p>2） 当Eden区填满时，程序有需要创建对象，JVM的垃圾回收器对Eden区执行垃圾回收(Minor GC),把不再被其他对象引用的对象销毁，执行完将存活的对象转移到Eden区的Survivor 0区。</p>
<p>3） 当再次触发垃圾回收，也就是Eden区再次填满，Survivor 0区内上次存活的对象中还活着的对象以及这次垃圾回收新存活的对象就会被移动到Survivor 1区。</p>
<p>4） 如果再次经历垃圾回收，此时会重新返回Survivor 0区，接着再去Survivor 1区。</p>
<p>5） 如果累计次数到达默认的15次，这会进入Old Gen区。可以通过设置参数，调整阈值 -XX:MaxTenuringThreshold&#x3D;N。如果Survivor区大于等于某个年领的对象超过了Survivor空间的一半，大于等于某个年龄的对象直接进入年老代；大对象（需要大量连续内存空间的java对象）直接进入年老代。</p>
<p>6） Old Gen（养老)区内存不足是,会再次触发GC，Major GC 进行养老区的内存清理。</p>
<p>7） 如果养老区执行了Major GC后仍然没有办法进行对象的保存,就会报OOM异常。</p>
<p> 如果累计次数到达默认的15次，这会进入Old Gen区。可以通过设置参数，调整阈值 -XX:MaxTenuringThreshold&#x3D;N。如果Survivor区大于等于某个年领的对象超过了Survivor空间的一半，大于等于某个年龄的对象直接进入年老代；大对象（需要大量连续内存空间的java对象）直接进入年老代。<br>  <img src="https://pic3.zhimg.com/80/v2-cae07c8febd9d7e40727ed0af7fb13be_720w.webp" alt="img"> </p>
<p><strong>堆GC</strong></p>
<p>Java 中的堆也是GC收集垃圾的主要区域。GC分为两种：部分收集器（Partial GC）和整堆收集器（Full GC）</p>
<p>部分收集器：</p>
<ul>
<li><p>新生代收集（Minor GC &#x2F; Young GC）: 只是新生代的垃圾收集</p>
</li>
<li><p>老年代收集（Major GC &#x2F; Old GC）: 只是老年代的垃圾收集 (CMS GC 单独回收老年代)</p>
</li>
<li><p>混合收集（Mixed GC）:收集整个新生代及老年代的垃圾收集 (G1 GC会混合回收, region区域回收)</p>
</li>
</ul>
<p> 整堆收集器（Full GC）：收集整个java堆和方法区的垃圾收集器. </p>
<p> 年轻代GC触发条件: 年轻代空间不足,就会触发Minor GC，这里年轻代指的是Eden代满，Survivor不满不会引发GC，Minor GC会引发STW(stop the world) ,暂停其他用户的线程,等垃圾回收接收,用户的线程才恢复。 </p>
<p> 老年代GC (Major GC)触发机制：老年代空间不足时,会尝试触发MinorGC. 如果空间还是不足,则触发Major GC </p>
<p> 如果Major GC , 内存仍然不足,则报错OOM，Major GC的速度比Minor GC慢10倍以上。 </p>
<p>FullGC 触发机制:</p>
<p>1）调用System.gc() , 系统会执行Full GC ,不是立即执行。</p>
<p>2）老年代空间不足。</p>
<p>3）方法区空间不足。</p>
<p>4）通过Minor GC进入老年代平均大小大于老年代可用内存。</p>
<p> <strong>元空间</strong></p>
<p>JDK1.7之前，HotSpot 虚拟机把方法区当成永久代来进行垃圾回收。而从 JDK 1.8 开始，移除永久代，并把方法区移至元空间，它位于本地内存中，而不是虚拟机内存中。相当于方法区到了元空间。</p>
<p><strong>区别</strong></p>
<p>1） 存储位置不同：永久代在物理上是堆的一部分，和新生代、老年代的地址是连续的，而元空间属于本地内存。</p>
<p>2） 存储内容不同：原来的永久代划分中，永久代用来存放类的元数据信息、静态变量以及常量池等。现在类的元信息存储在元空间，静态变量和常量池等并入堆中，相当于原来的永久代中的数据，被元空间和堆内存给瓜分了。</p>
<p> <img src="/posts/23682/asset/v2-9c0cf32167d724fa668c5c12093e659b_720w.webp" alt="img"> </p>
<p> <strong>废除永久代的目的</strong> </p>
<p>1） 永久代需要存放类的元数据、静态变量和常量等。它的大小不容易确定，容易造成内存溢出。</p>
<p>2） 融合HotSpot VM与 JRockit VM而做出的努力，因为JRockit没有永久代。</p>
<p>3） 永久代会为GC带来不必要的复杂度，回收效率偏低。</p>
<p><strong>使用元空间好处</strong></p>
<p>1） 由于类的元数据分配在本地内存中，元空间的最大可分配空间就是系统可用内存空间。不会遇到永久代时的内存溢出错误。</p>
<p>2） 将运行时常量池从永久代分离出来，与类的元数据分开，提升类元数据的独立性。</p>
<p>3） 将元数据从永久代剥离出来到元空间，可以提升对元数据的管理同时提升GC效率。</p>
<p><strong>元空间相关参数设置</strong></p>
<p>-XX:MetaspaceSize，初始空间大小，达到该值就会触发垃圾收集，根据释放的空间进行动态缩小或增大。</p>
<p>-XX:MaxMetaspaceSize，最大空间，默认是没有限制的，最大可利用空间是整个系统内存的可用空间。</p>
<p>-XX:MinMetaspaceFreeRatio，在GC之后，最小的Metaspace剩余空间容量的百分比，默认40%，小于此值增大元空间。</p>
<p>-XX:MaxMetaspaceFreeRatio，在GC之后，最大的Metaspace剩余空间容量的百分比，默认70%，大于此值缩小元空间。</p>
<h3 id="方法区简介"><a href="#方法区简介" class="headerlink" title="方法区简介"></a>方法区简介</h3><p>方法区（Method Area） 与Java堆一样， 是各个线程共享的内存区域， 它用于存储已被虚拟机加载的类型信息、</p>
<p>常量、 静态变量、 即编译器编译后的代码缓存等数据。元空间、永久代是方法区具体的落地实现。方法区看作是一块独立于Java堆的内存空间，它主要是用来存储所加载的类信息。逻辑上属于堆但是不会垃圾回收。</p>
<p> 常量、 静态变量、 即编译器编译后的代码缓存等数据。元空间、永久代是方法区具体的落地实现。方法区看作是一块独立于Java堆的内存空间，它主要是用来存储所加载的类信息。逻辑上属于堆但是不会垃圾回收 </p>
<p> <img src="https://pic4.zhimg.com/80/v2-c935e0a301202e13aa4b9697c11c565b_720w.webp" alt="img"> </p>
<p><strong>特点</strong></p>
<p>1） 方法区与堆一样是各个线程共享的内存区域</p>
<p>2） 方法区在JVM启动的时候就会被创建并且它实例的物理内存空间和Java堆一样都可以不连续</p>
<p>3） 方法区的大小跟堆空间一样 可以选择固定大小或者动态变化</p>
<p>4） 方法区的对象决定了系统可以保存多少个类,如果系统定义了太多的类 导致方法区内存溢出抛出异常</p>
<p>5） 关闭JVM就会释放这个区域的内存</p>
<h3 id="方法区结构"><a href="#方法区结构" class="headerlink" title="方法区结构"></a>方法区结构</h3><p> 类加载器将Class文件加载到内存之后，将类的信息存储到方法区中。 </p>
<p> <img src="/posts/23682/asset/v2-dd7e02dca86ae26329580506e0630863_720w.webp" alt="img"> </p>
<p> 方法区中存储的内容：类型信息、运行时常量池、字符串常量池 </p>
<p> <img src="https://pic3.zhimg.com/80/v2-0be9453a775f1a7d6acd4e555b9cc01e_720w.webp" alt="img"> </p>
<p><strong>类型信息</strong></p>
<p>每个加载的类型，如类class、接口interface、枚举enum、注解annotation，jvm在方法区进行存储类型信息。</p>
<p>1、类的全限定类名。2、父类全限定类名。3、类的修饰符。4、类的接口有序列表</p>
<p><strong>域信息</strong></p>
<p>域信息，即为类的属性，成员变量。即保存类所有的成员变量相关信息及声明顺序。</p>
<p><strong>方法信息</strong></p>
<p>1、保存方法名称方法的返回类型。2、方法参数的数量和类型（按顺序）。</p>
<p>3、方法的修饰符public、private、protecte等等。4、方法的字节码bytecodes、操作数栈、局部变量表及大小</p>
<p>5、异常表。每个异常处理的开始、结束位置、代码处理在程序计数器中的偏移地址、被捕获的异常类的常量池索引</p>
<h3 id="方法区设置"><a href="#方法区设置" class="headerlink" title="方法区设置"></a>方法区设置</h3><p>方法区的大小不必是固定的，JVM可以根据应用的需要动态调整。</p>
<p><strong>Jdk7</strong></p>
<p>-xx:Permsize来设置永久代初始分配空间</p>
<p>-XX:MaxPermsize来设定永久代最大可分配空间</p>
<p><strong>Jdk8</strong></p>
<p>-XX:MetaspaceSize 和 -XX:MaxMetaspaceSize指定元空间最小最大值，如果触及最小，进行Full GC然后根据释放的空间重新调整空间大小，或大或小。</p>
<p>jps #查看进程号</p>
<p>jinfo -flag MetaspaceSize 进程号 #查看Metaspace 最大分配内存空间</p>
<p>jinfo -flag MaxMetaspaceSize 进程号 #查看Metaspace最大空间</p>
<h3 id="运行时常量池"><a href="#运行时常量池" class="headerlink" title="运行时常量池"></a>运行时常量池</h3><p>字节码文件中，内部包含了常量池。</p>
<p>方法区中，内部包含了运行时常量池。</p>
<p>常量池：存放编译期间生成的各种字面量与符号引用。</p>
<p>运行时常量池：常量池表在运行时的表现形式。</p>
<p> <img src="/posts/23682/asset/v2-b88f93cb10284bb32483420af5404bf4_720w.webp" alt="img"> </p>
<p> 编译后的字节码文件中包含了类型信息、域信息、方法信息等。通过ClassLoader将字节码文件的常量池中的信息加载到内存中，存储在了方法区的运行时常量池中。常量池，可以看做是一张表，虚拟机指令根据这张常量表找到要执行的类名、方法名、参数类型、字面量等类型。 </p>
<p> <strong>字节码常量池表</strong> </p>
<p><img src="/posts/23682/asset/v2-8b8577af74a074ae11d8270eaacabb4e_720w.webp" alt="img"></p>
<p> <strong>方法区中对常量池表的符号引用，也就是运行时常量池。</strong> </p>
<p><img src="/posts/23682/asset/v2-6909c09ec4129763c591f6df86948490_720w.webp" alt="img"> </p>
<h3 id="直接内存-堆外内存"><a href="#直接内存-堆外内存" class="headerlink" title="直接内存(堆外内存)"></a>直接内存(堆外内存)</h3><p>直接内存（Direct Memory） 不是虚拟机运行时数据区的一部分，JDK 1.4中新加入了NIO类，引入通道（Channel） 与缓冲区 （Buffer）的I&#x2F;O方式，通过分配堆外内存，然后通过堆中DirectByteBuffer对象进行引用操作，提高性能，避免复制数据带来的性能和时间消耗。</p>
<p> <img src="/posts/23682/asset/v2-641f88db807730f102e59036c42b9994_720w.webp" alt="img"> </p>
<p> NIO的Buffer提供一个可以直接访问系统物理内存的类——DirectBuffer，普通的ByteBuffer仍在JVM堆上分配内存，其最大内存受到最大堆内存的 限制。而DirectBffer直接分配在物理内存中，并不占用堆空间。 </p>
<p> 优点： </p>
<p>1）改善堆过大时垃圾回收效率，减少停顿。Full GC时会扫描堆内存，回收效率和堆大小成正比。Native的内 存，由OS负责管理和回收。</p>
<p>2）减少内存在Native堆和JVM堆拷贝过程，避免拷贝损耗，降低内存使用。</p>
<p>3）可突破JVM内存大小限制。</p>
<h3 id="Java堆溢出"><a href="#Java堆溢出" class="headerlink" title="Java堆溢出"></a>Java堆溢出</h3><p>堆内存中主要存放对象、数组等，如果不断地创建这些对象，并且保证 GC Roots 到对象之间有可达路径来避免垃</p>
<p>圾收集回收机制清除这些对象，当这些对象所占空间超过最大堆容量时，就会产生 OutOfMemoryError 的异常。</p>
<p> <img src="/posts/23682/asset/v2-8437a4ae8b1ac64a682dab9d29963135_720w.webp" alt="img"> </p>
<p> java.lang.OutOfMemoryError: Java heap space 的信息，说明在堆内存空间产生内存溢出的异常。 </p>
<p> 产生原理：新产生的对象最初分配在新生代，新生代满后会进行一次 Minor GC ，如果 Minor GC 后空间不足会把该对象和 新生代满足条件的对象放入老年代，老年代空间不足时会进行 Full GC ，之后如果空间还不足以存放新对象则抛 出 OutOfMemoryError 异常。 </p>
<p><strong>造成堆内存溢出的原因</strong></p>
<p>1）内存中加载的数据过多，如一次从数据库中取出过多数据；</p>
<p>2）集合对对象引用过多且使用完后没有清空；</p>
<p>3）代码中存在死循环或循环产生过多重复对象；</p>
<p>4）堆内存分配不合理</p>
<h3 id="虚拟机栈和本地方法栈溢出"><a href="#虚拟机栈和本地方法栈溢出" class="headerlink" title="虚拟机栈和本地方法栈溢出"></a>虚拟机栈和本地方法栈溢出</h3><p>HotSpot虚拟机中并不区分虚拟机栈和本地方法栈，所以栈容量只能由-Xss参数来设定。</p>
<p>两种异常</p>
<ol>
<li><p>StackOverflowError异常：线程请求的栈深度大于虚拟机所允许的最大深度，默认压栈次数1000-2000。</p>
</li>
<li><p>OutOfMemoryError异常：虚拟机的栈内存允许动态扩展，但是扩展栈容量无法申请到足够的内存。</p>
</li>
</ol>
<p> <img src="https://pic2.zhimg.com/80/v2-d428119b36867d6949ef3d5ce7d77891_720w.webp" alt="img"><br>  <img src="/posts/23682/asset/v2-1f300050a4bd3186505ee1a2856c441e_720w.webp" alt="img"> </p>
<p> 不同JDK版本控制台结果可能不同，如果是JDK11的话，就不会抛出异常，而是提示增大栈容量-Xss。 </p>
<h3 id="运行时常量池内存溢出"><a href="#运行时常量池内存溢出" class="headerlink" title="运行时常量池内存溢出"></a>运行时常量池内存溢出</h3><p>运行时常量池是方法区的一部分，但是JDK7和JDK8针对永久代做了改变,JDK8方法区被移除永久代到了元空间，String::intern()是一个本地方法，它的作用是如果字符串常量池中已经包含一个等于此String对象的 字符串，则返回代表池中这个字符串的String对象的引用；否则会将此String对象包含的字符串添加到常量池中，并且返回此String对象的引用。</p>
<p> <img src="https://pic2.zhimg.com/80/v2-b2b6853ced31a335e5d73e431a5d88a5_720w.webp" alt="img"> </p>
<p> 在JDK 6或更早之前的HotSpot虚拟机中， 常量池都是分配在永久代中，自JDK 7起， 原本存放在永久代的字符串常量池被移至Java堆之中。 </p>
<h3 id="方法区内存溢出"><a href="#方法区内存溢出" class="headerlink" title="方法区内存溢出"></a>方法区内存溢出</h3><p>方法区的其他部分的内容， 方法区的主要职责是用于存放类型的相关信息， 如类名、 访问修饰符、 常量池、 字段描述、 方法描述等。</p>
<p>方法区溢出也是一种常见的内存溢出异常，一个类如果要被垃圾收集器回收，要达成的条件是比较苛刻的。在经常运行时生成大量动态类的应用场景里， 就应该特别关注这些类的回收状况，比如CGLib字节码增强和动态语言以及大量JSP或动态产生JSP 文件的应用等。JDK 8中转移到元空间中，就需要通过元空间的合理设置来避免内存溢出。</p>
<p> <img src="/posts/23682/asset/v2-59ea710407c1a75705797ad22742c841_720w.webp" alt="img"> </p>
<p> <img src="/posts/23682/asset/v2-6f89a11233af2d794cd4d5b8c7211058_720w.webp" alt="img"> </p>
<p> -XX： MaxMetaspaceSize： 设置元空间最大值，默认是-1，即不限制，或者说只受限于本地内存大小。 </p>
<p> -XX： MetaspaceSize： 指定元空间的初始空间大小， 以字节为单位， 达到该值就会触发垃圾收集进行类型卸载。 </p>
<h3 id="直接内存溢出"><a href="#直接内存溢出" class="headerlink" title="直接内存溢出"></a>直接内存溢出</h3><p>直接内存（Direct Memory）不属于Java虚拟机内存的一部分，而是直接作用在本地内存的，直接内存的容量大小可通过-XX： MaxDirectMemorySize参数来指定， 如果不去指定， 默认与 Java堆最大值（由-Xmx指定）一致。</p>
<p>通过Unsafe类可以进行一些读写操作，JDK 10时才将Unsafe 的部分功能通过VarHandle开放给外部使用。</p>
<p> <img src="/posts/23682/asset/v2-e9ba2ddf71a37d3821115cd85f56c990_720w.webp" alt="img"> </p>
<p> <img src="/posts/23682/asset/v2-5fd66b5cbf95886620c30c4397fc45f3_720w.webp" alt="img"> </p>
<p> 直接溢出通过查看Heap Dump文件大小来确定，内存溢出之后产生的Dump文件很小， 而程序中又直接或间接使用了 DirectMemory（典型的间接使用就是NIO，使用了buffer缓存）。 </p>
<h3 id="三、JVM加载机制"><a href="#三、JVM加载机制" class="headerlink" title="三、JVM加载机制"></a>三、JVM加载机制</h3><h3 id="类加载子系统简介"><a href="#类加载子系统简介" class="headerlink" title="类加载子系统简介"></a>类加载子系统简介</h3><p>1、类加载子系统负责从文件系统或网络中加载.class文件，class文件在文件开头有特定的文件标识。</p>
<p>2、把加载后的class类信息存放于方法区，除类信息外，方法区还会存放运行时常量池信息，可能还包括字符串字面量和数字常量，即Class文件中在常量池中部分内存映射。</p>
<p>3、ClassLoader只负责class文件的加载，至于它的运行由Execution Engine决定。</p>
<p>4、如果调用构造器实例化对象，则该对象存放在堆区。</p>
<p> <img src="/posts/23682/asset/v2-1850b594e564e833ca2e522d8d7629e8_720w.webp" alt="img"> </p>
<p><strong>类加载器角色</strong></p>
<p>字节码文件Car.class通过类加载器classloader加载到JVM方法区中，并创建一个一模一样的Class文件，他被称为DNA元数据模板，然后根据这个模板，进行实例化，生成N个实例放入堆中，这时就可以通过getClassloader、getClass等方法获取加载器或模板类，类加载器在这个过程中就相当于搬运工。 <img src="/posts/23682/asset/v2-482f4d42dc18bda0cd257dffcb480f43_720w.webp" alt="img"> </p>
<h3 id="类加载的执行过程"><a href="#类加载的执行过程" class="headerlink" title="类加载的执行过程"></a>类加载的执行过程</h3><p>类从被加载到虚拟机内存中开始，到卸载出内存，它的整个生命周期包括：加载（Loading）、验证（Verification）、准备（Preparation）、解析（Resolution）、初始化（Initiallization）、使用（Using）和卸载（Unloading）这7个阶段。其中验证、准备、解析3个部分统称为连接（Linking）。</p>
<p> <img src="https://pic1.zhimg.com/80/v2-73073f4ea2ffcc74af489c18b96ff9a8_720w.webp" alt="img"> </p>
<p> 加载、验证、准备、初始化、卸载这5个阶段的顺序是确定的，类的加载过程必须按照这种顺序按部就班地开始，而解析阶段不一定。 </p>
<p><strong>加载</strong></p>
<p>加载是类加载的第一个阶段。有两种时机会触发类加载。</p>
<p>预加载：虚拟机启动时加载，加载的是JAVA_HOME&#x2F;lib&#x2F;下的rt.jar下的.class文件，这个jar包的内容是程序运行时非常用到的，像java.lang、java.util、java.io等等。</p>
<p>运行时加载：虚拟机在用到一个.class文件的时候，会先去内存中查看一下这个.class文件有没有被加载，如果没有就会按照类的全限定名来加载这个类。运行时加载就是上面类加载器角色的过程，获取class文件的二进制流，将类信息、静态变量、常量这些class文件放入方法区，并在方法区生成一个代表这个class对象的class对象，也就是DNA元数据模板，作为这个类各种数据访问接口与堆交互。</p>
<p><strong>连接</strong></p>
<p>连接是类加载的第二个阶段。连接包含三个步骤： 分别是 验证Verification , 准备Preparation , 解析Resolution 三个过程。</p>
<p>验证：确保.class文件的字节流中包含的信息符合当前虚拟机的要求，不会有危害信息，如格式验证、元数据验证、符号引用验证、字节码验证。</p>
<p> 准备：正式为类变量分配内存并设置其初始值的阶段，这些变量所使用的内存都将在方法区中分配。这是分配的是类变量，不是实例变量，实例变量会在对象实例化时分配，且类变量没有被final修饰。 </p>
<p>符号引用：类和接口的全限定名、字段的名称和描述符、方法的名称和描述符。</p>
<p>直接引用：类或接口的解析、类方法解析、接口方法解析、字段解析。</p>
<p><strong>初始化</strong></p>
<p>初始化是类加载的最后阶段。执行类构造器也就是clinit()方法的过程。Clinit方法是Javac编译器的自动生成物，用于收集静态变量和执行静态代码块，因为这个构造器，所以我们定义的静态代码块，在项目启动时就会被执行加载，，并且加载优先级非常高，相同静态修饰，父类优先于子类，同类自上而下顺序加载，不过接口的clinit ()方法不需要先执行父接口的clinit ()方法。因为只有当父接口中定义的变量被使用时，父接口才会被初始化。在多线程情况下，只需要一个线程执行clinit ()方法，其他则同步阻塞。</p>
<p> <img src="https://pic2.zhimg.com/80/v2-1a02ec0c527109000c5e65556f2c74f9_720w.webp" alt="img"> </p>
<h3 id="cinit方法与init方法"><a href="#cinit方法与init方法" class="headerlink" title="cinit方法与init方法"></a>cinit方法与init方法</h3><p>cinit完成类的初始化，init完成对象初始化。</p>
<p> <img src="/posts/23682/asset/v2-51e286fe367e243df65154e513ae05e9_720w.webp" alt="img"> </p>
<p>类的初始化先于对象初始化执行，且类的初始化只会执行一次而对象的初始化阶段可能多次赋值。</p>
<p> <img src="/posts/23682/asset/v2-89c860288c542e474325ef7c7910e981_720w.webp" alt="img"> </p>
<p> 执行顺序：A类static代码块-&gt;B类static代码块-&gt;B类父类A类对象构造方法-&gt;B类对象构造方法-&gt;继续new B但是类初始化静态代码块只会执行一次，因此又是B类父类A类对象构造方法-&gt;B类对象构造方法。 </p>
<h3 id="类加载器"><a href="#类加载器" class="headerlink" title="类加载器"></a>类加载器</h3><p>类的加载指的是将类的.class文件中的二进制数据读入到内存中，将其放在运行时数据区的方法区内，然后在创建一个java.lang.Class对象，用来封装类在方法区内的数据结构。JVM在用到该类是才会加载，也就是按需加载，并不是一开始就全部加载到内存中。</p>
<p><strong>类加载器分类</strong></p>
<p>BootStrapClassLoader（启动类加载器）：也称为引导类加载器，由c&#x2F;c++实现，嵌套再jvm内部，来加载Java的核心类库（JAVA_HOME&#x2F;jre&#x2F;lib&#x2F;rt.jar、resource.jar或sun.boot.class.path路径下的内容）。</p>
<p>ExtensionClassLoader（扩展类加载器）：加载JDK的安装目录的jre&#x2F;lib&#x2F;ext 子目录（扩展目录）下类库。</p>
<p>SystemClassLoader（系统类加载器）：程序中默认的类加载器，Java应用的类都是由它来完成加载的，它负责加载环境变量classpath或系统属性java.class.path 指定路径下的类库。</p>
<p>User-Defined ClassLoader（用户自定义类加载器）：自定义来定制类的加载方式。</p>
<p> <img src="/posts/23682/asset/v2-f5226bde5a89adb1d6647d256ff8e0f3_720w.webp" alt="img"> </p>
<p> 加载顺序：自底向上检查是否加载，然后自上而下加载类库。 </p>
<h3 id="双亲委派模型"><a href="#双亲委派模型" class="headerlink" title="双亲委派模型"></a>双亲委派模型</h3><p> 如果一个类加载器收到类加载请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器完成。每个类加载器都是如此，只有当父加载器在自己的搜索范围内找不到指定的类时（即 ClassNotFoundException ），子加载器才会尝试自己去加载。 </p>
<p> <img src="https://pic3.zhimg.com/80/v2-622ab5936534be2372cda1ca0188edd6_720w.webp" alt="img"> </p>
<p><strong>双亲委派模型设计目的</strong></p>
<p>自定义一个 java.lang.String 类，该 String 类具有系统的 String 类相同的功能，只是在某个函数稍作修改，植入病毒代码，就可以通过自定义加载器加载到JVM中，然后执行的时候，如果没有这个模型，这个String类就被加载到程序中了，而存在双亲委派模型就只会加载顶层类中的核心类库中的String类。</p>
<p> <strong>双亲委派模型加载过程</strong> </p>
<p>1）首先，检查一下指定名称的类是否已经加载过，如果加载过了，就不需要再加载，直接返回。</p>
<p>2）如果此类没有加载过，那么，再判断一下是否有父加载器；如果有父加载器，则由父加载器加载（即调用 parent.loadClass(name, false)）或者是调用 bootstrap 类加载器来加载。</p>
<p> 3）如果父加载器及 bootstrap 类加载器都没有找到指定的类，那么调用当前类加载器，即自定义加载器的 findClass 方法来完成类加载。 </p>
<h3 id="自定义类加载器"><a href="#自定义类加载器" class="headerlink" title="自定义类加载器"></a>自定义类加载器</h3><p>自定义加载器不仅仅是用户自己编写的类加载器，其实还包括扩展类加载器和系统类加载器。</p>
<p><strong>自定义加载器的作用</strong></p>
<p>1） 隔离加载类：模块隔离,把类加载到不同的应用选中。比如tomcat，通过不同类加载器在多项目部署隔离不同应用程序。</p>
<p>2） 修改类加载方式：除了Bootstrap加载器外，其他类加载器可以按需加载，实现对资源最大化利用。</p>
<p>3） 扩展加载源：多种加载方式，如从数据库、网络、或其他终端</p>
<p>4） 防止源码泄漏：java代码容易被编译和篡改，可以进行编译加密，类加载需要自定义还原加密字节码</p>
<p> <strong>自定义加载器加载过程</strong> </p>
<p> 先通过loadClass进行加载，判断此类是否被存在于父类，如果存在直接返回对象，如果不存在执行findClass方法，而自定义类加载器的实现逻辑就是重写这个方法，当完成findClass方法之后，便把读取的文件存储字节数组，通过defineClass把这些字节数据转换成class对象并返回。 </p>
<p><strong>自定义加载器编写</strong></p>
<p>实现方式</p>
<p>1）重写loadClass方法(是实现双亲委派逻辑的地方,修改他会破坏双亲委派机制,不推荐)</p>
<p>2）重写findClass方法 (推荐)</p>
<p> <img src="https://pic4.zhimg.com/80/v2-7013edcf33f8588f31c81856af3ef06f_720w.webp" alt="img"> </p>
<p> <img src="/posts/23682/asset/v2-c5cfd7a1644d53e34e1f6176a292cf7c_720w.webp" alt="img"> </p>
<h3 id="ClassLoader源码剖析"><a href="#ClassLoader源码剖析" class="headerlink" title="ClassLoader源码剖析"></a>ClassLoader源码剖析</h3><p> <strong>类关系图</strong> </p>
<p> <img src="https://pic2.zhimg.com/80/v2-3b0202ea35bf7b57ffaabe9d987e40c5_720w.webp" alt="img"> </p>
<p><strong>Launcher类源码</strong></p>
<p>Launcher类是一个启动类，主要作用是通过构造方法初始化扩展类加载器，并通过扩展类加载器初始化应用类加载器，也就是设置父类加载器。接着设置当前线程的上下文类加载器，也就是应用类加载器，最后加载安全模式。</p>
<p> <img src="/posts/23682/asset/v2-9c87a363ede848c8bea080cc0d934d9c_720w.webp" alt="img"> </p>
<p> Launcher类的构造方法是通过静态变量的初始化执行构造方法来完成的，构造方法 Launcher() 中做了四件事情：创建扩展类加载器、创建应用程序类加载器、设置ContextClassLoader、安装安全管理器 security manager。 </p>
<p><strong>ClassLoader类源码</strong></p>
<p>ClassLoader类，它是一个抽象类，其后所有的类加载器都继承自ClassLoader，不包括启动类加载器。</p>
<p> <img src="/posts/23682/asset/v2-060d29ef6b3c853471d30287a3e70fa6_720w.webp" alt="img"> </p>
<p>loadClass方法</p>
<p>加载指定名称（包括包名）的二进制类型，方法逻辑就是双亲委派模式的实现。</p>
<p> <img src="https://pic4.zhimg.com/80/v2-89aaae5893844890dad6aae5f6d0b637_720w.webp" alt="img"> </p>
<p>findClass方法</p>
<p>把自定义的类加载逻辑写在findClass()方法中,通过loadClass方法调用，当loadClass()方法中父加载器加载失败后，则调用自己的findClass()方法来完成类加载，这样就可以保证自定义的类加载器也符合双亲委托模式。</p>
<p> <img src="/posts/23682/asset/v2-6264d1147e435512018bd3f10a92bfb8_720w.webp" alt="img"> </p>
<p>defineClass方法</p>
<p>将byte字节流解析成JVM能够识别的Class对象，与findClass结合使用。</p>
<p> <img src="/posts/23682/asset/v2-b2627ce28db45d7e44488c5244d92b7e_720w.webp" alt="img"> </p>
<p>resolveClass方法</p>
<p>为类变量分配内存并设置初始值同时将字节码文件中的符号引用转换为直接引用。</p>
]]></content>
      <categories>
        <category>基础知识</category>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>基础知识</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title>垃圾回收机制及算法</title>
    <url>/posts/12926/</url>
    <content><![CDATA[<h3 id="垃圾回收的概述"><a href="#垃圾回收的概述" class="headerlink" title="垃圾回收的概述"></a>垃圾回收的概述</h3><p>垃圾收集被称为GC，判断对象是否还存活进行回收，垃圾回收作用的区域就是堆区和方法区，主要是堆区。</p>
<p>垃圾回收可以有效的防止内存泄漏，有效的利用可使用的内存，不用考虑内存的管理，但是自动内存管理对于检测内存泄漏和内存溢出问题更加困难。</p>
<h3 id="引用计数法"><a href="#引用计数法" class="headerlink" title="引用计数法"></a>引用计数法</h3><p>给每个创建的对象添加一个引用计数器，每当有一个地方引用此对象时，计数器就加1，引用失效就减1，为0表示对象不能被使用。缺点：如果A和B互相引用，却没被其他任何对象引用，那么这个两个对象其实已经是垃圾对象，但是他们引用数不为0，无法回收，java并没有使用此算法，所以循环引用的对象仍然会被回收。</p>
<h3 id="可达性分析算法"><a href="#可达性分析算法" class="headerlink" title="可达性分析算法"></a>可达性分析算法</h3><p> 可达性分析算法是主流编程语言使用的垃圾回收算法。通过一系列的“GC Roots”的对象作为起始点，从起始点开始向下搜索到对象的路径。搜索所经过的路径称为引用链(Reference Chain)，当一个对象到任何GC Roots都没有引用链时，则表明对象“不可达”，即该对象是不可用的。其实就是从各种根节点往下搜，不可达就是垃圾对象。 </p>
<p> <img src="https://pic3.zhimg.com/80/v2-30ec7652d2f36542e17ef76085e3cab6_720w.webp" alt="img"> </p>
<p>可作为GC Roots的对象：</p>
<p>栈帧中的局部变量表中的reference引用所引用的对象</p>
<p>方法区中static静态引用的对象</p>
<p>方法区中final常量引用的对象</p>
<p>本地方法栈中JNI(Native方法)引用的对象</p>
<p>Java虚拟机内部的引用</p>
<p>所有被同步锁（synchronized关键字） 持有的对象</p>
<p> <img src="/posts/12926/asset/v2-a1e2651fd85e7901ad2b86f51bfe2ab5_720w.webp" alt="img"> </p>
<h3 id="判断对象是否存活"><a href="#判断对象是否存活" class="headerlink" title="判断对象是否存活"></a>判断对象是否存活</h3><p> 在可达性分析算法中判定为不可达的对象， 也不是“非死不可”的， 这时候它们暂时还处于“缓刑”阶段， 要真 </p>
<p>正宣告一个对象死亡， 至少要经历两次标记过程。</p>
<p>第一次标记：对象在进行可达性分析后发现没有与GC Roots相连接的引用链，做第一次标记，标记之后再判断这个对象是否要执行finalize()方法，此方法就是为回收对象创造的逃脱机制。如果没有重写finalize方法或者finalize方法已经被虚拟机调用了，那就按原本计划下去，直到被回收。如果重写了finalize()方法，该对象将会被放置在一个名为F-Queue的 队列之中，之后收集器将对F-Queue中的对象进行第二次小规模的标记，如果此时对象重新与引用链上的任何一个对象建立关联，即可逃脱被垃圾回收的命运，由于finalize方法只会被执行一次，因此自救也只会有一次。</p>
<p>  <img src="https://pic2.zhimg.com/80/v2-31b34fa483953fbfbdbc9bd303e1d8a5_720w.webp" alt="img"> </p>
<h3 id="对象的引用"><a href="#对象的引用" class="headerlink" title="对象的引用"></a>对象的引用</h3><p>JDK1.2之后，Java对引用的概念做了扩充，将引用分为 强引用(Strong Reference) 、 软引用(Soft Reference) 、 弱引用(Weak Reference) 和 虚引用(Phantom Reference) 四种，这四种引用的强度依次递减。</p>
<p> <strong>强引用</strong>：强引用是使用最普遍的引用。如果一个对象具有强引用，那垃圾回收器绝不会回收它。当内存空间不足，Java虚拟机宁愿抛出OutOfMemoryError错误，使程序异常终止，也不会靠随意回收具有强引用的对象来解决内存不足的问题。比如我们常用的 A a &#x3D; new A就是强引用。 </p>
<p> <strong>软引用</strong>：如果一个对象只具有软引用，则内存空间足够，垃圾回收器就不会回收它；如果内存空间不足了，就会回收这些对象的内存。只要垃圾回收器没有回收它，该对象就可以被程序使用。 软引用可以和一个引用队列 ReferenceQueue联合使用，如果软引用所引用的对象被垃圾回收器回收，Java虚拟机就会把这个软引用加入到与之关联的引用队列中。</p>
<p> <strong>弱引用</strong>：用来描述那些非必须对象， 但是它的强度比软引用更弱一些， 被弱引用关联的对象只能生存到下一次垃圾收集发生为止。当垃圾收集器开始工作， 无论当前内存是否足够，都会回收掉只被弱引用关联的对象。弱引用相比较于软引用生命周期更短，且内存是否充足不影响回收。 </p>
<p> <strong>虚引用</strong>：最弱的一种引用关系。如果一个对象仅持有虚引用，在任何时候都可能被垃圾回收器回收。虚引用主要用来跟踪对象被垃圾回收器回收的活动。虚引用必须和引用队列 ReferenceQueue联合使用，当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中。 </p>
<h3 id="分代收集理论"><a href="#分代收集理论" class="headerlink" title="分代收集理论"></a>分代收集理论</h3><p>根据对象的生命周期将内存划分，然后进行分区管理，他建立在两个分代假说上：弱分代假说和强分代假说，即大部分对象很快被回收，但是对象经过的回收次数越多越难被回收。</p>
<p>垃圾收集器的一致的设计原则：收集器应该将Java堆划分出不同的区域，然后将回收对象依据其年龄（年龄即对象熬过垃圾收集过程的次数） 分配到不同的区域之中存储。如果一个区域中大多数对象都是朝生夕灭， 难以熬过垃圾收集过程的话，那么把它们集中放在一起， 每次回收时只关注如何保留少量存活而不是去标记那些大量将要被回收的对象， 就能以较低代价回收到大量的空间；如果剩下的都是难以消亡的对象， 那把它们集中放在一块， 虚拟机便可以使用较低的频率来回收这个区域， 这就同时兼顾了垃圾收集的时间开销和内存的空间有效利用。</p>
<p>回收类型的划分：</p>
<p>部分收集（Partial GC）：新生代收集（Minor GC&#x2F;Young GC）、老年代收集（Major GC&#x2F;Old GC） CMS、混合收集（Mixed GC）G1</p>
<p> 整堆收集（Full GC）：收集整个Java堆和方法区的垃圾收集 </p>
<p> <img src="/posts/12926/asset/v2-22ff06038d9ef7b48766811d913313c8_720w.webp" alt="img"> </p>
<h3 id="标记-清除算法"><a href="#标记-清除算法" class="headerlink" title="标记-清除算法"></a>标记-清除算法</h3><p>算法分为“标记”和“清除”两个阶段： 首先标记出所有需要回收的对象，在标记完成后，统一回收掉所有被标记的对象，也可以反过来，标记存活的对象，统一回收所有未被标记的对象。</p>
<p>  <img src="https://pic2.zhimg.com/80/v2-10541a492bb82c3c2bd84f793e42a625_720w.webp" alt="img"> </p>
<p>缺点：</p>
<p>1） 效率低，标记和清除两个过程的执行效率随对象数量增长而降低；</p>
<p>2） 内存空间的碎片化，标记-清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致当以后在程序运行过程中需要分配较大对象时无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。</p>
<h3 id="标记-复制算法"><a href="#标记-复制算法" class="headerlink" title="标记-复制算法"></a>标记-复制算法</h3><p> 决标记-清除算法面对大量可回收对象时执行效率低的问题，内存按容量划分为大小相等的两块，每次只使用其中的一块。 当这一块的内存用完了， 就将还存活的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉，因此也不用考虑内存空间碎片的复杂情况。 </p>
<p> <img src="/posts/12926/asset/v2-fe0eaa58f61e159e793f62e8cf52e2d4_720w.webp" alt="img"> </p>
<p>缺点：</p>
<p>1） 需要两倍空间，也就是需要提前预留一半的内存区域用来存放存活的对象，可用空间少了，总体GC频率增高</p>
<p>2） 存活对象数量越多，需要复制的对象就越多，成本提高，效率降低</p>
<p>3） 老年代存活对象较多，无法使用这种算法。</p>
<p> HotSpot虚拟机针对堆进行了分代，年轻代分成一个Eden区和两个Survivor区，默认8:1:1，就是基于弱分代假说，即大部分对象都熬不过第一次垃圾回收，分配一块较大区域放第一次垃圾回收的对象，两个Survivor区就是为了复制存活的对象，即始终有一个Survivor区被浪费。 </p>
<h3 id="标记-整理算法"><a href="#标记-整理算法" class="headerlink" title="标记-整理算法"></a>标记-整理算法</h3><p>标记-复制算法在对象存活率较高时就要进行较多的复制操作，效率将会降低，而且复制算法浪费空间，因此结合“标记-清除”和“复制”两个算法的优点，产生了标记整理算法，即第一个阶段从根节点开始标记所有被引用对象，第二阶段遍历整个堆，把存活对象向一端移动，直接清理边界以外的内存。</p>
<p> <img src="https://pic3.zhimg.com/80/v2-609f3791afea0a15b812ece386218b92_720w.webp" alt="img"> </p>
<p>缺点：</p>
<p>移动则内存回收时会更复杂，不移动则内存分配时会更复杂，从垃圾收集的停顿时间来看，不移动对象停顿时间会更短，甚至可以不需要停顿，但是从整个程序的吞吐量来看，移动对象会更划算，根据实际场景使用相应算法。</p>
<h3 id="垃圾收集器概述"><a href="#垃圾收集器概述" class="headerlink" title="垃圾收集器概述"></a>垃圾收集器概述</h3><p>垃圾回收算法分类两类，第一类算法判断对象生死算法，引用计数法、可达性分析算法 ；第二类收集死亡对象方法有四种,标记-清除算法、标记-复制算法、标记-整理算法。一般的实现采用分代回收算法，根据不同代的特点应</p>
<p> 垃圾回收算法分类两类，第一类算法判断对象生死算法，引用计数法、可达性分析算法 ；第二类收集死亡对象方法有四种,标记-清除算法、标记-复制算法、标记-整理算法。一般的实现采用分代回收算法，根据不同代的特点应用不同的算法。垃圾回收算法是内存回收的方法论。垃圾收集器是算法的落地实现。</p>
<p> <img src="/posts/12926/asset/v2-f9fea3ba8a7a203242444724315f3024_720w.webp" alt="img"> </p>
<p><strong>串行垃圾回收（Serial）</strong></p>
<p>单线程环境设计且只使用一个线程进行垃圾回收，会暂停所有的用户线程，不适合交互性强的服务器环境。</p>
<p> <img src="/posts/12926/asset/v2-bff5492188b7d8249ccc2d59c0799e64_720w.webp" alt="img"> </p>
<p><strong>并行垃圾回收（Parallel）</strong></p>
<p>多个垃圾收集器线程并行工作，同样会暂停用户线程，适用于科学计算、大数据后台处理等多交互场景。</p>
<p><strong>并发垃圾回收（CMS）</strong></p>
<p>用户线程和垃圾回收线程同时执行，不一定是并行的，可能是交替执行，可能一边垃圾回收，一边运行应用线程，</p>
<p>不需要停顿用户线程，互联网应用程序中经常使用，适用对响应时间有要求的场景。</p>
<p> <img src="https://pic4.zhimg.com/80/v2-21950237abc711c32f6c4cc65b2ba5df_720w.webp" alt="img"> </p>
<p><strong>G1垃圾回收</strong></p>
<p>G1垃圾回收器将堆内存分割成不同的区域然后并发地对其进行垃圾回收。</p>
<p> <img src="https://pic4.zhimg.com/80/v2-44b56275c9ae2134313eb0e77df64d07_720w.webp" alt="img"> </p>
<p> <strong>组合关系，即一个回收年轻代一个回收老年代，虚线弃用，即JDK8后不能使用。</strong> </p>
<p> <img src="/posts/12926/asset/v2-b37a383977a012bf981347c95519e257_720w.webp" alt="img"> </p>
<p>DK8中默认使用组合是: Parallel Scavenge GC 、ParallelOld GC</p>
<p>JDK9默认是用G1为垃圾收集器</p>
<p>JDK14 弃用了: Parallel Scavenge GC 、Parallel OldGC并移除了 CMS GC</p>
<p><strong>GC性能指标</strong></p>
<p>吞吐量：即CPU用于运行用户代码的时间与CPU总消耗时间的比值（吞吐量 &#x3D; 运行用户代码时间 &#x2F; ( 运行用户代码时间 + 垃圾收集时间 )）。例如：虚拟机共运行100分钟，垃圾收集器花掉1分钟，那么吞吐量就是99%</p>
<p>暂停时间：执行垃圾回收时，程序的工作线程被暂停的时间</p>
<p>内存占用：java堆所占内存的大小</p>
<p>收集频率：垃圾收集的频次</p>
<h3 id="Serial收集器"><a href="#Serial收集器" class="headerlink" title="Serial收集器"></a>Serial收集器</h3><p>单线程收集器，使用标记-复制算法，“单线程”的意义不仅仅说明它只会使用一个CPU或一个收集线程去完成垃圾收集工作；更重要的是它在垃圾收集的时候，必须暂停其他工作线程，直到垃圾收集完毕；目前基本被弃用，不过Serial收集器由于简单并且高效，因为Serial收集器没有线程间的交互，通过-XX:+UseSerialGC配置。</p>
<h3 id="ParNew-收集器"><a href="#ParNew-收集器" class="headerlink" title="ParNew 收集器"></a>ParNew 收集器</h3><p>ParNew收集器实质上是Serial收集器的多线程并行版本，使用标记-复制算法，多CPU效率更高，但是垃圾收集的时候仍然需要暂停其他工作线程来工作。ParNew收集器在单CPU服务器上的垃圾收集效率绝对不会比Serial收集器高；但是在多CPU服务器上，效果会明显比Serial好，通过-XX:+UseParNewGC配置，并通过- XX:ParllGCThreads指定线程数。</p>
<h3 id="Parallel-Scavenge收集器"><a href="#Parallel-Scavenge收集器" class="headerlink" title="Parallel Scavenge收集器"></a>Parallel Scavenge收集器</h3><p>吞吐量优先收集器，和ParNew收集器类似，是一个新生代收集器。使用复制算法的并行多线程收集器。Parallel Scavenge是Java1.8默认的收集器，特点是并行的多线程回收，以吞吐量优先。适合后台运算，交互不多的任务。</p>
<p>推荐组合方式 Parallel Scavenge GC+ Parallel Old GC 适用于JDK1.6以上，无法和CMS组合。</p>
<p><strong>特点</strong></p>
<p>1）Parallel Scavenge收集器的目标是达到一个可控制的吞吐量（Throughput）； 吞吐量&#x3D;运行用户代码时间&#x2F;(运行用户代码时间+垃圾收集时间) (虚拟机总共运行100分钟，垃圾收集时间为1分钟，那么吞吐量就是99%)</p>
<p>2）自适应调节策略,自动指定年轻代、Eden、Survivor区的比例。</p>
<p><strong>参数设置</strong></p>
<p>-XX:+UseParallelGC ：使用此收集器</p>
<p>-XX:MaxGCPauseMillis ：最大垃圾收集停顿时间，毫秒级，不是越小越好，时间越短，那么就是空间换时间的策略，新生代就会变小，收集频率高了，即多次收集累加停顿时间会延长，造成吞吐量下降。</p>
<p>-XX:GCTimeRatio：大于0小于100的整数，即假设GCTimeRatio的值为n，那么系统将花费不超过1&#x2F;(1+n)的时间用于垃圾收集，默认99%。</p>
<p>- XX:ParllGCThreads：设置年轻代线程数，小于等于8默认等于CPU核心数，大于8设置3+(5*CPU_COUNT)&#x2F;8。</p>
<p>-XX:+UseAdaptiveSizePolicy：虚拟机会根据系统运行情况进行自适应调节年轻代、Eden、Suvisor区的比例，晋升老年代的对象年龄等。</p>
<h3 id="Serial-Old收集器"><a href="#Serial-Old收集器" class="headerlink" title="Serial Old收集器"></a>Serial Old收集器</h3><p>Serial Old是Serial收集器的老年代版本，它同样是一个单线程收集器，使用标记-整理算法。在JDK1.5及之前，与Parallel Scavenge收集器搭配使用，Parallel Scavenge收集器架构中本身有PS MarkSweep收集器来进行老年代收集，但是他与Serial Old的实现几乎一样，所以两者并没有做任何区别。通过配置-XX:+UseSerialGC使用。</p>
<h3 id="Parallel-Old收集器"><a href="#Parallel-Old收集器" class="headerlink" title="Parallel Old收集器"></a>Parallel Old收集器</h3><p>Parallel Old是Parallel Scavenge收集器的老年代版本，支持多线程并发收集，基于标记-整理算法实现，JDK6出现的，用于代替JDK6之前组合老年代的Serial Old收集器，适用于多CPU模式，在注重吞吐量以及CPU资源敏感的场景非常适合。通过配置-XX:+UseParallelOldGC来使用此收集器</p>
<p> <img src="https://pic4.zhimg.com/80/v2-f4cb4afef84a1a8d07376570d82b9823_720w.webp" alt="img"> </p>
<h3 id="CMS-收集器"><a href="#CMS-收集器" class="headerlink" title="CMS 收集器"></a>CMS 收集器</h3><p>老年代垃圾收集器，以获取最短垃圾收集停顿时间为目标的收集器，尽可能缩短垃圾收集时用户线程的停顿时间，适用于与用户交互的程序，系统停顿时间最短，给用户带来良好的体验，CMS收集器使用的算法是标记-清除算法实现。</p>
<p><strong>CMS垃圾收集过程</strong></p>
<p>初始标记-&gt;并发标记-&gt;重新标记-&gt;并发清除</p>
<p>初始标记和重新标记都会停止所有线程，时间较短。最消耗时间的并发标记与并发清除阶段都不需要暂停工作。</p>
<p> <img src="https://pic4.zhimg.com/80/v2-1cef2b657631b1e9322ad3f9ad2f705b_720w.webp" alt="img"> </p>
<p>初始标记（Initial-Mark）阶段：暂停所有工作线程，标记GC Roots 能够关联到的对象。</p>
<p>并发标记（Concurrent-Mark）阶段：从GC Roots的直接关联对象开始遍历整个对象图。</p>
<p>重新标记（Remark）阶段：由于并发标记阶段，程序的工作线程会和垃圾收集线程同时运行或者交叉运行可能造成标记产生变动，针对这部分变动的对象重新标记。</p>
<p>清除并发（Concurrent-Sweep）阶段：清理删除掉标记判断已经死亡的对象,并释放内存空间。</p>
<p><strong>CMS收集器缺点</strong></p>
<p>1）CMS收集器对CPU资源非常敏感。并发标记和并发清理阶段会因为占用了一部分线程而导致应用程序变慢，总吞吐量会降低。CMS默认启动的回收线程数是（处理器核心数量 +3） &#x2F;4，4核以下效率会明显降低。</p>
<p>2）CMS收集器无法处理浮动垃圾，因为CMS是并发的，需要预留足够内存空间提供给用户线程使用，导致不能再老年代填满之后触发回收。如果老年代已达到阀值，浮动垃圾就会晋升失败，无法到达老年代，老年代就会抛弃CMS收集器启用Serial Old收集器来进行串行化回收，消耗时间大幅度提升。</p>
<p>3）空间碎片:CMS是一款基于标记-清除算法实现的收集器，所有会有空间碎片的现象。通过-XX： CMSFullGCsBeforeCompaction参数可以设置若干次不整理空间的Full GC之后下一次Full GC整理空间，默认0即每次整理。</p>
<h3 id="并发可达性分析-三色标记"><a href="#并发可达性分析-三色标记" class="headerlink" title="并发可达性分析-三色标记"></a>并发可达性分析-三色标记</h3><p>回收过程：标记出哪些对象是存活的，哪些是垃圾，然后进行回收（清除&#x2F;复制&#x2F;整理），如果有移动过对象（复制&#x2F;整理），还需要更新引用。</p>
<p> 白色：尚未访问过。 </p>
<p> 灰色：当前对象已访问过，但是当前对象引用到的其他对象尚未全部访问完。全部访问后，会转换为黑色。 </p>
<p> 黑色：当前对象已访问过，而且当前对象引用到的其他对象也全部访问过了。 </p>
<p><strong>执行过程</strong></p>
<p>1） 初始时，所有对象都在 【白色集合】中；</p>
<p>2） 当GC Roots 直接引用到这个对象，他就会被挪到【灰色集合】中；</p>
<p>3） 再灰色集合中获取对象，如果这个对象还引用到其他对象，把其他对象移进来，自己被挪到【黑色集合】</p>
<p>4） 重复执行，直到所有对象都被查找完毕，灰色集合为空。</p>
<p>5） 剩余【白色集合】的对象即为GC Roots 不可达，进行回收。</p>
<p>当Stop The World时，对象间的引用是不会发生变化的，可以轻松完成标记。而当需要支持并发标记时，即标记期间应用线程还在继续跑，对象间的引用可能发生变化，多标和漏标的情况就有可能发生。</p>
<p> <strong>多标-浮动垃圾</strong> </p>
<p> <img src="https://pic3.zhimg.com/80/v2-dacab44ca81d7c80a44b73a26b61ac6e_720w.webp" alt="img"> </p>
<p> 标记执行到E断开了，这时候E应该白色垃圾对象，但是实际他已经被置为灰色了，所以本轮垃圾回收，他就不会被清理，但是在下一轮回收，就会被清理掉了，也被称为浮动垃圾，即本该回收却没有回收到，对程序无影响。 </p>
<p><strong>漏标</strong></p>
<p><img src="https://pic2.zhimg.com/80/v2-3af0a2a1b88eb07a056086e0aa2d926d_720w.webp" alt="img"></p>
<p>标记执行如下，D引用E，D黑色，E灰色，E引用G，下一步应该是E黑色，G灰色，但是这时候E和G之间断开了，G就成了垃圾对象，后面D又引用到了G，即D-&gt;E-&gt;G和D-&gt;G同时并发发生，因为D已经是黑色了，不会再做重新遍历处理，导致回收的时候G对象被当做垃圾回收掉，影响程序正确性。</p>
<p>漏标的两大必要条件：</p>
<p>条件一：灰色对象断开了白色对象的引用；即灰色对象原来成员变量的引用发生了变化。</p>
<p>条件二：黑色对象重新引用了该白色对象；即黑色对象成员变量增加了新的引用。</p>
<p>解决办法：将对象G记录起来，然后作为灰色对象再进行遍历即可。如定义一个集合，等初始标记完成，再次标记确定，也就是CMS中的重新标记阶段。</p>
<h3 id="G1垃圾收集器"><a href="#G1垃圾收集器" class="headerlink" title="G1垃圾收集器"></a>G1垃圾收集器</h3><p>Garbage First是一款面向服务端应用的垃圾收集器，主要针对配备多核CPU及大容量内存的机器，以极高概率满足</p>
<p>GC停顿时间的同时，还兼具高吞吐量的性能特征。</p>
<p><strong>G1的特点</strong></p>
<p>1）G1把内存划分为多个独立的区域Region</p>
<p>2）G1仍然保留分代思想,保留了新生代和老年代,但他们不再是物理隔离,而是一部分Region的集合</p>
<p>3）G1能够充分利用多CPU、多核环境硬件优势，尽量缩短暂停时间STW</p>
<p>4）G1整体采用标记整理算法,局部是采用复制算法,不会产生内存碎片</p>
<p>5）G1的停顿可预测,能够明确指定在一个时间段内,消耗在垃圾收集上的时间不超过设置时间</p>
<p>6）G1跟踪各个Region里面垃圾的价值大小,会维护一个优先列表,每次根据允许的时间来回收价值最大的区域,从 而保证在有限事件内高效的收集垃圾。</p>
<p><strong>Region区域</strong></p>
<p>G1不再坚持固定大小以及固定数量的 分代区域划分，而是把连续的Java堆划分为多个独立区域（Region），每一 个Region都可以根据需要，扮演新生代的Eden空间、Survivor空间，或者老年代空间。</p>
<p> <img src="/posts/12926/asset/v2-460cca85f19705919c313312c6c7d52f_720w.webp" alt="img"> </p>
<p>1） G1收集器时，它将整个Java堆划分成约2048个大小相同的独立Region块，每个块大小可浮动，为2的次幂，即2M、4M等等。</p>
<p>2） 新生代和老年代不是物理隔离,它们都是一部分Region的集合。</p>
<p>3） G1垃圾收集器新增Humongous内存区域，用于存储大对象，即超过1 .5个region块。</p>
<p><strong>G1垃圾回收过程</strong></p>
<p>G1提供了两种GC模式，Young GC（年轻代）和Mixed GC（年轻代和老年代），两种均是完全Stop The World的。</p>
<p>Young GC：选定所有年轻代里的Region。通过控制年轻代的region个数，即年轻代内存大小，来控制young GC 的时间开销。</p>
<p>Mixed GC：选定所有年轻代里的Region，外加根据global concurrent marking统计得出收集收益高的若干老年代 Region，因为老年代也是一个个的region块，通过统计得出最大收益的块进行回收。</p>
<p>初始标记 :和CMS一样只标记GC Roots直接关联的对象。</p>
<p>并发标记 :进行GC Roots Traceing过程。</p>
<p>最终标记 :修正并发标记期间,因程序运行导致发生变化的那一部分对象，计算所有区域活跃度并且回收已经标记死亡的对象，活跃度计算规则，即这个区域的对象是否还在频繁被引用等等，活跃低就说明快要挂了。</p>
<p>筛选回收 :根据时间来进行价值最大化收集。</p>
<p> <img src="/posts/12926/asset/v2-2e8ed16fef2e013acb4ec0fd0b0a780c_720w.webp" alt="img"><br>   <strong>Young GC</strong></p>
<p>对年轻代所有对象进行标记，如果是垃圾就清理，如果不是就复制到幸存者区域，当次数达到阀值，再复制到老年区，年轻代的GC会出现SWT，并且使用多个线程并行完成。</p>
<p><strong>Mixed GC</strong></p>
<p>初始标记阶段：对存活对象进行标记。</p>
<p>并发标记阶段：用户线程和标记一起运行，找到空白区域，进行删除标记，并且根据并发用户线程运行计算区域活跃度。</p>
<p>最终标记阶段：清理删除标记的区域，使用快照（SATB）算法。</p>
<p>筛选回收阶段：使用复制&#x2F;整理算法对活跃度最低的区域进行最快地收集，这里老年代的GC和年轻代GC是一起垃圾收集的。</p>
<p> <strong>G1常用参数</strong> </p>
<p> <img src="/posts/12926/asset/v2-b52877f81fd1cf5129a6bc2300813bb4_720w.webp" alt="img"> </p>
]]></content>
      <categories>
        <category>基础知识</category>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>基础知识</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title>常用指令与可视化调试工具</title>
    <url>/posts/34961/</url>
    <content><![CDATA[<h3 id="jps指令"><a href="#jps指令" class="headerlink" title="jps指令"></a>jps指令</h3><p>Java版的ps命令，查看java进程及其相关的信息。</p>
<p>命令格式：jps [options] [hostid]</p>
<p>options参数解释：</p>
<p>-l : 显示进程id,显示主类全名或jar路径</p>
<p>-q : 显示进程id</p>
<p>-m : 显示进程id, 显示JVM启动时传递给main()的参数</p>
<p>-v : 显示进程id,显示JVM启动时显示指定的JVM参数</p>
<p>hostid : 主机或其他服务器ip</p>
<h3 id="jinfo指令"><a href="#jinfo指令" class="headerlink" title="jinfo指令"></a>jinfo指令</h3><p>常用指令之一，主要用来查看JVM参数和动态修改部分JVM参数的命令。</p>
<p>命令格式：jinfo [options] <pid></p>
<p>options参数解释：</p>
<p>no options 输出所有的系统属性和参数</p>
<p>-flag 打印指定名称的参数</p>
<p>-flag [+|-] 打开或关闭参数</p>
<p>-flag &#x3D; 设置参数</p>
<p>-flags 打印所有参数</p>
<p>-sysprops 打印系统配置</p>
<h3 id="jstat指令"><a href="#jstat指令" class="headerlink" title="jstat指令"></a>jstat指令</h3><p>常用指令之一，主要用来查看JVM运行时的状态信息，包括内存状态、垃圾回收等。</p>
<p>命令格式：jstat [option] VMID [interval] [count ]</p>
<p>VMID是进程id，interval是打印间隔时间（毫秒），count是打印次数（默认一直打印）。</p>
<p>option参数解释：</p>
<p>-class class loader的行为统计</p>
<p>-compiler HotSpt JIT即时编译器行为统计</p>
<p>-gc 垃圾回收堆的行为统计</p>
<p>-gccapacity 各个垃圾回收代容量(young,old,perm)和他们相应的空间统计</p>
<p>-gcutil 垃圾回收统计概述</p>
<p>-gccause 垃圾收集统计概述（同-gcutil），附加最近两次垃圾回收事件的原因</p>
<p>-gcnew 新生代行为统计</p>
<p>-gcnewcapacity 新生代与其相应的内存空间的统计</p>
<p>-gcold 年老代和永生代行为统计</p>
<p>-gcoldcapacity 年老代行为统计</p>
<p>-printcompilation HotSpot编译方法统计</p>
<p>查看GC堆容量使用情况 jstat -gc 2708 200 10</p>
<p> <img src="/posts/34961/asset/v2-30a7af7abe09bf0ac0072d3b529c9592_720w.webp" alt="img"> </p>
<p>0C幸存0区容量、S0U幸存0区已使用量、EC Eden区总量、EU Eden区已使用量、OC老年区总容量、OU老年区已使用总量、MC方法区总量、MU方法去已使用量、CCSC压缩空间总量、CCSU压缩已使用量、YGC 年轻代垃圾回收次数、YGCT 年轻代执行垃圾回收消耗时间、FGC Full GC垃圾回收次数、FGCT Full GC垃圾回收消耗时间、GCT 垃圾回收消耗总时间</p>
<p>查看GC堆百分比占比情况jstat -gcutil 2708 200 3</p>
<p> <img src="/posts/34961/asset/v2-a96e660cfbe703435a92eff10a356970_720w.webp" alt="img"> </p>
<p> S0 幸存0区使用百分比、E Eden区使用百分比、O 老年代使用百分比、M 元数据区使用百分比、CCS 压缩使用百分比 </p>
<p> <strong>示例：3次创建byte对象，GC垃圾回收情况，对象从年轻代晋升到老年代。</strong> </p>
<p> <img src="/posts/34961/asset/v2-4a9502720c9c3c9f598bd43a2b888630_720w.webp" alt="img"> </p>
<h3 id="jstack指令"><a href="#jstack指令" class="headerlink" title="jstack指令"></a>jstack指令</h3><p>查看JVM线程快照的命令，线程快照是当前JVM线程正在执行的方法堆栈集合，定位线程出现长时间卡顿的原因，例如死锁，死循环等。</p>
<p>命令格式：jstack [options]</p>
<p>option参数解释：</p>
<p>-F 当使用jstack 无响应时，强制输出线程堆栈。</p>
<p>-m 同时输出java堆栈和c&#x2F;c++堆栈信息(混合模式)</p>
<p>-l 除了输出堆栈信息外,还显示关于锁的附加信息，如死锁。</p>
<p><strong>cpu占用过高问题排查</strong></p>
<p>1）使用Process Explorer工具找到cpu占用率较高的线程</p>
<p>2）在thread卡中找到cpu占用高的线程id</p>
<p>3）线程id转换成16进制</p>
<p>4）使用jstack -l 查看进程的线程快照 根据16进制id找到对应线程</p>
<p>5）线程快照中找到指定线程,并分析代码</p>
<h3 id="jmap指令"><a href="#jmap指令" class="headerlink" title="jmap指令"></a>jmap指令</h3><p>jmap可以生成 java 程序的 dump 文件， 也可以查看堆内对象示例的统计信息、查看 ClassLoader 的信息以及 finalizer 队列</p>
<p>命令格式：jmap [option] (连接正在执行的进程) 不加参数默认打印所有</p>
<p>option参数解释：</p>
<p>-heap 打印java heap摘要</p>
<p>-histo[:live] 打印堆中的java对象统计信息</p>
<p>-clstats 打印类加载器统计信息</p>
<p>-finalizerinfo 打印在f-queue中等待执行finalizer方法的对象</p>
<p>-dump: 生成java堆的dump文件</p>
<h3 id="jhat指令"><a href="#jhat指令" class="headerlink" title="jhat指令"></a>jhat指令</h3><p>jhat是用来分析jmap生成dump文件的命令，jhat内置了应用服务器，可以通过网页查看dump文件分析结果，jhat一般是用在离线分析上。</p>
<p>命令格式 : jhat [option][dumpfile]</p>
<p>option参数解释：</p>
<p>-stack false: 关闭对象分配调用堆栈的跟踪</p>
<p>-refs false: 关闭对象引用的跟踪</p>
<p>-port : HTTP服务器端口，默认是7000 -debug : debug级别</p>
<p>-version 分析报告版本</p>
<h3 id="jconsole-监控管理工具"><a href="#jconsole-监控管理工具" class="headerlink" title="jconsole 监控管理工具"></a>jconsole 监控管理工具</h3><p>java5开始，在JDK中自带的java监控和管理控制台，用于对JVM中内存，线程和类等的监控，是一个基于JMX的GUI性能监测工具。</p>
<p> <img src="/posts/34961/asset/v2-6d6f3fb255547206b62d5468951a1043_720w.webp" alt="img"> </p>
<h3 id="VisualVM-可视化优化工具"><a href="#VisualVM-可视化优化工具" class="headerlink" title="VisualVM 可视化优化工具"></a>VisualVM 可视化优化工具</h3><p>VisualVM 是一个工具，它提供了一个可视界面，用于查看 Java 虚拟机 (Java Virtual Machine, JVM) 上运行的基于 Java 技术的应用程序（Java 应用程序）的详细信息，如果存在死锁等异常问题会直接警告，然后根据警告找到线程定位到对应代码。</p>
<p><img src="/posts/34961/asset/v2-4cc3fa0dcd06aea3373399d22df1806c_720w.webp" alt="img"></p>
<h3 id="六、GC日志分析"><a href="#六、GC日志分析" class="headerlink" title="六、GC日志分析"></a>六、GC日志分析</h3><h3 id="GC日志参数"><a href="#GC日志参数" class="headerlink" title="GC日志参数"></a>GC日志参数</h3><p>GC日志是一个很重要的工具，它准确记录了每一次的GC的执行时间和执行结果，通过分析GC日志可以优化堆设置 和GC设置，或者改进应用程序的对象分配模式。</p>
<p> <img src="https://pic3.zhimg.com/80/v2-2bdf38c2aea5ef897990fc9baba52a5e_720w.webp" alt="img"> </p>
<p> <strong>常用垃圾收集器参数</strong> </p>
<p> <img src="/posts/34961/asset/v2-6fe1716284f65558aa14dea28559fc6b_720w.webp" alt="img"> </p>
<h3 id="GC日志分析"><a href="#GC日志分析" class="headerlink" title="GC日志分析"></a>GC日志分析</h3><p>比如日志格式如下</p>
<p>比如日志格式如下</p>
<p><img src="/posts/34961/asset/v2-b4cab45de9a831ae75373c4df411b2ce_720w.webp" alt="img"></p>
<p>进行抽象化</p>
<p><img src="https://pic2.zhimg.com/80/v2-ce187d3551e0f6c73840969afc60cba9_720w.webp" alt="img"></p>
<p>a: GC 或者是 Full GC</p>
<p>b: 用来说明发生这次 GC 的原因</p>
<p>c: 表示发生GC的区域，这里表示是新生代发生了GC，上面那个例子是因为在新生代中内存不够给新对象分配了，然后触发了 GC</p>
<p>d: GC 之前该区域已使用的容量</p>
<p>e: GC 之后该区域已使用的容量</p>
<p>f: 该内存区域的总容量</p>
<p>g: 表示该区域这次 GC 使用的时间</p>
<p>h: 表示 GC 前整个堆的已使用容量</p>
<p>i: 表示 GC 后整个堆的已使用容量</p>
<p>j: 表示 Java 堆的总容量</p>
<p>k: 表示 Java堆 这次 GC 使用的时间</p>
<p>l: 代表用户态消耗的 CPU 时间</p>
<p>m: 代表内核态消耗的 CPU 时间</p>
<p>n: 整个 GC 事件从开始到结束的墙钟时间（Wall Clock Time）</p>
<p>大对象直接进入老年代，虚拟机提供一个参数 -XX:PretenureSizeThreshold 用来设置直接在老年代分配的对象的大小，如果对象大于这个值就会直接在老年代分配，避免Eden区和Survivor区复制消耗性能。</p>
<h3 id="日志分析工具"><a href="#日志分析工具" class="headerlink" title="日志分析工具"></a>日志分析工具</h3><p>GC日志可视化分析工具GCeasy（在线的GC日志分析器 在线地址<a href="https://link.zhihu.com/?target=https://gceasy.io/index.jsp">https://gceasy.io/index.jsp</a>）和GCviewer（免费开源软件），通过这些工具可以直接看到JVM各个分代的内存使用情况、垃圾回收次数、垃圾回收的原因、垃圾回收占用的时间、吞吐量等。</p>
<p> <img src="https://pic3.zhimg.com/80/v2-5a7bd0fd1cac0ee875d315c76206af0e_720w.webp" alt="img"> </p>
<h3 id="七、JVM调优实战"><a href="#七、JVM调优实战" class="headerlink" title="七、JVM调优实战"></a>七、JVM调优实战</h3><h3 id="Tomcat与JVM调优"><a href="#Tomcat与JVM调优" class="headerlink" title="Tomcat与JVM调优"></a>Tomcat与JVM调优</h3><p>修改tomcat-users.xml 配置tomcat管理用户</p>
<p> <img src="/posts/34961/asset/v2-768fb9fceab6d9824ffe8d10f9c5fdee_720w.webp" alt="img"> </p>
<p> <img src="/posts/34961/asset/v2-03b9194f5b04ad88f987d52353c8d2dc_720w.webp" alt="img"> </p>
<h3 id="Apache-Jmeter测试工具"><a href="#Apache-Jmeter测试工具" class="headerlink" title="Apache Jmeter测试工具"></a>Apache Jmeter测试工具</h3><p>Apache Jmeter是开源的压力测试工具，我们借助于此工具进行测试，将测试出tomcat 的吞吐量等信息。</p>
<p>下载地址：<a href="https://link.zhihu.com/?target=http://jmeter.apache.org/download_jmeter.cgi">http://jmeter.apache.org/download_jmeter.cgi</a></p>
<p><img src="/posts/34961/asset/v2-ebc60e79c65fa990e3d99c3c15cfb6bf_720w.webp" alt="img"></p>
<p><img src="/posts/34961/asset/v2-d2bce287563520ace265002bd94f2623_720w.webp" alt="img"></p>
<h3 id="调整tomcat参数进行优化"><a href="#调整tomcat参数进行优化" class="headerlink" title="调整tomcat参数进行优化"></a>调整tomcat参数进行优化</h3><p>1） 禁用AJP服务，AJP是定向包协议，Tomcat在 server.xml 中配置了两种连接器，一种监听8080，负责和其他的HTTP服务器建立连接，一种监听8009，负责和其他的HTTP服务器建立连接，第二种如要要用可以配置nginx实现负载均衡，所以可以直接注释掉。</p>
<p><img src="https://pic4.zhimg.com/80/v2-9a5e87aeca057b69bd3800a22bce608f_720w.webp" alt="img"></p>
<p>2） 设置执行器(线程池)，频繁地创建线程会造成性能浪费，所以使用线程池来优化，通过修改server.xml文件</p>
<p><img src="/posts/34961/asset/v2-96f56a9a910a1f0777a89c4793149790_720w.webp" alt="img"></p>
<p>3） 设置最大等待队列，默认情况下，请求发送到tomcat，如果tomcat正忙，那么该请求会一直等待，可以设置超过就不等待，请求失败，降低服务器负载。</p>
<p><img src="https://pic3.zhimg.com/80/v2-eb62e81fef70afcac9b83ccea14d26c2_720w.webp" alt="img"></p>
<p>4） 设置nio2的运行模式，tomcat8以前默认是bio，同步并阻塞，性能低下无优化，8之后是nio，同步非阻塞，还有个性能更高的nio2，异步非阻塞，可以更改设置。</p>
<p><img src="https://pic4.zhimg.com/80/v2-f2611c4638799daca59262b434e1102b_720w.webp" alt="img"></p>
<h3 id="调整JVM参数进行优化"><a href="#调整JVM参数进行优化" class="headerlink" title="调整JVM参数进行优化"></a>调整JVM参数进行优化</h3><p>1） 设置并行垃圾回收器，提高并发效率。</p>
<p>修改catalina.sh</p>
<p><img src="/posts/34961/asset/v2-908b0acf5c91622709d3990f05983a8a_720w.webp" alt="img"></p>
<p>2） 通过GC easy查看GC日志文件，查看年轻代和老年代空间大小分配是否合理并调整优化。</p>
<p><img src="https://pic3.zhimg.com/80/v2-dfc17b51ab661dddff0f4c3cf2a89ea6_720w.webp" alt="img"></p>
<p>修改catalina.sh</p>
<p><img src="/posts/34961/asset/v2-e622a0aaff1b791169cd59a672743a52_720w.webp" alt="img"></p>
<p>3） 设置G1垃圾收集器，G1的性能是非常强悍的，能用G1的情况下优先使用，能极大提高程序运行性能。</p>
<p>修改catalina.sh</p>
<p><img src="/posts/34961/asset/v2-6471820880d2f347a6d6d76e736bb084_720w.webp" alt="img"></p>
<h3 id="八、Linux优化"><a href="#八、Linux优化" class="headerlink" title="八、Linux优化"></a>八、Linux优化</h3><h3 id="Linux性能优化概述"><a href="#Linux性能优化概述" class="headerlink" title="Linux性能优化概述"></a>Linux性能优化概述</h3><p>Linux性能的基本指标、工具，相应的观测、分析和调优方法。包括CPU性能、磁盘I&#x2F;O性能、内存性能及网络性能。其实最终目的就是为了实现高并发和吞吐快，也就是延时和吞吐。</p>
<p><strong>调优的步骤</strong></p>
<p>1） 选择指标评估应用程序和系统性能</p>
<p>2） 设置性能目标</p>
<p>3） 进行性能基准测试</p>
<p>4） 性能分析，如果未达到目标，分析定位瓶颈。</p>
<p>5） 根据分析结果优化应用程序和系统</p>
<p>6） 进行性能监控和阀值警告机制</p>
<p><strong>性能优化方法论</strong></p>
<p>应用程序维度：吞吐量和请求延迟评估应用程序性能</p>
<p>系统资源维度：CPU使用率评估系统CPU使用情况</p>
<p>多个性能问题同时存在，二八原则，即优先优化问题最大最重要的，也是提示最大的。</p>
<p>多种优化方案，选择提升性能最明显的，复杂的优化方案会降低程序可维护性。</p>
<h3 id="Linux优化-CPU优化（性能统计）"><a href="#Linux优化-CPU优化（性能统计）" class="headerlink" title="Linux优化-CPU优化（性能统计）"></a>Linux优化-CPU优化（性能统计）</h3><p><strong>1）平均负载率</strong></p>
<p>单位时间内，系统处于可运行状态和不可中断状态的平均进程数，也就是平均活跃进程数，平均负载率高不一定CPU使用率也高，比如I&#x2F;O密集架进程，等待I&#x2F;O。</p>
<p>可运行状态的进程：正在使用CPU和等待CPU的进程，ps指令，处于R状态的进程。</p>
<p>不可中断状态的进程：处于内核态关键流程中的进程，如I&#x2F;O响应，ps指令，处于D状态的进程。</p>
<p>查看负载命令uptime</p>
<p><img src="/posts/34961/asset/v2-78c64ef28b2d3475124d482524e4ab2b_720w.webp" alt="img"></p>
<p>主要看最后三个值，也就是1分钟，5分钟，15分钟平均负载，相差不大说明系统负载稳定。</p>
<p>平均负载最理想的情况是等于CPU个数，从上图来说，如果系统只有1个CPU，1分钟的负载率就高达501%，说明有多个进程正在争抢这个CPU，已经超载，最佳方案是平均负载不能高于CPU数量的70%。</p>
<p> Linux系统压力测试工具Stress </p>
<p> <img src="/posts/34961/asset/v2-c8dcf6fcf0989dd247d1b092f4fe7260_720w.webp" alt="img"> </p>
<p>Linux系统性能监控和分析工具Sysstat</p>
<p>mpstat命令：实时查看每个CPU的性能指标以及所有CPU的平均指标。</p>
<p>pidstat命令：实时查看进程的CPU、内存、I&#x2F;O以及上下文切换等性能指标。</p>
<p> <img src="/posts/34961/asset/v2-af70e393d888d502b03f1b651a063688_720w.webp" alt="img"> </p>
<p><strong>2）上下文切换</strong></p>
<p>Linux是多任务操作系统，支持远大于CPU数量的任务同时运行，通过频繁的上下文切换，将CPU轮流分配给不同任务。CPU上下文切换就是保存当前任务的上下文，即CPU寄存器和程序计数器，加载新任务的上下文到CPU寄存器和程序计数器中，调转程序计数器所指的新位置，运行新任务，保存的上下文存储在系统中，通过任务重新调度执行加载。</p>
<p>上下文切换时机：</p>
<p>CPU会给每一个进程划分时间片，时间片耗尽上下文切换。</p>
<p>进程资源不足，如内存不够，就挂起</p>
<p>通过sleep函数休眠</p>
<p>有优先级更高的进程</p>
<p>发生故障，硬件中断。</p>
<p>发生故障，硬件中断。</p>
<p><img src="https://pic3.zhimg.com/80/v2-481f72e193a21cca694a29003a67ffaa_720w.webp" alt="img"></p>
<p>从Ring 0 内核空间即内核态到Ring 3用户空间即用户态权限递减，即Ring 0能访问所有。</p>
<p>进程的上下文切换：一个进程到另一个进程</p>
<p>系统调用：同一个进程运行，即上面模型图中的特权模式切换，即内核态和用户态切换，比如读取一个文件，先是把用户开发文件，保存用户态指令，然后切换到内核态执行，再切换回用户态响应结果。</p>
<p>进程上下文切换：进程是资源拥有的结伴单位，切换就两步，保存上下文，切换上下文。</p>
<p>CPU挑选进程运行原则：每个CPU都维护了一个等待队列，按优先级和CPU等待时间排序，即优先级和先入先出原则执行进程。</p>
<p>线程上下文切换：线程是调度的基本单位，切换分两种，两个线程属于不同进程和进程切换一致，属于同一进程，共有资源不动，只切换私有资源。</p>
<p>中断上下文切换：受到中断信号，保存当前进程，等待中断结束继续运行，中断优先级比进程上下文切换高，并发也不会同时发生。</p>
<p>通过<strong>vmstat</strong>工具分析上下文切换情况及中断次数</p>
<p>命令vmstat 3 5 即3秒打印一次结果一共输出5次</p>
<p><img src="/posts/34961/asset/v2-3a606c50f0f6ee9c741ee5421ed9b654_720w.webp" alt="img"></p>
<p>查看进程对应情况命令 pidstat -u -w 3</p>
<p><img src="/posts/34961/asset/v2-0b16d2591192d02fc04d876cce03ab3d_720w.webp" alt="img"></p>
<p><strong>3）CPU使用率</strong></p>
<p>单位时间内CPU的使用情况，百分比显示。CPU使用率&#x3D;1-（空间时间&#x2F;总CPU时间），性能工具是按间隔时间求平均得到使用率。</p>
<p>top(总体)、ps（所有进程）、pidstat（单个进程）是最常用性能分析工具</p>
<h3 id="Linux优化-CPU优化（调优策略）"><a href="#Linux优化-CPU优化（调优策略）" class="headerlink" title="Linux优化-CPU优化（调优策略）"></a>Linux优化-CPU优化（调优策略）</h3><p>CPU优化分应用程序维度和系统的角度，即代码工程优化和系统参数设置优化。</p>
<p>应用程序优化：排除所有不必要操作保留核心逻辑</p>
<p>1） 编译器优化，大部分编译器都提高优化选项，开启之后，在编译阶段就能对工程优化，提高性能。</p>
<p>2） 减少循环的次数、减少递归、减少动态内存分配</p>
<p>3） 算法优化，使用复杂度更低的算法。</p>
<p>4） 异步处理，提高程序并发处理能力，避免程序因等待资源一直阻塞，比如把轮询替换为事件通知。</p>
<p>5） 多线程代替多进程，多线程之前的切换比多进程切换成本低</p>
<p>6） 多用缓存，经常访问的数据和计算过程的步骤放入缓存，加快程序处理速度。</p>
<p>系统角度：利用CPU缓存的本地性并控制进程的CPU使用情况</p>
<p>1） 进程优先级调整</p>
<p>2） 进程设置资源限制，避免过多消耗系统资源</p>
<p>3） 中断负载均衡，任何中断处理程序都会消耗大量CPU资源，把中断处理过程均衡分配到多个CPU上。</p>
<h3 id="Linux优化-内存优化（性能统计）"><a href="#Linux优化-内存优化（性能统计）" class="headerlink" title="Linux优化-内存优化（性能统计）"></a>Linux优化-内存优化（性能统计）</h3><p>要先知道内存的各个内存量，才能根据指标进行优化，分系统内存和进程内存。</p>
<p>系统内存使用情况 free命令 free -h -c 2 -s 2间隔两秒输出两次 并人性化输出所有信息</p>
<p><img src="/posts/34961/asset/v2-8263bdafadac6d53de27e3830e457ec8_720w.webp" alt="img"></p>
<p>从头开始列名含义：总内存大小、已使用内存大小、未使用内存大小、共享内存大小、缓存和缓冲区内存大小、新进程可用内存大小（包含未使用和可回收内存）。</p>
<p> <img src="/posts/34961/asset/v2-fc7c273b6c3228e297db06097fc2e1a9_720w.webp" alt="img"> </p>
<p>Buffer是对磁盘数据的缓存，Cache是文件数据的缓存，读写请求都可以使用。</p>
<p>缓存和缓冲区的缓存命中率越高，使用缓存带来的收益就会越高，应用程序的性能就会越好。</p>
<p>通过top指令查看进程内存</p>
<p><img src="/posts/34961/asset/v2-e9235a51adff31ab2a3e93f759ef1ee4_720w.webp" alt="img"></p>
<p><img src="/posts/34961/asset/v2-8ded33a1217be22b02f2a91b0955512a_720w.webp" alt="img"></p>
<p><img src="https://pic2.zhimg.com/80/v2-e8a527e5e600969d37ba5ad5c4b1e511_720w.webp" alt="img"></p>
<p><img src="/posts/34961/asset/v2-36064a2617aaba1e21480aae0a2a983f_720w.webp" alt="img"></p>
<p><img src="/posts/34961/asset/v2-834df3f0e2531a3db6e2d08be5e1c52f_720w.webp" alt="img"></p>
<p><img src="/posts/34961/asset/v2-007a901417cc5657690803a599f3471f_720w.webp" alt="img"></p>
<p><img src="/posts/34961/asset/v2-b2ca9554086ad18681ccd2b875d80acc_720w.webp" alt="img"></p>
<h3 id="Linux优化-内存优化（调优策略）"><a href="#Linux优化-内存优化（调优策略）" class="headerlink" title="Linux优化-内存优化（调优策略）"></a>Linux优化-内存优化（调优策略）</h3><p>1） 禁止Swap，使用本地内存空间，避免服务器因物理内存不够用，使用Swap分区空间。</p>
<p>2） 减少内存的动态分配，使用如内存池，大页等。</p>
<p>3） 尽量使用缓存和缓冲区来访问数据。如redis组件。</p>
<p>4） 使用cgroups限制进程内存使用情况。</p>
<p>5） 通过&#x2F;proc&#x2F;pid&#x2F;oom_adj调整核心应用的oom_score，设置为0，保证内存紧张，核心应用不会被OOM杀死。</p>
<h3 id="Linux优化-磁盘IO优化（性能统计）"><a href="#Linux优化-磁盘IO优化（性能统计）" class="headerlink" title="Linux优化-磁盘IO优化（性能统计）"></a>Linux优化-磁盘IO优化（性能统计）</h3><p>文件数据的储存：超级块、索引节点区、数据块区</p>
<p>超级块：整个文件系统的状态</p>
<p>索引节点区：存储索引节点，便于查找</p>
<p>数据块区：存储文件的数据</p>
<p>1） 每秒IO数（IOPS）：每秒磁盘连续读次数和连续写次数之和。</p>
<p>2） 吞吐量（Throughput）：硬盘传输数据流的速度，即读写数据之和</p>
<p>3） 平均IO数据尺寸：吞吐量&#x2F;IO数目</p>
<p>4） 磁盘活动时间百分比：磁盘处于活动时间的比率，即磁盘利用率。</p>
<p>5） 服务时间：磁盘进行读和写执行时间。</p>
<p>6） IO等待队列长度：等待磁盘处理的IO请求长度</p>
<p>7） 等待时间：磁盘读或写等待执行的时间</p>
<p>IO性能观测工具iostat，通过他查看磁盘的使用率、IOPS、吞吐量，使用命令iostat -d -x 1</p>
<p> <img src="/posts/34961/asset/v2-ec05fbbe9aa068f7b7594552e8fa12c2_720w.webp" alt="img"> </p>
<h3 id="Linux优化-磁盘IO优化（调优策略）"><a href="#Linux优化-磁盘IO优化（调优策略）" class="headerlink" title="Linux优化-磁盘IO优化（调优策略）"></a>Linux优化-磁盘IO优化（调优策略）</h3><p>应用程序优化策略</p>
<p>1） 追加写代替随机写</p>
<p>2） 利用缓存IO降低IO次数</p>
<p>3） 使用redis外部缓存</p>
<p>4） 频繁读写同一块磁盘空间，使用mmap代替read&#x2F;write，减少内存拷贝次数</p>
<p>5） 同步写场景，将请求合并，不要多次请求同步写入磁盘。</p>
<p>6） 多应用程序共享磁盘，使用cgroups进行限制</p>
<p>文件系统优化策略</p>
<p>1） 如果做了负载均衡，选择最适配的文件系统，如Ubuntu默认ext4，CentOS 7默认xfs</p>
<p>2） 优化文件系统配置</p>
<p>3） 优化文件系统缓存</p>
<p>磁盘优化策略</p>
<p>1） 选择更好的磁盘，如固态硬盘SSD代替机械硬盘HDD</p>
<p>2） 使用RAID把多块磁盘组合成一个矩阵逻辑磁盘</p>
<p>3） 选择最合适的IO调度算法，如虚拟机和SSD使用noop调度算法，数据库应用可以改为deadline算法</p>
<p>4） 对应用程序数据进行磁盘级别隔离</p>
<p>5） 读场景较多，增大磁盘预读数据</p>
<p>6） 如果对磁盘操作频繁，调整磁盘队列的长度，增大磁盘吞吐量</p>
]]></content>
      <categories>
        <category>基础知识</category>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>基础知识</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title>kafaka相关知识</title>
    <url>/posts/4542/</url>
    <content><![CDATA[<h3 id="一、kafka架构"><a href="#一、kafka架构" class="headerlink" title="一、kafka架构"></a><strong>一、kafka架构</strong></h3><h3 id="Kafka基础知识"><a href="#Kafka基础知识" class="headerlink" title="Kafka基础知识"></a><strong>Kafka基础知识</strong></h3><p>Kafka是最初由Linkedin公司开发，是一个分布式、分区的、多副本的、多生产者、多订阅者，基于zookeeper协 调的分布式日志系统(也可以当做MQ系统)，常见可以用于webynginx日志、访问日志，消息服务等等，Linkedin于 2010年贡献给了Apache基金会并成为顶级开源项目。主要应用场景是:日志收集系统和消息系统。</p>
<p>Kafka主要设计目标如下:</p>
<p>以时间复杂度为O(1)的方式提供消息持久化能力，即使对TB级以上数据也能保证常数时间的访问性能。</p>
<p>高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒100K条消息的传输。支持KafkaServer间的消息分区，及分布式消费，同时保证每个partition内的消息顺序传输。同时支持离线数据处理和实时数据处理。支持在线水平扩展</p>
<p><img src="/posts/4542/asset/v2-295a2f08e5575c1534de3a765b477499_720w.webp" alt="img"></p>
<p>kafka是一种发布-订阅模式, 对于消息中间件，消息分推拉两种模式。Kafka只有消息的拉取，没有推送，可以通过轮询实现消息的推送。1.Kafka在一个或多个可以跨越多个数据中心的服务器上作为集群运行。</p>
<p>2.Kafka集群中按照主题分类管理，一个主题可以有多个分区，一个分区可以有多个副本分区。</p>
<p>3.每个记录由一个键，一个值和一个时间戳组成。</p>
<p>Kafka具有四个核心API:</p>
<p>1.ProducerAPI:允许应用程序将记录流发布到一个或多个Kafka主题。2.ConsumerAPI:允许应用程序订阅一个或多个主题并处理为其生成的记录流。3.StreamsAPI:允许应用程序充当流处理器，使用一个或多个主题的输入流，并生成一个或多个输出主题的 输出流，从而有效地将输入流转换为输出流。4.ConnectorAPI:允许构建和运行将Kafka主题连接到现有应用程序或数据系统的可重用生产者或使用者。例如，关系数据库的连接器可能会捕获对表的所有更改。</p>
<p><strong>Kafka优势</strong></p>
<p>1.高吞吐量:单机每秒处理几十上百万的消息量。即使存储了许多TB的消息，它也保持稳定的性能。2.高性能:单节点支持上千个客户端，并保证零停机和零数据丢失。3.持久化数据存储:将消息持久化到磁盘。通过将数据持久化到硬盘以及replication防止数据丢失。</p>
<p>4.分布式系统，无需停机就可扩展机器。</p>
<p>5.可靠性-kafka是分布式，分区，复制和容错的。</p>
<p>6.客户端状态维护：消息被处理的状态是在Consumer端维护，而不是由server端维护。当失败时能自动平衡。</p>
<p>7.支持online和offline的场景。</p>
<p>8.支持多种客户端语言。Kafka支持Java、.NET、PHP、Python等多种语言。</p>
<p><strong>Kafka应用场景</strong></p>
<p>日志收集：一个公司可以用Kafka可以收集各种服务的Log，通过Kafka以统一接口服务的方式开放给各种Consumer。</p>
<p>消息系统：解耦生产者和消费者、缓存消息等。</p>
<p>用户活动跟踪：用来记录web用户或者APP用户的各种活动，如网页搜索、搜索、点击，用户数据收集然后进行用户行为分析。</p>
<p>运营指标：Kafka也经常用来记录运营监控数据。包括收集各种分布式应用的数据，生产各种操作的集中反馈，比</p>
<p>如报警和报告；</p>
<p>流式处理：比如Spark Streaming和Storm。</p>
<h3 id="Kafka基本架构"><a href="#Kafka基本架构" class="headerlink" title="Kafka基本架构"></a><strong>Kafka基本架构</strong></h3><p><strong>消息和批次</strong></p>
<p>Kafka的数据单元称为消息。可以把消息看成是数据库里的一个“数据行”或一条“记录”，消息由字节数组组成。批次就是一组消息，这些消息属于同一个主题和分区。</p>
<p><strong>模式</strong></p>
<p>消息模式（schema）有许多可用的选项，以便于理解。如JSON和XML，但是它们缺乏强类型处理能力。Kafka的</p>
<p>许多开发者喜欢使用Apache Avro。Avro提供了一种紧凑的序列化格式，模式和消息体分开。当模式发生变化时，不需要重新生成代码，它还支持强类型和模式进化，其版本既向前兼容，也向后兼容。</p>
<p><strong>主题和分区</strong></p>
<p>Kafka的消息通过主题进行分类。主题可比是数据库的表或者文件系统里的文件夹。主题可以被分为若干分区，一</p>
<p>个主题通过分区分布于Kafka集群中，提供了横向扩展的能力。</p>
<p><strong>生产者和消费者</strong></p>
<p>生产者创建消息。消费者消费消息。消息被发布到一个特定的主题上。、</p>
<p><strong>Borker和集群</strong></p>
<p>一个独立的Kafka服务器称为broker。broker接收来自生产者的消息，为消息设置偏移量，并提交消息到磁盘保</p>
<p>存。broker为消费者提供服务，对读取分区的请求做出响应，返回已经提交到磁盘上的消息。单个broker可以轻松处理数千个分区以及每秒百万级的消息量。每个集群都有一个broker是集群控制器。</p>
<h3 id="Kafka核心概念"><a href="#Kafka核心概念" class="headerlink" title="Kafka核心概念"></a><strong>Kafka核心概念</strong></h3><p><strong>Producer</strong></p>
<p>生产者创建消息。</p>
<p><strong>Consumer</strong></p>
<p>消费者读取消息</p>
<p><strong>Broker</strong></p>
<p>一个独立的Kafka 服务器被称为broker，是集群的组成部分。</p>
<p><strong>Topic</strong></p>
<p>每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。</p>
<p><strong>Partition</strong></p>
<p>\1. 主题可以被分为若干个分区，一个分区就是一个提交日志。</p>
<p>\2. 消息以追加的方式写入分区，然后以先入先出的顺序读取。</p>
<p>\3. 无法在整个主题范围内保证消息的顺序，但可以保证消息在单个分区内的顺序。</p>
<p>\4. Kafka 通过分区来实现数据冗余和伸缩性。</p>
<p>\5. 在需要严格保证消息的消费顺序的场景下，需要将partition数目设为1。</p>
<p><strong>Replicas</strong></p>
<p>kafka 使用主题来组织数据，每个主题被分为若干个分区，每个分区有多个副本。</p>
<p><strong>Offset</strong></p>
<p>生产者Offset：消息写入的时候，每一个分区都有一个offset，这个offset就是生产者的offset，同时也是这个分区的最新最大的offset。</p>
<p>消费者Offset：某个分区的offset情况，生产者写入的offset是最新最大的值是12，而当Consumer A进行消费时，从0开始消费，一直消费到了9，消费者的offset就记录在9，Consumer B就纪录在了11。</p>
<p><strong>副本</strong></p>
<p>Kafka通过副本保证高可用。副本分为首领副本(Leader)和跟随者副本(Follower)。</p>
<p><strong>AR</strong></p>
<p>分区中的所有副本统称为AR（Assigned Repllicas），AR&#x3D;ISR+OSR。</p>
<p><strong>ISR</strong></p>
<p>所有与leader副本保持一定程度同步的副本（包括Leader）组成ISR（In-Sync Replicas），ISR集合是AR集合中</p>
<p>的一个子集。</p>
<p><strong>OSR</strong></p>
<p>与leader副本同步滞后过多的副本（不包括leader）副本，组成OSR(Out-Sync Relipcas)。</p>
<h3 id="Kafka的安装和配置"><a href="#Kafka的安装和配置" class="headerlink" title="Kafka的安装和配置"></a><strong>Kafka的安装和配置</strong></h3><p>第一步：jdk安装，上传jdk-8u261-linux-x64.rpm到服务器并安装。</p>
<p>rpm -ivh jdk-8u261-linux-x64.rpm</p>
<p>第二步：配置java环境变量</p>
<p>vim &#x2F;etc&#x2F;profile</p>
<p># 生效</p>
<p>source &#x2F;etc&#x2F;profile</p>
<p># 验证</p>
<p>java -version</p>
<p><img src="/posts/4542/asset/v2-4da982abc6fe7f1ede1dacb0dd709af0_720w.webp" alt="img"></p>
<p>第三步：上传zookeeper安装包并解压。</p>
<p>tar -zxf zookeeper-3.4.14.tar.gz</p>
<p>cd &#x2F;zookeeper-3.4.14&#x2F;conf</p>
<p># 复制zoo_sample.cfg命名为zoo.cfg</p>
<p>cp zoo_sample.cfg zoo.cfg</p>
<p># 编辑zoo.cfg文件</p>
<p>vim zoo.cfg</p>
<p>dataDir&#x3D;&#x2F;usr&#x2F;local&#x2F;zookeeper&#x2F;zookeeper-3.4.14&#x2F;data</p>
<p>第四步：配置zookeeper环境变量</p>
<p>vim &#x2F;etc&#x2F;profile</p>
<p><img src="/posts/4542/asset/v2-1ec1fae3efe56b476573ec315a6166e9_720w.webp" alt="img"></p>
<p>启动命令：zkServer.sh start 查看状态命令：zkServer.sh status</p>
<p><img src="https://pic3.zhimg.com/80/v2-d3c7336fb5b73794a3493068980613de_720w.webp" alt="img"></p>
<p>第五步：上传kafka_2.12-1.0.2.tgz到服务器并解压</p>
<p>tar -zxf kafka_2.12-1.0.2.tgz</p>
<p>第六步：配置kafka环境变量</p>
<p>vim &#x2F;etc&#x2F;profile</p>
<p><img src="/posts/4542/asset/v2-5158f11ef8852c66a196b2259acb7d03_720w.webp" alt="img"></p>
<p>第七步：修改kafka配置文件，连接zookeeper</p>
<p># 进入配置文件夹修改server.properties文件</p>
<p>cd config&#x2F;</p>
<p>vim server.properties</p>
<p><img src="/posts/4542/asset/v2-bf68a825f3d911b88699c88efe048630_720w.webp" alt="img"></p>
<p><img src="/posts/4542/asset/v2-0d4b24c09095be06652097b401ae1fe6_720w.webp" alt="img"></p>
<p><img src="https://pic3.zhimg.com/80/v2-6109289979f2ec0bf92ed756f643478a_720w.webp" alt="img"></p>
<p>第七步：启动kafka</p>
<p>kafka-server-start.sh -daemon ..&#x2F;config&#x2F;server.properties</p>
<p><img src="/posts/4542/asset/v2-cbe59c6138e89afdd6b108735a153dde_720w.webp" alt="img"></p>
<p><strong>消费和主题</strong></p>
<p># 列出现有的主题</p>
<p>[root@node1 ~]# kafka-topics.sh –list –zookeeper localhost:2181&#x2F;myKafka</p>
<p># 创建主题，该主题包含一个分区，该分区为Leader分区，它没有Follower分区副本。</p>
<p>[root@node1 ~]# kafka-topics.sh –zookeeper localhost:2181&#x2F;myKafka –create –topic topic_1 –partitions 1 –replication-factor 1</p>
<p># 查看分区信息</p>
<p>[root@node1 ~]# kafka-topics.sh –zookeeper localhost:2181&#x2F;myKafka –list</p>
<p># 查看指定主题的详细信息</p>
<p>[root@node1 ~]# kafka-topics.sh –zookeeper localhost:2181&#x2F;myKafka –describe –topic topic_1</p>
<p># 删除指定主题</p>
<p>[root@node1 ~]# kafka-topics.sh –zookeeper localhost:2181&#x2F;myKafka –delete –topic topic_1</p>
<p># 开启生产者</p>
<p>[root@node1 ~]# kafka-console-producer.sh –topic topic_1 –broker-list localhost:9020</p>
<p># 开启消费者</p>
<p>[root@node1 ~]# kafka-console-consumer.sh –bootstrap-server localhost:9092 –topic topic_1</p>
<p># 开启消费者方式二，从头消费，不按照偏移量消费</p>
<p>[root@node1 ~]# kafka-console-consumer.sh –bootstrap-server localhost:9092 –topic topic_1 –from-beginning</p>
<h3 id="Kafka消息接收和发送"><a href="#Kafka消息接收和发送" class="headerlink" title="Kafka消息接收和发送"></a><strong>Kafka消息接收和发送</strong></h3><p><img src="https://pic1.zhimg.com/80/v2-33ee6ba7eb215adc92ab28ae7737f630_720w.webp" alt="img"></p>
<p>生产者主要的对象有：KafkaProducer ，ProducerRecord 。</p>
<p>其中KafkaProducer 是用于发送消息的类，ProducerRecord 类用于封装Kafka的消息。</p>
<p>KafkaProducer 的创建需要指定的参数和含义：</p>
<p><img src="/posts/4542/asset/v2-10df6b711930f9d996004ee6bb689fe5_720w.webp" alt="img"></p>
<h3 id="二、Kafka高级特性"><a href="#二、Kafka高级特性" class="headerlink" title="二、Kafka高级特性"></a><strong>二、Kafka高级特性</strong></h3><h3 id="生产者"><a href="#生产者" class="headerlink" title="生产者"></a><strong>生产者</strong></h3><p><strong>消息发送</strong></p>
<p>流程图：</p>
<p><img src="https://pic4.zhimg.com/80/v2-3d763983e0e8dee638fb3310c45d76d3_720w.webp" alt="img"></p>
<p>\1. Producer创建时，会创建一个Sender线程并设置为守护线程。</p>
<p>\2. 生产消息时，内部其实是异步流程；生产的消息先经过拦截器-&gt;序列化器-&gt;分区器，然后将消息缓存在缓冲</p>
<p>区（该缓冲区也是在Producer创建时创建）。</p>
<p>\3. 批次发送的条件为：缓冲区数据大小达到batch.size或者linger.ms达到上限，哪个先达到就算哪个。</p>
<p>\4. 批次发送后，发往指定分区，然后落盘到broker；如果生产者配置了retrires参数大于0并且失败原因允许重</p>
<p>试，那么客户端内部会对该消息进行重试。</p>
<p>\5. 落盘到broker成功，返回生产元数据给生产者。</p>
<p>\6. 元数据返回有两种方式：一种是通过阻塞直接返回，另一种是通过回调返回。</p>
<p>配置参数：</p>
<p><img src="/posts/4542/asset/v2-671213205c0957944ebcf9ac769118ee_720w.webp" alt="img"></p>
<p><strong>序列化器</strong></p>
<p><img src="/posts/4542/asset/v2-a7e3b2c7d87583ac2612f15e546a5ba6_720w.webp" alt="img"></p>
<p>Kafka中的数据都是字节数组，将消息发送到Kafka之前需要先将数据序列化为字节数组，序列化器的作用就是用于序列化要发送的消息。</p>
<p><strong>分区器</strong></p>
<p>默认分区计算：</p>
<p>\1. 如果record提供了分区号，则使用record提供的分区号</p>
<p>\2. 如果record没有提供分区号，则使用key的序列化后的值的hash值对分区数量取模</p>
<p>\3. 如果record没有提供分区号，也没有提供key，则使用轮询的方式分配分区号。</p>
<p><strong>拦截器</strong></p>
<p>Producer拦截器（interceptor）和Consumer端Interceptor是在Kafka 0.10版本被引入的，主要用于实现Client</p>
<p>端的定制化控制逻辑。</p>
<p>Intercetpor的实现接口是org.apache.kafka.clients.producer.ProducerInterceptor，其定义的方法包括：</p>
<p>onSend(ProducerRecord)：该方法封装进KafkaProducer.send方法中，即运行在用户主线程中。Producer</p>
<p>确保在消息被序列化以计算分区前调用该方法。用户可以在该方法中对消息做任何操作，但最好保证不要修</p>
<p>改消息所属的topic和分区，否则会影响目标分区的计算。</p>
<p>onAcknowledgement(RecordMetadata, Exception)：该方法会在消息被应答之前或消息发送失败时调用，</p>
<p>并且通常都是在Producer回调逻辑触发之前。onAcknowledgement运行在Producer的IO线程中，因此不</p>
<p>要在该方法中放入很重的逻辑，否则会拖慢Producer的消息发送效率。</p>
<p>close：关闭Interceptor，主要用于执行一些资源清理工作。</p>
<p><strong>原理</strong></p>
<p><img src="/posts/4542/asset/v2-a76e24630eb52bd354e569bb54ec0cff_720w.webp" alt="img"></p>
<p>主线程：负责消息创建，拦截器，序列化器，分区器等操作，并将消息追加到消息收集器。</p>
<p>Sender线程：</p>
<p>该线程从消息收集器获取缓存的消息，将其处理为 &lt;Node, List<ProducerBatch> 的形式，表示集群的broker节点。</p>
<p>进一步将&lt;Node, List<ProducerBatch>转化为&lt;Node, Request&gt;形式，此时才可以向服务端发送数据。在发送之前，Sender线程将消息以 Map&lt;NodeId, Deque<Request>&gt; 的形式保存到InFlightRequests 中进行缓存，可以通过其获取 leastLoadedNode ,即当前Node中负载压力最小的一个，以实现消息的尽快发出。</p>
<p><img src="/posts/4542/asset/v2-b811fe1207faa5f3976da9525a2be468_720w.webp" alt="img"></p>
<p><img src="/posts/4542/asset/v2-b9ef22e0de8c94995fcdc9c348ac546d_720w.webp" alt="img"></p>
<h3 id="消费者"><a href="#消费者" class="headerlink" title="消费者"></a><strong>消费者</strong></h3><p><strong>消费组</strong></p>
<p>消费者从订阅的主题消费消息，消费消息的偏移量保存在Kafka的名字是 __consumer_offsets 的主题中，消费者还可以将自己的偏移量存储到Zookeeper，需要设置offset.storage&#x3D;zookeeper。推荐使用Kafka存储消费者的偏移量。因为Zookeeper不适合高并发。多个从同一个主题消费的消费者可以加入到一个消费组中。消费组中的消费者共享group_id。</p>
<p>消费者四种情况：</p>
<p>\1. 消费组均衡地给消费者分配分区，每个分区只由消费组中一个消费者消费。</p>
<p>\2. 消费组均衡地给消费者分配分区，每个分区只由消费组中一个消费者消费。</p>
<p>\3. 如果在消费组中添加一个消费者2，则每个消费者分别从两个分区接收消息。</p>
<p>\4. 如果消费组有四个消费者，则每个消费者可以分配到一个分区。</p>
<p>\5. 如果向消费组中添加更多的消费者，超过主题分区数量，则有一部分消费者就会闲置，不会接收任何消息。</p>
<p><img src="https://pic4.zhimg.com/80/v2-8cf187a8f07b9762195b08b5dd907acb_720w.webp" alt="img"></p>
<p><strong>心跳机制</strong></p>
<p>消费者宕机，退出消费组，触发再平衡，重新给消费组中的消费者分配分区。</p>
<p>Kafka 的心跳是 Kafka Consumer 和 Broker 之间的健康检查，只有当 Broker Coordinator 正常时，Consumer</p>
<p>才会发送心跳。broker 处理心跳的逻辑在 GroupCoordinator 类中：如果心跳超期， broker coordinator 会把消费者从 group中移除，并触发 rebalance。</p>
<p><img src="/posts/4542/asset/v2-8793dffabc86dd221f2ef0bdfe281d05_720w.webp" alt="img"></p>
<p><strong>订阅</strong></p>
<p>Topic，Kafka用于分类管理消息的逻辑单元，类似与MySQL的数据库。</p>
<p>Partition，是Kafka下数据存储的基本单元，这个是物理上的概念。同一个topic的数据，会被分散的存储到多个partition中，这些partition可以在同一台机器上，也可以是在多台机器上。优势在于：有利于水平扩展，避免单台机器在磁盘空间和性能上的限制，同时可以通过复制来增加数据冗余性，提高容灾能力。为了做到均匀分布，通常partition的数量通常是Broker Server数量的整数倍。</p>
<p>Consumer Group，同样是逻辑上的概念，是Kafka实现单播和广播两种消息模型的手段。保证一个消费组获取到特定主题的全部的消息。在消费组内部，若干个消费者消费主题分区的消息，消费组可以保证一个主题的每个分区只被消费组中的一个消费者消费。</p>
<p>consumer 采用 pull 模式从 broker 中读取数据。</p>
<p>采用 pull 模式，consumer 可自主控制消费消息的速率，可以自己控制消费方式（批量消费&#x2F;逐条消费)，还可以选择不同的提交方式从而实现不同的传输语义。</p>
<p><strong>反序列化</strong></p>
<p>Kafka的broker中所有的消息都是字节数组，消费者获取到消息之后，需要先对消息进行反序列化处理，然后才能</p>
<p>交给用户程序消费处理。消费者的反序列化器包括key的和value的反序列化器。</p>
<p>key.deserializer</p>
<p>value.deserializer</p>
<p>IntegerDeserializer</p>
<p>StringDeserializer</p>
<p>需要实现 org.apache.kafka.common.serialization.Deserializer<T> 接口。</p>
<p><strong>位移提交</strong></p>
<p>\1. Consumer需要向Kafka记录自己的位移数据，这个汇报过程称为提交位移(Committing Offsets)</p>
<p>\2. Consumer 需要为分配给它的每个分区提交各自的位移数据</p>
<p>3.位移提交的由Consumer端负责的，Kafka只负责保管。</p>
<p>4.位移提交分为自动提交和手动提交</p>
<p>5.位移提交分为同步提交和异步提交</p>
<p><strong>消费位移管理</strong></p>
<p>Kafka中，消费者根据消息的位移顺序消费消息。消费者的位移由消费者管理，可以存储于zookeeper中，也可以存储于Kafka主题__consumer_offsets中。Kafka提供了消费者API，让消费者可以管理自己的位移。</p>
<p><strong>再均衡</strong></p>
<p>重平衡其实就是一个协议，它规定了如何让消费者组下的所有消费者来分配topic中的每一个分区。比如一个topic</p>
<p>有100个分区，一个消费者组内有20个消费者，在协调者的控制下让组内每一个消费者分配到5个分区，这个分配的过程就是重平衡，是kafka为人诟病最多的一个点。</p>
<p>重平衡的触发条件主要有三个：</p>
<p>\1. 消费者组内成员发生变更，这个变更包括了增加和减少消费者，比如消费者宕机退出消费组。</p>
<p>\2. 主题的分区数发生变更，kafka目前只支持增加分区，当增加的时候就会触发重平衡。</p>
<p>\3. 订阅的主题发生变化，当消费者组使用正则表达式订阅主题，而恰好又新建了对应的主题，就会触发重平衡。</p>
<p>重平衡过程中，消费者无法从kafka消费消息，这对kafka的TPS影响极大，而如果kafka集内节点较多，比如数百个，那重平衡可能会耗时极多。数分钟到数小时都有可能，而这段时间kafka基本处于不可用状态。所以在实际环境中，应该尽量避免重平衡发生。避免重平衡，是不可能，因为你无法完全保证消费者不会故障。而消费者故障是最常见引发重平衡的地方，需要尽力避免消费者故障，比如合理利用心跳来维持。控制发送心跳的频率，频率越高越不容易被误判。</p>
<p><strong>消费者管理</strong></p>
<p>消费组：consumer group是kafka提供的可扩展且具有容错性的消费者机制。</p>
<p>三个特性：</p>
<p>\1. 消费组有一个或多个消费者，消费者可以是一个进程，也可以是一个线程</p>
<p>\2. group.id是一个字符串，唯一标识一个消费组</p>
<p>\3. 消费组订阅的主题每个分区只能分配给消费组一个消费者。</p>
<p>消费者位移：消费者在消费的过程中记录已消费的数据，即消费位移（offset）信息。</p>
<p>kafka提供了5个协议来处理与消费组协调相关的问题：</p>
<p>Heartbeat请求：consumer需要定期给组协调器发送心跳来表明自己还活着</p>
<p>LeaveGroup请求：主动告诉组协调器我要离开消费组</p>
<p>SyncGroup请求：消费组Leader把分配方案告诉组内所有成员</p>
<p>JoinGroup请求：成员请求加入组</p>
<p>DescribeGroup请求：显示组的所有信息，包括成员信息，协议名称，分配方案，订阅信息等。通常该请求</p>
<p>是给管理员使用</p>
<p>组协调器在再均衡的时候主要用到了前面4种请求。</p>
<p>消费组组协调器根据状态机对消费组做不同处理：</p>
<p>\1. Dead：组内已经没有任何成员的最终状态，组的元数据也已经被组协调器移除了。这种状态响应各种请求都</p>
<p>是一个response：UNKNOWN_MEMBER_ID</p>
<p>\2. Empty：组内无成员，但是位移信息还没有过期。这种状态只能响应JoinGroup请求</p>
<p>\3. PreparingRebalance：组准备开启新的rebalance，等待成员加入</p>
<p>\4. AwaitingSync：正在等待leader consumer将分配方案传给各个成员</p>
<p>\5. Stable：再均衡完成，可以开始消费。</p>
<h3 id="主题"><a href="#主题" class="headerlink" title="主题"></a><strong>主题</strong></h3><p><strong>创建主题</strong></p>
<p>kafka-topics.sh –zookeeper localhost:2181&#x2F;myKafka –create –topic topic_x – partitions 1 –replication-factor 1 kafka-topics.sh –zookeeper localhost:2181&#x2F;myKafka –create –topic topic_test_02 – partitions 3 –replication-factor 1 –config max.message.bytes&#x3D;1048576 –config segment.bytes&#x3D;10485760</p>
<p><strong>查看主题</strong></p>
<p>kafka-topics.sh –zookeeper localhost:2181&#x2F;myKafka –list</p>
<p>kafka-topics.sh –zookeeper localhost:2181&#x2F;myKafka –describe –topic topic_x</p>
<p>kafka-topics.sh –zookeeper localhost:2181&#x2F;myKafka –topics-with-overrides –describe</p>
<p><strong>修改主题</strong></p>
<p>kafka-topics.sh –zookeeper localhost:2181&#x2F;myKafka –create –topic topic_test_01 – partitions 2 –replication-factor 1</p>
<p>kafka-topics.sh –zookeeper localhost:2181&#x2F;myKafka –alter –topic topic_test_01 – config max.message.bytes&#x3D;1048576</p>
<p>kafka-topics.sh –zookeeper localhost:2181&#x2F;myKafka –describe –topic topic_test_01</p>
<p>kafka-topics.sh –zookeeper localhost:2181&#x2F;myKafka –alter –topic topic_test_01 – config segment.bytes&#x3D;10485760</p>
<p>kafka-topics.sh –zookeeper localhost:2181&#x2F;myKafka –alter –delete-config max.message.bytes –topic topic_test_01</p>
<p><strong>删除主题</strong></p>
<p>kafka-topics.sh –zookeeper localhost:2181&#x2F;myKafka –delete –topic topic_</p>
<p><strong>增加分区</strong></p>
<p>kafka-topics.sh –zookeeper localhost&#x2F;myKafka –alter –topic myTop1 –partitions 2</p>
<p><strong>分区副本的分配</strong></p>
<p>副本分配的三个目标：</p>
<p>\1. 均衡的将副本分散各个broker上</p>
<p>\2. 对于某个broker上分配的分区，他的其他副本在其他broker上</p>
<p>\3. 如果所有的broker都有机架信息，尽量将分区的各个副本分配到不同机架的broker上</p>
<p>不考虑机架信息的情况：</p>
<p>\1. 第一个副本通过轮询方式挑选一个broker，进行分配，该轮询是从broker列表随机轮询</p>
<p>\2. 其余副本是通过增加偏移进行分配</p>
<p><strong>偏移量管理</strong></p>
<p>__consumer_offsets主题中保存了各个消费组的偏移量。早期由zookeeper管理。</p>
<h3 id="KafkaAdminClient应用"><a href="#KafkaAdminClient应用" class="headerlink" title="KafkaAdminClient应用"></a><strong>KafkaAdminClient应用</strong></h3><p>除了使用kafka的bin目录脚本工具来管理kafka之外，还可以通过kafkaAdminClient来将kafka的api将管理功能继承到此客户端中方便调用。其内部原理是使用kafka自定义的一套二进制协议来实现。</p>
<p>\1. 创建主题：createTopics(final Collection newTopics, final CreateTopicsOptions options)</p>
<p>\2. 删除主题：deleteTopics(final Collection topicNames, DeleteTopicsOptions options)</p>
<p>\3. 列出所有主题：listTopics(final ListTopicsOptions options)</p>
<p>\4. 查询主题：describeTopics(final Collection topicNames, DescribeTopicsOptions options)</p>
<p>\5. 查询集群信息：describeCluster(DescribeClusterOptions options)</p>
<p>\6. 查询配置信息：describeConfigs(Collection configResources, final DescribeConfigsOptions options)</p>
<p>\7. 修改配置信息：alterConfigs(Map configs, final AlterConfigsOptions options)</p>
<p>\8. 修改副本的日志目录：alterReplicaLogDirs(Map replicaAssignment, final AlterReplicaLogDirsOptions options)</p>
<p>\9. 查询节点的日志目录信息：describeLogDirs(Collection brokers, DescribeLogDirsOptions options)</p>
<p>\10. 增加分区：createPartitions(Map newPartitions, final CreatePartitionsOptions options)</p>
<p>主要操作步骤：</p>
<p>\1. 客户端根据方法的调用创建相应协议请求。</p>
<p>\2. 客户端发送请求到kafka broker。</p>
<p>\3. Kafka broker 处理相应请求并回执，比如CreateTopicRequest对应的是CreateTopicResponse</p>
<p>\4. 客户端接收相应回执并解析处理。</p>
<h3 id="分区"><a href="#分区" class="headerlink" title="分区"></a><strong>分区</strong></h3><p><strong>副本机制</strong></p>
<p>Kafka在一定数量上的服务器上对主题分区进行复制，当集群中某个broker宕机后系统可以自动故障转移到其他可用副本上，不会造成数据丢失。</p>
<p><img src="/posts/4542/asset/v2-3fe7b358df964f9b1d8d25d24dd37afe_720w.webp" alt="img"></p>
<p>同步节点定义：</p>
<p>\1. 节点必须能够维持与zookeeper会话，心跳机制。</p>
<p>\2. 对于Follower副本分区，他复制在leader分区的写入，延迟不能太高。</p>
<p>宕机恢复：</p>
<p>\1. 少部分副本宕机，从follower从选择一个leader，若宕机恢复，清空commit。重新从leader上pull</p>
<p>\2. 全部副本宕机，等待ISR其中一个恢复作为leader 或者选择第一个恢复的副本作为leader，前者等待时间长，后者可能丢失数据。</p>
<p><strong>Leader选举</strong></p>
<p>Kafka中的leader分区选举，通过维护一个动态变化的ISR集合来实现，一旦Leader分区丢掉，则从ISR中随机挑选一个副本来做新的Leader分区，没有使用过半原则。如果ISR中的副本都丢失了，则要么等待ISR中某个副本恢复成为Leader或者选择第一个恢复的副本做为Leader，两种方式利弊如上。</p>
<p><strong>分区重新分配</strong></p>
<p>向已经部署好的kafka集群添加机器，需要从已部署好的kafka节点中复制相应配置文件，然后把里面的broker id修改成全局唯一，最后启动这个节点将他加入到现有的kafka集群中。但是新添加的kafka节点不会自动分配数据，因此无法分担集群负载，因此需要手动将部分分区移动到新添加的kafka节点上，kafka内部自带有相应工具。</p>
<p><strong>自动再均衡</strong></p>
<p>当我们分好区运行一段时间后，broker的宕机重启，会引发leader分区和follower分区的角色转化，最后可能导致leader大部分都集中在少数几台broker上，由于leader负责客户端的读写操作，因此集中leader分区的少数服务器I&#x2F;O、CPU、内存都会很紧张，针对这种不平衡情况就需要让leader的分区重新恢复到均衡状态，kafka提供了自动再均衡脚本：kafka-preferred-replica-election.sh，该工具会让每个分区的leader副本分配在合适位置，让leader分区和follower分区在服务器之间均衡分配。</p>
<p><strong>修改副本因子</strong></p>
<p>一开始集群较小，因此副本因子较小，现在需要扩容，就要修改副本因子，通过kafka-reassign-partitions.sh修改副本因子。</p>
<p><strong>分区分配策略</strong></p>
<p>在kafka中，每个Topic会包含多个分区，默认情况下一个分区只能被一个消费组下面的一个消费者消费，因此会产生分区分配问题，kafka针对这个问题提供了三种分区分配算法：RangeAssignor、RoundRobinAssignor、StickyAssignor。</p>
<p>RangeAssignor：消费组的成员订阅他们感兴趣的Topic并将这种订阅关系传递给作为订阅组协调者的broker，协调者选择其中一个消费者来执行这个消费组的分区分配并将分配结果转发给消费组内所有的消费者，他是kafka默认采用的分配算法。</p>
<p>RoundRobinAssignor：将消费组内订阅的所有Topic的分区及所有消费者进行排序后尽量均衡的分配。如果消费组内，消费者订阅的Topic列表是相同的，那分配结果尽量均衡，如果订阅的topic列表是不同的，那么分配结果不保证均衡，因为某些消费者不参与一些topic分配。</p>
<p>StickyAssignor：虽然RoundRobinAssignor在RangeAssignor上做了一些优化来更均衡的分配分区，但是在一些情况依旧会出现分配偏差，因为以上两种算法没有考虑上一次的分配结果，如果在新一次分配之前考虑上一次的分配结果，尽量少的调整分区分配变动，能节省不少开销，StickyAssignor因此而诞生，他保证分区的分配尽量均衡，并且每一次重新分配的结果尽量与上一次分配结果保持一致。</p>
<h3 id="物理存储"><a href="#物理存储" class="headerlink" title="物理存储"></a><strong>物理存储</strong></h3><p><strong>日志存储</strong></p>
<p>Kafka消息是以主题为单位进行归类，各个主题之间又相互独立，互不影响，每个主题可以分一个或多个分区，每个分区各自存在一个记录消息数据的日志文件。</p>
<p><img src="https://pic1.zhimg.com/80/v2-486f1237aea933b27f3e62c637e14f5c_720w.webp" alt="img"></p>
<p>偏移量索引文件用于记录消息偏移量与物理地址之间的映射地址之间的映射关系，时间戳索引文件根据时间戳查找对应偏移量。消息内容保存在log日志文件中，新内容追加末尾，采用顺序写的方式。如果需要找到对应偏移量的文件，因为kafka中存在一个ConcurrentSkipListMap保存每个日志分段，可以通过跳跃表方式定位到00000000000000000000.index，再通过二分法在偏移量索引文件中找对应偏移量范围最大内的索引文件，缩小范围之后再顺序找对应偏移量的消息。</p>
<p><img src="/posts/4542/asset/v2-c65502f6c47b524a4db3b2096e4a0415_720w.webp" alt="img"></p>
<p>Kafka提供了两种日志清理策略：</p>
<p>\1. 日志删除，按照一定删除策略，将不满足条件数据进行数据删除。Kafka通过设定日志保留时间节点进行执行日志删除任务，默认七天，超过就删除，删除是通过跳跃表找到待删除的日志分段，在文件加.delete后缀，然后交给一个延迟删除任务来删除这些指定后缀文件。</p>
<p>\2. 日志压缩，针对每个消息的key进行整合，对于有相同key不同的value的值，只保留最后一个版本。日志压缩和key有关，确保每个消息的key不为null。</p>
<h3 id="磁盘存储"><a href="#磁盘存储" class="headerlink" title="磁盘存储"></a><strong>磁盘存储</strong></h3><p><strong>零拷贝</strong></p>
<p>Kafka性能非常高，但是他却把数据存储在磁盘中，需要对数据进行落盘，因此kafka是多方面协同的结果，包括宏观架构、分布式partition存储，ISR数据同步、以及各种高效利用磁盘的特性。零拷贝不是不需要拷贝，而且减少不必要的拷贝次数，nginx高性能中也有零拷贝应用。</p>
<p>传统IO：先读取，再发送，经过1-4次复制，第一次将磁盘文件读取到操作系统内核缓存区，第二次copy到application应用程序的缓存，第三次再copy到socket网络发送到缓冲区，最后copy到网络协议栈，由网卡进行网络传输。</p>
<p>Kafka：网络数据持久化到磁盘，磁盘文件通过网络发送，不需要第二和第三个副本。</p>
<p><strong>页缓存</strong></p>
<p>页缓存就是操作系统实现的一种主要磁盘缓存，用来减少对磁盘的IO操作，也就是把磁盘中的数据缓存在内存中，把对磁盘的访问变成对内存的访问，提高效率。</p>
<p><strong>mmap和senfile</strong></p>
<p>\1. linux内核提供实现零拷贝的api</p>
<p>\2. sendfile是将读到内核空间的数据，转到socket buffer，进行网络发送。</p>
<p>\3. mmap将磁盘文件映射到内存，支持读和写，对内存的操作会反应在磁盘文件上。</p>
<p>\4. rocketmq在消费消息使用了mmap，kafka使用了sendfile。</p>
<p>Kafka速度快的原因：</p>
<p>\1. partition顺序读写，充分利用磁盘特性。</p>
<p>\2. producer生产的数据持久化到broker，采用mmap文件映射，实现顺序的快速写入。</p>
<p>\3. customer从broker读取消息，采用sendfile，将磁盘文件读到OS内核缓存区，然后直接转到socket buffer进行网络发送。</p>
<h3 id="事务"><a href="#事务" class="headerlink" title="事务"></a><strong>事务</strong></h3><p>Kafka的producer发送消息可能是分布式事务，引入2PC，有事务协调者Transaction Coordinator。而且事务管理中日志不可缺，kafka通过内部一个topic来保存事务日志，事务具有commit和abort两种操作，因此也具有对应的两种隔离级别，而且事务ID一定要设置，幂等性也要开启，幂等性的实现通过一个唯一ID。</p>
<p><img src="https://pic4.zhimg.com/80/v2-5021de3c7f9a2908c84388c5f5bd3463_720w.webp" alt="img"></p>
<p>在kafka事务中，一个原子性操作，根据操作类型分为3种情况：</p>
<p>1． 只有producer生产消息，需要事务介入</p>
<p>2． 消费消息和生产消息并存，需要事务介入，最常见模式。</p>
<p>3． 只有consumer消费消息，可以手动commit，意义不大。</p>
<h3 id="控制器"><a href="#控制器" class="headerlink" title="控制器"></a><strong>控制器</strong></h3><p>控制器就是一个broker，控制器还负责leader分区的选举。</p>
<p>Kafka集群包含若干个broker，集群上创建的主题，包含若干个分区，每个分区包含若干个副本，副本因子包括leader副本和follower副本，副本又分为ISR同步副本分区和OSR非同步副本分区。</p>
<p><strong>borker选举</strong></p>
<p>\1. kafka使用zookeeper的分布式锁选举控制器，并在节点加入集群或退出集群时通知控制器。</p>
<p>\2. 控制器负责在节点加入或离开集群时进行分区leader选举。</p>
<p>\3. 控制器使用epoch来避免脑裂，脑裂是指两个节点同时认为自己是当前控制器。</p>
<h3 id="可靠性保证和一致性保证"><a href="#可靠性保证和一致性保证" class="headerlink" title="可靠性保证和一致性保证"></a><strong>可靠性保证和一致性保证</strong></h3><p><strong>可靠性保证</strong></p>
<p>创建topic主题时可以指定副本因子和分区的副本数，leader负责读写的节点，其他是follower，producer只把消息发送到leader上，follower定期从leader上pull数据，因此就会存在一定的延时性，为了保证可靠性，可以设置ack&#x3D;all。Follower收到消息后，会像leader发送ack，一旦leader收到ISR中所有replica中的ACK，leader就会commit，那么leader就会像producer发送ack，保存消息可靠性。</p>
<p><strong>一致性保证</strong></p>
<p>水位或者水印表示位置信息，即位移，kafka源码中使用的是高水位HW。</p>
<p>每个分区副本对象都有两个重要属性：LEO和HW</p>
<p>LEO：日志末端位移，记录了该副本日志中下一条消息的位移值。</p>
<p>HW：水位值，即水淹到这里，对于同一个副本对象而言，其HW值不会大于LEO值。</p>
<p><img src="https://pic2.zhimg.com/80/v2-1151083cf8c45dd7c69fe5a84e4ec945_720w.webp" alt="img"></p>
<p>上图HW值就是7，表示位移0-7的所有消息已经提交，LEO值是14，指下一条消息来得时候位移。</p>
<p>Follower副本的LEO值就是日志的LEO值，新写入一条消息就更新LEO。</p>
<p>Follower更新HW发生在更新LEO之后，一旦follower向log写入数据，就更新自己的hw值。</p>
<p>和follower更新LEO相同，leader写log时候自动更新自己的LEO值。</p>
<p>Leader的HW值就是分区的HW值，当尝试确定分区HW时，他会选出所有满足条件的副本，比较他们的LEO，并选择最小的LEO值作为HW值。</p>
<h3 id="消息重复的场景及解决方案"><a href="#消息重复的场景及解决方案" class="headerlink" title="消息重复的场景及解决方案"></a><strong>消息重复的场景及解决方案</strong></h3><p>消息重复发送在三个阶段：生产者阶段、broke阶段、消费者阶段</p>
<p>根本原因：生产者发送的消息没有收到正确的broke响应，导致producer重试，producer发出一条消息，broke落盘以后因为网络等种种原因发送端得到一个发送失败的响应或网络中断，然后producer收到一个可恢复的exception重试消息导致消息重复。</p>
<p><strong>生产者发送重复解决方案</strong></p>
<p>\1. 启动kafka幂等性</p>
<p>\2. Ack&#x3D;0,不重试，但是可能丢失消息。</p>
<p><strong>生产者和broke阶段消息丢失场景</strong></p>
<p>\1. ack&#x3D;0,不重试，发送完不管结果，发送失败就丢失了。</p>
<p>\2. ack&#x3D;1 leader crash 生产者发送消息完，等待leader写入成功就返回了，leader分区丢失了，此时follower还没同步，消息丢失。</p>
<p><strong>解决生产者和broke阶段消息丢失</strong></p>
<p>\1. 禁用unclean选举，ack&#x3D;all</p>
<p>\2. 失败的offset单独记录</p>
<p><strong>消费者数据重复场景及解决方案</strong></p>
<p>数据消费完没有及时提交offset到broke</p>
<p>解决方案：取消自动提交，通过手动提交或者下游做幂等，保证每次一致。</p>
<h3 id="consumer-offsets"><a href="#consumer-offsets" class="headerlink" title="__consumer_offsets"></a><strong>__consumer_offsets</strong></h3><p>Kafka内部的一个主题。Zookeeper不适合大批量的频繁写入操作，而通过这个主题来实现这个功能。</p>
<h3 id="延时队列"><a href="#延时队列" class="headerlink" title="延时队列"></a><strong>延时队列</strong></h3><p>两个follower副本已经拉取到了leader副本的最新位置，此时又向leader副本发送拉取请求，而leader副本并没有新的消息写入，就会导致follower副本一直发送拉取请求，而且总拉取空的结果，导致空转消耗资源。</p>
<p>Kafka通过延迟操作的概念，在处理拉取请求时，先读取一次日志文件，如果收集不到足够多的消息，就会创建一个延时拉取操作以等待拉取到足够数量的消息，当延时拉取操作执行时，会在读取一次日志文件，然后将拉取结果返回给follower副本。Kafka中还有延时数据删除、延时生产等等。</p>
<h3 id="重试队列"><a href="#重试队列" class="headerlink" title="重试队列"></a><strong>重试队列</strong></h3><p>Kafka没有重试机制，也没有死信队列，需要自己来实现消息重试功能。</p>
<p>实现逻辑：</p>
<p>\1. 创建一个topic作为重试topic，用去接收等待重试消息。</p>
<p>\2. 普通topic消费者设置待重试消息的下一个重试topic。</p>
<p>\3. 从重试topic获取待重试消息储存到redis的zset中，并以下一次消费时间排序。</p>
<p>\4. 定时任务从redis获取到达消费事件的消息，并把消息发送到对应的topic</p>
<p>\5. 同一个消息重试次数过多则不再重试。</p>
<h3 id="ngx-kafka-module安装与配置"><a href="#ngx-kafka-module安装与配置" class="headerlink" title="ngx_kafka_module安装与配置"></a><strong>ngx_kafka_module安装与配置</strong></h3><p><strong>1. Install librdkafka</strong></p>
<p>#安装git</p>
<p>yum -y install git</p>
<p>#安装c++环境</p>
<p>yum install gcc-c++</p>
<p>#git librdkafka并编译</p>
<p>git clone <a href="https://link.zhihu.com/?target=https://github.com/edenhill/librdkafka">https://github.com/edenhill/librdkafka</a></p>
<p>cd librdkafka</p>
<p>.&#x2F;configure</p>
<p>make</p>
<p>sudo make install</p>
<p><strong>2. Install ngx_kafka_module</strong></p>
<p>git clone <a href="https://link.zhihu.com/?target=https://github.com/brg-liuwei/ngx_kafka_module">https://github.com/brg-liuwei/ngx_kafka_module</a></p>
<p># cd &#x2F;opt&#x2F;nginx-1.19.8</p>
<p>.&#x2F;configure –add-module&#x3D;&#x2F;opt&#x2F;nginx_extra&#x2F;ngx_kafka_module</p>
<p>make</p>
<p>sudo make install</p>
<p># or, use <code>sudo make upgrade</code> instead of <code>sudo make install</code></p>
<p><strong>3.</strong> <strong>配置nginx</strong></p>
<p>http {</p>
<p># some other configs</p>
<p>kafka;</p>
<p>kafka_broker_list 127.0.0.1:9092; # host:port …</p>
<p>server {</p>
<p># some other configs</p>
<p>location &#x3D; &#x2F;ozdemo&#x2F;kafka {</p>
<p># optional directive: kafka_partition [<partition-num> | auto]</p>
<p>#</p>
<p># kafka_partition auto; # default value</p>
<p># kafka_partition 0;</p>
<p># kafka_partition 1;</p>
<p>kafka_topic topic_ozdemo;</p>
<p>}</p>
<p>}</p>
<p>}</p>
<p><strong>4.重启nginx</strong></p>
<p>.&#x2F;nginx -s reload</p>
<p><strong>5.测试ngx_kafka_module</strong></p>
<p># 列出现有的主题</p>
<p>kafka-topics.sh –list –zookeeper localhost:2181&#x2F;kafka</p>
<p># 创建主题，该主题包含一个分区，该分区为Leader分区，它没有Follower分区副本。</p>
<p>kafka-topics.sh –zookeeper localhost:2181&#x2F;kafka –create –topic topic_ozdemo –partitions 1 –replication-factor 1</p>
<p># 查看分区信息</p>
<p>kafka-topics.sh –zookeeper localhost:2181&#x2F;kafka –list</p>
<p># 查看指定主题的详细信息</p>
<p>kafka-topics.sh –zookeeper localhost:2181&#x2F;kafka –describe –topic topic_ozdemo</p>
<p># 删除指定主题</p>
<p>kafka-topics.sh –zookeeper localhost:2181&#x2F;kafka –delete –topic topic_ozdemo</p>
<p>kafka-topics.sh –zookeeper localhost:2181&#x2F;kafka –create –topic topic_ozdemo –partitions 1 –replication-factor 1</p>
<p># 开启消费者</p>
<p>kafka-console-consumer.sh –bootstrap-server localhost:9092 –topic topic_ozdemo</p>
<p># 开启消费者方式二，从头消费，不按照偏移量消费</p>
<p>kafka-console-consumer.sh –bootstrap-server localhost:9092 –topic topic_ozdemo –from-beginning</p>
<p># 测试</p>
<p>curl <a href="http://127.0.0.1/ozdemo/kafka">http://127.0.0.1/ozdemo/kafka</a> -d “message send to kafka topic”</p>
]]></content>
      <categories>
        <category>基础知识</category>
        <category>kafaka</category>
      </categories>
      <tags>
        <tag>基础知识</tag>
        <tag>kafaka</tag>
      </tags>
  </entry>
  <entry>
    <title>MongoDB</title>
    <url>/posts/51937/</url>
    <content><![CDATA[<h3 id="一、-MongoDB概念与结构"><a href="#一、-MongoDB概念与结构" class="headerlink" title="一、 MongoDB概念与结构"></a><strong>一、</strong> <strong>MongoDB概念与结构</strong></h3><h3 id="MongoDB体系结构"><a href="#MongoDB体系结构" class="headerlink" title="MongoDB体系结构"></a><strong>MongoDB体系结构</strong></h3><p>MongoDB 由C++编写而成，是一个介于关系数据库和非关系数据库之间的产品，是非关系数据库中功能最丰富、</p>
<p>最像关系数据库的。在高负载的情况下，通过添加更多的节点，可以保证服务器性能。</p>
<p><img src="https://pic4.zhimg.com/80/v2-654bbb8652e47f05da55752446e668cb_720w.webp" alt="img"></p>
<p><img src="/posts/51937/asset/v2-51fe7292ba6163b5a4c12d99d758a8dc_720w.webp" alt="img"></p>
<h3 id="BSON结构"><a href="#BSON结构" class="headerlink" title="BSON结构"></a><strong>BSON结构</strong></h3><p>BSON是一种类json的一种二进制形式的存储格式，简称Binary JSON，它和JSON一样，支持内嵌的文档对象和数组对象，但是BSON有JSON没有的一些数据类型，如Date和Binary Data类型。具备轻量性、可遍历性、高效性三个特征。而MongoDB使用了BSON这种结构来存储数据和网络数据交换，他把这种格式转化成一文档这个概念(Document)，这里的一个Document也可以理解成关系数据库中的一条记录(Record)，并且可以嵌套。</p>
<p><img src="https://pic4.zhimg.com/80/v2-e8d4bc342d3ff3bfb700f79137e1ac77_720w.webp" alt="img"></p>
<h3 id="MongoDB的安装和启动"><a href="#MongoDB的安装和启动" class="headerlink" title="MongoDB的安装和启动"></a><strong>MongoDB的安装和启动</strong></h3><p>1） 创建mongodb文件夹：mkdir mongodb</p>
<p>2） 上传压缩包并解压：tar -zxvf mongodb-linux-x86_64-4.1.3.tgz</p>
<p><img src="/posts/51937/asset/v2-38f6582626926c7a134eefde5511b93c_720w.webp" alt="img"></p>
<p>3） 进入解压出来的目录文件中，建立多级目录db：mkdir -p &#x2F;data&#x2F;db</p>
<p><img src="/posts/51937/asset/v2-a25547bafbbd284bac286fa65f564459_720w.webp" alt="img"></p>
<p>4） 启动MongoDB，执行命令：.&#x2F;bin&#x2F;mongod</p>
<p><img src="https://pic4.zhimg.com/80/v2-4f53bff151d65f87eec81ddf00c1019b_720w.webp" alt="img"></p>
<p>5） 另一种启动方式，以配置文件方式，先创建mongo.conf文件并设置配置参数：vi mongo.confdbpath&#x3D;&#x2F;data&#x2F;db&#x2F;</p>
<p>port&#x3D;27017</p>
<p>bind_ip&#x3D;0.0.0.0</p>
<p>fork&#x3D;true</p>
<p>logpath &#x3D; &#x2F;data&#x2F;db&#x2F;mongodb.log</p>
<p>logappend &#x3D; true</p>
<p>auth&#x3D;false</p>
<p>dbpath 数据库目录，默认&#x2F;data&#x2F;db</p>
<p>port 监听的端口，默认27017</p>
<p>bind_ip 监听IP地址，默认全部可以访问</p>
<p>fork 是否已后台启动的方式登陆</p>
<p>logpath 日志路径</p>
<p>logappend 是否追加日志</p>
<p>auth 是开启用户密码登陆</p>
<p>config 指定配置文件</p>
<p>6） 创建配置文件对应多级目录：mkdir -p data&#x2F;mongo，启动MongoDB：.&#x2F;bin&#x2F;mongod -f mongo.conf</p>
<p>7） 修复错误bin&#x2F;mongod –repair</p>
<h3 id="二、MongoDB命令和索引"><a href="#二、MongoDB命令和索引" class="headerlink" title="二、MongoDB命令和索引"></a><strong>二、MongoDB命令和索引</strong></h3><h3 id="MongoDB基本操作"><a href="#MongoDB基本操作" class="headerlink" title="MongoDB基本操作"></a><strong>MongoDB基本操作</strong></h3><p><strong>基本操作</strong></p>
<p>查看数据库 show dbs;</p>
<p>切换数据库 如果没有对应的数据库则创建 use 数据库名;</p>
<p>创建集合 db.createCollection(“集合名”)</p>
<p>查看集合 show tables; show collections;</p>
<p>删除集合 db.集合名.drop();</p>
<p>删除当前数据库 db.dropDatabase();</p>
<p><strong>数据添加</strong></p>
<p>插入单条、多条数据 db.集合名.insert(文档)、db.集合名.insert([文档,文档])</p>
<p>例如: db.lg_resume_preview.insert({name:”张晓峰”,city:”bj”})</p>
<p><strong>数据查询</strong></p>
<p>db.集合名.find(条件)</p>
<p>And条件 db.集合名.find({key1:value1, key2:value2}).pretty()</p>
<p>Or条件 db.集合名.find({$or:[{key1:value1}, {key2:value2}]}).pretty()</p>
<p>Not条件 db.集合名.find({key:{$not:{$操作符:value}}).pretty()</p>
<p>分页查询 db.集合名.find({条件}).sort({排序字段:排序方式})).skip(跳过的行数).limit(一页显示多少数据)</p>
<p><img src="/posts/51937/asset/v2-b49b36e6179a0d3171ef0e29447173b6_720w.webp" alt="img"></p>
<p><strong>数据更新</strong></p>
<p>db.集合名.update(</p>
<p><query>,</p>
<p><update>,</p>
<p>{</p>
<p>upsert: <boolean>,</p>
<p>multi: <boolean>,</p>
<p>writeConcern: <document></p>
<p>}</p>
<p>)</p>
<p>参数说明:</p>
<p>db.集合名.update({条件},{$set:{字段名:值}},{multi:true}</p>
<p>query : update的查询条件，类似sql update查询内where后面的。</p>
<p>update : update的对象和一些更新的操作符（如$set,$inc…）等，也可以理解为sql update中set后面的</p>
<p>upsert : 可选，如果不存在update的记录，是否插入objNew,true为插入，默认是false，不插入。</p>
<p>multi : 可选，MongoDB 默认是false,只更新找到的第一条记录，如果这个参数为true,就把按条件查出来多条记录全部更新。</p>
<p>writeConcern :可选，用来指定mongod对写操作的回执行为比如写的行为是否需要确认。</p>
<p><strong>数据删除</strong></p>
<p>db.collection.remove(</p>
<p><query>,</p>
<p>{</p>
<p>justOne: <boolean>,</p>
<p>writeConcern: <document></p>
<p>}</p>
<p>)</p>
<p>参数说明：</p>
<p>query :（可选）删除的文档的条件。</p>
<p>justOne : （可选）如果设为 true 或 1，则只删除一个文档，如果不设置该参数，或使用默认值</p>
<p>false，则删除所有匹配条件的文档。</p>
<p>writeConcern :（可选）用来指定mongod对写操作的回执行为。</p>
<h3 id="MongoDB聚合操作"><a href="#MongoDB聚合操作" class="headerlink" title="MongoDB聚合操作"></a><strong>MongoDB聚合操作</strong></h3><p>聚合是MongoDB的高级查询语言，它允许我们通过转化合并由多个文档的数据来生成新的在单个文档</p>
<p>里不存在的文档信息。一般都是将记录按条件分组之后进行一系列求最大值，最小值，平均值的简单操作，也可以对记录进行复杂数据统计，数据挖掘的操作。</p>
<p><strong>单目的聚合操作</strong></p>
<p>单目的聚合常用命令：count() 和 distinct()</p>
<p><strong>聚合管道</strong></p>
<p>统计数据(诸如统计平均值,求和等)，并返回计算后的数据结果。</p>
<p><img src="/posts/51937/asset/v2-823a6ec8ba3f811299a3f2ff7c45a4f1_720w.webp" alt="img"></p>
<p>常用操作:</p>
<p>$group：将集合中的文档分组，可用于统计结果。</p>
<p>$project：修改输入文档的结构。可以用来重命名、增加或删除域，也可以用于创建计算结果以及</p>
<p>嵌套文档。</p>
<p>$match：用于过滤数据，只输出符合条件的文档。$match使用MongoDB的标准查询操作。</p>
<p>$limit：用来限制MongoDB聚合管道返回的文档数。</p>
<p>$skip：在聚合管道中跳过指定数量的文档，并返回余下的文档。</p>
<p>$sort：将输入文档排序后输出。</p>
<p>$geoNear：输出接近某一地理位置的有序文档。</p>
<p><strong>MapReduce编程模型</strong></p>
<p>Pipeline查询速度快于MapReduce，但是MapReduce的强大之处在于能够在多台Server上并行执行复杂的聚合逻辑。MongoDB不允许Pipeline的单个聚合操作占用过多的系统内存，超过20%直接报错。</p>
<p><img src="/posts/51937/asset/v2-2cdf37db2e76e6939486a4fb702769e8_720w.webp" alt="img"></p>
<p>参数说明：</p>
<p>map：是JavaScript 函数，负责将每一个输入文档转换为零或多个文档，生成键值对序列,作为reduce 函数参数</p>
<p>reduce：是JavaScript 函数，对map操作的输出做合并的化简的操作（将key-value变成keyvalues，也就是把values数组变成一个单一的值value）</p>
<p>out：统计结果存放集合</p>
<p>query： 一个筛选条件，只有满足条件的文档才会调用map函数。</p>
<p>sort： 和limit结合的sort排序参数（也是在发往map函数前给文档排序），可以优化分组机制</p>
<p>limit： 发往map函数的文档数量的上限（要是没有limit，单独使用sort的用处不大）</p>
<p>finalize：可以对reduce输出结果再一次修改</p>
<p>verbose：是否包括结果信息中的时间信息，默认为fasle</p>
<h3 id="MongoDB索引类型"><a href="#MongoDB索引类型" class="headerlink" title="MongoDB索引类型"></a><strong>MongoDB索引类型</strong></h3><p><strong>单键索引</strong> <strong>(Single Field)</strong></p>
<p>MongoDB的单键索引也就是我们熟悉的普通索引，可以在任何字段上创建，但是他自带一种TTL索引，也就是过期索引，可以设置时间并过期失效，只支持日期字段。</p>
<p>db.集合名.createIndex({“字段名”:排序方式})</p>
<p>db.集合名.createIndex({“日期字段”:排序方式}, {expireAfterSeconds: 秒数})</p>
<p><strong>复合索引(Compound Index)</strong></p>
<p>与mysql的复合索引相同，支持基于多个字段的索引。</p>
<p>db.集合名.createIndex( { “字段名1” : 排序方式, “字段名2” : 排序方式 } )</p>
<p><strong>多键索引(Multikey indexes)</strong></p>
<p>针对属性包含数组数据的情况，MongoDB支持针对数组中每一个element创建索引，Multikey</p>
<p>indexes支持strings，numbers和nested documents</p>
<p><strong>地理空间索引(Geospatial Index)</strong></p>
<p>针对地理空间坐标数据创建索引。</p>
<p>2dsphere索引，用于存储和查找球面上的点</p>
<p>2d索引，用于存储和查找平面上的点</p>
<p><img src="https://pic2.zhimg.com/80/v2-a8d35ded711b29784244491e95992325_720w.webp" alt="img"></p>
<p><strong>全文索引</strong></p>
<p>MongoDB提供了针对string内容的文本查询，Text Index支持任意属性值为string或string数组元素的 索引查询。注意:一个集合仅支持最多一个Text Index，中文分词推荐ES。</p>
<p>db.集合.createIndex({“字段”: “text”})</p>
<p>db.集合.find({“$text”: {“$search”: “coffee”}})</p>
<p><strong>哈希索引 Hashed Index</strong></p>
<p>针对属性的哈希值进行索引查询,当要使用Hashed index时，MongoDB能够自动的计算hash值。</p>
<p>db.集合.createIndex({“字段”: “hashed”})</p>
<h3 id="Explain参数及慢查询分析"><a href="#Explain参数及慢查询分析" class="headerlink" title="Explain参数及慢查询分析"></a><strong>Explain参数及慢查询分析</strong></h3><p><strong>索引管理</strong></p>
<p>创建：db.COLLECTION_NAME.createIndex({“字段”:排序方式}, {background: true});</p>
<p>获取集合所有索引：db.COLLECTION_NAME.getIndexes()</p>
<p>索引大小：db.COLLECTION_NAME.totalIndexSize()</p>
<p>重建：db.COLLECTION_NAME.reIndex()</p>
<p>删除：db.COLLECTION_NAME.dropIndex(“INDEX-NAME”)</p>
<p><strong>Explain执行计划分析</strong></p>
<p>设置不同参数可查看不同执行计划分析</p>
<p>queryPlanner：默认参数</p>
<p>executionStats：统计信息</p>
<p>allPlansExecution：所有执行计划信息</p>
<p><img src="/posts/51937/asset/v2-cab3387afaa1287c0d6755a92163c1a6_720w.webp" alt="img"></p>
<p>1）第一层，executionTimeMillis最为直观explain返回值是executionTimeMillis值，指的是这条语句的执</p>
<p>行时间，这个值当然是希望越少越好。</p>
<p>其中有3个executionTimeMillis，分别是：</p>
<p>executionStats.executionTimeMillis 该query的整体查询时间。</p>
<p>executionStats.executionStages.executionTimeMillisEstimate 该查询检索document获得数据的时间。</p>
<p>executionStats.executionStages.inputStage.executionTimeMillisEstimate 该查询扫描文档 index</p>
<p>所用时间。</p>
<p>2）第二层，index与document扫描数与查询返回条目数 关注3个返回项 nReturned、</p>
<p>totalKeysExamined、totalDocsExamined，分别代表该条查询返回的条目、索引扫描条目、文档扫描</p>
<p>条目。直观的影响到executionTimeMillis耗时，我们需要扫描的越少速度越快。最理想的状态是：nReturned&#x3D;totalKeysExamined&#x3D;totalDocsExamined</p>
<p>3）第三层，stage状态分析。</p>
<p>所有类型如下：</p>
<p>COLLSCAN：全表扫描</p>
<p>IXSCAN：索引扫描</p>
<p>FETCH：根据索引去检索指定document</p>
<p>SHARD_MERGE：将各个分片返回数据进行merge</p>
<p>SORT：表明在内存中进行了排序</p>
<p>LIMIT：使用limit限制返回数</p>
<p>SKIP：使用skip进行跳过</p>
<p>IDHACK：针对_id进行查询</p>
<p>SHARDING_FILTER：通过mongos对分片数据进行查询</p>
<p>COUNT：利用db.coll.explain().count()之类进行count运算</p>
<p>TEXT：使用全文索引进行查询时候的stage返回</p>
<p>PROJECTION：限定返回字段时候stage的返回</p>
<p>优秀stage的组合(查询的时候尽可能用上索引)：</p>
<p>Fetch+IDHACK</p>
<p>Fetch+IXSCAN</p>
<p>Limit+（Fetch+IXSCAN）</p>
<p>PROJECTION+IXSCAN</p>
<p>SHARDING_FITER+IXSCAN</p>
<p>需要优化的组合：</p>
<p>COLLSCAN(全表扫描)</p>
<p>SORT(使用sort但是无index)</p>
<p>COUNT 不使用index进行count)</p>
<p><strong>慢查询分析</strong></p>
<p>1）开启内置的查询分析器,记录读写操作效率</p>
<p>db.setProfilingLevel(n,m),n的取值可选0,1,2</p>
<p>0表示不记录</p>
<p>1表示记录慢速操作,如果值为1,m必须赋值单位为ms,用于定义慢速查询时间的阈值</p>
<p>2表示记录所有的读写操作</p>
<p>2）查询监控结果</p>
<p>db.system.profile.find().sort({millis:-1}).limit(3)</p>
<p>3）分析慢速查询</p>
<p>应用程序设计不合理、不正确的数据模型、硬件配置问题,缺少索引等</p>
<p>4）解读explain结果，是否缺少索引</p>
<h3 id="MongoDB索引底层实现原理"><a href="#MongoDB索引底层实现原理" class="headerlink" title="MongoDB索引底层实现原理"></a><strong>MongoDB索引底层实现原理</strong></h3><p>MongoDB 是文档型的数据库，它使用BSON 格式保存数据，比关系型数据库存储更方便。</p>
<p><strong>MongoDB底层B-树</strong>：</p>
<p>1）多路非二叉树</p>
<p>2）每个节点既保存数据又保存索引</p>
<p>3）搜索时相当于二分查找</p>
<p><img src="https://pic2.zhimg.com/80/v2-c345fc430f5c63e7b002939367a014e1_720w.webp" alt="img"></p>
<p><strong>Mysql Innodb底层B+树：</strong></p>
<p>1）多路非二叉</p>
<p>2）只有叶子节点保存数据</p>
<p>3）搜索时也相当于二分查找</p>
<p>4）增加了相邻节点指针</p>
<p><img src="https://pic4.zhimg.com/80/v2-e201a60599e54f545bcc752bdb60046b_720w.webp" alt="img"></p>
<p><strong>比较差异：</strong></p>
<p>1）B+树相邻接点的指针可以大大增加区间访问性，可使用在范围查询等，而B-树每个节点 key 和 data 在一起 适合随机读写 ，而区间查找效率很差。</p>
<p>2）B+树更适合外部存储，也就是磁盘存储，使用B-结构的话，每次磁盘预读中的很多数据是用不上 的数据。因此，它没能利用好磁盘预读的提供的数据。由于节点内无 data 域，每个节点能索引的范围更大更精确。</p>
<p>3）注意这个区别相当重要，是基于（1）（2）的，B-树每个节点即保存数据又保存索引树的深度小，所以磁盘IO的次数很少，B+树只有叶子节点保存，较B树而言深度大磁盘IO多，但是区间访问比较 好。</p>
<h3 id="MongoDB的适用场景"><a href="#MongoDB的适用场景" class="headerlink" title="MongoDB的适用场景"></a><strong>MongoDB的适用场景</strong></h3><p><strong>使用场景</strong></p>
<p>● 网站数据：Mongo 非常适合实时的插入,更新与查询，并具备网站实时数据存储所需的复制及高 度伸缩性。</p>
<p>● 缓存：由于性能很高，Mongo 也适合作为信息基础设施的缓存层。在系统重启之后，由Mongo 搭建的持久化缓存层可以避免下层的数据源过载。</p>
<p>● 大尺寸、低价值的数据：使用传统的关系型数据库存储一些大尺寸低价值数据时会比较浪费， 在此之前，很多时候程序员往往会选择传统的文件进行存储。</p>
<p>● 高伸缩性的场景：Mongo 非常适合由数十或数百台服务器组成的数据库，Mongo 的路线图中 已经包含对MapReduce 引擎的内置支持以及集群高可用的解决方案。</p>
<p>● 用于对象及JSON 数据的存储：Mongo 的BSON 数据格式非常适合文档化格式的存储及查询。</p>
<p>1）游戏场景，使用 MongoDB 存储游戏用户信息，用户的装备、积分等直接以内嵌文档的形式存 储，方便查询、更新。</p>
<p>2）物流场景，使用 MongoDB 存储订单信息，订单状态在运送过程中会不断更新，以 MongoDB 内 嵌数组的形式来存储，一次查询就能将订单所有的变更读取出来。</p>
<p>3）社交场景，使用 MongoDB 存储存储用户信息，以及用户发表的朋友圈信息，通过地理位置索引 实现附近的人、地点等功能。</p>
<p>4）物联网场景，使用 MongoDB 存储所有接入的智能设备信息，以及设备汇报的日志信息，并对这 些信息进行多维度的分析。</p>
<p>5）直播，使用 MongoDB 存储用户信息、礼物信息等。</p>
<p><strong>使用条件</strong></p>
<p><img src="https://pic4.zhimg.com/80/v2-9776b06f1067fd9f43649194b61018c7_720w.webp" alt="img"></p>
<h3 id="三、MongoDB架构及集群高可用"><a href="#三、MongoDB架构及集群高可用" class="headerlink" title="三、MongoDB架构及集群高可用"></a><strong>三、MongoDB架构及集群高可用</strong></h3><h3 id="MongoDB存储引擎和数据模型"><a href="#MongoDB存储引擎和数据模型" class="headerlink" title="MongoDB存储引擎和数据模型"></a><strong>MongoDB存储引擎和数据模型</strong></h3><p><strong>存储引擎</strong></p>
<p>MongoDB底层使用了可插拔的存储引擎以满足用户的不同需要，与Mysql相同，最新版本使用WiredTiger 作为默认的存储引擎，WiredTiger 提供了不同粒度的并发控制和压缩机制，能够为不同种类的应用提供了最好的性能和存储率。</p>
<p><img src="https://pic4.zhimg.com/80/v2-d48a798485490aaa8586e4cf168f1457_720w.webp" alt="img"></p>
<p><strong>数据模型</strong></p>
<p>内嵌：把相关联的数据保存在同一个文档结构之中。</p>
<p>1.数据对象之间有包含关系 ,一般是数据对象之间有一对多或者一对一的关系 。</p>
<p>2.需要经常一起读取的数据。</p>
<p>3.有 map-reduce&#x2F;aggregation 需求的数据放在一起，这些操作都只能操作单个collection。</p>
<p>引用：通过存储数据引用信息来实现两个不同文档之间的关联。</p>
<p>1.当内嵌数据会导致很多数据的重复，并且读性能的优势又不足于覆盖数据重复的弊端 。</p>
<p>2.需要表达比较复杂的多对多关系的时候 。</p>
<p>3.大型层次结果数据集嵌套不要太深。</p>
<h3 id="MongoDB存储引擎"><a href="#MongoDB存储引擎" class="headerlink" title="MongoDB存储引擎"></a><strong>MongoDB存储引擎</strong></h3><p>存储引擎是MongoDB的核心组件，负责管理数据如何存储在硬盘和内存上。mongodb3.2开始默认的存储引擎是WiredTiger，3.2版本之前的默认存储引擎是MMAPv1。</p>
<p><strong>WiredTiger存储引擎优势</strong></p>
<p>1）文档空间分配方式： WiredTiger使用的是BTree存储 MMAPV1 线性存储 需要Padding</p>
<p>2）并发级别： WiredTiger 文档级别锁 MMAPV1引擎使用表级锁</p>
<p>3）数据压缩： snappy (默认) 和 zlib ,相比MMAPV1(无压缩) 空间节省数倍。</p>
<p>4）内存使用： WiredTiger 可以指定内存的使用大小。</p>
<p>5）Cache使用： WT引擎使用了二阶缓存WiredTiger Cache, File System Cache来保证Disk上的数据的最终一致性，而MMAPv1只有journal日志。</p>
<p><img src="/posts/51937/asset/v2-1d4fae40243a5547696f7bf3b8033ed4_720w.webp" alt="img"></p>
<p><strong>WiredTiger存储引擎实现原理</strong></p>
<p>WiredTiger的写操作会默认写入 Cache ,并持久化到 WAL (Write Ahead Log)，每60s或Log文件达到2G 做一次checkpoint（就是把table中的元数据存储在临时文件中）产生快照文件。WiredTiger初始化时，恢复至最新的快照状态，然后再根据WAL 恢复数据，保证数据的完整性。WiredTiger采用Copy on write的方式管理写操作 （insert、update、delete），写操作会先缓存在cache里，持久化时，写操作不会在原来的leaf page 上进行，而是写入新分配的page，每次checkpoint都会产生一个新的root page。在数据库宕机时 , 为保证 MongoDB 中数据的持久性，MongoDB 使用了 Write Ahead Logging 向磁盘上的 journal 文件预先进行写入。除了journal 日志，MongoDB 还使用检查点（checkpoint）来保证数据的一致性。</p>
<p><img src="/posts/51937/asset/v2-e6f1e5236707121c13f5b78581920fdc_720w.webp" alt="img"></p>
<h3 id="MongoDB集群之复制集实战"><a href="#MongoDB集群之复制集实战" class="headerlink" title="MongoDB集群之复制集实战"></a><strong>MongoDB集群之复制集实战</strong></h3><p>MongoDB主从复制结构没有自动故障转移功能，需要指定master和slave端,存在一定缺陷，因此4.0后不再支持，建议使用复制集或者分片集群。</p>
<p>1） 建立复制集文件夹并将解压包放入并解压</p>
<p>mkdir replica-one</p>
<p>mv mongodb-linux-x86_64-4.1.3.tgz replica-one&#x2F;</p>
<p>tar -xvf mongodb-linux-x86_64-4.1.3.tgz</p>
<p>2） 进入解压文件夹，进行配置并创建对应文件夹</p>
<p>vi mongo_37017.conf</p>
<p><img src="/posts/51937/asset/v2-85d9b17e8b7e43bd8deab040440d40f4_720w.webp" alt="img"></p>
<p>mkdir &#x2F;data&#x2F;mongo&#x2F;data&#x2F;server1 -p</p>
<p>mkdir &#x2F;data&#x2F;mongo&#x2F;logs -p</p>
<p>3）复制配置文件成集群并修改配置</p>
<p>cp mongo_37017.conf mongo_37018.conf</p>
<p>vi mongo_37018.conf</p>
<p>cp mongo_37017.conf mongo_37019conf</p>
<p>vi mongo_37019.conf</p>
<p>4）启动三个节点，进入任何一个节点进行配置命令</p>
<p>.&#x2F;bin&#x2F;mongod -f mongo_37017.conf</p>
<p>.&#x2F;bin&#x2F;mongod -f mongo_37018.conf</p>
<p>.&#x2F;bin&#x2F;mongod -f mongo_37019.conf</p>
<p>.&#x2F;bin&#x2F;mongo –port 37017</p>
<p>var cfg &#x3D;{“_id”:”lagouCluster”,</p>
<p>“protocolVersion” : 1,</p>
<p>“members”:[</p>
<p>{“_id”:1,”host”:” 47.106.138.46:37017”,”priority”:10},</p>
<p>{“_id”:2,”host”:” 47.106.138.46:37018”}</p>
<p>]</p>
<p>}rs.initiate(cfg)&#x2F;&#x2F;初始化</p>
<p>rs.reconfig(cfg) &#x2F;&#x2F;重新加载配置并生效</p>
<p>rs.addArb(“47.106.138.46:37020”)&#x2F;&#x2F;配置仲裁节点</p>
<p><img src="https://pic3.zhimg.com/80/v2-248db476e8080782d02519f1975f7f5a_720w.webp" alt="img"></p>
<p>rs.status()&#x2F;&#x2F;状态查看</p>
<p>rs.add(“47.106.138.46:37019”) &#x2F;&#x2F;增加节点</p>
<p>rs.remove(“47.106.138.46:37019”)&#x2F;&#x2F;删除slave节点</p>
<p>rs.slaveOk &#x2F;&#x2F;从节点查询之前同步命令</p>
<p><img src="https://pic4.zhimg.com/80/v2-cdd125ffdf47977abbf608e23060b0c7_720w.webp" alt="img"></p>
<h3 id="MongoDB集群之分片集群实战"><a href="#MongoDB集群之分片集群实战" class="headerlink" title="MongoDB集群之分片集群实战"></a><strong>MongoDB集群之分片集群实战</strong></h3><p>分片是MongoDB用来将大型集合水平分割到不同服务器或者复制集上所采用的方法。不需要功能强大的大型计算机就可以存储更多的数据，处理更大的负载。</p>
<p>工作原理</p>
<p><img src="https://pic3.zhimg.com/80/v2-3e3e0c1283f1fa32061817d7ab1fd21e_720w.webp" alt="img"></p>
<p>1） 解压安装包，搭建配置节点集群</p>
<p>tar -xvf mongodb-linux-x86_64-4.1.3.tgz &#x2F;&#x2F;解压命令</p>
<p>mv mongodb-linux-x86_64-4.1.3 shard_cluster &#x2F;&#x2F;重命名命令</p>
<p>2） 进入解压文件夹内，配置集群节点</p>
<p>mkdir cofig &#x2F;&#x2F;创建配置节点文件夹</p>
<p>vi config-17017.conf &#x2F;&#x2F;配置节点信息</p>
<p><img src="https://pic4.zhimg.com/80/v2-893fd535df7de594418b148fb5503bab_720w.webp" alt="img"></p>
<p>mkdir config1 logs &#x2F;&#x2F;建立配置信息文件夹</p>
<p>3） 以相同方式配置剩余两个配置节点</p>
<p>cp config-17017.conf config-17018.conf &#x2F;&#x2F;复制配置节点</p>
<p>vi config-17018.conf &#x2F;&#x2F;修改配置节点</p>
<p><img src="https://pic4.zhimg.com/80/v2-d7d86daf8c16a7e1a472ea25ad8e8caf_720w.webp" alt="img"></p>
<p>mkdir config2 &#x2F;&#x2F;创建对应配置文件夹</p>
<p>4） 启动配置节点</p>
<p>.&#x2F;bin&#x2F;mongod -f config&#x2F;config-17017.conf</p>
<p>.&#x2F;bin&#x2F;mongod -f config&#x2F;config-17018.conf</p>
<p>.&#x2F;bin&#x2F;mongod -f config&#x2F;config-17019.conf</p>
<p><img src="https://pic1.zhimg.com/80/v2-8f46bd26ba1e83aee16ea91a76b23904_720w.webp" alt="img"></p>
<p>5） 进入任意节点的mongo shell 并添加配置节点集群</p>
<p>.&#x2F;bin&#x2F;mongo –port 17017 &#x2F;&#x2F;进入节点库</p>
<p>use admin &#x2F;&#x2F;admin权限库配置才能生效</p>
<p>var cfg &#x3D;{“_id”:”configsvr”,</p>
<p>“members”:[</p>
<p>{“_id”:1,”host”:”47.106.138.46:17017”},</p>
<p>{“_id”:2,”host”:”47.106.138.46:17018”},</p>
<p>{“_id”:3,”host”:”47.106.138.46:17019”}]</p>
<p>};&#x2F;&#x2F;集群配置</p>
<p>rs.initiate(cfg) &#x2F;&#x2F;初始化生效</p>
<p><img src="/posts/51937/asset/v2-975821a5bc70c40a9979cd7dba2e131c_720w.webp" alt="img"></p>
<p>6） 配置shard集群，解压安装包到对应目录</p>
<p>tar -xvf mongodb-linux-x86_64-4.1.3.tgz</p>
<p>mkdir shard1 shard2 &#x2F;&#x2F;创建两个分片集群目录</p>
<p>mkdir shard1-37017 shard1-37018 shard1-37019 &#x2F;&#x2F;建立第一个集群的各节点目录</p>
<p>7） 配置集群节点信息</p>
<p>vi shard1-37017.conf</p>
<p><img src="https://pic3.zhimg.com/80/v2-63eb366a889c9afe3d173201ea60ee72_720w.webp" alt="img"></p>
<p>8） 依次配置第二第三个节点信息，然后启动所有节点并配置集群</p>
<p>.&#x2F;bin&#x2F;mongod -f shard&#x2F;shard1&#x2F;shard1-37017.conf</p>
<p>.&#x2F;bin&#x2F;mongod -f shard&#x2F;shard1&#x2F;shard1-37018.conf</p>
<p>.&#x2F;bin&#x2F;mongod -f shard&#x2F;shard1&#x2F;shard1-37019.conf</p>
<p>.&#x2F;bin&#x2F;mongo –port 37017 &#x2F;&#x2F;进入节点库</p>
<p>use admin &#x2F;&#x2F;admin权限库配置才能生效</p>
<p>var cfg &#x3D;{“_id”:”shard1”,</p>
<p>“protocolVersion” : 1,</p>
<p>“members”:[</p>
<p>{“_id”:1,”host”:”49.235.85.246:37017”},</p>
<p>{“_id”:2,”host”:”49.235.85.246:37018”},</p>
<p>{“_id”:3,”host”:”49.235.85.246:37019”}]</p>
<p>};&#x2F;&#x2F;集群配置</p>
<p>rs.initiate(cfg) &#x2F;&#x2F;初始化生效</p>
<p><img src="https://pic1.zhimg.com/80/v2-742abddaf64e240f34283e57da2fb394_720w.webp" alt="img"></p>
<p>9） 以相同方法配置另一个集群并启动所有节点</p>
<p>.&#x2F;bin&#x2F;mongod -f shard&#x2F;shard2&#x2F;shard2-47017.conf</p>
<p>.&#x2F;bin&#x2F;mongod -f shard&#x2F;shard2&#x2F;shard2-47018.conf</p>
<p>.&#x2F;bin&#x2F;mongod -f shard&#x2F;shard2&#x2F;shard2-47019.conf</p>
<p>.&#x2F;bin&#x2F;mongo –port 47017 &#x2F;&#x2F;进入节点库</p>
<p>var cfg &#x3D;{“_id”:”shard2”,</p>
<p>“protocolVersion” : 1,</p>
<p>“members”:[</p>
<p>{“_id”:1,”host”:”49.235.85.246:47017”},</p>
<p>{“_id”:2,”host”:”49.235.85.246:47018”},</p>
<p>{“_id”:3,”host”:”49.235.85.246:47019”}]</p>
<p>};&#x2F;&#x2F;集群配置</p>
<p>rs.initiate(cfg) &#x2F;&#x2F;初始化生效</p>
<p><img src="https://pic4.zhimg.com/80/v2-640b42edf0df6f311589c2244bdb1917_720w.webp" alt="img"></p>
<p>10）配置和启动路由节点</p>
<p>mkdir route logs &#x2F;&#x2F;创建路由配置文件夹及日志文件夹</p>
<p>vi route-27107.conf&#x2F;&#x2F;创建并配置以下路由配置信息</p>
<p>port&#x3D;27017</p>
<p>bind_ip&#x3D;0.0.0.0</p>
<p>fork&#x3D;true</p>
<p>logpath&#x3D;route&#x2F;logs&#x2F;route.log</p>
<p>configdb&#x3D;configsvr&#x2F;47.106.138.46:17017,47.106.138.46:17018,47.106.138.46:1701911）启动路由服务并配置分片集群路由信息</p>
<p>.&#x2F;bin&#x2F;mongos -f route&#x2F;route-27017.conf &#x2F;&#x2F;启动路由服务 注意是mongos</p>
<p>.&#x2F;bin&#x2F;mongo –port 27017 &#x2F;&#x2F;进入路由</p>
<p>sh.status() &#x2F;&#x2F;查看分片集群信息sh.addShard(“shard1&#x2F;49.235.85.246:37017,49.235.85.246:37018,49.235.85.246:37019”); sh.addShard(“shard2&#x2F;49.235.85.246:47017,49.235.85.246:47018,49.235.85.246:47019”);</p>
<p><img src="https://pic1.zhimg.com/80/v2-1f048418f893a5783facba1028b1ec80_720w.webp" alt="img"></p>
<p>12）开启数据库和集合分片完成分片集群配置</p>
<p>sh.enableSharding(“lg_resume”) &#x2F;&#x2F;为数据库开启分片功能sh.shardCollection(“lg_resume.lg_resume_data”,{“name”:”hashed”}) &#x2F;&#x2F;指定对应表的分片规则，语句规则是以字段name哈希分片，也可以范围分片</p>
<h3 id="四、MongoDB安全认证及数据监控"><a href="#四、MongoDB安全认证及数据监控" class="headerlink" title="四、MongoDB安全认证及数据监控"></a><strong>四、MongoDB安全认证及数据监控</strong></h3><h3 id="MongoDB安全认证实战"><a href="#MongoDB安全认证实战" class="headerlink" title="MongoDB安全认证实战"></a><strong>MongoDB安全认证实战</strong></h3><p>MongoDB默认没有账号的，可以直接连接，无须身份验证，实际项目中，在生产环境需要增加权限验证，保证数据安全。</p>
<p>1）切换到admin数据库添加用户，创建超级管理员</p>
<p>use admin;</p>
<p>db.createUser({</p>
<p>user: “root”,</p>
<p>pwd: “123456”,</p>
<p>roles: [{ role: “root”, db: “admin” }]</p>
<p>});</p>
<p>2） 为访问的库创建普通用户</p>
<p>use lg_resume &#x2F;&#x2F;切换到普通库</p>
<p>db.createUser({</p>
<p>user:”fangyf”,</p>
<p>pwd:”123456”,</p>
<p>roles:[{role:”readWrite”,db:”lagou_resume”}]</p>
<p>})3）关闭所有的分片节点和路由节点</p>
<p>yum install psmisc &#x2F;&#x2F;安装psmisckillall mongod &#x2F;&#x2F;快速关闭所有进程</p>
<p>4）生成密钥文件并修改权限</p>
<p>mkdir data&#x2F;mongodb -p &#x2F;&#x2F;创建文件夹</p>
<p>openssl rand -base64 756 &gt; data&#x2F;mongodb&#x2F;testKeyFile.file &#x2F;&#x2F;创建密钥文件chmod 600 data&#x2F;mongodb&#x2F;testKeyFile.file &#x2F;&#x2F;修改权限</p>
<p>5）配置节点集群和分片节点集群开启安全认证和指定密钥文件，所有配置文件追加auth&#x3D;true</p>
<p>keyFile&#x3D;data&#x2F;mongodb&#x2F;testKeyFile.file6）在路由配置文件中 设置密钥文件</p>
<p>keyFile&#x3D;data&#x2F;mongodb&#x2F;testKeyFile.file</p>
<p>7）依次启动所有的配置节点分片节点和路由节点使用路由进行权限验证.&#x2F;bin&#x2F;mongod -f config&#x2F;config-17017.conf</p>
<p>.&#x2F;bin&#x2F;mongod -f config&#x2F;config-17018.conf</p>
<p>.&#x2F;bin&#x2F;mongod -f config&#x2F;config-17019.conf</p>
<p>.&#x2F;bin&#x2F;mongod -f shard&#x2F;shard1&#x2F;shard1-37017.conf</p>
<p>.&#x2F;bin&#x2F;mongod -f shard&#x2F;shard1&#x2F;shard1-37018.conf</p>
<p>.&#x2F;bin&#x2F;mongod -f shard&#x2F;shard1&#x2F;shard1-37019.conf</p>
<p>.&#x2F;bin&#x2F;mongod -f shard&#x2F;shard2&#x2F;shard2-47017.conf</p>
<p>.&#x2F;bin&#x2F;mongod -f shard&#x2F;shard2&#x2F;shard2-47018.conf</p>
<p>.&#x2F;bin&#x2F;mongod -f shard&#x2F;shard2&#x2F;shard2-47019.conf</p>
<p>.&#x2F;bin&#x2F;mongos -f route&#x2F;route-27017.conf</p>
<p><strong>其他操作</strong></p>
<p>修改密码</p>
<p>db.changeUserPassword( ‘root’ , ‘rootNew’ );</p>
<p>用户添加角色</p>
<p>db.grantRolesToUser( ‘用户名’ , [{ role: ‘角色名’ , db: ‘数据库名’}])</p>
<p>以auth 方向启动mongod</p>
<p>.&#x2F;bin&#x2F;mongod -f conf&#x2F;mongo.conf –auth(在mongo.conf中添加auth&#x3D;true参数正常启动也可)</p>
<p>验证项目</p>
<p>db.auth(“账号”,”密码”)</p>
<p>删除项目</p>
<p>db.dropUser(“用户名”)</p>
<p>各个角色解析</p>
<p><img src="https://pic2.zhimg.com/80/v2-8579c1a7c2b11a5b6e1a2fdc933035e9_720w.webp" alt="img"></p>
<p><img src="https://pic3.zhimg.com/80/v2-0ee4f9af30567a0aa23228c0e7f12586_720w.webp" alt="img"></p>
<h3 id="MongoDB数据监控"><a href="#MongoDB数据监控" class="headerlink" title="MongoDB数据监控"></a><strong>MongoDB数据监控</strong></h3><p><strong>数据监控</strong></p>
<p>MongoDB Ops Manager(MMS) 用于监控和备份MongoDB的基础设施服务。</p>
<p>1)简易的自动化数据库部署、扩展、升级和任务管理;</p>
<p>2)通过 OPS 平台提供的超过 100 项仪表、图表，可以对 mongodb 进行多种监控;</p>
<p>3)支持单节点、分片集群的备份和恢复;</p>
<p><strong>数据备份</strong></p>
<p>支持定时备份及集群环境下全量加增量的备份和恢复</p>
<p><img src="https://pic1.zhimg.com/80/v2-93116f2029131707644068cf0e102ff0_720w.webp" alt="img"></p>
<p>在MongoDB 中我们使用mongodump命令来备份MongoDB数据。</p>
<p>命令：mongodump -h dbhost -d dbname -o dbdirectory</p>
<p>-h:ip加端口 -d:备份的实例 -o:备份数据存放位置</p>
<p>比如：.&#x2F;bin&#x2F;mongodump -h 127.0.0.1:37017 -d lg -o &#x2F;root&#x2F;bdatas</p>
<p><img src="https://pic2.zhimg.com/80/v2-ee9f4088d5546927cc2bb2a5c7880389_720w.webp" alt="img"></p>
<p><strong>数据恢复</strong></p>
<p>mongodb使用 mongorestore 命令来恢复备份的数据。</p>
<p>命令：mongorestore -h <hostname>&lt;:port&gt; -d dbname <path></p>
<p>-h:ip加端口 -d:恢复的实例 <path>备份数据所在位置</p>
<p>比如：.&#x2F;bin&#x2F;mongorestore -h 127.0.0.1:37017 -d lg &#x2F;root&#x2F;bdatas&#x2F;lg</p>
]]></content>
      <categories>
        <category>基础知识</category>
        <category>mongoDB</category>
      </categories>
      <tags>
        <tag>基础知识</tag>
        <tag>mongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title>mybatis框架知识</title>
    <url>/posts/19125/</url>
    <content><![CDATA[<h2 id="一、Mybatis高级应用"><a href="#一、Mybatis高级应用" class="headerlink" title="一、Mybatis高级应用"></a><strong>一、Mybatis高级应用</strong></h2><p><strong>映射文件</strong>：约束头；根标签；命名空间；操作标签（curd）;结果实体类；语句的id标识；sql语句</p>
<p><strong>Environment标签</strong>：数据库配置环节</p>
<p><strong>TransactionManager标签</strong>：事务管理器</p>
<p><strong>DataSource标签</strong>：数据源-&gt;pooled 使用连接池管理，unpooled反之</p>
<p><strong>Mapper标签</strong>：加载映射，可单独加也可以直接加一个包下所有。</p>
<p><strong>Propreties标签</strong>：加载外部对应文件，比如提取jdbc或者日志配置文件</p>
<p><strong>TypeAliases标签</strong>：给实体类全限定名起别名，使用packge可以批量</p>
<p><strong>forEach标签</strong>:collection遍历的集合；open开始部分；close结束部分；item遍历的元素；sperator分隔符</p>
<p>代理模式开发接口规范：</p>
<p>\1. mapper.xml的namespace与接口限定名一致</p>
<p>\2. mapper接口方法名与mapper.xml定义的每个statament的id相同</p>
<p>\3. mapper接口方法的入参对应mapper.xml的parameterType类型相同</p>
<p>\4. mapper接口方法的返回结果对应mapper.xml的resultType类型相同</p>
<p><strong>Mybatis复杂映射</strong>：通过resultMap手动配置实体属性与表配置关系。一对一：在resultMap标签内通过assocition标签配置实体类引用的另一个实体类字段。一对多、多对多：collection标签。</p>
<p><strong>Mybatis注解开发</strong>；使用@result注解代替resultMap，column数据库列名，property装配的属性名，@one一对一，@many一对多，多对多。（通过当前方法上面的查询结果根据@result注解内关联字段，调取另一个方法注解关联sql，获取综合返回结果）</p>
<p><strong>Mybatis一级缓存</strong>；存储在sqlsession中，默认开启，底层是一个hashmap（cachekey键(statsmentid+params+boundsql+rowbounds),值(具体对象)）。第一次查询先去缓存中查找，找到直接返回，没找到去数据库获取，返回查询结果并缓存。事务提交操作会清空缓存。</p>
<p>一级缓存源码理解：根据父子关系翻阅源码，比如sqlsession(clearCache)-&gt;defaultSqlsession(clearCache)-&gt;excutor(clearLocalCache)-&gt;</p>
<p>baseExcutor(clearLocalCache)-&gt;perpetualCache(clear)查看最底层，他定义的就是一个hashmap,得出结果缓存就是存放map对象。方法执行底层中都要调用createCacheKey获取cachekey,在方法内通过Configuration.getEnvironment是否为空来决定是否完成cachekey值的封装。根据key是否为空来判定缓存的添加。</p>
<p><strong>Mybatis二级缓存</strong>：</p>
<p>横跨sqlsesion,默认关闭，通过注解标签@CacheNamespace开启二级缓存，多个sqlsession共享二级缓存，二级缓存的不是对象，是缓存的数据，注意二级缓存实体类要实现序列化接口，因为二级缓存能存储内存和硬盘。可以引入外部redis非关系性数据库来进行二级缓存，自定义缓存类必须要实现cache包下的Cache接口。</p>
<p>全局二级缓存开启</p>
<settings>

<setting name="cacheEnabled" value="true"/>

</settings>

<p><strong>Mybatis整合Redis缓存：</strong>解决分布式二级缓存，对缓存数据进行集中管理，从redis缓存服务器中获取缓存数据，redis源码自带默认配置。缓存的数据也是一个hash结构。</p>
<p><strong>三层架构：</strong>api接口层-&gt;传统或者代理方式、数据处理层-&gt;数据库操作、框架支撑层-&gt;连接，事务，配置，缓存等等。</p>
<p><strong>Sqlsession</strong>:作为mybatis工作的主要顶层api,表示和数据库交互的会话，完成数据库curd功能</p>
<p><strong>Excutor</strong>:Mybatis执行器，负责sql语句的生成和查询缓存的维护</p>
<p><strong>BatchExecutor</strong> (重⽤语句并执⾏批量更新)</p>
<p><strong>ReuseExecutor</strong> (重⽤预处理语句 prepared statements)</p>
<p><strong>SimpleExecutor</strong> (普通的执⾏器，默认)</p>
<p>(1、根据传递的参数，完成SQL语句的动态解析，⽣成BoundSql对象，供StatementHandler使⽤；</p>
<p>(2、为查询创建缓存，以提⾼性能</p>
<p>(3、创建JDBC的Statement连接对象，传递给<em>StatementHandler</em>对象，返回List查询结果。</p>
<p><strong>StatementHandler</strong>：封装了jdbc statement操作，设置参数，将结果转化成list集合</p>
<p>对于JDBC的PreparedStatement类型的对象，创建的过程中，我们使⽤的是SQL语句字符串会包含若⼲个？占位符，我们其后再对占位符进⾏设值。StatementHandler通过parameterize(statement)⽅法对 S tatement 进⾏设值；</p>
<p>StatementHandler 通过 List query(Statement statement, ResultHandler resultHandler)⽅法来完成执⾏Statement，和将Statement对象返回的resultSet封装成List；</p>
<p><strong>ParameterHandler</strong>:把传递的参数转化成jdbc statement所需要的参数</p>
<p><strong>ResultSetHandler</strong>：将jdbc返回的结果集转化成list类型集合</p>
<p><strong>TypeHandler</strong>：负责java数据和jdbc数据类型之间的映射和转换</p>
<p><strong>MappedStatement</strong>：维护了一条＜select | update | delete | insert＞节点的封装</p>
<p><strong>SqlSource</strong>:根据用户传递的parameterObject动态生成sql语句，封装到BoundSql对象并返回</p>
<p><strong>BoundSql</strong>:动态生成sql语句和参数信息</p>
<p><strong>Mybatis执行总体流程：</strong></p>
<p>\1. 加载配置文件并初始化</p>
<p>\2. 接受调用请求</p>
<p>\3. 处理操作请求（根据sql的id查找对应的mappedstatement对象-&gt;根据传入参数解析mappedstatement对象，得到sql和入参-&gt;获取数据库连接并执行sql，返回结果-&gt;根据mappedstatement对象结果映射配置对执行结果进行转化处理，得到最终返回结果）</p>
<p>\4. 返回处理结果</p>
<h3 id="Mybatis二级缓存解析"><a href="#Mybatis二级缓存解析" class="headerlink" title="Mybatis二级缓存解析"></a>Mybatis二级缓存解析</h3><p>⼆级缓存构建在⼀级缓存之上，在收到查询请求时，MyBatis ⾸先会查询⼆级缓存，若⼆级缓存未命中，再去查询⼀级缓存，⼀级缓存没有，再查询数据库。二级缓存-&gt;一级缓存-&gt;数据库与⼀级缓存不同，⼆级缓存和具体的命名空间绑定，⼀个Mapper中有⼀个Cache，相同Mapper中的MappedStatement共⽤⼀个Cache，⼀级缓存则是和 SqlSession 绑定。</p>
<p><strong>Cache标签解析</strong>：在xml配置文件初始化的时候，在build方法内通过XmlConfigBuilder类的parser方法对configuration标签下所有子节点标签进行解析，找到引入的mapper配置标签，进入对应mapper内部解析方法，在resource或url或class任意不为空的情况下，调用构造的XMLMapperBuilder类中parse方法对mapper节点进行解析，在对应逻辑中找到cache处理模块（里面还有一个相关的处理cache-ref标签解析，是应对引入其他缓存数据库作为二级缓存）。获取标签内所有可定义属性，根据解析的属性通过builderAssistant.useNewCache方法来创建cache对象，最后存入configuration，并赋值给MapperBuilderAssistant的currentCache,而这个变量在构造MappedStatement的build对象时会对currentCache封装，所以相同mapper的MappedStatement共用一个caChe</p>
<p><img src="/posts/19125/asset/v2-661f3a62b41e3add5c8015b2e38f9a56_720w.webp" alt="img"></p>
<p><img src="/posts/19125/asset/v2-90c1e384d755405a222f82baed5f9b3d_720w.webp" alt="img"></p>
<p><img src="https://pic2.zhimg.com/80/v2-d8ab8a5134d008cc37f7905538b808f1_720w.webp" alt="img"></p>
<p><strong>二级缓存的执行</strong>：在使用端通过对具体方法的调用，比如查询，到重载方法后会执行executor.query()方法，因为开启了二级缓存，这时候执行器的query方法就会走CachingExecutor类，而不是默认的BaseExecutor类。在对应类里面获取BoundSql对象并创建CacheKey对象，把参数带入query方法，在具体方法内如果cache不为空，进入具体逻辑，首先有一个flushCacheIfRequired方法通过flushCache&#x3D;”true”设置属性对缓存是否清空进行处理，接着会有一个tcm.getObject方法，从二级缓存中获取结果，如果为空执行delegate.query（）方法从一级缓存获取结果，SimpleExecutor其实就是delegate的具体实现。如果没有再从数据库获取，最后通过tcm.setObjetc再把结果存入一个map对象中,这里还没有存入二级缓存，在执行commit或者close时，才会把map对象转移到二级缓存中，而tcm就是TransactionalCacheManager事务缓存管理器(说到事务就明白了撒，进行事务管控，没有提交就暂时把数据操作临时存放，待完成后进行事务提交，完成最终操作) ，但是⼆级缓存是从 MappedStatement 中获取的。由于 MappedStatement 存在于全局配置中，可以多个 CachingExecutor 获取到，这样就会出现线程安全问题。除此之外，若不加以控制，多个事务共⽤⼀个缓存实例，会导致脏读问题。因此设计可一个Map&lt;Cache, TransactionalCache&gt; transactionalCaches &#x3D; new HashMap&lt;Cache, TransactionalCache&gt;();来映射Cache 与 TransactionalCache的关系。在进行tcm.setObject时, 存储⼆级缓存对象的时候是放到了TransactionalCache.entriesToAddOnCommit这个map中。而查询又是TransactionalCache.delegate中去查询，避免了数据问题的产生，在提交之后，通过flushPendingEntries方法把数据加载进了delegate中，二级缓存数据正式生效。</p>
<p><img src="/posts/19125/asset/v2-67617f298484a1f9ad07c8e38bf3f4df_720w.webp" alt="img"></p>
<p><img src="/posts/19125/asset/v2-ddf814c3c592422b0549f8d2b15eb754_720w.webp" alt="img"></p>
<p><img src="/posts/19125/asset/v2-3f5da40429a84e755b3c1389b539e75e_720w.webp" alt="img"></p>
<p><img src="/posts/19125/asset/v2-e68a7357cfaf642c008ed520649ee951_720w.webp" alt="img"></p>
<p><img src="/posts/19125/asset/v2-d65009539b71f2ee2f991cac88cb9b2d_720w.webp" alt="img"></p>
<p><img src="https://pic3.zhimg.com/80/v2-f23cb9bed8d949962bb3e8e65e03b262_720w.webp" alt="img"></p>
<h2 id="延迟加载"><a href="#延迟加载" class="headerlink" title="延迟加载"></a>延迟加载</h2><p>一对多，多对多采用延迟加载，什么时候用什么时候加载</p>
<p>一对一，多对一采用；立即加载，默认采用策略</p>
<p>优点：延迟加载可以实现先从单表查询，需要时再关联其他表获取数据，提高查询效率，优化数据库性能。</p>
<p>缺点：因为只有当需要⽤到数据时，才会进⾏数据库查询，这样在⼤批量数据查询时，因为查询⼯作也要消耗时间，所以可能造成⽤户等待时间变⻓，造成⽤户体验下降。</p>
<p>在association和collection标签中都有⼀个fetchType属性，通过修改它的值，可以修改局部的加载策略</p>
<p>局部延迟加载</p>
<p><img src="/posts/19125/asset/v2-da3c38a975eb8544e02534b7b0c44d03_720w.webp" alt="img"></p>
<p>全局延迟加载</p>
<p><img src="https://pic3.zhimg.com/80/v2-54ddaf1cd090c9831eef0d1a29be9eaa_720w.webp" alt="img"></p>
<p>它的原理是，使⽤ CGLIB 或 Javassist( 默认 ) 创建⽬标对象的代理对象。当调⽤代理对象的延迟加载属性getting ⽅法时，进⼊拦截器⽅法。⽐如调⽤ a.getB().getName() ⽅法，进⼊拦截器的invoke(…) ⽅法，到invoke方法，通过代理拦截到指定⽅法，执⾏数据加载Invoke方法：获取或设置实体类属性延迟加载底层判断，第一层判断是否是延迟加载的属性，第二层是否是setting方法，移除延迟加载，第三层是否是getting方法，并且配置了延迟加载， 发现 a.getB() 需要延迟加载时，那么就会单独发送事先保存好的查询关联 B对象的 SQL ，把 B 查询上来，然后调⽤ a.setB(b) ⽅法，于是 a 对象 b 属性就有值了，接着完成 a.getB().getName() ⽅法的调⽤。</p>
<h2 id="Mybatis设计模式"><a href="#Mybatis设计模式" class="headerlink" title="Mybatis设计模式"></a>Mybatis设计模式</h2><p><img src="/posts/19125/asset/v2-3cdc8e19a41f4ee1489758029677e729_720w.webp" alt="img"></p>
<p><strong>构建者设计模式</strong></p>
<p>Builder模式的定义是”将⼀个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。”，它属于创建类模式，⼀般来说，如果⼀个对象的构建⽐较复杂，超出了构造函数所能包含的范围，就可以使⽤⼯⼚模式和Builder模式，相对于⼯⼚模式会产出⼀个完整的产品，Builder应⽤于更加复杂的对象的构建，甚⾄只会构建产品的⼀个部分，直⽩来说，就是使⽤多个简单的对象⼀步⼀步构建成⼀个复杂的对象。</p>
<p><img src="/posts/19125/asset/v2-f8a6c6a5ca3a7dc17a7a0ad8d9f90338_720w.webp" alt="img"></p>
<p><strong>工厂模式</strong></p>
<p>在Mybatis中⽐如SqlSessionFactory使⽤的是⼯⼚模式，该⼯⼚没有那么复杂的逻辑，是⼀个简单⼯⼚模式。</p>
<p>简单⼯⼚模式(Simple Factory Pattern)：⼜称为静态⼯⼚⽅法(Static Factory Method)模式，它属于创建型模式。</p>
<p>在简单⼯⼚模式中，可以根据参数的不同返回不同类的实例。简单⼯⼚模式专⻔定义⼀个类来负责创建其他类的实例，被创建的实例通常都具有共同的⽗类。</p>
<p>在mybatis中SqlSessionFactory负责SqlSession创建，并且的openSession ()⽅法重载了很多个，分别⽀持autoCommit、Executor、Transaction等参数的输⼊，来构建核⼼的SqlSession对象。</p>
<p>在DefaultSqlSessionFactory的openSessionFromDataSource方法，通过获取的数据库连接、事务对象、执行器，最后构建了defaultSqlSession。</p>
<p><strong>代理模式</strong></p>
<p>代理模式(Proxy Pattern):给某⼀个对象提供⼀个代理，并由代理对象控制对原对象的引⽤。代理模式的英⽂叫做Proxy，它是⼀种对象结构型模式，代理模式分为静态代理和动态代理，我们来介绍动态代理，我们使⽤Configuration的getMapper⽅法时，会调⽤mapperRegistry.getMapper⽅法，⽽该⽅法⼜会调⽤mapperProxyFactory.newInstance(sqlSession)来⽣成⼀个具体的代理，通过T newInstance(SqlSession sqlSession)⽅法会得到⼀个MapperProxy对象，这个MapperProxy对象实现了InvocationHandler重写了invoke方法，该⽅法则会调⽤后续的sqlSession.cud&gt;executor.execute&gt;prepareStatement 等⼀系列⽅法，完成 SQL 的执⾏和返回，最后调⽤T newInstance(MapperProxy mapperProxy)⽣成代理对象然后返回 。</p>
]]></content>
      <categories>
        <category>基础知识</category>
        <category>mybatis</category>
      </categories>
      <tags>
        <tag>基础知识</tag>
        <tag>mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title>mysql事务和锁相关知识</title>
    <url>/posts/33988/</url>
    <content><![CDATA[<h3 id="ACID特性"><a href="#ACID特性" class="headerlink" title="ACID特性"></a><strong>ACID特性</strong></h3><p>关系型数据库管理系统中，一个逻辑工作单元要成为事务，必须满足这4个特性，即原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）和持久性（Durability）。</p>
<p>原子性：每一个写事务，都会修改BufferPool，从而产生相应的Redo&#x2F;Undo日志，脏页没有刷成功数据库挂了可以通过 Redo 日志将其恢复出来，脏页刷新成功数据库挂了通过Undo来实现同步。</p>
<p>持久性：Redo log在系统Crash重启之类的情况时，可以修复数据，从而保障事务的持久性。</p>
<p>隔离性：InnoDB 支持的隔离性有 4 种，隔离性从低到高分别为：读未提交、读提交、可重复读、可串行化。锁和多版本控制（MVCC）技术就是用于保障隔离性的。</p>
<p>一致性：数据的完整性是通过原子性、隔离性、持久性来保证的，而这3个特性又是通过 Redo&#x2F;Undo 来保证的。</p>
<p><img src="https://pic4.zhimg.com/80/v2-71404860e0fc856d6b32c07a85d63973_720w.webp" alt="img"></p>
<h3 id="并发事务和排队"><a href="#并发事务和排队" class="headerlink" title="并发事务和排队"></a><strong>并发事务和排队</strong></h3><p><strong>事务并发问题</strong></p>
<p>1） 更新丢失：当两个或多个事务更新同一行记录，会产生更新丢失现象。可以分为回滚覆盖和提交覆盖。</p>
<p>2） 脏读：一个事务读取到了另一个事务修改但未提交的数据。</p>
<p>3） 不可重复读：一个事务中多次读取同一行记录不一致，后面读取的跟前面读取的不一致。</p>
<p>4） 幻读：一个事务中多次按相同条件查询，结果不一致。</p>
<p><strong>排队</strong></p>
<p>完全顺序执行所有事务的数据库操作，不需要加锁，简单的说就是全局排队，强一致性，处理性能低。</p>
<h3 id="排他锁和读写锁"><a href="#排他锁和读写锁" class="headerlink" title="排他锁和读写锁"></a><strong>排他锁和读写锁</strong></h3><p><strong>排他锁</strong></p>
<p>如果事务之间涉及到相同的数据项时，使用排他锁，或叫互斥锁，先进入的事务独占数据项以后，其他事务被阻塞，等待前面的事务释放锁。</p>
<p><img src="https://pic2.zhimg.com/80/v2-3da7850b5feff0450d0550d6571afa19_720w.webp" alt="img"></p>
<p><strong>读写锁</strong></p>
<p>读写锁就是进一步细化锁的颗粒度，区分读操作和写操作，让读和读之间不加锁，读写锁，可以让读和读并行，而读和写、写和读、写和写这几种之间还是要加排他锁。</p>
<p><img src="/posts/33988/asset/v2-4f8dd53fe4ec8a99f026271b6b19d2f4_720w.webp" alt="img"></p>
<h3 id="MVCC"><a href="#MVCC" class="headerlink" title="MVCC"></a><strong>MVCC</strong></h3><p>多版本控制MVCC，也就是Copy on Write的思想。MVCC除了支持读和读并行，还支持读和写、写和读的并行，但为了保证一致性，写和写是无法并行的，写写并行可以用乐观锁和悲观锁。每次事务修改操作之前，都会在Undo日志中记录修改之前的数据状态和事务号，该备份记录可以用于其他事务的读取，也可以进行必要时的数据回滚。</p>
<p><img src="/posts/33988/asset/v2-dbc06ab99cd63206f8a67501538d336e_720w.webp" alt="img"></p>
<p><strong>实现原理</strong></p>
<p>MVCC最大的好处是读不加锁，读写不冲突。，读操作可以分为两类: 快照读与当前读，支持可重复读和读已提交。</p>
<p>快照读：读取的是记录的快照版本（有可能是历史版本），不用加锁。</p>
<p>当前读：读取的是记录的最新版本，并且当前读返回的记录，都会加锁，保证其他事务不会再并发修改这条记录。</p>
<h3 id="事务隔离级别"><a href="#事务隔离级别" class="headerlink" title="事务隔离级别"></a><strong>事务隔离级别</strong></h3><p>数据库的事务隔离级别越高，并发问题就越小，但是并发处理能力越差。</p>
<p><img src="/posts/33988/asset/v2-82f99b6291ccc7c3fbbdf11bf05c4600_720w.webp" alt="img"></p>
<p>读未提交：解决了回滚覆盖类型的更新丢失，但是可能发生脏读现象，也就是可能读取到其他会话中未提交事务修改的数据。</p>
<p>已提交读：只能读取到其他会话中已经提交的数据，解决了脏读。但可能发生 不可重复读现象，也就是可能在一个事务中两次查询结果不一致。</p>
<p>可重复度：解决了不可重复读，它确保同一事务的多个实例在并发读取数据时，会看到同样的数据行。不过可能会出现幻读，当用户读取某一范围的数据行时，另一个事务又在该范围插入了新行，当用户在读取该范围的数据时会发现有新的幻影行。</p>
<p>可串行化：所有的增删改查串行执行。它通过强制事务排序，解决相互冲突，从而解决幻读的问题。</p>
<p><strong>事务隔离级别和锁的关系</strong></p>
<p>1）事务隔离级别是SQL92定制的标准，相当于事务并发控制的整体解决方案，本质上是对锁和MVCC使用的封装，隐藏了底层细节。</p>
<p>2）锁是数据库实现并发控制的基础，事务隔离性是采用锁来实现，对相应操作加不同的锁，就可以防止其他事务同时对数据进行读写操作。</p>
<p>3）对用户来讲，首先选择使用隔离级别，当选用的隔离级别不能解决并发问题或需求时，才有必要在开发中手动的设置锁。</p>
<h3 id="锁分类"><a href="#锁分类" class="headerlink" title="锁分类"></a><strong>锁分类</strong></h3><p><strong>操作的粒度可分为表级锁、行级锁和页级锁</strong></p>
<p>1）表级锁：每次操作锁住整张表。锁定粒度大，发生锁冲突的概率最高，并发度最低。应用在 MyISAM、InnoDB、BDB 等存储引擎中。</p>
<p>2）行级锁：每次操作锁住一行数据。锁定粒度最小，发生锁冲突的概率最低，并发度最高。应 用在InnoDB 存储引擎中。</p>
<p>3）页级锁：每次锁定相邻的一组记录，锁定粒度界于表锁和行锁之间，开销和加锁时间界于表锁和行锁之间，并发度一般。应用在BDB 存储引擎中。</p>
<p><img src="/posts/33988/asset/v2-afcc03f3cbdf336481a01754f97c6bc5_720w.webp" alt="img"></p>
<p><strong>操作的类型可分为读锁和写锁</strong></p>
<p>读锁（S锁）：共享锁，针对同一份数据，多个读操作可以同时进行而不会互相影响。</p>
<p>写锁（X锁）：排他锁，当前写操作没有完成前，它会阻断其他写锁和读锁。</p>
<p>IS锁、IX锁：意向读锁、意向写锁，属于表级锁，S和X主要针对行级锁。在对表记录添加S或X锁之前，会先对表添加IS或IX锁。</p>
<p><strong>操作的性能可分为乐观锁和悲观锁</strong></p>
<p>乐观锁：一般的实现方式是对记录数据版本进行比对，在数据更新提交的时候才会进行冲突检测，如果发现冲突了，则提示错误信息。</p>
<p>悲观锁：在对一条数据修改的时候，为了避免同时被其他人修改，在修改数据之前先锁定， 再修改的控制方式。共享锁和排他锁是悲观锁的不同实现，但都属于悲观锁范畴。</p>
<h3 id="行锁原理"><a href="#行锁原理" class="headerlink" title="行锁原理"></a><strong>行锁原理</strong></h3><p>InnoDB行锁是通过对索引数据页上的记录加锁实现的，主要实现算法有 3 种：Record Lock、Gap Lock 和 Next-key Lock。</p>
<p>RecordLock锁：锁定单个行记录的锁。（记录锁，RC、RR隔离级别都支持）</p>
<p>GapLock锁：间隙锁，锁定索引记录间隙，确保索引记录的间隙不变。（范围锁，RR隔离级别支 持）</p>
<p>Next-key Lock 锁：记录锁和间隙锁组合，同时锁住数据，并且锁住数据前后范围。（记录锁+范围锁，RR隔离级别支持）</p>
<p><strong>锁的应用</strong></p>
<p>主键加锁行为：仅在主键索引记录上加X锁。</p>
<p>唯一键加锁行为：唯一索引上加X锁，然后在主键索引记录上加X锁。</p>
<p>非唯一键加锁行为：对满足条件的记录和主键分别加X锁，前后范围分别加Gap Lock。</p>
<p>无索引加锁行为：表里所有行和间隙都会加X锁，当没有索引时，会导致全表锁定，因为InnoDB引擎 锁机制是基于索引实现的记录锁定。</p>
<p>1） select … from 语句 不加锁</p>
<p>2） select … from lock in share mode语句 共享锁 Next-Key Lock锁，存在唯一索引可降级为RecordLock锁。</p>
<p>3） select … from for update语句 排他锁 Next-Key Lock锁，存在唯一索引可降级为RecordLock锁。</p>
<p>4） update … where 语句 Next-Key Lock锁，存在唯一索引可降级为RecordLock锁。</p>
<p>5） delete … where 语句 Next-Key Lock锁，存在唯一索引可降级为RecordLock锁。</p>
<p>6） insert语句 RecordLock锁。</p>
<h3 id="悲观锁"><a href="#悲观锁" class="headerlink" title="悲观锁"></a><strong>悲观锁</strong></h3><p>数据处理过程，将数据处于锁定状态，一般使用数据库的锁机制实现。从广义上来讲，行锁、表锁、读锁、写锁、共享锁、排他锁等，都属于悲观锁。</p>
<p>表级锁：每次操作都锁住整张表，并发度最低。</p>
<p>共享锁（行级锁-读锁）：只能读取，不能修改，修改操作被阻塞。</p>
<p>排他锁（行级锁-写锁）：当前事务可以读取和修改，其他事务不能修改，也不能获取记录锁。</p>
<h3 id="乐观锁"><a href="#乐观锁" class="headerlink" title="乐观锁"></a><strong>乐观锁</strong></h3><p>在数据库操作时， 想法很乐观，认为这次的操作不会导致冲突，因此在数据库操作时并不做任何的特殊处理，即不加锁，而是在进行事务提交时再去判断是否有冲突了。</p>
<p>乐观锁实现：使用版本字段（version）、使用时间戳（Timestamp）</p>
<p><img src="/posts/33988/asset/v2-36833a702f33f8ad0c0e8c0574c35167_720w.webp" alt="img"></p>
<h3 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a><strong>死锁</strong></h3><p><strong>表锁死锁</strong></p>
<p>用户A–》A表（表锁）–》B表（表锁）</p>
<p>用户B–》B表（表锁）–》A表（表锁）</p>
<p>用户A、B都锁住一张表，又在互相访问且不释放锁住的表资源，因此对于数据库的多表操作时，尽量按照相同的顺序进行处理，尽量避免同时锁定两个资源。</p>
<p><strong>行级锁死锁</strong></p>
<p>1）事务中执行了一条没有索引条件的查询，引发全表扫描，把行级锁上升为全表记录锁定，多个这样的事务执行后，就很容易产生死锁和阻塞，因此SQL语句中不要使用太复杂的关联多表的查询。</p>
<p>2）两个事务分别想拿到对方持有的锁，互相等待，于是产生死锁，因此在同一个事务中，尽可能做到一次锁定所需要的所有资源。</p>
<p><strong>共享锁转换为排他锁</strong></p>
<p>事务A查询一条记录，加共享锁，这时候事务B对同一条记录进行更新，事务B 的排他锁要等事务A共享锁释放，而事务A需要继续执行更新需要排他锁，而事务B的排他锁已经在等待队列中，因此可以通过乐观锁控制，或者前端提交按钮做控制，避免用户频繁点击造成这种情况。</p>
<p><strong>死锁排查</strong></p>
<p>查看死锁日志及锁状态变量</p>
<p>1）查看近期死锁日志信息；</p>
<p>2）使用explain查看下SQL执行计划</p>
]]></content>
      <categories>
        <category>基础知识</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>基础知识</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>mysql性能优化总结</title>
    <url>/posts/48068/</url>
    <content><![CDATA[<h2 id="系统配置优化"><a href="#系统配置优化" class="headerlink" title="系统配置优化"></a><strong>系统配置优化</strong></h2><p>1）保证从内存中读取数据，扩大innodb_buffer_pool_size，默认128M，可到3&#x2F;4，修改 my.cnf，降低磁盘操作。</p>
<p>2）数据预热，通过预热脚本，将磁盘上的全部数据缓存到内存中。</p>
<p>3）降低磁盘写入次数，增大redolog，减少落盘次数，生产中不开通用查询日志，遇到性能问题开慢查询日志，不要求极高安全性，将写redolog策略 innodb_flush_log_at_trx_commit设置为0或2，不即时写入减少磁盘操作。</p>
<p>4）提高磁盘读写性能，使用SSD或内存磁盘。</p>
<h2 id="表结构设计优化"><a href="#表结构设计优化" class="headerlink" title="表结构设计优化"></a><strong>表结构设计优化</strong></h2><p>1）设计中间表，针对于统计或实时性不高需求。</p>
<p>2）设计冗余字段，减少表之间关联操作，比如用户、订单，也可以在订单表加入一个所属用户姓名。</p>
<p>3）拆表，字段太多或者字段使用较少进行拆分。</p>
<p>4）主键优化，每张表一个主键索引，分布式情况下雪花，不然就自增。</p>
<p>5）字段设计，将表字段长度设计得尽量小，因为越小查询越快，而且最好都为not null避免null值比较，能用数值类型就别用文本，数值类型效率高，如性别。</p>
<h2 id="SQL索引及优化"><a href="#SQL索引及优化" class="headerlink" title="SQL索引及优化"></a><strong>SQL索引及优化</strong></h2><p>1）使用explain查看索引使用情况，通过慢查询日志找执行时间过程的sql，进行分析，查看索引使用情况，重点关注如下：</p>
<p>type列，连接类型，最好达到range级别，杜绝出现all级别。</p>
<p>rows列，扫描行数，预估值。</p>
<p>extra列，详细说明，建议优化的值如下：Using filesort，Using temporary 。</p>
<p>2）sql语句中in包含的值不应过多，避免消耗过大。</p>
<p>3）select语句务必指明字段名称，减少CPU、IO、内存、网络带宽消耗，而且表结构变化用*可能影响前端。</p>
<p>4）当只需要一条数据的时候，使用limit 1，停止全表扫描。</p>
<p>5）排序字段加索引提高效率。</p>
<p>6）限制条件中其他字段没有索引，尽量少用or，否则会造成查询不走索引。</p>
<p>7）用union all 代替union，因为union将结果合并后还要过滤性操作去重。</p>
<p>8）order by rand()不走索引，别用。</p>
<p>9）区分in和exists、not in和not exists，如果是exists，那么以外层表为驱动表，先被访问，如果是in，那么先执行子查询。所以in适合于外表大而内表小的情况；exists适合于外表小而内表大的情况。</p>
<p>10）使用合理的分页方式以提高分页的效率，降低 limit m,n 中m 的值。</p>
<p>11）分段查询，当查询范围过大，查询缓慢时，通过程序，分段进行查询，循环遍历，将结果合并处理。</p>
<p>12）不建议使用%前缀模糊查询，只有’name%’才有走索引。</p>
<p>13）where子句中对字段少用表达式操作，因为会造成不走索引。</p>
<p>14）避免隐式转换，传入类型和定义类型不一致触发隐式转换。</p>
<p>15）联合索引，要遵守最左前缀法则，否则失效。</p>
<p>16）优化器采取它认为合适的索引来检索sql语句效率不理想可以使用force index来强制查询走某个索引。</p>
<p>17）存在范围查询，比如between、&gt;、&lt;等条件时，会造成后面的索引字段失效。</p>
<p>18）使用join优化，尽量使用inner join，避免left join，并且以小表驱动大表，减少嵌套循环 次数。</p>
]]></content>
      <categories>
        <category>基础知识</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>基础知识</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>mysql架构原理相关知识</title>
    <url>/posts/55736/</url>
    <content><![CDATA[<h2 id="体系架构"><a href="#体系架构" class="headerlink" title="体系架构"></a>体系架构</h2><p>MySQL Server架构自顶向下大致可以分网络连接层、服务层、存储引擎层和系统文件层。</p>
<p><img src="/posts/55736/asset/v2-c5ceb83fc00ab5a23e9a95705be0a362_720w.webp" alt="img"></p>
<p><strong>网络连接层</strong></p>
<p>客户端连接器：提供与MySQL服务器建立的支持。</p>
<p><strong>服务层</strong></p>
<p>主要包含系统管理和控制工具、连接池、SQL接口、解析器、查询优化器和缓存六个部分。</p>
<p>1） 连接池：存储和管理客户端与数据库的连接。</p>
<p>2） 系统管理和控制工具：集群、备份、安全管理。</p>
<p>3） SQL接口：接受客户端发送的各种SQL命令并返回查询结果。</p>
<p>4） 解析器：解析SQL，生成一颗解析树，验证SQL是否合法。</p>
<p>5） 查询优化器：将解析树转化成执行计划，与存储引擎进行交互。</p>
<p>6） 缓存：各种缓存，比如表、记录、权限等等，缓存有命中查询结果直接返回。</p>
<p><strong>存储引擎层</strong></p>
<p>负责MySQL中数据的存储与提取，与底层系统文件进行交互，可插拔，常见的两类：MyISAM和InnoDB。</p>
<p><strong>系统文件层</strong></p>
<p>负责将数据库的数据和日志存储在文件系统之上，并完成与存储引擎的交互，比如日志、配置文件等等。</p>
<p>错误日志查询：show variables like ‘%log_error%’</p>
<p>通用查询日志：show variables like ‘%general%’;</p>
<p>二进制日志(恢复和主从复制)：show binary logs;</p>
<p>慢查询日志(记录超时，默认10秒)：show variables like ‘%slow_query%’;</p>
<p>配置文件: 存放MySQL所有的配置信息文件。</p>
<h2 id="运行机制"><a href="#运行机制" class="headerlink" title="运行机制"></a>运行机制</h2><p><img src="/posts/55736/asset/v2-5f77df9836b4dbff124ecb437f338ed8_720w.webp" alt="img"></p>
<p>1） 建立连接，通过客户端&#x2F;服务器通信协议与MySQL建立连接。通信方式是半双工，也就是不能同时即发送数据也接收数据，除此之外还有全双工和单工，通过show processlist;可以查看用户正在运行的线程信息。</p>
<p>2） 查询缓存，开启了查询缓存且在查询缓存过程中查询到完全相同的SQL语句，则将查询结果直接返回给客户端，没有的话则进入下一环节。不过查询的结果大于query_cache_limit设置或者存在不确定参数，比如now()不会走缓存。show variables like ‘%query_cache%’;可查看缓存信息。</p>
<p>3） 解析器，将客户端发送的SQL进行语法解析，生成”解析树”，并检验SQL是否合法。</p>
<p>4） 查询优化器，根据“解析树”生成最优的执行计划，其实就是SQL优化，比如in排序，max函数等等。</p>
<p>5） 查询执行引擎，根据 SQL 语句中表的存储引擎类型，以及对应的API接口与底层存储引擎缓存或者物理文件的交互，得到查询结果并返回给客户端，如果开启了查询缓存，会把结果存入缓存中，并且返回方式是增量返回，不是一次性全部返回。</p>
<h2 id="存储引擎"><a href="#存储引擎" class="headerlink" title="存储引擎"></a>存储引擎</h2><p>根据MySQL提供的文件访问层抽象接口定制的一种文件访问机制，负责MySQL中的数据的存储和提取。5.5版本之前默认采用MyISAM存储引擎，5.5开始采用InnoDB存储引擎。</p>
<p><strong>InnoDB和MyISAM对比</strong></p>
<p>1）事务和外键</p>
<p>InnoDB支持事务和外键，具有安全性和完整性，适合大量insert或update操作</p>
<p>MyISAM不支持事务和外键，它提供高速存储和检索，适合大量的select查询操作</p>
<p>2）锁机制</p>
<p>InnoDB支持行级锁，锁定指定记录。基于索引来加锁实现。</p>
<p>MyISAM支持表级锁，锁定整张表。</p>
<p>3）索引结构</p>
<p>InnoDB使用聚集索引（聚簇索引），索引和记录在一起存储，既缓存索引，也缓存记录。</p>
<p>MyISAM使用非聚集索引（非聚簇索引），索引和记录分开。</p>
<p>4）并发处理能力</p>
<p>MyISAM使用表锁，会导致写操作并发率低，读之间并不阻塞，读写阻塞。</p>
<p>InnoDB读写阻塞可以与隔离级别有关，可以采用多版本并发控制（MVCC）来支持高并发</p>
<p>5）存储文件</p>
<p>InnoDB表对应两个文件，一个.frm表结构文件，一个.ibd数据文件。InnoDB表最大支持64TB；</p>
<p>MyISAM表对应三个文件，一个.frm表结构文件，一个MYD表数据文件，一个.MYI索引文件。默认限制是256TB。</p>
<p>6）MyISAM适用场景</p>
<p>不需要事务支持（不支持）</p>
<p>并发相对较低（锁定机制问题）</p>
<p>数据修改相对较少，以读为主</p>
<p>数据一致性要求不高</p>
<p>7）InnoDB适用场景</p>
<p>需要事务支持（具有较好的事务特性）</p>
<p>行级锁定对高并发有很好的适应能力</p>
<p>数据更新较为频繁的场景</p>
<p>数据一致性要求较高</p>
<p>硬件设备内存较大，可以利用InnoDB较好的缓存能力来提高内存利用率，减少磁盘IO</p>
<h2 id="InnoDB存储结构"><a href="#InnoDB存储结构" class="headerlink" title="InnoDB存储结构"></a>InnoDB存储结构</h2><p>MySQL 5.5版本开始默认使用InnoDB作为引擎，它擅长处理事务，具有自动崩溃恢复的特性。</p>
<p><img src="/posts/55736/asset/v2-a985024375ec9136860c055c228a2c0e_720w.webp" alt="img"></p>
<p>内存结构主要包括Buffer Pool、Change Buffer、Adaptive Hash Index和Log Buffer四大组件。</p>
<p><strong>Buffer Pool</strong></p>
<p>缓冲池，简称BP。BP以Page页为单位，默认大小16K，BP的底层采用链表数据结构管理Page。通过改进型LRU算法维护，即中间插入，命中往头部移动，未命中往尾部移动，实行末尾淘汰。</p>
<p>建议：将innodb_buffer_pool_size设置为总内存大小的60%-80%，innodb_buffer_pool_instances可以设置为多个，这样可以避免缓存争夺。</p>
<p><strong>Change Buffer</strong></p>
<p>写缓冲区，简称CB。在进行DML操作时，如果BP没有其相应的Page数据，并不会立刻将磁盘页加载到缓冲池，而是在CB记录缓冲变更，等未来数据被读取时，再将数据合并恢复到BP中，默认占BP的25%。</p>
<p><strong>Adaptive Hash Index</strong></p>
<p>自适应哈希索引，用于优化对BP数据的查询。InnoDB存储引擎会自动根据访问的频率和模式来为某些页建立哈希索引。</p>
<p><strong>Log Buffer</strong></p>
<p>日志缓冲区，保存要写入磁盘上log文件（Redo&#x2F;Undo）的数据，日志缓冲区的内容定期刷新到磁盘log文件中。</p>
<p>缓冲区满自动刷新到磁盘。</p>
<h2 id="InnoDB磁盘结构"><a href="#InnoDB磁盘结构" class="headerlink" title="InnoDB磁盘结构"></a>InnoDB磁盘结构</h2><p>InnoDB磁盘主要包含Tablespaces，InnoDB Data Dictionary，Doublewrite Buffer、Redo Log 和Undo Logs。</p>
<p><strong>表空间（Tablespaces）</strong></p>
<p>存储表结构和数据。并且分为系统表空间、独立表空间、 通用表空间、临时表空间、Undo表空间等多种类型。</p>
<p>1） 系统表空间：默认包含任何用户在系统表空间创建的表数据和索引数据，是InnoDB Data Dictionary，Doublewrite Buffer，Change Buffer，Undo Logs的存储区域。</p>
<p>2） 独立表空间：默认开启，独立表空间是一个单表表空间，该表创建于自己的数据文件中，而非创建于系统表空间中。</p>
<p>3） 通用表空间：通用表空间为通过create tablespace语法创建的共享表空间。</p>
<p>4） 撤销表空间：撤销表空间由一个或多个包含Undo日志文件组成。</p>
<p>5） 临时表空间：分为session temporary tablespaces 和global temporary tablespace两种。session temporary tablespaces 存储的是用户创建的临时表和磁盘内部的临时表。global temporary tablespace储存用户临时表的回滚段。</p>
<p><strong>数据字典（InnoDB Data Dictionary）</strong></p>
<p>InnoDB数据字典由内部系统表组成，这些表包含用于查找表、索引和表字段等对象的元数据。</p>
<p><strong>双写缓冲区（Doublewrite Buffer）</strong></p>
<p>位于系统表空间，是一个存储区域。在BufferPage的page页刷新到磁盘真正的位置前，会先将数据存在Doublewrite 缓冲区，当出现进程崩溃，从这里获取数据并恢复。</p>
<p><strong>重做日志（Redo Log）</strong></p>
<p>重做日志是一种基于磁盘的数据结构，用于在崩溃恢复期间更正不完整事务写入的数据。MySQL以循环方式写入重做日志文件，记录InnoDB中所有对Buffer Pool修改的日志，当出现崩溃从重做日志中把数据更新到数据文件。</p>
<p><strong>撤销日志（Undo Logs）</strong></p>
<p>撤消日志是在事务开始之前保存的被修改数据的备份，用于例外情况时回滚事务。撤消日志属于逻辑日志，根据每行记录进行记录。</p>
<p><strong>版本差异</strong></p>
<p>5.7版本：Undo日志表空间从共享表空间分离，安装时可自由指定，增加临时表空间，并且可动态修改Buffer Pool</p>
<p>8.0版本：数据字典和Undo、Doublewrite Buffer都从共享表空间分离，临时表空间可以配置多个物理文件。</p>
<h2 id="InnoDB线程模型"><a href="#InnoDB线程模型" class="headerlink" title="InnoDB线程模型"></a>InnoDB线程模型</h2><p><img src="/posts/55736/asset/v2-cc202580f1c4f4826891e35992850621_720w.webp" alt="img"></p>
<p><strong>IO Thread</strong></p>
<p>使用了大量的AIO（Async IO）来做读写处理，10个IO Thread，分别是write（4），read（4），insert buffer和log thread。</p>
<p><strong>Purge Thread</strong></p>
<p>事务提交之后，回收已经分配的undo 页。</p>
<p><strong>Page Cleaner Thread</strong></p>
<p>将脏数据刷新到磁盘，脏数据刷盘后相应的redo log也就可以覆盖，即可以同步数据，又能达到redo log循环使用的目的。</p>
<p><strong>Master Thread</strong></p>
<p>Master thread是InnoDB的主线程，负责调度其他各线程，优先级最高。作用是将缓冲池中的数据异步刷新到磁盘 ，保证数据的一致性，比如脏页的刷新、undo页回收、redo日志刷新、合并写缓冲等，分1秒和10秒执行。</p>
<h2 id="InnoDB数据文件"><a href="#InnoDB数据文件" class="headerlink" title="InnoDB数据文件"></a>InnoDB数据文件</h2><p><img src="/posts/55736/asset/v2-22c7f251c589a0608244177d9de6fc74_720w.webp" alt="img"></p>
<p>InnoDB数据文件存储结构：分为一个ibd数据文件-&gt;Segment（段）-&gt;Extent（区）-&gt;Page（页）-&gt;Row（行）</p>
<p>Tablesapce：表空间，用于存储多个ibd数据文件，用于存储表的记录和索引。一个文件包含多个段。</p>
<p>Segment：段，用于管理多个Extent，分为数据段、索引段、回滚段。</p>
<p>Extent：区，一个区固定包含64个连续的页，大小为1M。</p>
<p>Page：页，用于存储多个Row行记录，大小为16K。包含很多种页类型，比如数据页，undo页，系统页等等。</p>
<p>Row：行，包含了记录的字段值，事务ID、滚动指针、字段指针等信息。</p>
<p>InnoDB只支持两种文件格式：Antelope 和 Barracuda。</p>
<p>InnoDB存储引擎支持四种行格式：REDUNDANT、COMPACT、DYNAMIC和COMPRESSED。</p>
<h2 id="Undo-Log"><a href="#Undo-Log" class="headerlink" title="Undo Log"></a>Undo Log</h2><p>数据库事务开始之前，会将要修改的记录存放到 Undo 日志里，当事务回滚时或者数据库崩溃时，可以利用 Undo 日志，撤销未提交事务对数据库产生的影响。事务提交之后也不会马上删除，而是进入删除队列待删除。Undo Log属于逻辑日志，记录一个变化过程，采用段的方式管理和记录。例如执行一个delete，undolog会记录一个insert；执行一个update，undolog会记录一个相反的update。</p>
<p>1） 实现事务的原子性</p>
<p>事务处理过程中，如果出现了错误或者用户执行了 ROLLBACK 语句，MySQL可以利用 Undo Log中的备份将数据恢复到事务开始之前的状态。</p>
<p>2） 实现多版本并发控制（MVCC）</p>
<p>事务未提交之前，Undo Log保存了未提交之前的版本数据，Undo Log中的数据可作为数据旧版本快照供其他并发事务进行快照读。</p>
<p><img src="/posts/55736/asset/v2-bed55a0140382cb8ea3063b3893ecd38_720w.webp" alt="img"></p>
<h3 id="Redo-Log"><a href="#Redo-Log" class="headerlink" title="Redo Log"></a>Redo Log</h3><p>指事务中修改的任何数据，将最新的数据备份存储的位置（Redo Log），被称为重做日志。事务操作的执行，就会生成Redo Log，在事务提交时会将产生Redo Log写入Log Buffer。等事务操作的脏页写入到磁盘之后，Redo Log占用的空间会被覆盖写入。</p>
<p><img src="https://pic3.zhimg.com/80/v2-8032b827a564cb1b085a64cc62d74136_720w.webp" alt="img"></p>
<p>Redo Log 文件内容是以顺序循环的方式写入文件，写满时则回溯到第一个文件，进行覆盖写。</p>
<h3 id="Binlog日志"><a href="#Binlog日志" class="headerlink" title="Binlog日志"></a>Binlog日志</h3><p>MySQL Server的日志，即Binary log（二进制日志），简称Binlog。Binlog是记录所有数据库表结构变更以及表数据修改的二进制日志，不会记录SELECT和SHOW这类操作。Binlog日志是以事件形式记录，还包含语句所执行的消耗时间。用于主从复制和数据恢复。</p>
<p>Binlog文件名默认为“主机名_binlog-序列号”格式，文件记录模式有STATEMENT、ROW和MIXED三种。</p>
<p><strong>Binlog文件结构</strong></p>
<p>MySQL的binlog文件中记录的是对数据库的各种修改操作，用来表示修改操作的数据结构是Log event。</p>
<p><img src="/posts/55736/asset/v2-1318c6a87917fd36e1e18cd242ac2020_720w.webp" alt="img"></p>
<p><strong>Binlog写入机制</strong></p>
<p>1） 根据记录模式和操作触发event事件生成log event（事件触发执行机制）</p>
<p>2） 将事务执行过程中产生log event写入缓冲区，每个事务线程都有一个缓冲区，存放两个缓冲区，即支持事务和不支持事务的缓冲区。</p>
<p>3） 事务在提交阶段会将产生的log event写入到外部binlog文件中，以串行写入，保证连续性。</p>
<p><strong>Binlog文件操作</strong></p>
<p>状态查看：show variables like ‘log_bin’;</p>
<p>开启Binlog功能：set global log_bin&#x3D;mysqllogbin;</p>
<p>使用 binlog 恢复数据：</p>
<p>mysqlbinlog–start-datetime&#x3D;”2020-04-25 18:00:00” –stopdatetime&#x3D;”2020-04-26 00:00:00” mysqlbinlog.000002 | mysql -uroot -p1234 &#x2F;&#x2F;按指定时间恢复</p>
<p>mysqlbinlog –start-position&#x3D;154 –stop-position&#x3D;957 mysqlbinlog.000002 | mysql -uroot -p1234&#x2F;&#x2F;按事件位置号恢复</p>
<p>删除Binlog文件：purge binary logs to ‘mysqlbinlog.000001’; &#x2F;&#x2F;删除指定文件</p>
<p>可以通过设置expire_logs_days参数来启动自动清理功能。默认值为0表示没启用。设置为1表示超 出1天binlog文件会自动删除掉。</p>
]]></content>
      <categories>
        <category>基础知识</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>基础知识</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>mysql索引原理相关知识</title>
    <url>/posts/64993/</url>
    <content><![CDATA[<h3 id="索引类型"><a href="#索引类型" class="headerlink" title="索引类型"></a><strong>索引类型</strong></h3><p>索引可以提升查询速度，会影响where查询，以及order by排序，分为B Tree索引、Hash索引、FULLTEXT全文索引、R Tree索引、普通索引、唯一索引、主键索引、复合索引、主键索引、辅助索引、聚集索引（聚簇索引）、非聚集索引（非聚簇索引）</p>
<p>1） 普通索引：这是最基本的索引类型，基于普通字段建立的索引，没有任何限制。</p>
<p>ALTER TABLE tablename ADD INDEX [索引的名字] (字段名);</p>
<p>2） 唯一索引：索引字段的值必须唯一，但允许有空值 。</p>
<p>ALTER TABLE tablename ADD UNIQUE INDEX [索引的名字] (字段名);</p>
<p>3） 主键索引：它是一种特殊的唯一索引，不允许有空值。</p>
<p>ALTER TABLE tablename ADD PRIMARY KEY (字段名);</p>
<p>4） 复合索引：用户可以在多个列上建立索 引，这种索引叫做组复合索引，分窄索引和宽索引，使用复合索引，要根据where条件建索引。</p>
<p>ALTER TABLE tablename ADD INDEX [索引的名字] (字段名1，字段名2…);</p>
<p>5） 全文索引：对于大量的文本数据检索，使用模糊查询效率很低。使用全文索引，查询速度会比like快很多倍。全文索引字段值可以进行切词模糊查询。</p>
<p>创建方式：ALTER TABLE tablename ADD FULLTEXT [索引的名字] (字段名); CREATE TABLE tablename ( […], FULLTEXT KEY [索引的名字] (字段名</p>
<h3 id="索引原理"><a href="#索引原理" class="headerlink" title="索引原理"></a><strong>索引原理</strong></h3><p>索引是存储引擎用于快速查找记录的一种数据结构，物理数据页存储。需要额外开辟空间和数据维护工作，索引可以加快检索速度，但是同时也会降低增删改操作速度。</p>
<p><strong>二分查找法</strong></p>
<p><img src="/posts/64993/asset/v2-84a8de595bf839089e10963602274e00_720w.webp" alt="img"></p>
<p><img src="/posts/64993/asset/v2-8067da8ea0a8300707852e5843abb2b7_720w.webp" alt="img"></p>
<p><img src="/posts/64993/asset/v2-db1b4742d543189e587803029ab6230a_720w.webp" alt="img"></p>
<p><img src="https://pic2.zhimg.com/80/v2-9df413feb67d3705c869d8bfd878b17d_720w.webp" alt="img"></p>
<p><strong>Hash结构</strong></p>
<p>Hash底层实现是由Hash表来实现的，是根据键值存储数据的结构。</p>
<p><img src="/posts/64993/asset/v2-4926108cd196dd035ef44343c95b9100_720w.webp" alt="img"></p>
<h3 id="B-Tree结构"><a href="#B-Tree结构" class="headerlink" title="B+Tree结构"></a><strong>B+Tree结构</strong></h3><p>MySQL数据库索引采用的是B+Tree结构，在B-Tree结构上做了优化改造。</p>
<p><strong>B-Tree结构</strong></p>
<p><img src="/posts/64993/asset/v2-e8123e8aadcb716f82f3fd67d5136636_720w.webp" alt="img"></p>
<p>原理：从根节点开始，对节点内的索引值序列采用二分法查找，如果命中就结束查找。没有命中会进入子节点重复查找过程，直到所对应的的节点指针为空，或已经是叶子节点了才结束。</p>
<p><strong>B+Tree结构</strong></p>
<p><img src="/posts/64993/asset/v2-672e3a39b1ac9a7560c895dce227655c_720w.webp" alt="img"></p>
<p>B+树进行范围查找时，只需要查找定位两个节点的索引值，然后利用叶子节点的指针进行遍历。</p>
<h3 id="聚簇索引和辅助索引"><a href="#聚簇索引和辅助索引" class="headerlink" title="聚簇索引和辅助索引"></a><strong>聚簇索引和辅助索引</strong></h3><p>B+Tree的叶子节点存放主键索引值和行记录就属于聚簇索引；如果索引值和行记录分开存放就属于非聚簇索引。</p>
<p>B+Tree的叶子节点存放的是主键字段值就属于主键索引；如果存放的是非主键值 就属于辅助索引。</p>
<p>聚簇索引：如果表定义了主键，则主键索引就是聚簇索引，否则第一个非空unique列作为聚簇索引，不然自建隐藏索引。</p>
<p>辅助索引：一个表InnoDB只能创建一个聚簇索引，但可以创建多个辅助索引。</p>
<p>非聚簇索引： MyISAM数据表的索引文件和数据文件是分开的，被称为非聚簇索引结构。</p>
<h3 id="Explain分析"><a href="#Explain分析" class="headerlink" title="Explain分析"></a><strong>Explain分析</strong></h3><p>EXPLAIN 命令用于对 SELECT 语句进行分析，并输出 SELECT 执行的详细信息。</p>
<p><img src="/posts/64993/asset/v2-5b21572c93a6fbf9e598e0bca12f49b4_720w.webp" alt="img"></p>
<p><strong>select_type查询的类型</strong></p>
<p>SIMPLE ： 表示查询语句不包含子查询或union</p>
<p>PRIMARY：表示此查询是最外层的查询</p>
<p>UNION：表示此查询是UNION的第二个或后续的查询</p>
<p>DEPENDENT UNION：UNION中的第二个或后续的查询语句，使用了外面查询结果</p>
<p>UNION RESULT：UNION的结果</p>
<p>SUBQUERY：SELECT子查询语句</p>
<p>DEPENDENT SUBQUERY：SELECT子查询语句依赖外层查询的结果。</p>
<p><strong>type</strong></p>
<p>ALL：表示全表扫描，性能最差。</p>
<p>index：表示基于索引的全表扫描，先扫描索引再扫描全表数据。</p>
<p>range：表示使用索引范围查询。使用&gt;、&gt;&#x3D;、&lt;、&lt;&#x3D;、in等等。</p>
<p>ref：表示使用非唯一索引进行单值查询。</p>
<p>eq_ref：一般情况下出现在多表join查询，表示前面表的每一个记录，都只能匹配后面表的一 行结果。</p>
<p>const：表示使用主键或唯一索引做等值查询，常量查询。</p>
<p>NULL：表示不用访问表，速度最快。</p>
<p><strong>possible_keys</strong></p>
<p>表示查询时能够使用到的索引。注意并不一定会真正使用，显示的是索引名称。</p>
<p><strong>key</strong></p>
<p>表示查询时真正使用到的索引，显示的是索引名称。</p>
<p><strong>rows</strong></p>
<p>MySQL查询优化器会根据统计信息，估算SQL要查询到结果需要扫描多少行记录。</p>
<p><strong>key_len</strong></p>
<p>表示查询使用了索引的字节数量。可以判断是否全部使用了组合索引。</p>
<p><strong>Extra</strong></p>
<p>Using where: 表示查询需要通过索引回表查询数据。</p>
<p>Using index: 表示查询需要通过索引，索引就可以满足所需数据。</p>
<p>Using filesort: 表示查询出来的结果需要额外排序，数据量小在内存，大的话在磁盘，有Using filesort 建议优化。</p>
<p>Using temprorary: 查询使用到了临时表，一般出现于去重、分组等操作。</p>
<h3 id="回表查询"><a href="#回表查询" class="headerlink" title="回表查询"></a><strong>回表查询</strong></h3><p>通过辅助索引无法直接定位行记录, 先通过辅助索引定位主键值，然后再通过聚簇索引定位行记录，它的性能比扫一遍索引树低。</p>
<h3 id="覆盖索引"><a href="#覆盖索引" class="headerlink" title="覆盖索引"></a><strong>覆盖索引</strong></h3><p>只需要在一棵索引树上就能获取SQL所需的所有列数据，无需回表，速度更快，这就叫做索引覆盖。将被查询的字段，建立到组合索引。</p>
<h3 id="最左前缀原则"><a href="#最左前缀原则" class="headerlink" title="最左前缀原则"></a><strong>最左前缀原则</strong></h3><p>复合索引使用时遵循最左前缀原则，最左前缀顾名思义，就是最左优先，即查询中使用到最左边的列， 那么查询就会使用到索引，如果从索引的第二列开始查找，索引将失效。</p>
<h3 id="LIKE查询和NULL查询"><a href="#LIKE查询和NULL查询" class="headerlink" title="LIKE查询和NULL查询"></a><strong>LIKE查询和NULL查询</strong></h3><p>select * from user where name like ‘%o%’; &#x2F;&#x2F;不起作用</p>
<p>select * from user where name like ‘o%’; &#x2F;&#x2F;起作用</p>
<p>select * from user where name like ‘%o’; &#x2F;&#x2F;不起作用</p>
<p>可以在含有NULL的列上使用索引，但NULL和其他数据还是有区别的，NULL列需要增加额外空间来记录其值是否为NULL。</p>
<h3 id="索引与排序"><a href="#索引与排序" class="headerlink" title="索引与排序"></a><strong>索引与排序</strong></h3><p>MySQL查询支持filesort和index两种方式的排序，filesort是先把结果查出，然后在缓存或磁盘进行排序操作，效率较低。使用index是指利用索引自动实现排序，不需另做排序操作，效率会比较高。</p>
<p>filesort有两种排序算法：双路排序和单路排序。</p>
<p><strong>index方式的排序</strong></p>
<ol>
<li><p>ORDER BY 子句索引列组合满足索引最左前列</p>
</li>
<li><p>WHERE子句+ORDER BY子句索引列组合满足索引最左前列</p>
</li>
</ol>
<p><strong>filesort方式的排序</strong></p>
<ol>
<li><p>对索引列同时使用了ASC和DESC</p>
</li>
<li><p>WHERE子句和ORDER BY子句满足最左前缀，但where子句使用了范围查询（例如&gt;、&lt;、in等）</p>
</li>
<li><p>ORDER BY或者WHERE+ORDER BY索引列没有满足索引最左前列</p>
</li>
<li><p>使用了不同的索引，MySQL每次只采用一个索引，ORDER BY涉及了两个索引</p>
</li>
<li><p>WHERE子句与ORDER BY子句，使用了不同的索引</p>
</li>
<li><p>WHERE子句或者ORDER BY子句中索引列使用了表达式，包括函数表达式</p>
</li>
</ol>
<h3 id="慢查询定位"><a href="#慢查询定位" class="headerlink" title="慢查询定位"></a><strong>慢查询定位</strong></h3><p>开启慢查询日志: SHOW VARIABLES LIKE ‘slow_query_log%’</p>
<p>通过文本编辑器打开slow.log日志</p>
<p>time：日志记录的时间</p>
<p>User@Host：执行的用户及主机</p>
<p>Query_time：执行的时间</p>
<p>Lock_time：锁表时间</p>
<p>Rows_sent：发送给请求方的记录数，结果数量</p>
<p>Rows_examined：语句扫描的记录条数</p>
<p>SET timestamp：语句执行的时间点</p>
<p>select….：执行的具体的SQL语句</p>
<p>也可以通过分析工具查看，比如mysqldumpslow。</p>
<h3 id="慢查询优化"><a href="#慢查询优化" class="headerlink" title="慢查询优化"></a><strong>慢查询优化</strong></h3><p><strong>如何判断是否为慢查询？</strong></p>
<p>依据SQL语句的执行时间，它把当前语句的执行时间跟 long_query_time 参数做比较，超出记录日志，long_query_time 参数的默认值是 10s，该参数值可以根据自己的业务需要进行调整。</p>
<p><strong>如何判断是否应用了索引？</strong></p>
<p>根据SQL语句执行过程中有没有用到表的索引，可通过 explain 命令分析查看</p>
<p>查询是否使用索引，只是表示一个SQL语句的执行过程；而是否为慢查询，是由它执行的时间决定，不止要创建索引，还要考虑索引过滤性，过滤性好，执行速度才会快。</p>
<p><strong>慢查询原因总结</strong></p>
<p>1） 全表扫描：explain分析type属性all</p>
<p>2） 全索引扫描：explain分析type属性index</p>
<p>3） 索引过滤性不好：靠索引字段选型、数据量和状态、表设计</p>
<p>4） 频繁的回表查询开销：尽量少用select *，使用覆盖索引</p>
<h3 id="分页查询优化"><a href="#分页查询优化" class="headerlink" title="分页查询优化"></a><strong>分页查询优化</strong></h3><p>一般的分页查询使用简单的 limit 子句就可以实现</p>
<p>SELECT * FROM 表名 LIMIT [offset,] rows</p>
<p>如果查询偏移量变化，比如查询万，百万级后面的数据，就不能用简单的直接分页了</p>
<p>1） 利用覆盖索引优化</p>
<p>2） 利用子查询优化</p>
<p>select * from user where id&gt;&#x3D; (select id from user limit 10000,1) limit 100;</p>
<p>使用了id做主键比较(id&gt;&#x3D;)，并且子查询使用了覆盖索引进行优化。</p>
]]></content>
      <categories>
        <category>基础知识</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>基础知识</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>mysql集群架构</title>
    <url>/posts/38076/</url>
    <content><![CDATA[<h3 id="集群架构设计"><a href="#集群架构设计" class="headerlink" title="集群架构设计"></a><strong>集群架构设计</strong></h3><p>集群架构设计的三个维度：可用性、扩展性、一致性</p>
<p><strong>可用性设计</strong></p>
<p>1） 站点高可用，冗余站点</p>
<p>2） 服务高可用，冗余服务</p>
<p>3） 数据高可用，冗余数据</p>
<p>高可用的方案：主从模式，双主模式（分双主双写和双主单写）</p>
<p><strong>扩展性设计</strong></p>
<p>1） 加从库，从库过多会引发主库性能损耗。</p>
<p>2） 分库分表，分为垂直拆分和水平拆分，垂直拆分可以缓解部分压力，水平拆分可以无限扩展。</p>
<p><strong>一致性设计</strong></p>
<p>1） 不使用从库</p>
<p>2） 增加访问路由层，得到主从同步最长时间t，在数据发生修改后的t时间内，先访问主库，保证数据一致。</p>
<h3 id="主从模式使用场景"><a href="#主从模式使用场景" class="headerlink" title="主从模式使用场景"></a><strong>主从模式使用场景</strong></h3><p>数据可以从一个MySQL数据库服务器主节点复制到一个或多个从节点，默认采用异步复制方式，这样从节点不用一直访问主服务器来更新自己的数据，从节点可以复制主数据库中的所有数据库，或者特定的数据库，或者特定的表。</p>
<p><img src="https://pic4.zhimg.com/80/v2-ff30969b4cef1c5705d834f371729f3b_720w.webp" alt="img"></p>
<p><strong>主从复制用途</strong></p>
<p>1） 实时灾备，用于故障切换（高可用）</p>
<p>2） 读写分离，提供查询服务（读扩展）</p>
<p>3） 数据备份，避免影响业务（高可用）</p>
<p><strong>主从部署必要条件</strong></p>
<p>1） 从库服务器能连通主库</p>
<p>2） 主库开启binlog日志（设置log-bin参数）</p>
<p>3） 主从server-id不同</p>
<h3 id="主从模式实现原理"><a href="#主从模式实现原理" class="headerlink" title="主从模式实现原理"></a><strong>主从模式实现原理</strong></h3><p><img src="/posts/38076/asset/v2-51471117491877873cff6c04ba55ca14_720w.webp" alt="img"></p>
<p>实现步骤：</p>
<p>1） 主库将数据库的变更操作记录到Binlog日志文件中</p>
<p>2） 从库读取主库中的Binlog日志文件信息写入到从库的Relay Log中继日志中</p>
<p>3） 从库读取中继日志信息在从库中进行Replay,更新从库数据信息</p>
<p>具体触发机制如下：</p>
<p>1） Master服务器对数据库更改操作记录在Binlog中，BinlogDump Thread接到写入请求后，读取 Binlog信息推送给Slave的I&#x2F;O Thread。</p>
<p>2） Slave的I&#x2F;O Thread将读取到的Binlog信息写入到本地Relay Log中。</p>
<p>3） Slave的SQL Thread检测到Relay Log的变更请求，解析relay log中内容在从库上执行。</p>
<p>存在的问题：</p>
<p>1） 主库宕机后，数据可能丢失</p>
<p>2） 从库只有一个SQL Thread，主库写压力大，复制很可能延时</p>
<p>解决的办法：</p>
<p>1） 半同步复制—解决数据丢失的问题</p>
<p>2） 并行复制—-解决从库复制延迟的问题</p>
<h3 id="半同步复制"><a href="#半同步复制" class="headerlink" title="半同步复制"></a><strong>半同步复制</strong></h3><p>从5.5开始，MySQL让Master在某一个时间点等待Slave节点的ACK消息，接收到ACK消息后才进行事务提交，这就是半同步复制。</p>
<p>主从复制时的完整过程：</p>
<p>1） InnoDB Redo File Write (Prepare Write)</p>
<p>2） Binlog File Flush &amp; Sync to Binlog File</p>
<p>3） InnoDB Redo File Commit（Commit Write）</p>
<p>4） Send Binlog to Slave</p>
<p>当Master不需要关注Slave是否接受到Binlog Event时，即为传统的主从复制。</p>
<p>当Master需要在第三步等待Slave返回ACK时，即为 after-commit，半同步复制（MySQL 5.5引入）。</p>
<p>当Master需要在第二步等待 Slave 返回 ACK 时，即为 after-sync，增强半同步（MySQL 5.7引入）。</p>
<p><img src="https://pic3.zhimg.com/80/v2-b40172df22381befa9054e11d3c42776_720w.webp" alt="img"></p>
<h3 id="并行复制"><a href="#并行复制" class="headerlink" title="并行复制"></a><strong>并行复制</strong></h3><p>MySQL从5.6版本开始追加了并行复制功能，改善复制延迟。</p>
<p><strong>5.6版本并行复制</strong></p>
<p>基于库的并行复制，也就是多线程分别执行各自库的操作，互不干扰，单库多表并发效率就不高了。</p>
<p><img src="https://pic4.zhimg.com/80/v2-756a05662eff8a22e62e0cf5cf1f68eb_720w.webp" alt="img"></p>
<p><strong>5.7版本并行复制</strong></p>
<p>基于组提交的并行复制，不再有库的并行复制限制。当事务提交时，通过在主库上的二进制日志中添加组提交信息，并将在单个操作中写入到二进制日志中。如果多个事务能同时提交成功，那么它们意味着没有冲突，因此可以在Slave上并行执行。MySQL 5.7的并行复制基于一个前提，即所有已经处于prepare阶段的事务，都是可以并行提交的。</p>
<p>InnoDB事务提交采用的是两阶段提交模式。一个阶段是prepare，另一个是commit。</p>
<p>在MySQL 5.7版本中，其设计方式是将组提交的信息存放在GTID中。为了避免用户没有开启GTID功能，MySQL 5.7又引入了称之为Anonymous_Gtid的二进制日志event类型，即日志中具有相同的last_committed，表示这些事务都在一组内。</p>
<p><strong>8.0 并行复制</strong></p>
<p>基于write-set的并行复制。有一个集合变量来存储事务修改的记录信息（主键哈希值），所有已经提交的事务所修改的主键值经过hash后都会与那个变量的集合进行对比，来判断改行是否与其冲突，并以此来确定依赖关系，没有冲突即可并行，row级别的粒度，类似于之前的表锁行锁差异，效率肯定更高。</p>
<h3 id="MySQL安装"><a href="#MySQL安装" class="headerlink" title="MySQL安装"></a><strong>MySQL安装</strong></h3><ol>
<li>上传mysql安装包到Linux服务器并进行解压</li>
</ol>
<p>tar -xvf mysql-5.7.28-1.el7.x86_64.rpm-bundle.tar</p>
<p><img src="/posts/38076/asset/v2-c1b69f6b4723170ca2730c32ea3a3836_720w.webp" alt="img"></p>
<ol start="2">
<li>检查是否已有Mysql安装，存在就移除‘</li>
</ol>
<p>rpm -qa | grep mariadb</p>
<p>rpm -e mariadb-libs-5.5.41-2.el7_0.x86_64 –nodeps</p>
<ol start="3">
<li>安装mysql-community-common-5.7.28-1.el7.x86_64.rpm</li>
</ol>
<p>rpm -ivh mysql-community-common-5.7.28-1.el7.x86_64.rpm</p>
<ol start="4">
<li>安装mysql-community-libs-5.7.28-1.el7.x86_64.rpm</li>
</ol>
<p>rpm -ivh mysql-community-libs-5.7.28-1.el7.x86_64.rpm</p>
<ol start="5">
<li>安装mysql-community-libs-compat-5.7.28-1.el7.x86_64.rpm</li>
</ol>
<p>rpm -ivh mysql-community-libs-compat-5.7.28-1.el7.x86_64.rpm</p>
<p>6）安装客户端 mysql-community-client-5.7.28-1.el7.x86_64.rpm</p>
<p>rpm -ivh mysql-community-client-5.7.28-1.el7.x86_64.rpm</p>
<p>7）安装服务端mysql-community-server-5.7.28-1.el7.x86_64.rpm</p>
<p>rpm -ivh mysql-community-server-5.7.28-1.el7.x86_64.rpm</p>
<p>8）安装开发包 mysql-community-devel-5.7.28-1.el7.x86_64.rpm</p>
<p>rpm -ivh mysql-community-devel-5.7.28-1.el7.x86_64.rpm</p>
<p>9）初始化Mysql</p>
<p>mysqld –initialize –user&#x3D;mysql</p>
<p>10）查看root随机生成默认密码</p>
<p>cat &#x2F;var&#x2F;log&#x2F;mysqld.log #root@localhost: Ajtag.WsR3,J</p>
<p>11）设置自动启动Mysql</p>
<p>systemctl start mysqld.service</p>
<p>12）查看状态</p>
<p>systemctl status mysqld.service</p>
<p><img src="/posts/38076/asset/v2-e649d2adf1adc14e3f74f88c2d079a09_720w.webp" alt="img"></p>
<p>13）登录Mysql</p>
<p>mysql -uroot -p # 密码：Ajtag.WsR3,J</p>
<p>14）修改数据库密码</p>
<p>set password&#x3D;password(‘root’); 修改密码</p>
<p>exit #退出</p>
<p>15）关闭服务器防火墙</p>
<p>systemctl stop iptables</p>
<p>systemctl stop firewalld</p>
<p>systemctl disable firewalld.service</p>
<p>注意1：如果安装执行出现Header V3 DSA&#x2F;SHA1 Signature, key ID 5072e1f5:错误，这是由于yum安装了旧版本的GPG keys造成的，在尾部加上–force –nodeps即可。</p>
<p><img src="/posts/38076/asset/v2-b1880af5b38bbfe82d293a3776cfe8a6_720w.webp" alt="img"></p>
<p>注意2：如果初始化mysql失败，执行yum -y install numactl命令</p>
<p><img src="/posts/38076/asset/v2-731dfcb311d39356d08647cd6b9b5497_720w.webp" alt="img"></p>
<p>注意3：如果安装完mysql之后，mysql命令登录不成功，使用yum install libncurses*命令</p>
<p><img src="/posts/38076/asset/v2-48e1659ee33d4ff458a23a3b2aac6880_720w.webp" alt="img"></p>
<h3 id="主从同步实战"><a href="#主从同步实战" class="headerlink" title="主从同步实战"></a><strong>主从同步实战</strong></h3><p>1） 修改主库my.cnf配置文件</p>
<p>执行命令vim &#x2F;etc&#x2F;my.cnf</p>
<p>log_bin&#x3D;mysql-bin #开启binlog,文件名称为mysql-bin</p>
<p>server-id&#x3D;1 #指定server-id</p>
<p>sync-binlog&#x3D;1 #执行几次后进行磁盘同步1就代表次数</p>
<p>#忽略以下库的同步</p>
<p>binlog-ignore-db&#x3D;performance_schema</p>
<p>binlog-ignore-db&#x3D;information_schema</p>
<p>binlog-ignore-db&#x3D;sys</p>
<p>#指定同步的库 不设置就是同步所有库</p>
<p>binlog-do-db&#x3D;test</p>
<p>2） 完成配置修改重启mysql</p>
<p>systemctl restart mysqld</p>
<ol>
<li>主库授权</li>
</ol>
<p>#登录MySQL</p>
<p>mysql -uroot -p</p>
<p>#主库授权设置</p>
<p>grant replication slave on <em>.</em> to ‘root‘@’%’ identified by ‘root’;</p>
<p>grant all privileges on <em>.</em> to ‘root‘@’%’ identified by ‘root’;</p>
<p>#刷新权限，立即生效</p>
<p>flush privileges;</p>
<p>#查看主库状态</p>
<p>show master status;</p>
<ol start="2">
<li>从库配置修改</li>
</ol>
<p>执行命令 vim &#x2F;etc&#x2F;my.cnf</p>
<p>server-id&#x3D;2</p>
<p>relay_log&#x3D;mysql-relay-bin #relay-log名称</p>
<p>read_only&#x3D;1 #此库只读</p>
<p>5） 完成配置修改重启mysql</p>
<p>systemctl restart mysqld</p>
<p>6） 从库启动授权</p>
<p>#登陆数据库设置复制的主库</p>
<p>change master to master_host&#x3D;’47.106.138.46’,master_port&#x3D;3306,master_user&#x3D;’root’,</p>
<p>master_password&#x3D;’root’,master_log_file&#x3D;’ master-bin.000002’,master_log_pos&#x3D;154;</p>
<p>#查看从库状态</p>
<p>show slave status \G;</p>
<p>#开启从库</p>
<p>start slave;</p>
<p>#停止从库</p>
<p>stop slave;</p>
<p>#重新绑定主库</p>
<p>reset master;</p>
<p>#主库修改配置，从库无法启动，重置</p>
<p>reset slave;</p>
<h3 id="半同步复制实战"><a href="#半同步复制实战" class="headerlink" title="半同步复制实战"></a><strong>半同步复制实战</strong></h3><p>1） 主库半同步复制设置</p>
<p>#是否支持动态加载</p>
<p>select @@have_dynamic_loading;</p>
<p><img src="https://pic4.zhimg.com/80/v2-2f4c9903e0bb14cb1fa9c9b59ada08f3_720w.webp" alt="img"></p>
<p>#查看插件列表</p>
<p>show plugins;</p>
<p><img src="/posts/38076/asset/v2-83c8b9513d9fdf7e9b078555744c2635_720w.webp" alt="img"></p>
<p>#安装半同步复制插件并起别名</p>
<p>install plugin rpl_semi_sync_master soname ‘semisync_master.so’;</p>
<p><img src="/posts/38076/asset/v2-64039004ba16bea9559b0f9fd1aec740_720w.webp" alt="img"></p>
<p>#查看半同步复制相关参数</p>
<p>show variables like ‘%semi%’;</p>
<p><img src="/posts/38076/asset/v2-24e4d7248413d8f2cc510b16bc43270c_720w.webp" alt="img"></p>
<p>#开启半同步复制</p>
<p>set global rpl_semi_sync_master_enabled&#x3D;1;</p>
<p>#设置超时时间，默认10秒，设置为1秒</p>
<p>set global rpl_semi_sync_master_timeout&#x3D;1000;</p>
<p><img src="/posts/38076/asset/v2-df0e23d3075e3104db2a63b1e6dab3d0_720w.webp" alt="img"></p>
<p>2） 从库半同步复制设置</p>
<p>#是否支持动态加载</p>
<p>select @@have_dynamic_loading;</p>
<p><img src="/posts/38076/asset/v2-ae6d948c2b19060a8853d9fe38caafb4_720w.webp" alt="img"></p>
<p>#查看插件列表</p>
<p>show plugins;</p>
<p>#安装从库半同步复制插件并起别名</p>
<p>install plugin rpl_semi_sync_slave soname ‘semisync_slave.so’;</p>
<p>#查看半同步复制相关参数</p>
<p>show variables like ‘%semi%’;</p>
<p><img src="https://pic4.zhimg.com/80/v2-7fc309545852cd827a47aadcdf95daeb_720w.webp" alt="img"></p>
<p>#开启从库半同步复制</p>
<p>set global rpl_semi_sync_slave_enabled&#x3D;1;</p>
<p><img src="https://pic2.zhimg.com/80/v2-b9fa1cb9be50e39bd097d8b9138011b9_720w.webp" alt="img"></p>
<p>#重新加载从库</p>
<p>stop slave;</p>
<p>start slave;</p>
<p><img src="/posts/38076/asset/v2-db98421ff876f2fab0e4cfba78668daf_720w.webp" alt="img"></p>
<p>切换到&#x2F;var&#x2F;log目录，查看mysqld.log日志文件核验半同步复制是否生效</p>
<p><img src="/posts/38076/asset/v2-3663b4abf6a582915a43a4c65850ef60_720w.webp" alt="img"></p>
<h3 id="并行复制实战"><a href="#并行复制实战" class="headerlink" title="并行复制实战"></a><strong>并行复制实战</strong></h3><p>1） 主库设置</p>
<p>#查看数据库组信息</p>
<p>show variables like ‘%binlog_group%’;</p>
<p><img src="https://pic4.zhimg.com/80/v2-760f3e043505dec2a37a8a6f26809e03_720w.webp" alt="img"></p>
<p>#设置延迟时间</p>
<p>set binlog_group_commit_sync_delay&#x3D;1000;</p>
<p>#设置组内事务数量</p>
<p>set binlog_group_commit_sync_no_delay_count&#x3D;100;</p>
<p>2）从库配置</p>
<p>#查看从库可设置参数</p>
<p>show variables like ‘%slave%’;</p>
<p><img src="/posts/38076/asset/v2-5da1e24569c71102e56dcd03104d6aad_720w.webp" alt="img"></p>
<p>#修改并行复制方式，由库改组</p>
<p>set global slave_parallel_type&#x3D;‘LOGICAL_CLOCK’;</p>
<p>#设置组内最大线程数</p>
<p>set global slave_parallel_workers&#x3D;8;</p>
<p>#查看relay相关参数</p>
<p>show variables like ‘%relay_log%’;</p>
<p><img src="/posts/38076/asset/v2-1aca2f5c25a136e2aacb9957b72110a6_720w.webp" alt="img"></p>
<p>#打开relay_log写入权限</p>
<p>set global relay_log_recovery&#x3D;1;</p>
<p>#设置日志信息源为table，提高效率</p>
<p>set global relay_log_info_repository&#x3D;’TAABLE’;</p>
<p>#重启服务，使配置生效</p>
<p>systemctl restart mysqld</p>
<h3 id="读写分离"><a href="#读写分离" class="headerlink" title="读写分离"></a><strong>读写分离</strong></h3><p>大多数互联网业务基本上读多写少，因此读写分离就可以提高读的效率，读写分离首先需要将数据库分为主从库，一个主库用于写数据，多个从库完成读数据的操作，主从库之间通过主从复制机制进行数据的同步，而且这样还可以进行主库主写，不加索引，从库主读，加索引，把两个库的效率提升到最高，不过需要解决主从同步延迟和读写分配机制。</p>
<p><img src="https://pic4.zhimg.com/80/v2-c6f56a158dfc5fde1a722d607ef62a63_720w.webp" alt="img"></p>
<p><strong>主从同步延迟</strong></p>
<p>1） 写后立刻读：在写入数据库后，某个时间段内读操作就去主库，之后读操作访问从库。</p>
<p>2） 二次查询：先去从库读取数据，找不到时就去主库进行数据读取，注意对恶意攻击限制。</p>
<p>3） 根据业务特殊处理：根据业务特点和重要程度进行调整，实时性高数据读写都在主库，其他在从库。</p>
<p><strong>读写分配机制</strong></p>
<p>控制何时去主库写，何时去从库读。</p>
<p>1） 基于编程和配置实现：根据操作类型进行路由分配，增删改时操作主库，查询时操作从库。</p>
<p>2） 基于服务器端代理实现：使用中间件代理，动态分配，常用MySQL Proxy、MyCat以及Shardingsphere等。</p>
<p><img src="https://pic4.zhimg.com/80/v2-b38def16fb105a6b59a2ffcf5946b24f_720w.webp" alt="img"></p>
<h3 id="读写分离实战"><a href="#读写分离实战" class="headerlink" title="读写分离实战"></a><strong>读写分离实战</strong></h3><p>1） 代理主机上解压mysql-proxy代理包</p>
<p>tar -xzvf mysql-proxy-0.8.5-linux-el6-x86-64bit.tar</p>
<p>2） 创建一个mysql-proxy配置文件</p>
<p>vim &#x2F;etc&#x2F;mysql-proxy.cnf</p>
<p>3） 在配置文件内写入相应配置参数</p>
<p>user&#x3D;root #运行mysql-proxy用户</p>
<p>admin-username&#x3D;root#主从mysql共有的用户</p>
<p>admin-password&#x3D;root#用户的密码</p>
<p>proxy-address&#x3D; 117.50.5.252:4040 #mysql-proxy运行ip和端口，不加端口，默认4040</p>
<p>proxy-backend-addresses&#x3D; 47.106.138.46 #指定后端主master写入数据</p>
<p>proxy-read-only-backend-addresses&#x3D; 49.235.85.246 #指定后端从slave读取数据</p>
<p>proxy-lua-script&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql-proxy&#x2F;lua&#x2F;rw-splitting.lua #指定读写分离配置文件位置</p>
<p>log-file&#x3D;&#x2F;var&#x2F; logs&#x2F;mysql-proxy.log #日志位置</p>
<p>log-level&#x3D;debug #定义log日志级别，由高到低分别有(error|warning|info|message|debug)</p>
<p>daemon&#x3D;true #以守护进程方式运行</p>
<p>keepalive&#x3D;true #mysql-proxy崩溃时，尝试重启</p>
<p>#保存退出！并修改文件权限</p>
<p>chmod 660 &#x2F;etc&#x2F;mysql-porxy.cnf</p>
<p>4）修改lua脚本配置文件</p>
<p>vi &#x2F;usr&#x2F;local&#x2F;mysql-proxy&#x2F;lua&#x2F;rw-splitting.lua</p>
<p>min_idle_connections &#x3D; 1, #最小连接数，默认超过4个连接数时，才开始读写分离，改为1</p>
<p>max_idle_connections &#x3D; 8, #最大连接数，默认8</p>
<p>5）运行proxy脚本，在对应bin目录找到mysql-proxy</p>
<p>.&#x2F;mysql-proxy –defaults-file&#x3D;&#x2F;etc&#x2F;mysql-proxy.cnf</p>
<h3 id="双主模式"><a href="#双主模式" class="headerlink" title="双主模式"></a><strong>双主模式</strong></h3><p>主从模式，一主多从、读写分离，如果是单主模式，单主故障问题没法避免，是双主或者多主，增加MySQL入口，可以提升了主库的可用性，推荐使用双主单写，因为双主双写存在ID冲突和双主更新覆盖丢失问题。</p>
<p><img src="/posts/38076/asset/v2-282dab7ec85bf22b47e226d5d3c9379f_720w.webp" alt="img"></p>
<p>双主模式实战</p>
<p>1） 修改主库1的配置</p>
<p>执行命令vim &#x2F;etc&#x2F;my.cnf</p>
<p>relay_log&#x3D;mysql-relay-bin #relay_log名称</p>
<p>log_slave_updates&#x3D;1</p>
<p>#双主双写自增主键设置 1，3，5，7… 双主单写不用设置</p>
<p>auto_increment_offset&#x3D;1 #自动递增</p>
<p>auto_increment_increment&#x3D;2 #递增量</p>
<p>2） 完成配置修改重启mysql</p>
<p>systemctl restart mysqld</p>
<p>3）修改主库2的配置</p>
<p>执行命令vim &#x2F;etc&#x2F;my.cnf</p>
<p>log_bin&#x3D;mysql-bin #开启binlog,文件名称为mysql-bin</p>
<p>server-id&#x3D;3 #指定server-id</p>
<p>sync-binlog&#x3D;1 #执行几次后进行磁盘同步 1就代表次数</p>
<p>#忽略以下库的同步</p>
<p>binlog-ignore-db&#x3D;performance_schema</p>
<p>binlog-ignore-db&#x3D;information_schema</p>
<p>binlog-ignore-db&#x3D;sys</p>
<p>relay_log&#x3D;mysql-relay-bin #relay_log名称</p>
<p>log_slave_updates&#x3D;1</p>
<p>#双主双写自增主键设置 2，4，6，8… 双主单写不用设置</p>
<p>auto_increment_offset&#x3D;2 #自动递增</p>
<p>auto_increment_increment&#x3D;2 #递增量</p>
<p>4）登陆mysql并授权</p>
<p>#主库授权设置</p>
<p>grant replication slave on <em>.</em> to ‘root‘@’%’ identified by ‘root’;</p>
<p>grant all privileges on <em>.</em> to ‘root‘@’%’ identified by ‘root’;</p>
<p>#刷新权限，立即生效</p>
<p>flush privileges;</p>
<p>5）主库1和主库2互复制设置</p>
<p>#设置复制的master1主库为master2</p>
<p>change master to master_host&#x3D;’47.106.138.46’,master_port&#x3D;3306,</p>
<p>master_user&#x3D;’root’,master_password&#x3D;’root’,master_log_file&#x3D;’mysql-bin.000004’,master_log_pos&#x3D;154;</p>
<p>#设置复制的master2主库为master1</p>
<p>change master to master_host&#x3D;’49.235.85.246’,master_port&#x3D;3306,</p>
<p>master_user&#x3D;’root’,master_password&#x3D;’root’,master_log_file&#x3D;’mysql-bin.000001’,master_log_pos&#x3D;867;</p>
<h3 id="MMM架构"><a href="#MMM架构" class="headerlink" title="MMM架构"></a><strong>MMM架构</strong></h3><p>MMM架构是管理和监控双主复制，支持双主故障切换的第三方软件。</p>
<p><img src="https://pic2.zhimg.com/80/v2-9d7c5bf386053c97ffeb8960f874199d_720w.webp" alt="img"></p>
<p><strong>MMM故障处理机制</strong></p>
<p>MMM 划分writer和reader两类角色，分别对应写节点和读节点。</p>
<p>1） 当 writer节点出现故障，程序会自动移除该节点上的VIP</p>
<p>2） 写操作切换到 Master2，并将Master2设置为writer</p>
<p>3） 将所有Slave节点会指向Master2</p>
<p>MMM 也会管理 Slave 节点，在出现宕机、复制延迟或复制错误，MMM会移除该节点的VIP，直到节点恢复正常。</p>
<p><strong>MMM监控机制</strong></p>
<p>MMM 包含monitor和agent两类程序</p>
<p>monitor：监控集群内数据库的状态，在出现异常时发布切换命令。</p>
<p>agent：运行在每个MySQL服务器上的代理进程，monitor 命令的执行者。</p>
<h3 id="MHA架构"><a href="#MHA架构" class="headerlink" title="MHA架构"></a><strong>MHA架构</strong></h3><p>MHA是一款优秀的故障切换和 主从提升的高可用软件。能30秒之内自动完成数据库的故障切换并最大保证数据一致性，并支持在线快速将Master切换到其他主机，通常只需0.5－2秒。</p>
<p><img src="https://pic3.zhimg.com/80/v2-35feebfa05d6d1756095095dfa774852_720w.webp" alt="img"></p>
<p>MHA由两部分组成：MHA Manager（管理节点）和MHA Node（数据节点）</p>
<p>MHA Manager会定时探测集群中的master节点，当master出现故障时，它可以自动将最新数据的 slave提升为新的master，然后将所有其他的slave重新指向新的master。</p>
<p><strong>MHA故障处理机制</strong></p>
<p>1） 把宕机master的binlog保存下来</p>
<p>2） 根据binlog位置点找到最新的slave</p>
<p>3） 用最新slave的relay log修复其它slave</p>
<p>4） 将保存下来的binlog在最新的slave上恢复</p>
<p>5） 将最新的slave提升为master</p>
<p>6） 将其它slave重新指向新提升的master，并开启主从复制</p>
<p><strong>MHA优点</strong></p>
<p>1） 自动故障转移快</p>
<p>2） 主库崩溃不存在数据一致性问题</p>
<p>3） 性能优秀，支持半同步复制和异步复制</p>
<p>4） 一个Manager监控节点可以监控多个集群</p>
<h3 id="MHA架构实战"><a href="#MHA架构实战" class="headerlink" title="MHA架构实战"></a><strong>MHA架构实战</strong></h3><p>1） 环境说明</p>
<p>腾讯云主机作为MHA管理，阿里云作为主服务器，华为云和Ucloud作为从服务器。</p>
<p>2） 把mha4mysql-node-0.58-0.el7.centos.noarch.rpm节点程序上传到每个服务器，在MHA管理服务器再上传mha4mysql-manager-0.58-0.el7.centos.noarch.rpm管理端程序。</p>
<p><img src="/posts/38076/asset/v2-6488669aacb36fd0533f13c349bf7d4c_720w.webp" alt="img"></p>
<p>3） 修改主库的&#x2F;etc&#x2F;my.cnf配置并重启mysql</p>
<p><img src="https://pic3.zhimg.com/80/v2-194ca4fdca0a2fbf8e7a289515aa1af6_720w.webp" alt="img"></p>
<p>4） 修改从库的&#x2F;etc&#x2F;my.cnf配置并重启mysql</p>
<p>server-id&#x3D;2</p>
<p>relay-log &#x3D; relay-log #开启中继日志</p>
<p>log-bin &#x3D; master-log #开启二进制日志</p>
<p>read_only &#x3D; ON #启用只读属性</p>
<p>relay_log_purge &#x3D; 0 #是否自动清空不再需要中继日志</p>
<p>skip_name_resolve #关闭名称解析（非必须）</p>
<p>log_slave_updates &#x3D; 1 #使得更新的数据写进二进制日志中</p>
<p>5） 重启修改配置的库，使配置生效</p>
<p>systemctl restart mysqld</p>
<p>6） 安装依赖</p>
<p>yum install perl-DBI -y</p>
<p>yum install perl-DBD-MySQL -y</p>
<p>yum install perl-Config-Tiny -y</p>
<p>yum install <a href="https://link.zhihu.com/?target=https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm">https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm</a></p>
<p>yum install perl-Log-Dispatch -y</p>
<p>yum install perl-Parallel-ForkManager -y</p>
<p>7） 主、从、MHA安装node程序</p>
<p>rpm -ivh mha4mysql-node-0.58-0.el7.centos.noarch.rpm</p>
<p>8） MHA安装manager程序</p>
<p>rpm -ivh mha4mysql-manager-0.58-0.el7.centos.noarch.rpm</p>
<p>9） 四台服务器之间建立免密设置，输入第一个命令，回车然后再输入各个服务器地址命名并输入登录密码</p>
<p>#MHA 49.235.99.6</p>
<p>ssh-keygen -t rsa</p>
<p>ssh-copy-id -i &#x2F;root&#x2F;.ssh&#x2F;id_rsa <a href="mailto:&#114;&#x6f;&#x6f;&#x74;&#64;&#52;&#x37;&#x2e;&#49;&#48;&#54;&#x2e;&#x31;&#x33;&#56;&#x2e;&#52;&#54;">&#114;&#x6f;&#x6f;&#x74;&#64;&#52;&#x37;&#x2e;&#49;&#48;&#54;&#x2e;&#x31;&#x33;&#56;&#x2e;&#52;&#54;</a></p>
<p>ssh-copy-id -i &#x2F;root&#x2F;.ssh&#x2F;id_rsa <a href="mailto:&#x72;&#111;&#111;&#116;&#64;&#52;&#x39;&#x2e;&#x32;&#x33;&#x35;&#x2e;&#56;&#53;&#46;&#50;&#52;&#x36;">&#x72;&#111;&#111;&#116;&#64;&#52;&#x39;&#x2e;&#x32;&#x33;&#x35;&#x2e;&#56;&#53;&#46;&#50;&#52;&#x36;</a></p>
<p>ssh-copy-id -i &#x2F;root&#x2F;.ssh&#x2F;id_rsa <a href="mailto:&#114;&#111;&#x6f;&#116;&#x40;&#49;&#x31;&#55;&#46;&#53;&#x30;&#x2e;&#x35;&#x2e;&#x32;&#x35;&#x32;">&#114;&#111;&#x6f;&#116;&#x40;&#49;&#x31;&#55;&#46;&#53;&#x30;&#x2e;&#x35;&#x2e;&#x32;&#x35;&#x32;</a></p>
<p>#master 47.106.138.46</p>
<p>ssh-keygen -t rsa</p>
<p>ssh-copy-id -i &#x2F;root&#x2F;.ssh&#x2F;id_rsa <a href="mailto:&#114;&#111;&#x6f;&#116;&#x40;&#x34;&#x39;&#46;&#50;&#51;&#x35;&#46;&#56;&#53;&#46;&#x32;&#52;&#x36;">&#114;&#111;&#x6f;&#116;&#x40;&#x34;&#x39;&#46;&#50;&#51;&#x35;&#46;&#56;&#53;&#46;&#x32;&#52;&#x36;</a></p>
<p>ssh-copy-id -i &#x2F;root&#x2F;.ssh&#x2F;id_rsa <a href="mailto:&#114;&#x6f;&#x6f;&#x74;&#x40;&#x31;&#49;&#x37;&#46;&#53;&#48;&#46;&#53;&#46;&#50;&#x35;&#x32;">&#114;&#x6f;&#x6f;&#x74;&#x40;&#x31;&#49;&#x37;&#46;&#53;&#48;&#46;&#53;&#46;&#50;&#x35;&#x32;</a></p>
<p>#slave1 49.235.85.246</p>
<p>ssh-keygen -t rsa</p>
<p>ssh-copy-id -i &#x2F;root&#x2F;.ssh&#x2F;id_rsa <a href="mailto:&#114;&#111;&#111;&#116;&#64;&#x34;&#55;&#46;&#49;&#x30;&#54;&#46;&#x31;&#51;&#56;&#46;&#x34;&#54;">&#114;&#111;&#111;&#116;&#64;&#x34;&#55;&#46;&#49;&#x30;&#54;&#46;&#x31;&#51;&#56;&#46;&#x34;&#54;</a></p>
<p>ssh-copy-id -i &#x2F;root&#x2F;.ssh&#x2F;id_rsa <a href="mailto:&#x72;&#111;&#111;&#116;&#64;&#49;&#49;&#x37;&#x2e;&#x35;&#48;&#46;&#x35;&#46;&#x32;&#x35;&#50;">&#x72;&#111;&#111;&#116;&#64;&#49;&#49;&#x37;&#x2e;&#x35;&#48;&#46;&#x35;&#46;&#x32;&#x35;&#50;</a></p>
<p>#slave2 117.50.5.252</p>
<p>ssh-keygen -t rsa</p>
<p>ssh-copy-id -i &#x2F;root&#x2F;.ssh&#x2F;id_rsa <a href="mailto:&#114;&#111;&#111;&#x74;&#x40;&#52;&#55;&#x2e;&#x31;&#48;&#x36;&#46;&#x31;&#x33;&#x38;&#x2e;&#x34;&#54;">&#114;&#111;&#111;&#x74;&#x40;&#52;&#55;&#x2e;&#x31;&#48;&#x36;&#46;&#x31;&#x33;&#x38;&#x2e;&#x34;&#54;</a></p>
<p>ssh-copy-id -i &#x2F;root&#x2F;.ssh&#x2F;id_rsa <a href="mailto:root@49.235.85.246">root@49.235.85.246</a></p>
<p><img src="/posts/38076/asset/v2-fe9272c565d7786eff09d558edd066f6_720w.webp" alt="img"></p>
<p>10）MHA配置</p>
<p>mkdir -p &#x2F;etc&#x2F;mha</p>
<p>vim &#x2F;etc&#x2F;mha&#x2F;mha.cnf</p>
<p>#下载scripts 并放到&#x2F;etc&#x2F;mha&#x2F;scripts路径下，记得给脚本加执行权限</p>
<p>下载连接：<a href="https://link.zhihu.com/?target=https://github.com/yoshinorim/mha4mysql-manager/samples/scripts">https://github.com/yoshinorim/mha4mysql-manager/samples/scripts</a></p>
<p>[server default]</p>
<p>manager_workdir&#x3D;&#x2F;etc&#x2F;mha&#x2F; #manager工作目录</p>
<p>manager_log&#x3D;&#x2F;etc&#x2F;mha&#x2F;manager.log #mananger日志</p>
<p>master_binlog_dir&#x3D;&#x2F;var&#x2F;lib&#x2F;mysql #binlog复制目录</p>
<p>user&#x3D;root</p>
<p>password&#x3D;root</p>
<p>ping_interval&#x3D;1</p>
<p>remote_workdir&#x3D;&#x2F;tmp</p>
<p>repl_password&#x3D;root</p>
<p>repl_user&#x3D;root</p>
<p>secondary_check_script&#x3D; &#x2F;usr&#x2F;bin&#x2F;masterha_secondary_check -s 49.235.85.246 -s 117.50.5.252 –user&#x3D;root –master_host&#x3D;47.106.138.46 –master_ip&#x3D;47.106.138.46 –master_port&#x3D;3306</p>
<p>master_ip_failover_script&#x3D;&#x2F;etc&#x2F;mha&#x2F;scripts&#x2F;master_ip_failover #切换脚本</p>
<p>master_ip_online_change_script&#x3D;&#x2F;etc&#x2F;mha&#x2F;scripts&#x2F;master_ip_online_change #手动switchover时候的切换</p>
<p>#shutdown_script&#x3D;””</p>
<p>ssh_user&#x3D;root</p>
<p>[server1]</p>
<p>hostname&#x3D;47.106.138.46</p>
<p>port&#x3D;3306</p>
<p>candidate_master&#x3D;1</p>
<p>check_repl_delay&#x3D;0</p>
<p>[server2]</p>
<p>hostname&#x3D;49.235.85.246</p>
<p>port&#x3D;3306</p>
<p>candidate_master&#x3D;1</p>
<p>check_repl_delay&#x3D;0</p>
<p>[server3]</p>
<p>hostname&#x3D;117.50.5.252</p>
<p>port&#x3D;3306</p>
<p>10）检查ssh连接和复制状态</p>
<p>#检查ssh免密连接</p>
<p>masterha_check_ssh –conf&#x3D;&#x2F;etc&#x2F;mha&#x2F;mha.cnf</p>
<p>#检查复制</p>
<p>masterha_check_repl –conf&#x3D;&#x2F;etc&#x2F;mha&#x2F;mha.cnf</p>
<p>11）启动Manager</p>
<p>nohup masterha_manager –conf&#x3D;&#x2F;etc&#x2F;mha&#x2F;mha.cnf&lt; &#x2F;dev&#x2F;null &gt; &#x2F;etc&#x2F;mha&#x2F;manager.log 2&gt;&amp;1 &amp;</p>
<p>12）查看状态</p>
<p>masterha_check_status –conf&#x3D;&#x2F;etc&#x2F;mha&#x2F;mha.cnf</p>
<p>13）停止Manager</p>
<p>masterha_stop –conf&#x3D;&#x2F;etc&#x2F;mha&#x2F;mha.cnf</p>
<p>rm &#x2F;etc&#x2F;mha&#x2F;&#x2F;mha.failover.complete</p>
<h3 id="主备切换策略"><a href="#主备切换策略" class="headerlink" title="主备切换策略"></a><strong>主备切换策略</strong></h3><p>主备切换是指将备库变为主库，主库变为备库，有可靠性优先和可用性优先两种策略，可靠性优先为常用。</p>
<p>主备延迟就是同一个事务，在备库执行完成的时间和主库执行完成的时间之间的差值。</p>
<p>同步延迟的原因：备库机器性能差、备库执行其他操作消耗CPU，分工问题、大事务耗时长。</p>
<p><strong>可靠性优先</strong></p>
<p>主备切换过程一般由专门的HA高可用组件完成，但是切换过程中会存在短时间不可用，为保证数据一致性。</p>
<p><strong>可用性优先</strong></p>
<p>不等主从同步完成，直接把业务请求切换至从库B ，并且让从库B可读写。</p>
<h3 id="分库分表"><a href="#分库分表" class="headerlink" title="分库分表"></a><strong>分库分表</strong></h3><p>分库分表，主要有垂直拆分和水平拆分两种拆分模式，都属于物理空间的拆分。</p>
<p>分库分表方案：只分库、只分表、分库又分表。</p>
<p>垂直拆分：由于表数量多导致的单个库大。将表拆分到多个库中。</p>
<p>水平拆分：由于表记录多导致的单个库大。将表记录拆分到多个表中。<strong>垂直拆分</strong></p>
<p>垂直拆分又称为纵向拆分，垂直拆分是将表按库进行分离，或者修改表结构按照访问的差异将某些</p>
<p>列拆分出去。</p>
<p>垂直分表就是将一张表中不常用的字段拆分到另一张表中，从而保证第一张表中的字段较少，避免 出现数据库跨页存储的问题，从而提升查询效率。</p>
<p>按业务分表</p>
<p><img src="/posts/38076/asset/v2-512f855cd6ca3dd513351a62f68fd8b1_720w.webp" alt="img"></p>
<p>字段过多分字段</p>
<p><img src="https://pic4.zhimg.com/80/v2-3ee7ffabb5302403cb9ce88379aea797_720w.webp" alt="img"></p>
<p>优点：</p>
<p>1） 拆分后业务清晰，拆分规则明确；</p>
<p>2） 易于数据的维护和扩展；</p>
<p>3） 可以使得行数据变小，一个数据块就能存放更多的数据，在查询时就会减少 I&#x2F;O 次 数；</p>
<p>4） 可以达到最大化利用 Cache 的目的。</p>
<p>5） 便于实现冷热分离的数据表设计模式。</p>
<p>缺点：</p>
<p>1） 主键出现冗余，需要管理冗余列；</p>
<p>2） 会引起表连接 JOIN 操作，提高了系统的复杂度；</p>
<p><strong>水平拆分</strong></p>
<p>水平拆分又称为横向拆分，根据某种规则将数据分散至多个库或表中，每个表仅包含数据的一部分。</p>
<p><img src="/posts/38076/asset/v2-91c4587208c0c40fbc30b41574624dfa_720w.webp" alt="img"></p>
<p>水平拆分：解决表中记录过多问题。</p>
<p>垂直拆分：解决表过多或者是表字段过多问题。</p>
<p>优点：</p>
<p>1） 不存在单库大数据，解决高并发的性能瓶颈；</p>
<p>2） 切分的表的结构相同，应用层改造较少，只需要增加路由规则即可；</p>
<p>3） 提高了系统的稳定性和负载能力。</p>
<p>缺点：</p>
<p>1） 分片事务的一致性难以解决；</p>
<p>2） 数据扩容的难度和维护量极大。</p>
<p><strong>主键策略</strong></p>
<p>1） UUID</p>
<p>2） SNOWFLAKE(雪花算法)</p>
<p>3） 数据库ID表</p>
<p>4） Redis生成ID</p>
<h3 id="分片策略"><a href="#分片策略" class="headerlink" title="分片策略"></a><strong>分片策略</strong></h3><p>数据分片是根据指定的分片键和分片策略将数据水平拆分，拆分成多个数据片后分散到多个数据存储节点中，其实就是把原本数据打散，存在多个数据库中，他和分库分表的差异就是：分片可以制定规则，相当于逻辑，达到对应目的，而分库分表是最终的物理实现。</p>
<p><strong>基于范围分片</strong></p>
<p>根据特定字段的范围进行拆分，比如用户ID、订单时间、产品价格等。</p>
<p>优点：新的数据可以落在新的存储节点上，如果集群扩容，数据无需迁移。</p>
<p>缺点：数据热点分布不均，数据冷热不均匀，导致节点负荷不均。</p>
<p><strong>哈希取模分片</strong></p>
<p>整型的Key可直接对设备数量取模，其他类型的字段可以先计算Key的哈希值，然后再对设备数量取模。</p>
<p>优点：实现简单，数据分配比较均匀，不容易出现冷热不均，负荷不均的情况。</p>
<p>缺点：扩容时会产生大量的数据迁移，比如从n台设备扩容到n+1，绝大部分数据需要重新分配和迁移。</p>
<p><strong>一致性哈希分片</strong></p>
<p>一致性Hash是将数据按照特征值映射到一个首尾相接的Hash环上，同时也将节点（按照IP地址或者机器名Hash）映射到这个环上。对于数据，从数据在环上的位置开始，顺时针找到的第一个节 点即为数据的存储节点。</p>
<p><img src="https://pic4.zhimg.com/80/v2-223ff8107ed392104bce5500f8602897_720w.webp" alt="img"></p>
<h3 id="扩容方案"><a href="#扩容方案" class="headerlink" title="扩容方案"></a><strong>扩容方案</strong></h3><p>数据库达到承受极限时，就需要增加新服务器节点数量进行横向扩容。</p>
<p><img src="https://pic4.zhimg.com/80/v2-2b3bad7b01ad32d1e8a203f1efe3498f_720w.webp" alt="img"></p>
<p>横向扩容需要解决的问题：</p>
<p>1） 数据迁移问题</p>
<p>2） 分片规则改变</p>
<p>3） 数据同步、时间点、数据一致性</p>
<p><strong>停机扩容</strong></p>
<p>停止所有对外服务，新增n个数据库，然后写一个数据迁移程序，将原有x个库的数据导入到最新的y个库中，数据迁移完成，修改数据库服务配置，并重启所有服务。</p>
<p><strong>平滑扩容</strong></p>
<p>持续对外提供服务，保证服务的可用性，通过配置双主同步、双主双写、检测数据同步等来实现。</p>
]]></content>
      <categories>
        <category>基础知识</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>基础知识</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>分库分表</title>
    <url>/posts/18707/</url>
    <content><![CDATA[<h3 id="分库分表背景及解决方案"><a href="#分库分表背景及解决方案" class="headerlink" title="分库分表背景及解决方案"></a><strong>分库分表背景及解决方案</strong></h3><p><strong>背景及问题</strong></p>
<p>用户增多单库承受不住使用主从架构分担请求，业务复杂，写入请求增多，提高程序性能，分库分表读写分离。</p>
<p><strong>解决方案</strong></p>
<p>垂直拆分：分为垂直分库和垂直分表</p>
<p>1）垂直分库：比如一个库中保存用户和订单，由于量都非常大，可以分成两个库分别来保存用户和订单信息。</p>
<p>2）垂直分表：比如一张表保存了用户信息，其中还有用户介绍，可以把用户介绍这种大文本单独设计一张表，进行关联，需要的时候进行关联查询。</p>
<p>水平拆分：分为水平分库和水平分表</p>
<p>1）水平分库：单张表的数据切分到多个服务器上去，每个服务器具有相应的库与表，只是表中数据集合不同。</p>
<p>2）水平分表：针对数据量巨大的单张表（比如订单表），按照规则把一张表的数据切分到多张表里面去。</p>
<p>水平分表规则：</p>
<p>1） RANGE（时间、地域、大小）</p>
<p>2） HASH（ID取模）</p>
<p>3） 站内信（维度，即自己只能看见自己，单请求在一个库）</p>
<p>4） 用户表（范围、ID HASH均匀分布）</p>
<p>5） 流水表（时间维度）</p>
<p>主键规则：</p>
<p>1） UUID</p>
<p>2） 雪花算法</p>
<p>数据一致性：</p>
<p>1）强一致性：XA协议</p>
<p>2）最终一致性：TCC、saga、Seata</p>
<p>数据库扩容：</p>
<p>1）成倍增加数据节点，实现平滑扩容</p>
<p>2）成倍扩容以后，表中的部分数据请求已被路由到其他节点上面，可以清理掉</p>
<p>业务层改造：</p>
<p>1）基于代理层方式：Mycat、Sharding-Proxy、MySQL Proxy</p>
<p>2）基于应用层方式：Sharding-jdbc</p>
<p>分库后面临的问题：</p>
<p>1） 事务问题</p>
<p>2） 跨库跨表的join问题</p>
<p>3） 数据库扩容、维护成本变高</p>
<h3 id="ShardingSphere"><a href="#ShardingSphere" class="headerlink" title="ShardingSphere"></a><strong>ShardingSphere</strong></h3><p>Apache ShardingSphere是一款开源的分布式数据库中间件组成的生态圈，它由Sharding-JDBC、Sharding-Proxy和Sharding-Sidecar（规划中）这3款相互独立的产品组成。ShardingSphere定位为关系型数据库中间件，旨在充分合理地在分布式的场景下利用关系型数据库的 计算和存储能力，而并非实现一个全新的关系型数据库。</p>
<p><img src="/posts/18707/asset/v2-964babbe15b51af0dfcbc9643e91d7f0_720w.webp" alt="img"></p>
<p>1） Sharding-JDBC：被定位为轻量级Java框架，在Java的JDBC层提供的额外服务，以jar包形式使用。</p>
<p>2） Sharding-Proxy：被定位为透明化的数据库代理端，提供封装了数据库二进制协议的服务端版 本，用于完成对异构语言的支持。</p>
<p>3） Sharding-Sidecar：被定位为Kubernetes或Mesos的云原生数据库代理，以DaemonSet的形式代 理所有对数据库的访问。</p>
<p><img src="/posts/18707/asset/v2-30c830b590e9d134176a7e5f44fc37d1_720w.webp" alt="img"></p>
<p><img src="https://pic2.zhimg.com/80/v2-85e6dc040ae2e7cd03c0496b2123aae1_720w.webp" alt="img"></p>
<h3 id="Sharding-JDBC"><a href="#Sharding-JDBC" class="headerlink" title="Sharding-JDBC"></a><strong>Sharding-JDBC</strong></h3><p>Sharding-JDBC定位为轻量级Java框架，在Java的JDBC层提供的额外服务。可理解为增强版的JDBC驱动，完全兼容JDBC和各种ORM 框架的使用。</p>
<p>1） 适用于任何基于Java的ORM框架，如：JPA, Hibernate, Mybatis, Spring JDBC Template或直接使 用JDBC。</p>
<p>2） 基于任何第三方的数据库连接池，如：DBCP, C3P0, BoneCP, Druid, HikariCP等。</p>
<p>3） 支持任意实现JDBC规范的数据库。目前支持MySQL，Oracle，SQLServer和PostgreSQL。</p>
<p><strong>Sharding-JDBC主要功能</strong></p>
<p>1） 数据分片：分库分表、读写分离、分片策略、分布式主键</p>
<p>2） 分布式事务：标准化事务接口、XA强一致性事务、柔性事务</p>
<p>3） 数据库治理：配置动态、服务治理、数据脱敏、链路追踪</p>
<p><strong>Sharding-JDBC 内部结构</strong></p>
<p><img src="/posts/18707/asset/v2-15b1dd469f4b267e4390c9cc205b5acb_720w.webp" alt="img"></p>
<p>1） 黄色部分表示的是Sharding-JDBC的入口API，采用工厂方法的形式提供。</p>
<p>2） 蓝色部分表示的是Sharding-JDBC的配置对象，提供灵活多变的配置方式。</p>
<p>3） 红色部分表示的是内部对象，由Sharding-JDBC内部使用，应用开发者无需关注。</p>
<p><strong>Sharding-JDBC初始化流程</strong></p>
<p>1） 根据配置的信息生成Configuration对象</p>
<p>2） 通过Factory会将Configuration对象转化为Rule对象</p>
<p>3） 通过Factory会将Rule对象与DataSource对象封装</p>
<p>4） Sharding-JDBC使用DataSource进行分库分表和读写分离操作</p>
<p><strong>Sharding-JDBC 使用过程</strong></p>
<p>1） 引入maven依赖</p>
<p>2） 规则配置，Java，YAML，Spring命名空间和Spring Boot Starter四种方式配置</p>
<p>3） 通过ShardingDataSourceFactory工厂和规则配置对象获取ShardingDataSource，创建DataSource。</p>
<h3 id="数据分片核心概念"><a href="#数据分片核心概念" class="headerlink" title="数据分片核心概念"></a><strong>数据分片核心概念</strong></h3><p><strong>表概念</strong></p>
<p>1） 真实表 数据库中真实存在的物理表。例如b_order0、b_order1</p>
<p>2） 逻辑表 在分片之后，同一类表结构的名称（总成）。例如b_order。</p>
<p>3） 数据节点 在分片之后，由数据源和数据表组成。例如ds0.b_order1 绑定表</p>
<p>4） 绑定表 指的是分片规则一致的关系表（主表、子表），例如b_order和b_order_item，均按照 order_id分片，则此两个表互为绑定表关系。绑定表之间的多表关联查询不会出现笛卡尔积 关联，可以提升关联查询效率。</p>
<p>5） 广播表 广播表会在不同的数据节点上进行存储，存储 的表结构和数据完全相同，比如省份，字典表信息</p>
<p><strong>分片算法</strong></p>
<p>1） 精确分片算法PreciseShardingAlgorithm</p>
<p>2） 范围分片算法RangeShardingAlgorithm</p>
<p>3） 复合分片算法ComplexKeysShardingAlgorithm</p>
<p>4） Hint分片算法HintShardingAlgorithm</p>
<p><strong>分片策略</strong></p>
<p>1） 标准分片策略StandardShardingStrateg</p>
<p>2） 复合分片策略ComplexShardingStrategy</p>
<p>3） 行表达式分片策略InlineShardingStrateg</p>
<p>4） Hint分片策略HintShardingStrategy</p>
<p>5） 不分片策略NoneShardingStrategy</p>
<p><strong>分片策略配置</strong></p>
<p>1） 数据源分片策略</p>
<p>2） 表分片策略</p>
<h3 id="数据分片流程"><a href="#数据分片流程" class="headerlink" title="数据分片流程"></a><strong>数据分片流程</strong></h3><p><img src="https://pic4.zhimg.com/80/v2-66649837f5f00d3651792bdfbb73e5c3_720w.webp" alt="img"></p>
<p>1） SQL解析：SQL解析分为词法解析和语法解析。先通过词法解析器将SQL拆分为一个个不可再分的单词。再使 用语法解析器对SQL进行理解，并最终提炼出解析上下文。</p>
<p>2） 查询优化：负责合并和优化分片条件，如OR等。</p>
<p>3） SQL路由：根据解析上下文匹配用户配置的分片策略，并生成路由路径。</p>
<p>4） SQL改写：将SQL改写为在真实数据库中可以正确执行的语句。</p>
<p>5） SQL执行：通过多线程执行器异步执行SQL。</p>
<p>6） 结果归并：将多个执行结果集归并以便于通过统一的JDBC接口输出。</p>
<h3 id="数据分片SQL使用规范"><a href="#数据分片SQL使用规范" class="headerlink" title="数据分片SQL使用规范"></a><strong>数据分片SQL使用规范</strong></h3><p><strong>SQL使用规范</strong></p>
<p>1） 支持路由至单数据节点时，目前MySQL数据库100%全兼容，路由至多数据节点时，全面支持DQL、DML、DDL、DCL、TCL。</p>
<p>2） 路由至多数据节点不支持CASE WHEN、HAVING、UNION (ALL)。</p>
<p>3） 支持分页子查询，但其他子查询有限支持，无论嵌套多少层，只能解析第一层。</p>
<p>4） 由于归并的限制，子查询中包含聚合函数目前无法支持。</p>
<p>5） 不支持包含schema的SQL。</p>
<p>6） 当分片键处于运算表达式或函数中的SQL时，将采用全路由的形式获取结果。</p>
<p><strong>不支持的SQL示例</strong></p>
<p>INSERT INTO tbl_name (col1, col2, …) VALUES(1+2, ?, …) &#x2F;&#x2F;VALUES语句不支持运算表达式</p>
<p>INSERT INTO tbl_name (col1, col2, …) SELECT col1, col2, … FROM tbl_name WHERE col3 &#x3D; ? &#x2F;&#x2F;INSERT .. SELECT</p>
<p>SELECT COUNT(col1) as count_alias FROM tbl_name GROUP BY col1 HAVING count_alias &gt; ? &#x2F;&#x2F;HAVING</p>
<p>SELECT * FROM tbl_name1 UNION SELECT * FROM tbl_name2 &#x2F;&#x2F;UNION</p>
<p>SELECT * FROM tbl_name1 UNION ALL SELECT * FROM tbl_name2 &#x2F;&#x2F;UNION ALL</p>
<p>SELECT * FROM ds.tbl_name1 &#x2F;&#x2F;包含schema</p>
<p>SELECT SUM(DISTINCT col1), SUM(col1) FROM tbl_name &#x2F;&#x2F;同时使用普通聚合函数和DISTINCT</p>
<p>SELECT * FROM tbl_name WHERE to_date(create_time, ‘yyyy-mm-dd’) &#x3D; ? &#x2F;&#x2F;会导致全路由<strong>分页查询</strong></p>
<p>完全支持MySQL和Oracle的分页查询，SQLServer由于分页查询较为复杂，仅部分支持</p>
<h3 id="数据分片Inline行表达式"><a href="#数据分片Inline行表达式" class="headerlink" title="数据分片Inline行表达式"></a><strong>数据分片Inline行表达式</strong></h3><p>前面分片策略说到了行表达式分片策略InlineShardingStrateg，他就是采用Inline行表达式进行分片的配置，简化数据节点和分片算法配置信息。完成配置简化、配置一体化。</p>
<p><strong>语法格式</strong></p>
<p>使用${ expression }或$-&gt;{ expression }标识行表达式</p>
<p>${begin..end} 表示范围区间</p>
<p>${[unit1, unit2, unit_x]} 表示枚举值</p>
<p>行表达式中如果出现多个${}或$-&gt;{}表达式，整个表达式结果会将每个子表达式结果进行笛卡尔 (积)组合</p>
<p>${[‘online’, ‘offline’]}_table${1..3}</p>
<p>$-&gt;{[‘online’, ‘offline’]}_table$-&gt;{1..3}</p>
<p>上面语句解析结果-&gt;</p>
<p>online_table1, online_table2, online_table3,</p>
<p>offline_table1, offline_table2, offline_table3</p>
<p>均匀分布的数据节点</p>
<p><img src="https://pic4.zhimg.com/80/v2-970525f81dcee0eb53abe2a8c6fbf44b_720w.webp" alt="img"></p>
<p>用行表达式：</p>
<p>db${0..1}.b_order${1..2} 或者 db$-&gt;{0..1}.b_order$-&gt;{1..2}</p>
<p>自定义的数据节点</p>
<p><img src="https://pic3.zhimg.com/80/v2-bc0b721e0719a1089594b92fed97c0a6_720w.webp" alt="img"></p>
<p>用行表达式：</p>
<p>db0.b_order${0..1},db1.b_order${2..4}</p>
<p>分片算法配置，根据分片键进行计算的方式，返回相应的真实数据源或真实表名称。</p>
<p>ds${id % 10} 或者 ds$-&gt;{id % 10} -&gt;结果为：ds0、ds1、ds2… ds9</p>
<p>分布式主键</p>
<p>内置的分布式主键生成器，例如UUID、SNOWFLAKE，还抽离出分布式主键生成器的接口，方便用户自行实现自定义的自增主键生成器。</p>
<p><img src="/posts/18707/asset/v2-6405c6ec3c7525164bfd4a96b2bb31b8_720w.webp" alt="img"></p>
<h3 id="读写分离及架构设计方案"><a href="#读写分离及架构设计方案" class="headerlink" title="读写分离及架构设计方案"></a><strong>读写分离及架构设计方案</strong></h3><p>读写分离是通过主从的配置方式，将查询请求均匀的分散到多个数据副本，进一步的提升系统的处理能力。</p>
<p><img src="/posts/18707/asset/v2-75183b46190d27fd94ef6e3766270680_720w.webp" alt="img"></p>
<p>主从架构：读写分离，目的是高可用、读写扩展。主从库内容相同，根据SQL语义进行路由。</p>
<p>分库分表架构：数据分片，目的读写扩展、存储扩容。库和表内容不同，根据分片配置进行路由。</p>
<p>读写分离虽然可以提升系统的吞吐量和可用性，但同时也带来了数据不一致的问题，包括多个主库之间的数据一致性，以及主库与从库之间的数据一致性的问题。</p>
<p><strong>架构设计方案</strong></p>
<p>方案一（第一阶段-&gt;一主两从）：数据量不是很多的情况下，我们可以将数据库进行读写分离，以应对高并发的需求，通过水平扩展从库，来缓解查询的压力。</p>
<p><img src="/posts/18707/asset/v2-9a1f37d83ec321262bf7cfe49a4e5ab4_720w.webp" alt="img"></p>
<p>方案二（第二阶段-&gt;主从加分表）：数据量达到500万的时候，数据量预估千万级别，将数据进行分表存储。</p>
<p><img src="https://pic4.zhimg.com/80/v2-5652a6faac34d6c8e90b4b99b5e10d23_720w.webp" alt="img"></p>
<p>方案三（最终阶段-&gt;分库分表加读写分离）：如果方案二不满足需求，数据量继续扩大，这时考虑分库分表，将数据存储在不同数据库的不同表中。</p>
<p><img src="https://pic2.zhimg.com/80/v2-ae1491e1e88ab8c63cd6644e53fe0f59_720w.webp" alt="img"></p>
<p>ShardingSphere读写分离模块的主要设计目标是让使用方尽量像使用一个数据库一样使用主从数据库集群，即规则让关联数据在同一个库中，避免跨库调用。</p>
<p>ShardingSphere核心功能</p>
<p>1） 提供一主多从的读写分离配置。仅支持单主库，可以支持独立使用，也可以配合分库分表使用</p>
<p>2） 独立使用读写分离，支持SQL透传。不需要SQL改写流程</p>
<p>3） 同一线程且同一数据库连接内，能保证数据一致性。如果有写入操作，后续的读操作均从主库读取。</p>
<p>4） 基于Hint的强制主库路由。可以强制路由走主库查询实时数据，避免主从同步数据延迟。</p>
<p>ShardingSphere不支持项</p>
<p>1） 主库和从库的数据同步</p>
<p>2） 主库和从库的数据同步延迟</p>
<p>3） 主库双写或多写</p>
<p>4） 跨主库和从库之间的事务的数据不一致。建议在主从架构中，事务中的读写均用主库操作，使用Hint强制路由。</p>
<h3 id="强制路由Hint"><a href="#强制路由Hint" class="headerlink" title="强制路由Hint"></a><strong>强制路由Hint</strong></h3><p>分片条件并不存在于SQL，而存在于外部业务逻辑，使用Hint指定了强制分片路由，那么SQL将会无视原有的分片逻辑，直接路由至指定的数据节点操作，比如事务操作，要求读写都在主库。</p>
<p>使用步骤：</p>
<p>1） 编写分库或分表路由策略，实现HintShardingAlgorithm接口</p>
<p>2） 在配置文件指定分库或分表策略</p>
<p>3） 在代码执行查询前使用HintManager指定执行策略值</p>
<h3 id="数据脱敏"><a href="#数据脱敏" class="headerlink" title="数据脱敏"></a><strong>数据脱敏</strong></h3><p>数据脱敏是指对某些敏感信息通过脱敏规则进行数据的变形，实现敏感隐私数据的可靠保护，其实就是加密。</p>
<p><img src="https://pic2.zhimg.com/80/v2-95ef39ead87ec9430908a06c5b3ba09d_720w.webp" alt="img"></p>
<p>脱敏配置四部分：数据源配置，加密器配置，脱敏表配置以及查询属性配置</p>
<p><img src="/posts/18707/asset/v2-791bb7d32578903dda62bd6ea63944e0_720w.webp" alt="img"></p>
<p>数据源配置：指DataSource的配置信息</p>
<p>加密器配置：指使用什么加密策略进行加解密。目前ShardingSphere内置了两种加解密策略： AES&#x2F;MD5</p>
<p>脱敏表配置：指定哪个列用于存储密文数据（cipherColumn）、哪个列用于存储明文数据 （plainColumn）以及用户想使用哪个列进行SQL编写（logicColumn）</p>
<p>查询属性的配置：当底层数据库表里同时存储了明文数据、密文数据后，该属性开关用于决定是直 接查询数据库表里的明文数据进行返回，还是查询密文数据通过Encrypt-JDBC解密后返回。</p>
<p><strong>加密策略解析</strong></p>
<p>ShardingSphere提供了两种加密策略用于数据脱敏，该两种策略分别对应ShardingSphere的两种加解 密的接口，即Encryptor和QueryAssistedEncryptor。</p>
<p>Encryptor：提供encrypt(), decrypt()两种方法对需要脱敏的数据进行加解密。</p>
<p>QueryAssistedEncryptor：即使是相同的数据，如两个用户的密码相同，它们在数据库里存储的脱敏数据也应当是不一样的。</p>
<h3 id="分布式事务理论CAP和BASE"><a href="#分布式事务理论CAP和BASE" class="headerlink" title="分布式事务理论CAP和BASE"></a><strong>分布式事务理论CAP和BASE</strong></h3><p><strong>CAP（强一致性）</strong></p>
<p>布鲁尔定理。对于共享数据系统，最多只能同时拥有CAP其中的两个</p>
<p><img src="https://pic4.zhimg.com/80/v2-92d88f53b7a320a293599a3e8f4a719b_720w.webp" alt="img"></p>
<p><strong>BASE（最终一致性）</strong></p>
<p>基本可用（Basically Available）、软状态（ Soft State）、最终一致性（ Eventual Consistency）。它的核心思想是即使无法做到强一致性（CAP 就是强一致性），但应用可以采用适合的方式达到最终一致性。</p>
<p>BA指的是基本业务可用性，支持分区失败；</p>
<p>S表示柔性状态，也就是允许短时间内不同步；</p>
<p>E表示最终一致性，数据最终是一致的，但是实时是不一致的。</p>
<h3 id="分布式事务模式2PC和3PC"><a href="#分布式事务模式2PC和3PC" class="headerlink" title="分布式事务模式2PC和3PC"></a><strong>分布式事务模式2PC和3PC</strong></h3><p><strong>2PC模式（强一致性）</strong></p>
<p>两阶段提交，就是将事务的提交过程分为两个阶段来进行处理。事务的发起者称协调者，事务的执行者称参与者。</p>
<p>1） 阶段 1：准备阶段 协调者向所有参与者发送事务内容，询问是否可以提交事务，并等待所有参与者答复。 各参与者执行事务操作，但不提交事务，将 undo 和 redo 信息记入事务日志中。 如参与者执行成功，给协调者反馈 yes；如执行失败，给协调者反馈 no。</p>
<p>2） 阶段 2：提交阶段 如果协调者收到了参与者的失败消息或者超时，直接给每个参与者发送回滚(rollback)消息； 否则，发送提交(commit)消息。</p>
<p>2PC 方案存在的问题</p>
<p>1） 性能问题：所有参与者在事务提交阶段处于同步阻塞状态，占用系统资源，容易导致性能瓶颈。</p>
<p>2） 可靠性问题：如果协调者存在单点故障问题，如果协调者出现故障，参与者将一直处于锁定状态。</p>
<p>3） 数据一致性问题：在阶段 2 中，如果发生局部网络问题，一部分事务参与者收到了提交消息，另一部分事务参与者没收到提交消息，那么就导致了节点之间数据的不一致。</p>
<p><strong>3PC模式（强一致性）</strong></p>
<p>两阶段提交的改进版本，引入超时机制，将两阶段的准备阶段拆分为 2 个阶段，插入了一个 preCommit 阶段。</p>
<p>1） 阶段1：canCommit 协调者向参与者发送 commit 请求，参与者如果可以提交就返回 yes 响应，否则返回 no 响应。</p>
<p>2） 阶段2：preCommit 协调者根据阶段 1 canCommit 参与者的反应情况执行预提交事务或中断事务操作。 参与者均反馈 yes：协调者向所有参与者发出 preCommit 请求，参与者收到 preCommit 请求后，执行事务操作，但不提交；将 undo 和 redo 信息记入事务日志 中；各参与者向协调者反馈 ack 响应或 no 响应，并等待最终指令。 任何一个参与者反馈 no或等待超时：协调者向所有参与者发出 abort 请求，无论收到协调者发出的 abort 请求，或者在等待协调者请求过程中出现超时，参与者均会中断事务。</p>
<p>3） 阶段3：do Commit 该阶段进行真正的事务提交，根据阶段 2 preCommit反馈的结果完成事务提交或中断操作。</p>
<h3 id="Sharding-JDBC整合XA原理"><a href="#Sharding-JDBC整合XA原理" class="headerlink" title="Sharding-JDBC整合XA原理"></a><strong>Sharding-JDBC整合XA原理</strong></h3><p>ShardingSphere整合XA事务时，分离了XA事务管理和连接池管理，这样接入XA时，可以做到对业务的零侵入，而且ShardingSphere集成后，可保证分片后跨库事务强一致性，XA本身也是强一致性的。</p>
<p><img src="/posts/18707/asset/v2-1ed6b4dd030dc68e98db716d128f806a_720w.webp" alt="img"></p>
<p>执行步骤：</p>
<p>1） Begin（开启XA全局事务）：调用具体的XA事务管理器开启XA的全局事务。</p>
<p>2） 执行物理SQL：将所有SQL操作，标记为XA事务。</p>
<p>3） Commit&#x2F;rollback（提交XA事务）：收集所有投票，全部收到提交，否则回滚。</p>
<h3 id="Sharding-JDBC整合Saga原理"><a href="#Sharding-JDBC整合Saga原理" class="headerlink" title="Sharding-JDBC整合Saga原理"></a><strong>Sharding-JDBC整合Saga原理</strong></h3><p>ShardingSphere是基于反向SQL技术实现的反向补偿操作，它将对数据库进行更新操作的SQL自动生成反向SQL，并交由Saga-actuator引擎执行。</p>
<p><img src="/posts/18707/asset/v2-e8b8ba565620660ba74624a57586b0ae_720w.webp" alt="img"></p>
<p>执行步骤：</p>
<p>1） Init（Saga引擎初始化）</p>
<p>2） Begin（开启Saga全局事务）：记录了所有子事务的正向SQL和逆向SQL</p>
<p>3） 执行物理SQL</p>
<p>4） Commit&#x2F;rollback（提交Saga事务）：生成Saga执行引擎所需的调用链路图，然后进行提交或回滚</p>
<h3 id="Sharding-JDBC整合Seata原理"><a href="#Sharding-JDBC整合Seata原理" class="headerlink" title="Sharding-JDBC整合Seata原理"></a><strong>Sharding-JDBC整合Seata原理</strong></h3><p>分布式事务的实现目前主要分为两阶段的XA强事务和BASE柔性事务。</p>
<p><img src="/posts/18707/asset/v2-f9c3031ba0835c77cd652bf4d8c96f3f_720w.webp" alt="img"></p>
<p>整合Seata AT事务时，需要把TM，RM，TC的模型融入到ShardingSphere 分布式事务的SPI的生态中。在数据库资源上，Seata通过对接DataSource接口，让JDBC操作可以同TC进行RPC通信。</p>
<p><img src="/posts/18707/asset/v2-9365fe4b636cff089764ca5948cf8ae4_720w.webp" alt="img"></p>
<p>执行步骤：</p>
<p>1） Init（Seata引擎初始化）：包含Seata柔性事务的应用启动时，用户配置的数据源会按seata.conf的配置，适配成Seata事务所 需的DataSourceProxy，并且注册到RM中。</p>
<p>2） Begin（开启Seata全局事务）：TM控制全局事务的边界，TM通过向TC发送Begin指令，获取全局事务ID，所有分支事务通过此全 局事务ID，参与到全局事务中；全局事务ID的上下文存放在当前线程变量中。</p>
<p>3） 执行分片物理SQL ：处于Seata全局事务中的分片SQL通过RM生成undo快照，并且发送participate指令到TC，加入到全局事务中。ShardingSphere的分片物理SQL是按多线程方式执行，因此整合Seata AT事务时， 需要在主线程和子线程间进行全局事务ID的上下文传递，这同服务间的上下文传递思路完全相同。</p>
<p>4） Commit&#x2F;rollback（提交Seata事务）：提交Seata事务时，TM会向TC发送全局事务的commit和rollback指令，TC根据全局事务ID协调所有分支事务进行commit和rollback。</p>
<h3 id="ShardingSphere-SPI-加载"><a href="#ShardingSphere-SPI-加载" class="headerlink" title="ShardingSphere SPI 加载"></a><strong>ShardingSphere SPI 加载</strong></h3><p>Apache ShardingSphere所有通过SPI方式载入的功能模块：</p>
<p>1） SQL解析接口：用于规定用于解析SQL的ANTLR语法文件</p>
<p>2） 数据库协议接口：用于Sharding-Proxy解析与适配访问数据库的协议</p>
<p>3） 数据脱敏接口：用于规定加解密器的加密、解密、类型获取、属性设置等方式</p>
<p>4） 分布式主键接口：用于规定如何生成全局性的自增、类型获取、属性设置等。</p>
<p>5） 分布式事务接口：用于规定如何将分布式事务适配为本地事务接口。</p>
<p>6） XA事务管理器接口：用于规定如何将XA事务的实现者适配为统一的XA事务接口。</p>
<p>7） 注册中心接口：用于规定注册中心初始化、存取数据、更新数据、监控等行为。</p>
<h3 id="ShardingSphere-编排治理"><a href="#ShardingSphere-编排治理" class="headerlink" title="ShardingSphere 编排治理"></a><strong>ShardingSphere 编排治理</strong></h3><p>提供配置中心&#x2F;注册中心（以及规划中的元数据中心）、配置动态化、数据库熔断禁用、 调用链路等治理能力。</p>
<p>1） 配置中心：将配置集中于配置中心，可以更加有效进行管理，并且支持数据源、表与分片及读写分离策略的动态切换。</p>
<p>2） 注册中心：存放运行时的动态&#x2F;临时状态数据，比如可用的proxy的实例，需要禁用或熔断的datasource实例。可以提供熔断数据库访问程序对数据库的访问和禁用从库的访问的编排治理能力。</p>
<p>3） 支持外部配置中心和注册中心扩展，基于SPI机制，比如Zookeeper、Nocas等等。</p>
<p>4） 应用性能监控：对分布式系统的性能诊断，包含调用链展示，应用拓扑分析等。</p>
<h3 id="Sharding-Proxy"><a href="#Sharding-Proxy" class="headerlink" title="Sharding-Proxy"></a><strong>Sharding-Proxy</strong></h3><p>Sharding-Proxy是ShardingSphere的第二个产品，定位为透明化的数据库代理端，提供封装了数据库二进制协议的服务端版本，用于完成对异构语言的支持，也就是一个代理组件，可以对其他语言使用，不只是JAVA，便于扩展，不过Sharding-Proxy 默认不支持hint。</p>
<p><img src="https://pic2.zhimg.com/80/v2-3b4894ab94f32cd419dd4518b6e6223d_720w.webp" alt="img"></p>
<p>Sharding-Proxy使用过程：</p>
<p>1） 下载Sharding-Proxy的最新发行版；</p>
<p>2） 解压缩后修改conf&#x2F;server.yaml和以config-前缀开头的文件，进行分片规则、读写分离规则配置 编辑%SHARDING_PROXY_HOME%\conf\config-xxx.yaml 编辑%SHARDING_PROXY_HOME%\conf\server.yaml</p>
<p>3） 引入依赖jar 如果后端连接MySQL数据库，需要下载MySQL驱动， 解压缩后将mysql-connector-java5.1.48.jar拷贝到${sharding-proxy}\lib目录。 如果后端连接PostgreSQL数据库，不需要引入额外依赖。</p>
<p>4） Linux操作系统请运行bin&#x2F;start.sh，Windows操作系统请运行bin&#x2F;start.bat启动Sharding-Proxy。 使用默认配置启动：${sharding-proxy}\bin\start.sh 配置端口启动：${sharding-proxy}\bin\start.sh ${port}</p>
<p>5） 使用客户端工具连接。如: mysql -h 127.0.0.1 -P 3307 -u root -p root</p>
]]></content>
      <categories>
        <category>基础知识</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>基础知识</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>rabbitmq相关知识</title>
    <url>/posts/16292/</url>
    <content><![CDATA[<h3 id="一、消息中间件基础知识"><a href="#一、消息中间件基础知识" class="headerlink" title="一、消息中间件基础知识"></a><strong>一、消息中间件基础知识</strong></h3><h3 id="两种常见分布式架构"><a href="#两种常见分布式架构" class="headerlink" title="两种常见分布式架构"></a><strong>两种常见分布式架构</strong></h3><p>SOA架构：用Dubbo和Zookeeper进行服务间的远程通信。根据实际业务，把系统拆分成合适的、独立部署的模块，模块之间相互独立。根据实际业务，把系统拆分成合适的、独立部署的模块，模块之间相互独立。Dubbo使用自定义的TCP协议，可以让请求报文体积更小，或者使用HTTP2协议，也可以减少报文 的体积，提高传输效率。</p>
<p><img src="https://pic3.zhimg.com/80/v2-6da1de1fa7158d241200e8417e00e3a2_720w.webp" alt="img"></p>
<p>微服务架构：SpringCloud中使用Feign解决服务之间远程通信的问题，Feign是轻量级RESTful的HTTP服务客户端，广泛应用于Spring Cloud中。符合面向接口化的编程习惯。</p>
<p>本质：封装了HTTP调用流程，类似Dubbo的服务调用。RPC主要基于TCP&#x2F;UDP协议，HTTP协议是应用层协议，是构建在传输层协议TCP之上的，RPC效率更高，RPC长连接：不必每次通信都像HTTP一样三次握手，减少网络开销； HTTP服务开发迭代更快：在接口不多，系统与系统之间交互比较少的情况下，HTTP就显得更加方便；相反，在接口比较多，系统与系统之间交互比较多的情况下，HTTP就没有RPC有优势。</p>
<p><img src="/posts/16292/asset/v2-3b4f563589e71dcba683ff959cf11013_720w.webp" alt="img"></p>
<h3 id="分布式通信存在的问题及解决办法"><a href="#分布式通信存在的问题及解决办法" class="headerlink" title="分布式通信存在的问题及解决办法"></a><strong>分布式通信存在的问题及解决办法</strong></h3><p>电商项目中，如果后台添加商品信息，该信息放到数据库，我们同时，需要更新搜索引擎的倒排索引。</p>
<p>解决办法一：在后台添加商品的方法中，如果数据插入数据库成功，就调用更新倒排索引的方法， 接着调用更新静态化页面的方法，如果更新失败重试，（不推荐，更新失败容易出现死循环且高并发场景不适用）</p>
<p>解决办法二：先执行添加商品的方法，商品添加成功，将更新索引和更新静态页面的任务缓存到一 个公共的位置，然后由相应的服务从该位置获取任务来执行。比如使用redis，使用阻塞队列轮询异步执行。（单使用redis，不使用消息队列，无法确认消息，不推荐）</p>
<p>解决办法三：分布式异步通信模式，如下图。</p>
<p><img src="https://pic4.zhimg.com/80/v2-a3dc4b23d71394a6ab19538569deb6c7_720w.webp" alt="img"></p>
<p>优点：系统间解耦，并具有一定的可恢复性，支持异构系统，下游通常可并发执行，系统具备弹性。服务解耦、流量削峰填谷等</p>
<p>缺点：消息中间件存在一些瓶颈和一致性问题，对于开发来讲不直观且不易调试，有额外成本。</p>
<p>使用异步消息模式需要注意的问题： 1. 哪些业务需要同步处理，哪些业务可以异步处理？ 2. 如何保证消息的安全？消息是否会丢失，是否会重复？ 3. 请求的延迟如何能够减少？ 4. 消息接收的顺序是否会影响到业务流程的正常执行？ 5. 消息处理失败后是否需要重发？如果重发如何保证幂等性？</p>
<p>幂等性：不管重发多少次，都要保证结果的一致性。</p>
<h3 id="消息中间件概念"><a href="#消息中间件概念" class="headerlink" title="消息中间件概念"></a><strong>消息中间件概念</strong></h3><p>消息中间件也可以称消息队列，是指用高效可靠的消息传递机制进行与平台无关的数据交流，并基于数据通信来进行分布式系统的集成。通过提供消息传递和消息队列模型，可以在分布式环境下扩展进程的通信。</p>
<p>消息中间件就是在通信的上下游之间截断：break it，Broker，然后利用中间件解耦、异步的特性，构建弹性、可靠、稳定的系统。异步处理、流量削峰、限流、缓冲、排队、最终一致性、消息驱动等需求的场景都可以使用消息中间件。</p>
<p><img src="https://pic2.zhimg.com/80/v2-8dd708e98c3b8a43404655a3805c7db9_720w.webp" alt="img"></p>
<h3 id="常用主流消息中间件介绍"><a href="#常用主流消息中间件介绍" class="headerlink" title="常用主流消息中间件介绍"></a><strong>常用主流消息中间件介绍</strong></h3><p>使用最为广泛的三款消息中间件：RabbitMQ、RocketMQ、Kafka。</p>
<p><strong>RabbitMQ</strong></p>
<p>RabbitMQ开始是用在电信业务的可靠通信的，也是少有的几款支持AMQP协议的产品之一。</p>
<p>优点： 1. 轻量级，快速，部署使用方便 2. 支持灵活的路由配置。RabbitMQ中，在生产者和队列之间有一个交换器模块。根据配置的路 由规则，生产者发送的消息可以发送到不同的队列中。路由规则很灵活，还可以自己实现。 3. RabbitMQ的客户端支持大多数的编程语言。</p>
<p>缺点： 1. 如果有大量消息堆积在队列中，性能会急剧下降 2. RabbitMQ的性能在Kafka和RocketMQ中是最差的，每秒处理几万到几十万的消息。如果应用要求高的性能，不要选择RabbitMQ。 3. RabbitMQ是Erlang开发的，功能扩展和二次开发代价很高。</p>
<p><strong>RocketMQ</strong></p>
<p>RocketMQ是一个开源的消息队列，使用java实现。借鉴了Kafka的设计并做了很多改进。 RocketMQ主要用于有序，事务，流计算，消息推送，日志流处理，binlog分发等场景。</p>
<p>RocketMQ几乎具备了消息队列应该具备的所有特性和功能。 java开发，阅读源代码、扩展、二次开发很方便。 对电商领域的响应延迟做了很多优化。在大多数情况下，响应在毫秒级。如果应用很关注响应时间，可以使用RocketMQ。 性能比RabbitMQ高一个数量级，每秒处理几十万的消息。</p>
<p>缺点： 跟周边系统的整合和兼容不是很好。</p>
<p><strong>Kafka</strong></p>
<p>Kafka的可靠性，稳定性和功能特性基本满足大多数的应用场景。 跟周边系统的兼容性是数一数二的，尤其是大数据和流计算领域，几乎所有相关的开源软件都支持 Kafka，Kafka高效，可伸缩，消息持久化。支持分区、副本和容错。Kafka是Scala和Java开发的，对批处理和异步处理做了大量的设计，因此Kafka可以得到非常高的性能。它的异步消息的发送和接收是三个中最好的，但是跟RocketMQ拉不开数量级，每秒处理几十万的消息。 如果是异步消息，并且开启了压缩，Kafka最终可以达到每秒处理2000w消息的级别。 但是由于是异步的和批处理的，延迟也会高，不适合电商场景。</p>
<p><img src="/posts/16292/asset/v2-25d5a8a38bba0a98430ad4a4cecf88c8_720w.webp" alt="img"></p>
<h3 id="消息中间件应用场景"><a href="#消息中间件应用场景" class="headerlink" title="消息中间件应用场景"></a><strong>消息中间件应用场景</strong></h3><p><strong>电商秒杀场景</strong></p>
<p>当秒杀开始前，用户在不断的刷新页面，系统应该如何应对高并发的读请求呢？</p>
<p>在秒杀开始时，大量并发用户瞬间向系统请求生成订单，扣减库存，系统应该如何应对高并发的写请求呢？</p>
<p>系统应该如何应对高并发的读请求：</p>
<p>使用缓存策略将请求挡在上层中的缓存中</p>
<p>能静态化的数据尽量做到静态化</p>
<p>加入限流（比如对短时间之内来自某一个用户，某一个IP、某个设备的重复请求做丢弃处理）</p>
<p>系统应该如何应对高并发的写请求：</p>
<p>生成订单，扣减库存，用户这些操作不经过缓存直达数据库。如果在 1s内，有 1 万个数据连接同时到达，系统的数据库会濒临崩溃。如何解决这个问题呢？我们可以使用消息队列。</p>
<p>消息队列的作用：</p>
<p>削去秒杀场景下的峰值写流量——流量削峰（削去秒杀场景下的峰值写流量，将秒杀请求暂存于消息队列，业务服务器响应用户“秒杀结果正在处理中。。。”，释放系统资源去 处理其它用户的请求）</p>
<p>通过异步处理简化秒杀请求中的业务流程——异步处理（先处理主要的业务，异步处理次要的业务。 如主要流程是生成订单、扣减库存；次要流程比如购买成功之后会给用户发优惠券，增加用户的积分）</p>
<p>解耦，实现秒杀系统模块之间松耦合——解耦（实现秒杀系统模块之间松耦合，将数据全部发送给消息队列，然后数据服务订阅这个消息队列，接收数据进行处理）</p>
<p><strong>B端C端数据同步场景</strong></p>
<p>B端面向企业用户，C端面向求职者。这两个模块业务处理逻辑不同，数据库表结构不同，实际上是处于解耦的状态。但是各自又需要对方的数据，需要共享：如 1. 当C端求职者在更新简历之后，B端企业用户如何尽早看到该简历更新？ 2. 当B端企业用户发布新的职位需求后，C端用户如何尽早看到该职位信息？</p>
<p>如何解决B端C端数据共享的问题？</p>
<p>\1. 同步方式：B端和C端通过RPC或WebService的方式发布服务，让对方来调用，以获取对方的信息。求职者每更新一次简历，就调用一次B端的服务，进行数据的同步；B端企业用户每更新职位需求，就调用C端的服务，进行数据的同步。</p>
<p>\2. 异步方式：使用消息队列，B端将更新的数据发布到消息队列，C端将更新的数据发布到消息队列，B端订阅C端的消息队列，C端订阅B端的消息队列。</p>
<p>使用同步方式，B端和C端耦合比较紧密，如果其中一个服务有问题，可能会导致另一个服务不可用。使用消息队列的异步方式，对B端C端进行解耦，只要消息队列可用，双方都可以将需要同步的信息 发送到消息队列，对方在收到消息队列推送来的消息的时候，各自更新自己的搜索引擎，更新自己的缓存数据。</p>
<h3 id="JMS规范"><a href="#JMS规范" class="headerlink" title="JMS规范"></a><strong>JMS规范</strong></h3><p>JMS即Java消息服务（Java Message Service）应用程序接口，是一个Java平台中关于面向消息中间件（MOM，Message oriented Middleware）的API，用于在两个应用程序之间，或分布式系统中发送 消息，进行异步通信。与具体平台无关的API，绝大多数MOM提供商都支持。 它类似于JDBC(Java Database Connectivity)。消息是JMS中的一种类型对象，由两部分组成：报文头和消息主体。</p>
<p>根据有效负载的类型来划分，可以将消息分为几种类型： 1. 简单文本(TextMessage) 2. 可序列化的对象(ObjectMessage) 3. 属性集合(MapMessage) 4. 字节流(BytesMessage) 5. 原始值流(StreamMessage) 6. 无有效负载的消息(Message)。</p>
<p>对象模型：ConnectionFactory 接口（连接工厂）、Connection 接口（连接）、Destination 接口（目标）、Session 接口（会话）、MessageConsumer 接口（消息消费者）、MessageProducer 接口（消息生产者）、Message 接口（消息）</p>
<p><img src="/posts/16292/asset/v2-f686e255887c31a8b5d03915ef62a245_720w.webp" alt="img"></p>
<p><strong>点对点模式</strong></p>
<p>一个生产者向一个特定的队列发布消息，一个消费者从该队列中读取消息。这里，生产者知道消费 者的队列，并直接将消息发送到消费者的队列，概括为： 一条消息只有一个消费者获得 生产者无需在接收者消费该消息期间处于运行状态，接收者也同样无需在消息发送时处于运行 状态。 每一个成功处理的消息要么自动确认，要么由接收者手动确认。</p>
<p><strong>发布&#x2F;订阅模式</strong></p>
<p>支持向一个特定的主题发布消息。0或多个订阅者可能对接收特定消息主题的消息感兴趣。发布者和订阅者彼此不知道对方。多个消费者可以获得消息。</p>
<p>在发布者和订阅者之间存在时间依赖性。 发布者需要建立一个主题，以便客户能够订阅。 订阅者必须保持持续的活动状态以接收消息，否则会丢失未上线时的消息。 对于持久订阅，订阅者未连接时发布的消息将在订阅者重连时重发。</p>
<p><strong>JMS在应用集群中的问题</strong></p>
<p>点对点和发布订阅模式在集群下都存在问题，点对点浪费空间，发布订阅对业务侵入较大，ActiveMQ通过“虚拟主题”解决了这个问题。</p>
<p>JMS规范文档(jms-1_1-fr-spec.pdf)下载地址： <a href="https://link.zhihu.com/?target=https://download.oracle.com/otndocs/jcp/7195-jms-1.1-fr-spec-oth-JSpec/">https://download.oracle.com/otndocs/jcp/7195-jms-1.1-fr-spec-oth-JSpec/</a></p>
<h3 id="AMQP协议"><a href="#AMQP协议" class="headerlink" title="AMQP协议"></a><strong>AMQP协议</strong></h3><p>AMQP全称高级消息队列协议（Advanced Message Queuing Protocol），是一种标准，类似于 JMS，兼容JMS协议。目前RabbitMQ主流支持AMQP 0-9-1，3.8.4版本支持AMQP 1.0，AMQP是一个二进制的协议，信息被组织成数据帧，有很多类型。。所有数据帧都拥有基本相同的格式：帧头，负载，帧尾。数据帧负载的格式依赖于数据帧的类型。</p>
<p><img src="/posts/16292/asset/v2-bc99e0de2763085eb075831f9c80bea3_720w.webp" alt="img"></p>
<p>Publisher：消息发送者，将消息发送到Exchange并指定RoutingKey，以便queue可以接收到指定的消息。</p>
<p>Consumer：消息消费者，从queue获取消息，一个Consumer可以订阅多个queue以从多个 queue中接收消息。 Server：一个具体的MQ服务实例，也称为Broker。</p>
<p>Virtual host：虚拟主机，一个Server下可以有多个虚拟主机，用于隔离不同项目，一个Virtual host通常包含多个Exchange、Message Queue。</p>
<p>Exchange：交换器，接收Producer发送来的消息，把消息转发到对应的Message Queue中。</p>
<p>Routing key：路由键，用于指定消息路由规则（Exchange将消息路由到具体的queue中），通 常需要和具体的Exchange类型、Binding的Routing key结合起来使用</p>
<p>Message Queue：实际存储消息的容器，并把消息传递给最终的Consumer。</p>
<p>AMQP 使用的数据类型如下：</p>
<p>Integers（数值范围1-8的十进制数字）：用于表示大小，数量，限制等，整数类型无符号的，可以在帧内不对齐。 Bits（统一为8个字节）：用于表示开&#x2F;关值。</p>
<p>Short strings：用于保存简短的文本属性，字符串个数限制为255，8个字节</p>
<p>Long strings：用于保存二进制数据块。</p>
<p>Field tables：包含键值对，字段值一般为字符串，整数等。</p>
<p>AMQP协议文档下载地址： <a href="https://link.zhihu.com/?target=https://www.amqp.org/sites/amqp.org/files/amqp0-9-1.zip">https://www.amqp.org/sites/amqp.org/files/amqp0-9-1.zip</a></p>
<h3 id="二、RabbitMQ架构"><a href="#二、RabbitMQ架构" class="headerlink" title="二、RabbitMQ架构"></a><strong>二、RabbitMQ架构</strong></h3><h3 id="RabbitMQ概念及基本架构"><a href="#RabbitMQ概念及基本架构" class="headerlink" title="RabbitMQ概念及基本架构"></a><strong>RabbitMQ概念及基本架构</strong></h3><p>RabbitMQ，俗称“兔子MQ”（可见其轻巧，敏捷），是目前非常热门的一款开源消息中间件。RabbitMQ具有很强大的插件扩展能力，并具备以下特点：</p>
<p>\1. 高可靠性、易扩展、高可用、功能丰富等</p>
<p>\2. 支持大多数（甚至冷门）的编程语言客户端。</p>
<p>\3. RabbitMQ遵循AMQP协议，自身采用Erlang</p>
<p>\4. RabbitMQ也支持MQTT等其他协议。</p>
<p>RabbitMQ常用的交换器类型有： fanout 、 direct 、 topic 、 headers 四种。</p>
<p>Fanout 会把所有发送到该交换器的消息路由到所有与该交换器绑定的队列中。</p>
<p>Direct direct类型的交换器路由规则很简单，它会把消息路由到那些BindingKey和RoutingKey完全匹配的队列中。</p>
<p>Topic topic类型的交换器在direct匹配规则上进行了扩展，可以存在两种特殊字符“*”和 “#”，用于模糊匹配。</p>
<p>Headers headers类型的交换器不依赖于路由键的匹配规则来路由信息，而是根据发送的消息内容中的 headers属性进行匹配。</p>
<p>RabbitMQ消息有两种类型： 1. 持久化消息和非持久化消息。 2. 这两种消息都会被写入磁盘。</p>
<p>持久化消息在到达队列时写入磁盘，同时会内存中保存一份备份，当内存吃紧时，消息从内存中清除。</p>
<p>非持久化消息一般只存于内存中，当内存压力大时数据刷盘处理，以节省内存空间。</p>
<p>RabbitMQ存储层包含两个部分：队列索引和消息存储。</p>
<p>队列索引：rabbit_queue_index 索引维护队列的落盘消息的信息，如存储地点、是否已被给消费者接收、是否已被消费者ack等。</p>
<p>消息存储：rabbit_msg_store 消息以键值对的形式存储到文件中，一个虚拟主机上的所有队列使用同一块存储，每个节点只有一 个。存储分为持久化存储（msg_store_persistent）和短暂存储（msg_store_transient）。持久化存 储的内容在broker重启后不会丢失，短暂存储的内容在broker重启后丢失。</p>
<p>队列结构 通常队列由rabbit_amqqueue_process和backing_queue这两部分组成， rabbit_amqqueue_process负责协议相关的消息处理，即接收生产者发布的消息、向消费者交付消 息、处理消息的确认（包括生产端的confirm和消费端的ack）等。backing_queue是消息存储的具体形 式和引擎，并向rabbit_amqqueue_process提供相关的接口以供调用。</p>
<p>为什么消息的堆积导致性能下降？</p>
<p>在系统负载较高时，消息若不能很快被消费掉，这些消息就会进入到很深的队列中去，这样会增加处理每个消息的平均开销。因为要花更多的时间和资源处理“堆积”的消息，如此用来处理新流入的消息 的能力就会降低，使得后流入的消息又被积压到很深的队列中，继续增大处理每个消息的平均开销，继 而情况变得越来越恶化，使得系统的处理能力大大降低。</p>
<h3 id="安装和配置RabbitMQ"><a href="#安装和配置RabbitMQ" class="headerlink" title="安装和配置RabbitMQ"></a><strong>安装和配置RabbitMQ</strong></h3><p>第一步：安装依赖</p>
<p>yum install socat -y</p>
<p>第二步：安装Erlang</p>
<p>rpm -ivh erlang-23.0.2-1.el7.x86_64.rpm –force –nodeps</p>
<p>第三步：安装RabbitMQ</p>
<p>rpm -ivh rabbitmq-server-3.8.4-1.el7.noarch.rpm –force –nodeps</p>
<p>第四步：启用RabbitMQ的管理插件</p>
<p>cd ..&#x2F;usr&#x2F;lib&#x2F;rabbitmq</p>
<p>rabbitmq-plugins enable rabbitmq_management</p>
<p><img src="/posts/16292/asset/v2-75f2678271ee6c17987e499897d08e28_720w.webp" alt="img"></p>
<p>第五步：启动RabbitMQ</p>
<p>systemctl start rabbitmq-server 前台启动</p>
<p>rabbitmq-server -detached 后台启动</p>
<p>第六步：添加用户</p>
<p>rabbitmqctl add_user root 123456</p>
<p>第七步：给用户添加权限</p>
<p>rabbitmqctl set_permissions root -p &#x2F; “.<em>“ “.</em>“ “.*”</p>
<p>第八步: 给用户设置标签</p>
<p>rabbitmqctl set_user_tags root administrator</p>
<p>第九步：打开浏览器，登录客户端</p>
<p><img src="/posts/16292/asset/v2-0f4d3a9e854ce512da3d7b65b3716964_720w.webp" alt="img"></p>
<h3 id="RabbitMQ常用操作命令"><a href="#RabbitMQ常用操作命令" class="headerlink" title="RabbitMQ常用操作命令"></a><strong>RabbitMQ常用操作命令</strong></h3><p># 前台启动Erlang VM和RabbitMQ</p>
<p>rabbitmq-server</p>
<p># 后台启动</p>
<p>rabbitmq-server -detached</p>
<p># 停止RabbitMQ和Erlang VM</p>
<p>rabbitmqctl stop</p>
<p># 查看所有队列</p>
<p>rabbitmqctl list_queues</p>
<p># 查看所有虚拟主机</p>
<p>rabbitmqctl list_vhosts</p>
<p># 在Erlang VM运行的情况下启动RabbitMQ应用</p>
<p>rabbitmqctl start_app rabbitmqctl stop_app</p>
<p># 查看节点状态</p>
<p>rabbitmqctl status</p>
<p># 查看所有可用的插件</p>
<p>rabbitmq-plugins list</p>
<p># 启用插件</p>
<p>rabbitmq-plugins enable</p>
<p># 停用插件</p>
<p>rabbitmq-plugins disable</p>
<p># 添加用户</p>
<p>rabbitmqctl add_user username password</p>
<p># 列出所有用户：</p>
<p>rabbitmqctl list_users</p>
<p># 删除用户：</p>
<p>rabbitmqctl delete_user username</p>
<p># 清除用户权限： r</p>
<p>abbitmqctl clear_permissions -p vhostpath username</p>
<p># 列出用户权限：</p>
<p>rabbitmqctl list_user_permissions username</p>
<p># 修改密码：</p>
<p>rabbitmqctl change_password username newpassword</p>
<p># 设置用户权限：</p>
<p>rabbitmqctl set_permissions -p vhostpath username “.<em>“ “.</em>“ “.*”</p>
<p># 创建虚拟主机:</p>
<p>rabbitmqctl add_vhost vhostpath</p>
<p># 列出所以虚拟主机:</p>
<p>rabbitmqctl list_vhosts</p>
<p># 列出虚拟主机上的所有权限:</p>
<p>rabbitmqctl list_permissions -p vhostpath</p>
<p># 删除虚拟主机:</p>
<p>rabbitmqctl delete_vhost vhost vhostpath</p>
<p># 移除所有数据，要在 rabbitmqctl stop_app 之后使用:</p>
<p>rabbitmqctl reset</p>
<h3 id="RabbitMQ工作流程详解"><a href="#RabbitMQ工作流程详解" class="headerlink" title="RabbitMQ工作流程详解"></a><strong>RabbitMQ工作流程详解</strong></h3><p><strong>生产者发送消息的流程</strong></p>
<p>\1. 生产者连接RabbitMQ，建立TCP连接( Connection)，开启信道（Channel）</p>
<p>\2. 生产者声明一个Exchange（交换器），并设置相关属性，比如交换器类型、是否持久化等</p>
<p>\3. 生产者声明一个队列井设置相关属性，比如是否排他、是否持久化、是否自动删除等</p>
<p>\4. 生产者通过 bindingKey （绑定Key）将交换器和队列绑定（ binding ）起来</p>
<p>\5. 生产者发送消息至RabbitMQ Broker，其中包含 routingKey （路由键）、交换器等信息</p>
<p>\6. 相应的交换器根据接收到的 routingKey 查找相匹配的队列。</p>
<p>\7. 如果找到，则将从生产者发送过来的消息存入相应的队列中。</p>
<p>\8. 如果没有找到，则根据生产者配置的属性选择丢弃还是回退给生产者</p>
<p>\9. 关闭信道。</p>
<p>\10. 关闭连接。</p>
<p><strong>消费者接收消息的过程</strong></p>
<p>\1. 消费者连接到RabbitMQ Broker ，建立一个连接(Connection ) ，开启一个信道(Channel) 。</p>
<p>\2. 消费者向RabbitMQ Broker 请求消费相应队列中的消息，可能会设置相应的回调函数， 以及 做一些准备工作 3. 等待RabbitMQ Broker 回应并投递相应队列中的消息， 消费者接收消息。</p>
<p>\4. 消费者确认( ack) 接收到的消息。</p>
<p>\5. RabbitMQ 从队列中删除相应己经被确认的消息。</p>
<p>\6. 关闭信道。</p>
<p>\7. 关闭连接。</p>
<h3 id="Connection-和Channel关系"><a href="#Connection-和Channel关系" class="headerlink" title="Connection 和Channel关系"></a><strong>Connection 和Channel关系</strong></h3><p>生产者和消费者，需要与RabbitMQ Broker 建立TCP连接，也就是Connection 。一旦TCP 连接建立起来，客户端紧接着创建一个AMQP 信道（Channel），每个信道都会被指派一个唯一的ID。信道是建立在Connection 之上的虚拟连接， RabbitMQ 处理的每条AMQP 指令都是通过信道完成的。</p>
<p>为什么不直接使用TCP连接，而是使用信道？</p>
<p>RabbitMQ 采用类似NIO的做法，复用TCP 连接，减少性能开销，便于管理。 当每个信道的流量不是很大时，复用单一的Connection 可以在产生性能瓶颈的情况下有效地节省 TCP 连接资源。当信道本身的流量很大时，一个Connection 就会产生性能瓶颈，流量被限制。需要建立多个 Connection ，分摊信道。</p>
<p><img src="https://pic2.zhimg.com/80/v2-0dfb0279d8b9f2ed2ffee47c08222769_720w.webp" alt="img"></p>
<h3 id="RabbitMQ工作模式详解"><a href="#RabbitMQ工作模式详解" class="headerlink" title="RabbitMQ工作模式详解"></a><strong>RabbitMQ工作模式详解</strong></h3><p><strong>工作队列模式Work Queue</strong></p>
<p>生产者发消息，启动多个消费者实例来消费消息，每个消费者仅消费部分信息，可达到负载均衡的效果。</p>
<p>结果：生产者生产消息发送给交换器，交换器向绑定他的消费者分发消息，负载均衡。</p>
<p><img src="https://pic2.zhimg.com/80/v2-5ac27fc15144c2206bf1533f9af48bb1_720w.webp" alt="img"></p>
<p><strong>发布订阅模式fanout</strong></p>
<p>使用fanout类型交换器，routingKey忽略。每个消费者定义生成一个队列并绑定到同一个Exchange，每个消费者都可以消费到完整的消息。消息广播给所有订阅该消息的消费者。生产者将消息发送给交换器。交换器非常简单，从生产者接收消息，将消息推送给消息队列。交换器的类型： direct 、 topic 、 headers 和 fanout 四种类型。发布订阅使 用fanout。不指定交换器会使用默认交换器default。</p>
<p>实现RabbitMQ的消费者有两种模式，推模式（Push）和拉模式（Pull）。 实现推模式推荐的方式 是继承 DefaultConsumer 基类，也可以使用Spring AMQP的 SimpleMessageListenerContainer 。</p>
<p>结果：生产者往交换器发送消息，消费者会声明一个临时队列，绑定到交换器，当消息过来，交换器会复制N份发送给订阅的消费者。实现将消息广播到很多接收者。</p>
<p><img src="/posts/16292/asset/v2-3750d6376288631be675854197cfcc40_720w.webp" alt="img"></p>
<p><strong>路由模式direct</strong></p>
<p>使用 direct 类型的Exchange，发N条消费并使用不同的 routingKey ，消费者定义队列并将队列、 routingKey 、Exchange绑定。此时使用 direct 模式Exchagne必须要 routingKey 完全匹配的情况下消息才会转发到对应的队列中被消费，通过路由模式实现让接收者只接收部分消息。</p>
<p>结果：生产者往交换器发送消息，消费者根据key绑定交换器，交换器根据匹配路由和key推送消息。实现通过 direct 类型的交换器做到了根据日志级别的不同，将消息发送给了不同队列的。</p>
<p><img src="https://pic4.zhimg.com/80/v2-9b4b22356224076ab4c6c26eafb8f2b7_720w.webp" alt="img"></p>
<p><strong>主题模式topic</strong></p>
<p>使用 topic 类型的交换器，队列绑定到交换器、 bindingKey 时使用通配符，交换器将消息路由转发到具体队列时会根据消息 routingKey 模糊匹配，比较灵活。</p>
<p>结果：生产者往交换器发送消息，消费者根据key绑定交换器，通过绑定器里面的通配符让交换器发送消息时进行分类发送，最后达到定制分发效果。</p>
<p><img src="/posts/16292/asset/v2-975eae7fb30dc58982d9aae52ded8120_720w.webp" alt="img"></p>
<h3 id="SpringBoot整合RabbitMQ"><a href="#SpringBoot整合RabbitMQ" class="headerlink" title="SpringBoot整合RabbitMQ"></a><strong>SpringBoot整合RabbitMQ</strong></h3><p>\1. 添加starter依赖</p>
<dependency>
<groupId>org.springframework.boot</groupId>
<artifactId>spring-boot-starter-amqp</artifactId>
</dependency>

<p>\2. application.properties中添加连接信息</p>
<p>spring.application.name&#x3D;springboot_rabbit<br>spring.rabbitmq.host&#x3D;127.0.0.1<br>spring.rabbitmq.virtual-host&#x3D;&#x2F;<br>spring.rabbitmq.username&#x3D;root<br>spring.rabbitmq.password&#x3D;123456<br>spring.rabbitmq.port&#x3D;5672</p>
<p>\3. 主入口类</p>
<p><img src="/posts/16292/asset/v2-d48d72a7258ca4baabb8bb1de751f2a3_720w.webp" alt="img"></p>
<p>4.RabbitConfig类</p>
<p><img src="https://pic3.zhimg.com/80/v2-9847b960b61754f1e7fff21a317cd6d6_720w.webp" alt="img"></p>
<p>5.使用RestController发送消息</p>
<p><img src="/posts/16292/asset/v2-2c53cc205d3070b20c50490eab4b43db_720w.webp" alt="img"></p>
<p>6.使用监听器，用于推消息</p>
<p><img src="/posts/16292/asset/v2-9019d9fd907975b63e05bb40938e4ba7_720w.webp" alt="img"></p>
<h3 id="三、RabbitMQ特性"><a href="#三、RabbitMQ特性" class="headerlink" title="三、RabbitMQ特性"></a><strong>三、RabbitMQ特性</strong></h3><h3 id="消息可靠性问题"><a href="#消息可靠性问题" class="headerlink" title="消息可靠性问题"></a><strong>消息可靠性问题</strong></h3><p>支付平台必须保证数据正确性，保证数据并发安全性，保证数据最终一致性。 支付平台通过如下几种方式保证数据一致性：</p>
<p>\1. 分布式锁，用redis或zookeeper等常用框架来实现。 比如我们在修改账单时，先锁定该账单，如果该账单有并发操作，后面的操作只能等 待上一个操作的锁释放后再依次执行。</p>
<p>优点：能够保证数据强一致性。 缺点：高并发场景下可能有性能问题。</p>
<p>\2. 消息队列，保证最终一致性，我们需要确保消息队列有ack机制 客户端收到消 息并消费处理完成后，客户端发送ack消息给消息中间件 如果消息中间件超过指定时间还没收 到ack消息，则定时去重发消息。</p>
<p>优点：异步、高并发 缺点：有一定延时、数据弱一致性，并且必须能够确保该业务操作肯定能够成 功完成，不可能失败。</p>
<h3 id="消息可靠性解决之异常捕获机制"><a href="#消息可靠性解决之异常捕获机制" class="headerlink" title="消息可靠性解决之异常捕获机制"></a><strong>消息可靠性解决之异常捕获机制</strong></h3><p>先执行业务操作，业务操作成功后执行消息发送，消息发送过程通过try catch 方式捕获异常， 在异常处理理的代码块中执行回滚业务操作或者执行重发操作等。这是一种最大努力确保的方式，并无法保证100%绝对可靠，因为这里没有异常并不代表消息就一定投递成功。</p>
<p><img src="/posts/16292/asset/v2-392e8d7654a00553aa654f11a601949b_720w.webp" alt="img"></p>
<h3 id="消息可靠性解决之AMQP-x2F-RabbitMQ的事务机制"><a href="#消息可靠性解决之AMQP-x2F-RabbitMQ的事务机制" class="headerlink" title="消息可靠性解决之AMQP&#x2F;RabbitMQ的事务机制"></a><strong>消息可靠性解决之AMQP&#x2F;RabbitMQ的事务机制</strong></h3><p>没有捕获到异常并不能代表消息就一定投递成功了。一直到事务提交后都没有异常，确实就说明消息是投递成功了。这种方式在性能方面的开销比较大，不推荐使用。</p>
<p><img src="/posts/16292/asset/v2-28c5f5c8be55f355121e0045a09f0fdf_720w.webp" alt="img"></p>
<h3 id="消息可靠性解决之发送端确认机制"><a href="#消息可靠性解决之发送端确认机制" class="headerlink" title="消息可靠性解决之发送端确认机制"></a><strong>消息可靠性解决之发送端确认机制</strong></h3><p>RabbitMQ后来引入了一种轻量量级的方式，叫发送方确认(publisher confirm)机制。生产者将信道设置成confirm(确认)模式，一旦信道进入confirm 模式，所有在该信道上⾯面发布的消息都会被指派 一个唯一的ID(从1 开始)，一旦消息被投递到所有匹配的队列之后（如果消息和队列是持久化的，那么确认消息会在消息持久化后发出），RabbitMQ 就会发送一个确认(Basic.Ack)给生产者(包含消息的唯一 ID)，这样生产者就知道消息已经正确送达了。</p>
<p><img src="/posts/16292/asset/v2-ae2895f6c6ba04e4b98fcb9894f16a71_720w.webp" alt="img"></p>
<h3 id="消息可靠性解决之持久化存储机制"><a href="#消息可靠性解决之持久化存储机制" class="headerlink" title="消息可靠性解决之持久化存储机制"></a><strong>消息可靠性解决之持久化存储机制</strong></h3><p>持久化是提高RabbitMQ可靠性的基础，否则当RabbitMQ遇到异常时（如：重启、断电、停机 等）数据将会丢失。主要从以下几个方面来保障消息的持久性：</p>
<p>\1. Exchange的持久化。通过定义时设置durable 参数为ture来保证Exchange相关的元数据不丢失。</p>
<p>\2. Queue的持久化。也是通过定义时设置durable 参数为ture来保证Queue相关的元数据不丢失。</p>
<p>3.消息的持久化。通过将消息的投递模式 (BasicProperties 中的 deliveryMode 属性)设置为 2 即可实现消息的持久化，保证消息自身不丢失。</p>
<p>RabbitMQ中的持久化消息都需要写入磁盘（当系统内存不足时，非持久化的消息也会被刷盘处理），这些处理动作都是在“持久层”中完成的。</p>
<p>\1. 队列索引(rabbit_queue_index)，rabbit_queue_index 负责维护Queue中消息的信息，包括 消息的存储位置、是否已交给消费者、是否已被消费及Ack确认等，每个Queue都有与之对应 的rabbit_queue_index。</p>
<p>\2. 消息存储(rabbit_msg_store)，rabbit_msg_store 以键值对的形式存储消息，它被所有队列列 共享，在每个节点中有且只有一个。</p>
<h3 id="消息可靠性解决之Consumer-ACK"><a href="#消息可靠性解决之Consumer-ACK" class="headerlink" title="消息可靠性解决之Consumer ACK"></a><strong>消息可靠性解决之Consumer ACK</strong></h3><p>如何保证消息被消费者成功消费？</p>
<p>生产者发送确认机制和消息的持久化存储机制，然而这依然无法完全保证整个过程的可靠性，因为如果消息被消费过程中业务处理失败了但是消息却已经出列了（被标记为已消费了），我 们又没有任何重试，那结果跟消息丢失没什么分别。 因此RabbitMQ在消费端会有Ack机制，即消费端消费消息后需要发送Ack确认报文给Broker端，告知自己是否已消费完成，否则可能会一直重发消息直到消息过期（AUTO模式）。</p>
<p>\1. 采用NONE模式，消费的过程中自行捕获异常，引发异常后直接记录日志并落到异常恢复表， 再通过后台定时任务扫描异常恢复表尝试做重试动作。如果业务不自行处理则有丢失数据的风险</p>
<p>\2. 采用AUTO（自动Ack）模式，不主动捕获异常，当消费过程中出现异常时会将消息放回 Queue中，然后消息会被重新分配到其他消费者节点（如果没有则还是选择当前节点）重新 被消费，默认会一直重发消息并直到消费完成返回Ack或者一直到过期</p>
<p>\3. 采用MANUAL（手动Ack）模式，消费者自行控制流程并手动调用channel相关的方法返回 Ack</p>
<p>SpringBoot项目中支持如下的一些配置：</p>
<p>#最大重试次数</p>
<p>spring.rabbitmq.listener.simple.retry.max-attempts&#x3D;5</p>
<p>#是否开启消费者重试（为false时关闭消费者重试，意思不是“不重试”，而是一直收到消息直到jack 确认或者一直到超时）</p>
<p>spring.rabbitmq.listener.simple.retry.enabled&#x3D;true</p>
<p>#重试间隔时间（单位毫秒）</p>
<p>spring.rabbitmq.listener.simple.retry.initial-interval&#x3D;5000</p>
<p>#重试超过最大次数后是否拒绝</p>
<p>spring.rabbitmq.listener.simple.default-requeue-rejected&#x3D;false</p>
<p>#ack模式</p>
<p>spring.rabbitmq.listener.simple.acknowledge-mode&#x3D;manual</p>
<h3 id="消息可靠性解决之消费端限流"><a href="#消息可靠性解决之消费端限流" class="headerlink" title="消息可靠性解决之消费端限流"></a><strong>消息可靠性解决之消费端限流</strong></h3><p>在电商的秒杀活动中，活动一开始会有大量并发写请求到达服务端，需要对消息进行削峰处理，如何削峰？</p>
<p>当消息投递速度远快于消费速度时，随着时间积累就会出现“消息积压”。消息中间件本身是具备一 定的缓冲能力的，但这个能力是有容量限制的，如果长期运行并没有任何处理，最终会导致Broker崩 溃，而分布式系统的故障往往会发生上下游传递，产生连锁反应。</p>
<p>\1. RabbitMQ 可以对内存和磁盘使用量设置阈值，当达到阈值后，生产者将被阻塞(block)，直 到对应项指标恢复正常。全局上可以防止超大流量、消息积压等导致的Broker被压垮。</p>
<p>\2. RabbitMQ 还默认提供了一种基于credit flow 的流控机制，面向每一个连接进行流控。当单个队列达到最大流速时，或者多个队列达到总流速时，都会触发流控。</p>
<p>\3. RabbitMQ中有一种QoS保证机制，可以限制Channel上接收到的未被Ack的消息数量，如果 超过这个数量限制RabbitMQ将不会再往消费端推送消息。这是一种流控手段，可以防止大量消息瞬时从Broker送达消费端造成消费端巨大压力（甚至压垮消费端）。比较值得注意的是 QoS机制仅对于消费端推模式有效，对拉模式无效。</p>
<p>提升下游应用的吞吐量和缩短消费过程的耗时，优化主要以下几种方式：</p>
<p>\1. 优化应用程序的性能，缩短响应时间（需要时间）</p>
<p>\2. 增加消费者节点实例（成本增加，而且底层数据库操作这些也可能是瓶颈）</p>
<p>\3. 调整并发消费的线程数（线程数并非越大越好，需要大量压测调优至合理值）</p>
<h3 id="消息可靠性保障"><a href="#消息可靠性保障" class="headerlink" title="消息可靠性保障"></a><strong>消息可靠性保障</strong></h3><p>消息可靠传输一般是业务系统接入消息中间件时首要考虑的问题，一般消息中间件的消息传输保障 分为三个层级：</p>
<p>\1. At most once：最多一次。消息可能会丢失，但绝不会重复传输</p>
<p>\2. At least once：最少一次。消息绝不会丢失，但可能会重复传输</p>
<p>\3. Exactly once：恰好一次。每条消息肯定会被传输一次且仅传输一次</p>
<p>RabbitMQ 支持其中的“最多一次”和“最少一次”。</p>
<p>其中“最少一次”投递实现需要考虑以下这个几个方面的内容：</p>
<p>\1. 消息生产者需要开启事务机制或者publisher confirm 机制，以确保消息可以可靠地传输到 RabbitMQ 中。</p>
<p>\2. 消息生产者需要配合使用 mandatory 参数或者备份交换器来确保消息能够从交换器路由到队列中，进而能够保存下来而不会被丢弃。</p>
<p>\3. 消息和队列都需要进行持久化处理，以确保RabbitMQ 服务器在遇到异常情况时不会造成消息丢失。</p>
<p>\4. 消费者在消费消息的同时需要将autoAck 设置为false，然后通过手动确认的方式去确认已经正确消费的消息，以避免在消费端引起不必要的消息丢失。</p>
<p>“最多一次”的方式就无须考虑以上那些方面，生产者随意发送，消费者随意消费，不过这样很难确 保消息不会丢失。</p>
<h3 id="消息幂等性处理"><a href="#消息幂等性处理" class="headerlink" title="消息幂等性处理"></a><strong>消息幂等性处理</strong></h3><p>一个幂等操作的特点是，其任意多次执行所产生的影响均与一次执行的影响相同。一个幂等的方 法，使用同样的参数，对它进行多次调用和一次调用，对系统产生的影响是一样的。 对于幂等的方法，不用担心重复执行会对系统造成任何改变。</p>
<p>对于幂等性的一些常见做法：</p>
<p>\1. 借助数据库唯一索引，重复插入直接报错，事务回滚。</p>
<p>\2. 前置检查机制。为了防止并发问题，我们通常需要借助“排他锁”来完成。在支付宝有一条铁律叫：一锁、二判、三操作。当然，我们也可以使用乐观锁或CAS机制，乐观锁一般会使用扩展一个版本号字段做判断条件。</p>
<p>\3. 唯一Id机制，比较通用的方式。</p>
<h3 id="消息可靠性分析"><a href="#消息可靠性分析" class="headerlink" title="消息可靠性分析"></a><strong>消息可靠性分析</strong></h3><p>在使用任何消息中间件的过程中，难免会出现消息丢失等异常情况，这个时候就需要有一个良好的机制来跟踪记录消息的过程（轨迹溯源），帮助我们排查问题。 在RabbitMQ 中可以使用Firehose 功能来实现消息追踪，Firehose 可以记录每一次发送或者消费 消息的记录，方便RabbitMQ 的使用者进行调试、排错等。Firehose 的原理是将生产者投递给RabbitMQ 的消息，或者RabbitMQ 投递给消费者的消息按照指定的格式发送到默认的交换器上。</p>
<p>开启Firehose命令： rabbitmqctl trace_on [-p vhost]</p>
<p>关闭命令为：rabbitmqctl trace_off [-p vhost]</p>
<p>Firehose 默认情况下处于关闭状态，并且Firehose 的状态是非持久化的，会在RabbitMQ服务重启的时候还原成默认的状态。Firehose 开启之后多少会影响RabbitMQ 整体服务性能，因为它会引起额 外的消息生成、路由和存储。</p>
<h3 id="TTL机制"><a href="#TTL机制" class="headerlink" title="TTL机制"></a><strong>TTL机制</strong></h3><p>在京东下单，订单创建成功，等待支付，一般会给30分钟的时间，开始倒计时。如果在这段时间内 用户没有支付，则默认订单取消。</p>
<p>常用实现办法：</p>
<p>\1. 定期轮询检查（数据库等）</p>
<p>\2. Timer定时器</p>
<p>\3. ScheduledExecutorService多线程</p>
<p>\4. RabbitMQ消息队列</p>
<p>TTL，Time to Live 的简称，即过期时间。 RabbitMQ 可以对消息和队列两个维度来设置TTL。</p>
<p>两种方法可以设置消息的TTL：</p>
<p>\1. 通过Queue属性设置，队列中所有消息都有相同的过期时间。</p>
<p>\2. 对消息自身进行单独设置，每条消息的TTL可以不同。</p>
<p>默认规则：</p>
<p>\1. 如果不设置TTL，则表示此消息不会过期；</p>
<p>\2. 如果TTL设置为0，则表示除非此时可以直接将消息投递到消费者，否则该消息会被立即丢弃；</p>
<p>通过命令行方式设置全局TTL，执行如下命令：</p>
<p>rabbitmqctl set_policy TTL “.*” ‘{“message-ttl”:30000}’ –apply-to queues</p>
<h3 id="死信队列"><a href="#死信队列" class="headerlink" title="死信队列"></a><strong>死信队列</strong></h3><p>用户下单，调用订单服务，然后订单服务调用派单系统通知外卖人员送单，这时候订单系统与派单系统采用 MQ异步通讯。在定义业务队列时可以考虑指定一个 死信交换机，并绑定一个死信队列。当消息变成死信时，该消 息就会被发送到该死信队列上，这样方便我们查看消息失败的原因。 DLX，全称为Dead-Letter-Exchange，死信交换器。消息在一个队列中变成死信（Dead Letter） 之后，被重新发送到一个特殊的交换器（DLX）中，同时，绑定DLX的队列就称为“死信队列”。</p>
<p>以下几种情况导致消息变为死信：</p>
<p>\1. 消息被拒绝（Basic.Reject&#x2F;Basic.Nack），并且设置requeue参数为false；</p>
<p>\2. 消息过期；</p>
<p>\3. 队列达到最大长度。</p>
<h3 id="延迟队列"><a href="#延迟队列" class="headerlink" title="延迟队列"></a><strong>延迟队列</strong></h3><p>延迟消息是指的消息发送出去后并不想立即就被消费，而是需要等（指定的）一段时间后才触发消费。</p>
<p>\1. 生产者将消息(msg)和路由键(routekey)发送指定的延时交换机(exchange)上</p>
<p>\2. 延时交换机(exchange)存储消息等待消息到期根据路由键(routekey)找到绑定自己的队列 (queue)并把消息给它 3. 队列(queue)再把消息发送给监听它的消费者(customer）</p>
<p><img src="/posts/16292/asset/v2-67f42bf578aac7906234553b779c511c_720w.webp" alt="img"></p>
<h3 id="一、RocketMQ架构"><a href="#一、RocketMQ架构" class="headerlink" title="一、RocketMQ架构"></a><strong>一、RocketMQ架构</strong></h3><h3 id="RocketMQ使用场景"><a href="#RocketMQ使用场景" class="headerlink" title="RocketMQ使用场景"></a><strong>RocketMQ使用场景</strong></h3><p>\1. 应用解耦：系统的耦合性越高，容错性就越低。以电商应用为例，用户创建订单后，如果耦合调用库存系统、 物流系统、支付系统，任何一个子系统出了故障或者因为升级等原因暂时不可用，都会造成下单操作异常，影响用户使用体验。</p>
<p>\2. 流量削峰：缓存起来，分散到很长一段时间处理，这样可以大大提到系统的稳定性和用户体验。</p>
<p>\3. 数据分发：通过消息队列可以让数据在多个系统之间进行流通。数据的产生方不需要关心谁来使用数据，只需 要将数据发送到消息队列，数据使用方直接在消息队列中直接获取数据即可</p>
<h3 id="RocketMQ-部署架构"><a href="#RocketMQ-部署架构" class="headerlink" title="RocketMQ 部署架构"></a><strong>RocketMQ 部署架构</strong></h3><p>RocketMQ的角色：</p>
<p>Producer：消息的发送者；举例：发信者</p>
<p>Consumer：消息接收者；举例：收信者</p>
<p>Broker：暂存和传输消息；举例：邮局</p>
<p>NameServer：管理Broker；举例：各个邮局的管理机构</p>
<p>Topic：区分消息的种类；一个发送者可以发送消息给一个或者多个Topic；一个消息的接收者 可以订阅一个或者多个Topic消息</p>
<p>Message Queue：相当于是Topic的分区；用于并行发送和接收消息</p>
<p><img src="https://pic2.zhimg.com/80/v2-185f773fac81200291b702b45f8678dd_720w.webp" alt="img"></p>
<p>执行流程:</p>
<p>\1. 启动NameServer，NameServer起来后监听端口，等待Broker、Producer、Consumer连上来，相当于一个路由控制中心。</p>
<p>\2. Broker启动，跟所有的NameServer保持长连接，定时发送心跳包。心跳包中包含当前 Broker信息(IP+端口等)以及存储所有Topic信息。注册成功后，NameServer集群中就有Topic 跟Broker的映射关系。</p>
<p>\3. 收发消息前，先创建Topic，创建Topic时需要指定该Topic要存储在哪些Broker上，也可以在发送消息时自动创建Topic。</p>
<p>\4. Producer发送消息，启动时先跟NameServer集群中的其中一台建立长连接，并从 NameServer中获取当前发送的Topic存在哪些Broker上，轮询从队列列表中选择一个队列， 然后与队列所在的Broker建立长连接从而向Broker发消息。</p>
<p>\5. Consumer跟Producer类似，跟其中一台NameServer建立长连接，获取当前订阅Topic存在 哪些Broker上，然后直接跟Broker建立连接通道，开始消费消息。</p>
<h3 id="RocketMQ特性"><a href="#RocketMQ特性" class="headerlink" title="RocketMQ特性"></a><strong>RocketMQ特性</strong></h3><p>\1. 订阅与发布：消息的发布是指某个生产者向某个topic发送消息；消息的订阅是指某个消费者关注了某个topic中带有某些tag的消息。</p>
<p>\2. 消息顺序：消息有序指的是一类消息消费时，能按照发送的顺序来消费。RocketMQ可以严格的保证消息有序。</p>
<p>\3. 消息过滤：RocketMQ的消费者可以根据Tag进行消息过滤，也支持自定义属性过滤。</p>
<p>\4. 消息可靠性：RocketMQ支持消息的高可靠，影响消息可靠性的几种情况： 1)Broker非正常关闭 2)Broker异常 Crash 3)OS Crash 4)机器掉电，但是能立即恢复供电情况 5)机器无法开机（可能是cpu、主板、内存等 关键设备损坏） 6)磁盘设备损坏，RocketMQ通过异步复制，可保证99%的消息不丢，但是仍然会有极少量的消息可能丢失。通过同步双写技术可以完全避免单点，但是性能会下降。</p>
<p>\5. 至少一次：指每个消息必须投递一次。Consumer先Pull消息到本地，消费完成后，才向服务器返回ack，如果没有消费一定不会ack消息，所以RocketMQ可以很好的支持此特性。</p>
<p>\6. 回溯消费：回溯消费是指Consumer已经消费成功的消息，由于业务上需求需要重新消费，要支持此功能， Broker在向Consumer投递成功消息后，消息仍然需要保留。</p>
<p>\7. 事务消息：RocketMQ事务消息是指应用本地事务和发送消息操作可以被定义到全局事务中，要么同时成功，要么同时失败。</p>
<p>\8. 定时消息：定时消息（延迟队列）是指消息发送到broker后，不会立即被消费，等待特定时间投递给真正的 topic。</p>
<p>\9. 消息重试：Consumer消费消息失败后，要提供一种重试机制，令消息再消费一次。</p>
<p>\10. 消息重投：消息重投保证消息尽可能发送成功、不丢失，但可能会造成消息重复，消息重复在RocketMQ中是 无法避免的问题。</p>
<p>\11. 流量控制：生产者流控，因为broker处理能力达到瓶颈，不会尝试消息重投；消费者流控，因为消费能力达到瓶颈。</p>
<p>\12. 死信队列：死信队列用于处理无法被正常消费的消息。 当一条消息初次消费失败，消息队列会自动进行消息重试；达到最大重试次数后，若消费依然失败，则表明消费者在正常情况下无法正确地消费该消息，此时，消息队列不会立刻将消息丢弃，而是将其发送到该消费者对应的特殊队列中。</p>
<h3 id="消费模式Push-or-Pull"><a href="#消费模式Push-or-Pull" class="headerlink" title="消费模式Push or Pull"></a><strong>消费模式Push or Pull</strong></h3><p>RocketMQ消息订阅有两种模式，一种是Push模式，即MQServer主动向消费端推送；另外一种是Pull模式，即消费端在需要时，主动到MQ Server拉取。但在具体实现时，Push和Pull模式本质都是采用消费端主动拉取的方式，即consumer轮询从 broker拉取消息。RocketMQ使用长轮询机制来模拟Push效果，算是兼顾了二者的优点。</p>
<p><strong>Push模式</strong></p>
<p>实时性高，但是消费端的处理能力有限，当瞬间推送很多消息给消费端时，容易造成消费端的消息积压，严重时会压垮客户端，Push方式里，consumer把长轮询的动作封装了，并注册MessageListener监听器，取到消息后，唤醒MessageListener的consumeMessage()来消费，对用户而言，感觉消息是被推送过来的。</p>
<p><strong>Pull模式</strong></p>
<p>主动权掌握在消费端自己手中，根据自己的处理能力量力而行。但是Pull的频率，定时间隔太久担心影响时效性，间隔太短担心做太多“无用功”浪费资源。比较折中的办法就是长轮询。Pull方式里，取消息的过程需要用户自己主动调用，首先通过打算消费的Topic拿到 MessageQueue的集合，遍历MessageQueue集合，然后针对每个MessageQueue批量取消息，一次取完后，记录该队列下一次要取的开始offset，直到取完了，再换另一个MessageQueue。</p>
<h3 id="RocketMQ核心概念"><a href="#RocketMQ核心概念" class="headerlink" title="RocketMQ核心概念"></a><strong>RocketMQ核心概念</strong></h3><p>\1. 消息模型：RocketMQ主要由Producer、Broker、Consumer 三部分组成，其中Producer 负责生产消息， Consumer 负责消费消息，Broker 负责存储消息。</p>
<p>\2. Producer：消息生产者，负责产生消息，一般由业务系统负责产生消息。</p>
<p>\3. Consumer：消息消费者，负责消费消息，一般是后台系统负责异步消费。</p>
<p>\4. PushConsumer：Consumer消费的一种类型，该模式下Broker收到数据后会主动推送给消费端。应用通常向 Consumer对象注册一个Listener接口，一旦收到消息，Consumer对象立刻回调Listener接口方法。该 消费模式一般实时性较高。</p>
<p>\5. PullConsumer：Consumer消费的一种类型，应用通常主动调用Consumer的拉消息方法从Broker服务器拉消息、 主动权由应用控制。一旦获取了批量消息，应用就会启动消费过程。</p>
<p>\6. ProducerGroup：同一类Producer的集合，这类Producer发送同一类消息且发送逻辑一致。如果发送的是事务消息 且原始生产者在发送之后崩溃，则Broker服务器会联系同一生产者组的其他生产者实例以提交或回溯消 费。</p>
<p>\7. ConsumerGroup：同一类Consumer的集合，这类Consumer通常消费同一类消息且消费逻辑一致。消费者组使得在 消息消费方面，实现负载均衡和容错的目标变得非常容易。要注意的是，消费者组的消费者实例必须订 阅完全相同的Topic。RocketMQ 支持两种消息模式：集群消费和广播消费。</p>
<p>\8. Broker：消息中转角色，负责存储消息，转发消息，一般也称为 Server。</p>
<p>\9. 一条消息被多个 Consumer 消费，即使这些 Consumer 属于同一个 Consumer Group，消息也会被 Consumer Group 中的每个 Consumer 都消费一次，广播消费中的 Consumer Group 概念可以认为在消息划分方面无意义。</p>
<p>\10. 集群消费：一个 Consumer Group 中的 Consumer 实例平均分摊消费消息。例如某个 Topic 有 9 条消息，其 中一个 Consumer Group 有 3 个实例，那举每个实例只消费其中的 3 条消息。</p>
<p>\11. 顺序消息：消费消息的顺序要同发送消息的顺序一致，在RocketMQ 中主要指的是局部顺序，即一类消息为满足顺序性，必须Producer单线程顺序发送，且发送到同一个队列，这样Consumer 就可以按照 Producer发送的顺序去消费消息</p>
<p>\12. 普通顺序消息：顺序消息的一种，正常情况下可以保证完全的顺序消息，但是一旦发生通信异常，Broker 重启， 由于队列总数发生发化，哈希取模后定位的队列会发化，产生短暂的消息顺序不一致。</p>
<p>\13. 严格顺序消息：顺序消息的一种，无论正常异常情况都能保证顺序，但是牺牲了分布式 Failover特性，即Broker集 群中只要有一台机器不可用，则整个集群都不可用，服务可用性大大降低。</p>
<p>\14. Message Queue：在 RocketMQ 中，所有消息队列都是持久化的，长度无限的数据结构，所谓长度无限是指队列中 的每个存储单元都是定长，访问其中的存储单元使用Offset来访问，offset 为 java long 类型，64 位， 理论上在 100 年内不会溢出，所以认为为是长度无限，另外队列中只保存最近几天的数据，之前的数据会按照过期时间来删除。</p>
<p>\15. 标签（Tag）：为消息设置的标志，用于同一主题下区分不同类型的消息。来自同一业务单元的消息，可以根据不 同业务目的在同一主题下设置不同标签。</p>
<h3 id="RocketMQ环境搭建"><a href="#RocketMQ环境搭建" class="headerlink" title="RocketMQ环境搭建"></a><strong>RocketMQ环境搭建</strong></h3><p>第一步：安装unzip，解压zip</p>
<p>yum install -y unzip zip</p>
<p>第二步：下载rocket包并解压</p>
<p>wget <a href="https://link.zhihu.com/?target=https://archive.apache.org/dist/rocketmq/4.5.1/rocketmq-all4.5.1-bin-release.zip">https://archive.apache.org/dist/rocketmq/4.5.1/rocketmq-all4.5.1-bin-release.zip</a></p>
<p>unzip unzip rocketmq-all-4.5.1-bin-release.zip</p>
<p>第三步：环境变量配置，配套jdk8以上</p>
<p>vim &#x2F;etc&#x2F;profile #修改配置</p>
<p>export ROCKET_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;rocketmq&#x2F;rocket</p>
<p>export PATH&#x3D;$PATH:$ROCKET_HOME&#x2F;bin</p>
<p>source &#x2F;etc&#x2F;profile #生效</p>
<p>第四步：修改启动、关闭配置文件，更改占用内存 64m 128m</p>
<p>vim bin&#x2F;runserver.sh</p>
<p>vim bin&#x2F;runbroker.sh</p>
<p>vim conf&#x2F;broker.conf</p>
<p>第五步：启动NameServer</p>
<p>sh bin&#x2F;mqnamesrv -n 117.50.5.252:9876 &amp;</p>
<p>第六步：启动Broker</p>
<p>sh bin&#x2F;mqbroker -n 117.50.5.252:9876 autoCreateTopicEnable&#x3D;true -c &#x2F;usr&#x2F;local&#x2F;rocketmq&#x2F;rocket&#x2F;conf&#x2F;broker.conf &amp;</p>
<p>第七步：停止命令</p>
<p>mqshutdown borker</p>
<p>mqshutdown namesrv</p>
<p><img src="/posts/16292/asset/v2-a4f358497b0a1e38b6498e01c57ad5e6_720w.webp" alt="img"></p>
<h3 id="二、RocketMQ特性"><a href="#二、RocketMQ特性" class="headerlink" title="二、RocketMQ特性"></a><strong>二、RocketMQ特性</strong></h3><h3 id="消息发送机制"><a href="#消息发送机制" class="headerlink" title="消息发送机制"></a><strong>消息发送机制</strong></h3><p>生产者向消息队列里写入消息，不同的业务场景需要生产者采用不同的写入策略。比如同步发送、异步发送、OneWay发送、延迟发送、发送事务消息等。 默认使用的是DefaultMQProducer类，发送消息要经过五个步骤：</p>
<p>1）设置Producer的GroupName。</p>
<p>2）设置InstanceName，当一个Jvm需要启动多个Producer的时候，通过设置不同的 InstanceName来区分，不设置的话系统使用默认名称“DEFAULT”。</p>
<p>3）设置发送失败重试次数，当网络出现异常的时候，这个次数影响消息的重复投递次数。想保证不丢消息，可以设置多重试几次。</p>
<p>4）设置NameServer地址</p>
<p>5）组装消息并发送。</p>
<p>提升写入的性能 发送一条消息出去要经过三步：</p>
<p>\1. 客户端发送请求到服务器。 2. 服务器处理该请求。 3. 服务器向客户端返回应答</p>
<p>Oneway方式只发送请求不等待应答，即将数据写入客户端的Socket缓冲区就返回，不等待对方返回结果。</p>
<p>另一种提高发送速度的方法是增加Producer的并发量，使用多个Producer同时发送，RocketMQ引入了一个并发窗口，在窗口内消息可以并发地写入DirectMem中，然后异步地将连续一段无空洞的数据刷入文件系统当中，写入性能达到90万+的TPS。</p>
<h3 id="消息消费机制"><a href="#消息消费机制" class="headerlink" title="消息消费机制"></a><strong>消息消费机制</strong></h3><p>消费的几个要点：</p>
<p>\1. 消息消费方式（Pull和Push）</p>
<p>\2. 消息消费的模式（广播模式和集群模式）</p>
<p>\3. 流量控制（可以结合sentinel来实现）</p>
<p>\4. 并发线程数设置</p>
<p>\5. 消息的过滤（Tag、Key） TagA||TagB||TagC * null</p>
<p>三种提高Consumer的处理能力的方法：</p>
<p>\1. 提高消费并行度，在同一个ConsumerGroup下（Clustering方式），可以通过增加Consumer实例的数量来提 高并行度。 通过加机器，或者在已有机器中启动多个Consumer进程都可以增加Consumer实例数。</p>
<p>\2. 以批量方式进行消费，某些业务场景下，多条消息同时处理的时间会大大小于逐个处理的时间总和，比如消费消息中，涉及update某个数据库，一次update10条的时间会大大小于十次update1条数据的时间。</p>
<p>\3. 检测延时情况，跳过非重要消息，Consumer在消费的过程中，如果发现由于某种原因发生严重的消息堆积，短时间无法消除堆 积，这个时候可以选择丢弃不重要的消息，使Consumer尽快追上Producer的进度。</p>
<h3 id="消息存储机制"><a href="#消息存储机制" class="headerlink" title="消息存储机制"></a><strong>消息存储机制</strong></h3><p><strong>消息存储</strong></p>
<p>目前的高性能磁盘，顺序写速度可以达到600MB&#x2F;s， 超过了一般网卡的传输速度。 但是磁盘随机写的速度只有大概100KB&#x2F;s，和顺序写的性能相差6000倍！ 因为有如此巨大的速度差别，好的消息队列系统会比普通的消息队列系统速度快多个数量级。 RocketMQ的消息用顺序写,保证了消息存储的速度。</p>
<p><strong>存储结构</strong></p>
<p>RocketMQ消息的存储是由ConsumeQueue和CommitLog配合完成 的，消息真正的物理存储文件 是CommitLog，ConsumeQueue是消息的逻辑队列，类似数据库的索引文件，存储的是指向物理存储 的地址。每 个Topic下的每个Message Queue都有一个对应的ConsumeQueue文件。</p>
<p>1） CommitLog：消息主体以及元数据的存储主体，存储Producer端写入的消息主体内容,消 息内容不是定长的。</p>
<p>2） ConsumeQueue：消息消费队列，引入的目的主要是提高消息消费的性能。</p>
<p>3） IndexFile：IndexFile（索引文件）提供了一种可以通过key或时间区间来查询消息的方法。</p>
<h3 id="消息过滤机制"><a href="#消息过滤机制" class="headerlink" title="消息过滤机制"></a><strong>消息过滤机制</strong></h3><p>RocketMQ分布式消息队列的消息过滤方式有别于其它MQ中间件，是在Consumer端订阅消息时再做消息过滤的。 RocketMQ这么做是在于其Producer端写入消息和Consumer端订阅消息采用分离存储的机制来实现的，Consumer端订阅消息是需要通过ConsumeQueue这个消息消费的逻辑队列拿到一个索引，然后再从CommitLog里面读取真正的消息实体内容。</p>
<p><strong>Tag过滤方式：</strong></p>
<p>Consumer端在订阅消息时除了指定Topic还可以指定TAG，如果一个消息有多 个TAG，可以用||分隔。</p>
<p>\1. Consumer端会将这个订阅请求构建成一个 SubscriptionData，发送一个Pull消息的请求给 Broker端。</p>
<p>\2. Broker端从RocketMQ的文件存储层—Store读取数据之前，会用这些数据先构建一个 MessageFilter，然后传给Store。</p>
<p>\3. Store从 ConsumeQueue读取到一条记录后，会用它记录的消息tag hash值去做过滤。</p>
<p>\4. 在服务端只是根据hashcode进行判断，无法精确对tag原始字符串进行过滤，在消息消费端拉 取到消息后，还需要对消息的原始tag字符串进行比对，如果不同，则丢弃该消息，不进行消 息消费。</p>
<p><strong>SQL92的过滤方式：</strong></p>
<p>仅对push的消费者起作用。 Tag方式虽然效率高，但是支持的过滤逻辑比较简单。 SQL表达式可以更加灵活的支持复杂过滤逻辑。</p>
<p>\1. 数字比较： &gt;, &gt;&#x3D;, &lt;&#x3D;, BETWEEN, &#x3D;</p>
<p>\2. 字符串比较： &#x3D;, &lt;&gt;, IN; IS NULL或者IS NOT NULL;</p>
<p>\3. 逻辑比较： AND, OR, NOT;</p>
<p>\4. Constant types are: 数字如：123, 3.1415; 字符串如：’abc’，必须是单引号引起来 NULL,特 殊常量 布尔型如：TRUE or FALSE;</p>
<h3 id="零拷贝原理"><a href="#零拷贝原理" class="headerlink" title="零拷贝原理"></a><strong>零拷贝原理</strong></h3><p><strong>cache和buffer的区别</strong></p>
<p>Cache：缓存区，是高速缓存，是位于CPU和主内存之间的容量较小但速度很快的存储器，因 为CPU的速度远远高于主内存的速度，CPU从内存中读取数据需等待很长的时间，而 Cache 保存着CPU刚用过的数据或循环使用的部分数据，这时从Cache中读取数据会更快，减少了 CPU等待的时间，提高了系统的性能。</p>
<p>Buffer：缓冲区，用于存储速度不同步的设备或优先级不同的设备之间传输数据；通过buffer 可以减少进程间通信需要等待的时间，当存储速度快的设备与存储速度慢的设备进行通信时， 存储慢的数据先把数据存放到buffer，达到一定程度存储快的设备再读取buffer的数据，在此 期间存储快的设备CPU可以干其他的事情。</p>
<p><strong>HeapByteBuffer和DirectByteBuffer</strong></p>
<p>HeapByteBuffer，是在jvm堆上面一个buffer，底层的本质是一个数组，用类封装维护了很多的 索引（limit&#x2F;position&#x2F;capacity等）。</p>
<p>DirectByteBuffer，底层的数据是维护在操作系统的内存中，而不是jvm里，DirectByteBuffer里维 护了一个引用address指向数据，进而操作数据。</p>
<p>HeapByteBuffer优点：内容维护在jvm里，把内容写进buffer里速度快；更容易回收。</p>
<p>DirectByteBuffer优点：跟外设（IO设备）打交道时会快很多，因为外设读取jvm堆里的数据时， 不是直接读取的，而是把jvm里的数据读到一个内存块里，再在这个块里读取的，如果使用 DirectByteBuffer，则可以省去这一步，实现zero copy（零拷贝）</p>
<p><strong>缓冲IO和直接IO</strong></p>
<p>缓存I&#x2F;O又被称作标准I&#x2F;O，大多数文件系统的默认I&#x2F;O操作都是缓存I&#x2F;O。</p>
<p>\1. 在一定程度上分离了内核空间和用户空间，保护系统本身的运行安全；</p>
<p>\2. 可以减少读盘的次数，从而提高性能。</p>
<p>缓存I&#x2F;O数据在传输过程中就需要在应用程序地址空间（用户空间）和缓存（内核空间）之间进行多次数据拷贝操作， 这些数据拷贝操作所带来的CPU以及内存开销是非常大的。</p>
<p>直接IO就是应用程序直接访问磁盘数据，而不经过内核缓冲区，这样做的目的是减少一次从内核缓 冲区到用户程序缓存的数据复制。</p>
<p>如果访问的数据不在应用程序缓存中，那么每次数据都会直接从磁盘加载，这种直接加载会非常缓慢。通常直接IO与异步IO结合使用，会得到比较好的性能。</p>
<p><strong>总结</strong></p>
<p>\1. 虽然叫零拷贝，实际上sendfile有2次数据拷贝的。第1次是从磁盘拷贝到内核缓冲区，第二次是从内核缓冲区拷贝到网卡（协议引擎）。如果网卡支持 SG-DMA技术，就无需从PageCache拷贝至 Socket 缓冲区；</p>
<p>\2. 之所以叫零拷贝，是从内存角度来看的，数据在内存中没有发生过拷贝，只是在内存和I&#x2F;O设备之间传输。很多时候我们认为sendfile才是零拷贝，mmap严格来说不算；</p>
<p>\3. Linux中的API为sendfile、mmap，Java中的API为FileChanel.transferTo()、 FileChannel.map()等；</p>
<p>\4. Netty、Kafka(sendfile)、Rocketmq（mmap）、Nginx等高性能中间件中，都有大量利用操作系统零拷贝特性。</p>
<h3 id="同步复制和异步复制"><a href="#同步复制和异步复制" class="headerlink" title="同步复制和异步复制"></a><strong>同步复制和异步复制</strong></h3><p>如果一个Broker组有Master和Slave，消息需要从Master复制到Slave 上，有同步和异步两种复制方式。</p>
<p>同步复制：</p>
<p>同步复制方式是等Master和Slave均写 成功后才反馈给客户端写成功状态； 在同步复制方式下，如果Master出故障，Slave上有全部的备份数据，容易恢复，但是同步复制会 增大数据写入延迟，降低系统吞吐量。</p>
<p>异步复制：</p>
<p>异步复制方式是只要Master写成功 即可反馈给客户端写成功状态。 在异步复制方式下，系统拥有较低的延迟和较高的吞吐量，但是如果Master出了故障，有些数据因 为没有被写 入Slave，有可能会丢失；</p>
<p>同步复制和异步复制是通过broker.conf 配置文件里的brokerRole参数进行设置的，这个参数可以被设置成ASYNC_MASTER、 SYNC_MASTER、SLAVE三个值中的一个。</p>
<p>通常情况下，应该把Master和Save配置成ASYNC_FLUSH的 刷盘 方式，主从之间配置成SYNC_MASTER的复制方式，这样即使有一台机器出故障，仍然能保证数据不丢。</p>
<p><img src="/posts/16292/asset/v2-cbb34f8a051b9e43db0d3bf2a31f8888_720w.webp" alt="img"></p>
<p><img src="/posts/16292/asset/v2-7e530348819890b965ee4af088baf61d_720w.webp" alt="img"></p>
<h3 id="高可用机制"><a href="#高可用机制" class="headerlink" title="高可用机制"></a><strong>高可用机制</strong></h3><p>RocketMQ分布式集群是通过Master和Slave的配合达到高可用性的。</p>
<p><img src="/posts/16292/asset/v2-f65e2c8987db065801d868b493a09cc1_720w.webp" alt="img"></p>
<p>消息消费高可用：在Consumer的配置文件中，并不需要设置是从Master读还是从Slave 读，当Master不可用或者繁忙的时候，Consumer会被自动切换到从Slave 读。</p>
<p>消息发送高可用：在创建Topic的时候，把Topic的多个Message Queue创建在多个Broker组上，这样既可以在性能方面具有扩展性，也可以降低主节点故障 对整体上带来的影响，而且当一个Broker组的Master不可用后，其他组的Master仍然可用，Producer 仍然可以发送消息的。</p>
<p><img src="/posts/16292/asset/v2-88f530e01d26c698ce87e3e28b955d55_720w.webp" alt="img"></p>
<p>在需要保证消息严格顺序的场景下，由于在主题层面无法保证严格顺序，所以必须指定队列来发送消息，对于任何一个队列，它一定是落在一组特定的主从节点上，如果这个主节点宕机，其他的主节点是无法替代这个主节点的，否则就无法保证严格顺序。 在这种复制模式下，严格顺序和高可用只能选择一个。RocketMQ 在 2018 年底迎来了一次重大的更新，引入 Dledger，增加了一种全新的复制方式解决了这个问题。</p>
<h3 id="刷盘机制"><a href="#刷盘机制" class="headerlink" title="刷盘机制"></a><strong>刷盘机制</strong></h3><p>RocketMQ 的所有消息都是持久化的，先写入系统 PageCache，然后刷盘，可以保证内存与磁盘 都有一份数据， 访问时，直接从内存读取。消息在通过Producer写入RocketMQ的时候，有两种写磁盘方式，分布式同步刷盘和异步刷盘。</p>
<p>同步刷盘和异步刷盘差异：</p>
<p>同步刷盘与异步刷盘的唯一区别是异步刷盘写完 PageCache直接返回，而同步刷盘需要等待刷盘完成才返回， 同步刷盘流程如下： (1). 写入 PageCache后，线程等待，通知刷盘线程刷盘。 (2). 刷盘线程刷盘后，唤醒前端等待线程，可能是一批线程。 (3). 前端等待线程向用户返回成功</p>
<h3 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a><strong>负载均衡</strong></h3><p>RocketMQ中的负载均衡都在Client端完成，具体来说的话，主要可以分为Producer端发送消息时候的负载均衡和Consumer端订阅消息的负载均衡。</p>
<p>Producer的负载均衡：</p>
<p><img src="https://pic1.zhimg.com/80/v2-8b4d46acf987359a14d5f0689f28b080_720w.webp" alt="img"></p>
<p>Consumer的负载均衡：</p>
<p><img src="/posts/16292/asset/v2-6e3971b940701c36ed9ad0a6b2487be9_720w.webp" alt="img"></p>
<p>在RocketMQ中，负载均衡或者消息分配是在Consumer端代码中完成的，Consumer从Broker处 获得全局信息，然后自己做负载均衡，只处理分给自己的那部分消息。 Pull Consumer可以看到所有的Message Queue，而且从哪个Message Queue读取消息，读消息 时的Offset都由使用者控制，使用者可以实现任何特殊方式的负载均衡。 DefaultMQPullConsumer有两个辅助方法可以帮助实现负载均衡，一个是 registerMessageQueueListener函数，一个是MQPullConsumerScheduleService。</p>
<p>DefaultMQPushConsumer的负载均衡过程不需要使用者操心，客户端程序会自动处理，每个 DefaultMQPushConsumer启动后，会马上会触发一个doRebalance动作；而且在同一个 ConsumerGroup里加入新的DefaultMQPush-Consumer时，各个Consumer都会被触发 doRebalance动作。</p>
<p>消息消费队列在同一消费组不同消费者之间的负载均衡，其核心设计理念是在一个消息消费队列在 同一时间只允许被同一消费组内的一个消费者消费，一个消息消费者能同时消费多个消息队列。</p>
<h3 id="消息重试"><a href="#消息重试" class="headerlink" title="消息重试"></a><strong>消息重试</strong></h3><p><strong>顺序消息的重试</strong></p>
<p>对于顺序消息，当消费者消费消息失败后，消息队列 RocketMQ 会自动不断进行消息重试（每次间隔时间为 1 秒），这时，应用会出现消息消费被阻塞的情况。因此，在使用顺序消息时，务必保证应 用能够及时监控并处理消费失败的情况，避免阻塞现象的发生。</p>
<p><strong>无序消息的重试</strong></p>
<p>对于无序消息（普通、定时、延时、事务消息），当消费者消费消息失败时，您可以通过设置返回 状态达到消息重试的结果。无序消息的重试只针对集群消费方式生效；广播方式不提供失败重试特性，即消费失败后，失败消 息不再重试，继续消费新的消息。</p>
<p>消息队列 RocketMQ 默认允许每条消息最多重试 16 次，每次重试的间隔时间如下：</p>
<p><img src="https://pic1.zhimg.com/80/v2-f6d62f8e582cd6fcc109233881ca7508_720w.webp" alt="img"></p>
<p>如果消息重试 16 次后仍然失败，消息将不再投递。</p>
<p>注意：</p>
<p>1） 消息最大重试次数的设置对相同 Group ID 下的所有 Consumer 实例有效。</p>
<p>2） 如果只对相同 Group ID 下两个 Consumer 实例中的其中一个设置了 MaxReconsumeTimes，那么该配置对两个 Consumer 实例均生效。</p>
<p>3） 配置采用覆盖的方式生效，即最后启动的 Consumer 实例会覆盖之前的启动实例的配置</p>
<h3 id="死信队列-1"><a href="#死信队列-1" class="headerlink" title="死信队列"></a><strong>死信队列</strong></h3><p>RocketMQ中消息重试超过一定次数后（默认16次）就会被放到死信队列中，在消息队列 RocketMQ 中，这种正常情况下无法被消费的消息称为死信消息（Dead-Letter Message），存储死信 消息的特殊队列称为死信队列（Dead-Letter Queue）。</p>
<p>可视化工具：rocketmq-console下载地址：</p>
<p><a href="https://link.zhihu.com/?target=https://github.com/apache/rocketmq-externals/archive/rocketmq-console-1.0.0.zip">https://github.com/apache/rocketmq-externals/archive/rocketmq-console-1.0.0.zip</a></p>
<p>死信消息特性：</p>
<p>1） 不会再被消费者正常消费。</p>
<p>2） 有效期与正常消息相同，均为 3 天，3 天后会被自动删除。因此，请在死信消息产生后的 3 天内及时处理。</p>
<p>死信队列特征：</p>
<p>1） 一个死信队列对应一个 Group ID， 而不是对应单个消费者实例。</p>
<p>2） 如果一个 Group ID 未产生死信消息，消息队列 RocketMQ 不会为其创建相应的死信队列。</p>
<p>3） 一个死信队列包含了对应 Group ID 产生的所有死信消息，不论该消息属于哪个 Topic。</p>
<p>一条消息进入死信队列，意味着某些因素导致消费者无法正常消费该消息，因此，通常需要您对其进行特殊处理。排查可疑因素并解决问题后，可以在消息队列 RocketMQ 控制台重新发送该消息，让消费者重新消费一次。</p>
<h3 id="延迟消息"><a href="#延迟消息" class="headerlink" title="延迟消息"></a><strong>延迟消息</strong></h3><p>定时消息（延迟队列）是指消息发送到broker后，不会立即被消费，等待特定时间投递给真正的 topic。 broker有配置项messageDelayLevel，默认值为“1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h”，18个level。可以配置自定义messageDelayLevel。</p>
<p>level有以下三种情况：</p>
<p>level &#x3D;&#x3D; 0，消息为非延迟消息</p>
<p>1&lt;&#x3D;level&lt;&#x3D;maxLevel，消息延迟特定时间，例如level&#x3D;&#x3D;1，延迟1s</p>
<p>level &gt; maxLevel，则level&#x3D;&#x3D; maxLevel，例如level&#x3D;&#x3D;20，延迟2h</p>
<p>发消息时，设置delayLevel等级即可： msg.setDelayLevel(level)。</p>
<h3 id="顺序消息"><a href="#顺序消息" class="headerlink" title="顺序消息"></a><strong>顺序消息</strong></h3><p>顺序消息是指消息的消费顺序和产生顺序相同，在有些业务逻辑下，必须保证顺序。比如订单的生 成、付款、发货，这3个消息必须按顺序处理才行。</p>
<p>顺序消息分为全局顺序消息和部分顺序消息：</p>
<p>\1. 全局顺序消息指某个Topic下的所有消息都要保证顺序；</p>
<p>\2. 部分顺序消息只要保证每一组消息被顺序消费即可，比如上面订单消息的例子，只要保证同一个订单ID的三个消息能按顺序消费即可。</p>
<p>要保证部分消息有序，需要发送端和消费端配合处理。在发送端，要做到把同一业务ID的消息发送 到同一个Message Queue；在消费过程中，要做到从同一个Message Queue读取的消息不被并发处理，这样才能达到部分有序。消费端通过使用MessageListenerOrderly类来解决单Message Queue的消息被并发处理的问题。</p>
<p>要保证全局顺序消息，需要先把Topic的读写队列数设置为一，然后Producer和Consumer的并发设置也要是一。简单来说，为了保证整个Topic的全局消息有序，只能消除所有的并发处理，各部分都设置成单线程处理。</p>
<h3 id="事务消息"><a href="#事务消息" class="headerlink" title="事务消息"></a><strong>事务消息</strong></h3><p>RocketMQ的事务消息，是指发送消息事件和其他事件需要同时成功或同时失败。比如银行转账， A银行的某账户要转一万元到B银行的某账户。A银行发送“B银行账户增加一万元”这个消息，要和“从A银 行账户扣除一万元”这个操作同时成功或者同时失败。RocketMQ采用两阶段提交的方式实现事务消息。</p>
<p>具体流程如下：</p>
<p>1）发送方向RocketMQ发送“待确认”消息。</p>
<p>2）RocketMQ将收到的“待确认”消息持久化成功后，向发送方回复消息已经发送成功，此时第一阶段消息发送完成。</p>
<p>3）发送方开始执行本地事件逻辑。</p>
<p>4）发送方根据本地事件执行结果向RocketMQ发送二次确认（Commit或是Rollback）消息， RocketMQ收到Commit状态则将第一阶段消息标记为可投递，订阅方将能够收到该消息；收到 Rollback状态则删除第一阶段的消息，订阅方接收不到该消息。</p>
<p>5）如果出现异常情况，步骤4）提交的二次确认最终未到达RocketMQ，服务器在经过固定时间段 后将对“待确认”消息发起回查请求。</p>
<p>6）发送方收到消息回查请求后（如果发送一阶段消息的Producer不能工作，回查请求将被发送到 和Producer在同一个Group里的其他Producer），通过检查对应消息的本地事件执行结果返回Commit 或Roolback状态。</p>
<p>7）RocketMQ收到回查请求后，按照步骤4）的逻辑处理。</p>
<p><strong>RocketMQ事务消息流程概要</strong></p>
<p>事务消息发送及提交：(1) 发送消息（half消息）。 (2) 服务端响应消息写入结果。 (3) 根据发送结果执行本地事务（如果写入失败，此时half消息对业务不可见，本地逻辑不执行）。 (4) 根据本地事务状态执行Commit或者Rollback（Commit操作生成消息索引，消息对消费者可 见）</p>
<p>事务消息的补偿流程：(1) 对没有Commit&#x2F;Rollback的事务消息（pending状态的消息），从服务端发起一次“回查” (2) Producer收到回查消息，检查回查消息对应的本地事务的状态 (3) 根据本地事务状态，重新Commit或者Rollback</p>
<p>补偿阶段用于解决消息Commit或者Rollback发生超时或者失败的情况。</p>
<p><strong>RocketMQ事务消息设计</strong></p>
<p>\1. 事务消息在一阶段对用户不可见</p>
<p>\2. Commit和Rollback操作以及Op消息的引入</p>
<p>\3. Op消息的存储和对应关系，Op消息的内容为对应的Half消息的存储的Offset，这样通过Op消息能索引到 Half消息进行后续的回查操作。</p>
<p>\4. Half消息的索引构建，在执行二阶段Commit操作时，需要构建出Half消息的索引。</p>
<p>\5. 处理二阶段失败的消息，如果在RocketMQ事务消息的二阶段过程中失败了，例如在做Commit操作时，出现网络问题导致 Commit失败，那么需要通过一定的策略使这条消息最终被Commit。RocketMQ采用了一种补偿机制， 称为“回查”。</p>
<p><img src="/posts/16292/asset/v2-60a054cd3e61ce15d4d05dd64c5fd263_720w.webp" alt="img"></p>
<h3 id="消息查询及优先级"><a href="#消息查询及优先级" class="headerlink" title="消息查询及优先级"></a><strong>消息查询及优先级</strong></h3><p><strong>消息查询</strong></p>
<p>RocketMQ支持按照下面两种维度（“按照Message Id查询消息”、“按照Message Key查询消息”）进行消息查询。</p>
<p>按照MessageId查询消息：MsgId 总共 16 字节，包含消息存储主机地址（ip&#x2F;port），消息 Commit Log offset。</p>
<p>按照Message Key查询消息：主要是基于RocketMQ的IndexFile索引文件来实现的。</p>
<p><img src="https://pic4.zhimg.com/80/v2-888d9d04eedcacc78d8e4286571789fb_720w.webp" alt="img"></p>
<p><strong>消息优先级</strong></p>
<p>有些场景，需要应用程序处理几种类型的消息，不同消息的优先级不同。RocketMQ是个先入先出的队列，不支持消息级别或者Topic级别的优先级。</p>
<p>1） 多个不同的消息类型使用同一个topic时，由于某一个种消息流量非常大，导致其他类型的消息无法及时消费，造成不公平，所以把流量大的类型消息在一个单独的 Topic，其他类型消息在另外一个 Topic，应用程序创建两个 Consumer，分别订阅不同的 Topic。创建一个 Topic， 设置Topic的 MessageQueue 数量超过 100 个，Producer根据订 单的门店号，把每个门店的订单写人 一 个 MessageQueue。 DefaultMQPushConsumer默认是采用 循环的方式逐个读取一个 Topic 的所有 MessageQueue，这样如果某家门店订单量大增，这家门店对 应的 MessageQueue 消息数增多，等待时间增长，但不会造成其他家门店等待时间增长。</p>
<p>2） 情况和第一种情况类似，但是不用创建大量的Topic。</p>
<p>3） 强制优先级 TypeA、 TypeB、 TypeC 三类消息 。TypeA 处于第一优先级，要确保只要有TypeA消息，必须优先处理; TypeB处于第二优先 级; TypeC 处于第三优先级 。</p>
<h3 id="底层网络通信-–-Netty"><a href="#底层网络通信-–-Netty" class="headerlink" title="底层网络通信 – Netty"></a><strong>底层网络通信</strong> <strong>– Netty</strong></h3><p>RocketMQ底层通信的实现是在Remoting模块里，因为借助了Netty而没有重复造轮子， RocketMQ的通信部分没有很多的代码，就是用Netty实现了一个自定义协议的客户端&#x2F;服务器程序。</p>
<p>\1. 自定义ByteBuf可以从底层解决ByteBuffer的一些问题，并且通过“内存池”的设计来提升性能</p>
<p>\2. Reactor主从多线程模型</p>
<p>\3. 充分利用了零拷贝，CAS&#x2F;volatite高效并发编程特性</p>
<p>\4. 无锁串行化设计</p>
<p>\5. 管道责任链的编程模型</p>
<p>\6. 高性能序列化框架的支持</p>
<p>\7. 灵活配置TCP协议参数</p>
<p><img src="/posts/16292/asset/v2-a0d118f2b64dadbc77c465f67969547d_720w.webp" alt="img"></p>
<p>RocketMQ消息队列中支持通信的方式主要有同步(sync)、异步(async)、单向(oneway) 三种。</p>
<p>RocketMQ的RPC通信采用Netty组件作为底层通信库，同样也遵循了Reactor多线程模型，同时又在这之上做了一些扩展和优化。</p>
<p><img src="https://pic4.zhimg.com/80/v2-9b9d39012f16ba92f739797784c2c32f_720w.webp" alt="img"></p>
<h3 id="限流机制"><a href="#限流机制" class="headerlink" title="限流机制"></a><strong>限流机制</strong></h3><p>RocketMQ消费端中我们可以：</p>
<p>\1. 设置最大消费线程数 2. 每次拉取消息条数等</p>
<p>同时：</p>
<p>\1. PushConsumer会判断获取但还未处理的消息个数、消息总大小、Offset的跨度， 2. 任何一个值超过设定的大小就隔一段时间再拉取消息，从而达到流量控制的目的。</p>
<p>Sentinel 专门为这种场景提供了匀速器的特性，可以把突然到来的大量请求以匀速的形式均摊，以 固定的间隔时间让请求通过，以稳定的速度逐步处理这些请求，起到“削峰填谷”的效果，从而避免流量突刺造成系统负载过高。同时堆积的请求将会排队，逐步进行处理；当请求排队预计超过最大超时时长 的时候则直接拒绝，而不是拒绝全部请求。比如在 RocketMQ 的场景下配置了匀速模式下请求 QPS 为 5，则会每 200 ms 处理一条消息，多 余的处理任务将排队；同时设置了超时时间为 5 s，预计排队时长超过 5s 的处理任务将会直接被拒绝。</p>
<h3 id="三、RocketMQ高级实战"><a href="#三、RocketMQ高级实战" class="headerlink" title="三、RocketMQ高级实战"></a><strong>三、RocketMQ高级实战</strong></h3><h3 id="生产者"><a href="#生产者" class="headerlink" title="生产者"></a><strong>生产者</strong></h3><p>Tags的使用：一个应用尽可能用一个Topic，而消息子类型则可以用tags来标识。tags可以由应用自由设置，只 有生产者在发送消息设置了tags，消费方在订阅消息时才可以利用tags通过broker做消息过滤： message.setTags(“TagA”)。</p>
<p>Keys的使用：每个消息在业务层面的唯一标识码要设置到keys字段，方便将来定位消息丢失问题。服务器会为每 个消息创建索引（哈希索引），应用可以通过topic、key来查询这条消息内容，以及消息被谁消费。由 于是哈希索引，请务必保证key尽可能唯一，这样可以避免潜在的哈希冲突。</p>
<p>日志的打印：</p>
<p>1） SEND_OK：消息发送成功。</p>
<p>2） FLUSH_DISK_TIMEOUT：消息发送成功但是服务器刷盘超时。</p>
<p>3） FLUSH_SLAVE_TIMEOUT：消息发送成功，但是服务器同步到Slave时超时。</p>
<p>4） SLAVE_NOT_AVAILABLE：消息发送成功，但是此时Slave不可用。</p>
<p>消息发送失败处理方式：Producer的send方法本身支持内部重试，至多重试2次，如果发送失败，则轮转到下一个Broker，如果本身向broker发送消息产生超时异常，就不会再重试。</p>
<p>选择oneway形式发送：oneway形式只发送请求 不等待应答，而发送请求在客户端实现层面仅仅是一个操作系统系统调用的开销，即将数据写入客户端 的socket缓冲区，此过程耗时通常在微秒级。</p>
<h3 id="消费者"><a href="#消费者" class="headerlink" title="消费者"></a><strong>消费者</strong></h3><p>消费过程幂等：RocketMQ无法避免消息重复，所以如果业务对消费重复非常敏感，务必要在业务层面进行去重处理，可以借助关系数据库进行去重。</p>
<p>消费速度慢的处理方：1. 提高消费并行度，2. 批量方式消费，3. 跳过非重要消息。</p>
<p>优化每条消息消费过程：把循环多次处理变为批量单次处理，减少IO次数。</p>
<p>消费打印日志：在消费入口方法打印消息，消费耗时等，方便后续排查问题。</p>
<p>其他消费建议：1. 确保同一组内的每个消费者订阅信息保持一致。2.使用有序消息，消费者将锁定每个消息队列，以确保他们被逐个消费。3. 并发消费不建议抛出异常，直接返回状态码。4. 不建议阻塞监听器，因为它会阻塞线程池，并最终可能会终止消费进程。</p>
<h3 id="Broker"><a href="#Broker" class="headerlink" title="Broker"></a><strong>Broker</strong></h3><p>Broker 角色分为 ASYNC_MASTER（异步主机）、SYNC_MASTER（同步主机）以及SLAVE（从 机）。SYNC_FLUSH（同步刷新）相比于ASYNC_FLUSH（异步处理）会损失很多性能，但是也更可靠， 所以需要根据实际的业务场景做好权衡。</p>
<p><img src="/posts/16292/asset/v2-ff1c8254b2b34d8fe9327a70b675f1eb_720w.webp" alt="img"></p>
<h3 id="NameServer"><a href="#NameServer" class="headerlink" title="NameServer"></a><strong>NameServer</strong></h3><p>NameServer的设计：</p>
<p>\1. NameServer互相独立，彼此没有通信关系，单台NameServer挂掉，不影响其他 NameServer。</p>
<p>\2. NameServer不去连接别的机器，不主动推消息。</p>
<p>\3. 单个Broker（Master、Slave）与所有NameServer进行定时注册，以便告知NameServer自 己还活着。</p>
<p>\4. Consumer随机与一个NameServer建立长连接，如果该NameServer断开，则从 NameServer列表中查找下一个进行连接。</p>
<p>\5. Producer随机与一个NameServer建立长连接，每隔30秒（此处时间可配置）从 NameServer获取Topic的最新队列情况，如果某个Broker Master宕机，Producer最多30秒 才能感知，在这个期间，发往该broker master的消息失败。Producer向提供Topic服务的 Master建立长连接，且定时向Master发送心跳。</p>
<p>RocketMQ为什么不使用ZooKeeper而自己开发NameServer？</p>
<p>zookeeper在粗粒度分布式锁，分布式选主，主备高可用切换等不需要高TPS支持的场景下有不可替代的作用，而这些需求往往多集中在大数据、离线任务等相关的业务领域，因为大数据领域，讲究分割数据集，并且大部分时间分任务多进程&#x2F;线程并行处理这些数据集，但是总是有一些点上需要将这些任务和进程统一协调，这时候就是ZooKeeper发挥巨大作用的用武之地。 但是在交易场景交易链路上，在主业务数据存取，大规模服务发现、大规模健康监测等方面有天然 的短板，应该竭力避免在这些场景下引入ZooKeeper，在阿里巴巴的生产实践中，应用对ZooKeeper申 请使用的时候要进行严格的场景、容量、SLA需求的评估。</p>
<h3 id="系统配置"><a href="#系统配置" class="headerlink" title="系统配置"></a><strong>系统配置</strong></h3><p>设置Xms和Xmx一样大，防止JVM重新调整堆空间大小影响性能。</p>
<p>-server -Xms8g -Xmx8g -Xmn4g</p>
<p>设置DirectByteBuffer内存大小。当DirectByteBuffer占用达到这个值，就会触发Full GC。</p>
<p>-XX:MaxDirectMemorySize&#x3D;15g</p>
<p>如果不太关心RocketMQ的启动时间，可以设置pre-touch，这样在JVM启动的时候就会分配完整的页空间。</p>
<p>-XX:+AlwaysPreTouch</p>
<p>禁用偏向锁可能减少JVM的停顿，在并发小的时候使用偏向锁有利于提升JVM效率，在高并发场合禁用掉。</p>
<p>-XX:-UseBiasedLocking</p>
<p>推荐使用JDK1.8的G1垃圾回收器。</p>
<h3 id="RocketMQ集群"><a href="#RocketMQ集群" class="headerlink" title="RocketMQ集群"></a><strong>RocketMQ集群</strong></h3><p>Producer与NameServer集群中的其中一个节点（随机选择）建立长连接，定期从 NameServer取Topic路由信息，并向提供Topic服务的Master建立长连接，且定时向Master 发送心跳。Consumer与NameServer集群中的其中一个节点（随机选择）建立长连接，定期从 NameServer取Topic路由信息，并向提供Topic服务的Master、Slave建立长连接，且定时向 Master、Slave发送心跳。</p>
<p><strong>单Master模式</strong></p>
<p>这种方式风险较大，一旦Broker重启或者宕机时，会导致整个服务不可用。</p>
<p><strong>多Master模式</strong></p>
<p>一个集群无Slave，全是Master，例如2个Master或者3个Master，单台机器宕机期间，这台机器上未被消费的消息在机器恢复之前不可订阅，消息实时性 会受到影响。</p>
<p><strong>多Master多Slave模式（异步）</strong></p>
<p>每个Master配置一个Slave，有多对Master-Slave，HA采用异步复制方式，主备有短暂消息延迟 （毫秒级），即使磁盘损坏，消息丢失的非常少，且消息实时性不会受影响，但是会丢失少量消息。</p>
<p><strong>多Master多Slave模式（异步）</strong></p>
<p>每个Master配置一个Slave，有多对Master-Slave，HA采用同步双写方式，即只有主备都写成功， 才向应用返回成功，消息无延迟，服务可用性与数据可用 性都非常高；但是性能比异步复制模式略低（大约低10%左右），发送单个消息的RT会略高，且目前版 本在主节点宕机后，备机不能自动切换为主机。</p>
]]></content>
      <categories>
        <category>基础知识</category>
        <category>rabbitmq</category>
      </categories>
      <tags>
        <tag>基础知识</tag>
        <tag>rabbitmq</tag>
      </tags>
  </entry>
  <entry>
    <title>spring如何解决循环依赖</title>
    <url>/posts/42455/</url>
    <content><![CDATA[<p>Spring通过三级缓存和提前暴露的方式来解决了循环依赖这个问题，举个例，A对象和B对象互相依</p>
<p>赖，Spring解决循环依赖过程如下：</p>
<p>1.通过反射实例化创建A对象并把A对象的工厂对象放入三级缓存；</p>
<p>2.按照Bean对象生命周期，下一步进行属性注入，A对象依赖B对象，B对象实例化并把B对象的工厂对象放入三级缓存；</p>
<p>3.B对象属性注入又依赖A对象，但是三级缓存中已存在A对象的工厂对象，通过工厂生产代理对象返回并放入二级缓存后删除三级缓存工厂对象；</p>
<p>4.B对象拿到返回的A代理对象就可以直接完成装配，放入一级缓存并删除三级缓存B对象工厂；</p>
<p>5.B对象完成实例化并返回，就可以把二级缓存中A对象同步到一级缓存销毁二级缓存对象解决循环依赖。</p>
]]></content>
      <categories>
        <category>基础知识</category>
        <category>spring</category>
      </categories>
      <tags>
        <tag>基础知识</tag>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title>redis数据库知识</title>
    <url>/posts/40341/</url>
    <content><![CDATA[<h3 id="一、-Redis基础知识"><a href="#一、-Redis基础知识" class="headerlink" title="一、 Redis基础知识"></a><strong>一、</strong> <strong>Redis基础知识</strong></h3><h3 id="Redis应用场景"><a href="#Redis应用场景" class="headerlink" title="Redis应用场景"></a><strong>Redis应用场景</strong></h3><p>\1. 缓存使用，减轻DB压力</p>
<p>\2. DB使用，用于临时存储数据（字典表，购买记录）</p>
<p>\3. 解决分布式场景下Session分离问题（登录信息）</p>
<p>\4. 任务队列（秒杀、抢红包等等）</p>
<p>\5. 乐观锁</p>
<p>\6. 应用排行榜 zset</p>
<p>\7. 签到 bitmap</p>
<p>\8. 分布式锁</p>
<p>\9. 冷热数据交换</p>
<h3 id="缓存的使用场景"><a href="#缓存的使用场景" class="headerlink" title="缓存的使用场景"></a><strong>缓存的使用场景</strong></h3><p>缓存原指CPU上的一种高速存储器，它先于内存与CPU交换数据，速度很快，现在泛指存储在计算机上的原始数据的复制集，便于快速访问，以空间换时间的一种技术。</p>
<p>\1. DB缓存，减轻DB服务器压力，将已经访问过的内容或数据存储起来，当再次访问时先找缓存，缓存命中返回数据，不命中再找数据库，并回填缓存。</p>
<p>\2. 提高系统响应能力，在大量瞬间访问时（高并发）MySQL单机会因为频繁IO而造成无法响应，MySQL的InnoDB是有行锁，将数据缓存在Redis中，也就是存在了内存中。</p>
<p>\3. 做Session分离，将登录成功后的Session信息，存放在Redis中，这样多个服务器(Tomcat)可以共享Session信息。</p>
<p>\4. 做分布式锁（Redis），多个进程（JVM）在并发时也会产生问题，也要控制时序性，可以采用分布式锁。使用Redis实现setNX。</p>
<p>\5. 做乐观锁(Redis），同步锁和数据库中的行锁、表锁都是悲观锁，悲观锁的性能是比较低的，响应性比较差，高性能、高响应（秒杀）采用乐观锁 Redis可以实现乐观锁 watch + incr。</p>
<h3 id="常见缓存的分类"><a href="#常见缓存的分类" class="headerlink" title="常见缓存的分类"></a><strong>常见缓存的分类</strong></h3><p>\1. 客户端缓存（页面缓存和浏览器缓存、APP缓存）</p>
<p>\2. 网络端缓存（Web代理缓存Nginx、边缘缓存CDN）</p>
<p>\3. 服务端缓存（数据库级缓存Mysql、平台级缓存EhCache、应用级缓存Redis）</p>
<h3 id="缓存的优缺点"><a href="#缓存的优缺点" class="headerlink" title="缓存的优缺点"></a><strong>缓存的优缺点</strong></h3><p>优点：</p>
<p>\1. 缓存的使用可以提升系统的响应能力，大大提升了用户体验。</p>
<p>\2. 减轻服务器压力</p>
<p>\3. 提升系统性能，缩短系统的响应时间，减少网络传输时间和应用延迟时间，提高系统的吞吐量，增加系统的并发用户数，提高了数据库资源的利用率</p>
<p>缺点：</p>
<p>\1. 额外的硬件支出，空间换时间</p>
<p>\2. 在高并发场景下会出现缓存失效（缓存穿透、缓存雪崩、缓存击穿）</p>
<p>\3. 缓存与数据库数据同步，Redis无法做到主从时时数据同步</p>
<p>\4. 缓存并发竞争，多个redis的客户端同时对一个key进行set值得时候由于执行顺序引起的并发问题</p>
<h3 id="缓存的读写模式"><a href="#缓存的读写模式" class="headerlink" title="缓存的读写模式"></a><strong>缓存的读写模式</strong></h3><p>\1. Cache Aside Pattern（读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应，更新的时候，先更新数据库，然后再删除缓存）</p>
<p><img src="/posts/40341/asset/v2-cd658eb1aa95faf43da33ee9bdff6ddd_720w.webp" alt="img"></p>
<p><img src="/posts/40341/asset/v2-a5dc797c32773aa964fdb8cf8a0bbc14_720w.webp" alt="img"></p>
<p>直接删除缓存而不是更新缓存，因为缓存是一个hash、list结构，更新需要遍历，代价大，懒加载的时候才需要更新缓存，也就是使用的时候。也可以采用异步的方式填充缓存，开启一个线程，定时将DB的数据刷到缓存中。</p>
<p>\2. Read&#x2F;Write Through Pattern（应用程序只操作缓存，缓存操作数据库）</p>
<p>Read-Through（穿透读模式&#x2F;直读模式）：应用程序读缓存，缓存没有，由缓存回源到数据库，并写入 缓存。 Write-Through（穿透写模式&#x2F;直写模式）：应用程序写缓存，缓存写数据库。</p>
<p>\3. Write Behind Caching Pattern（应用程序只更新缓存）</p>
<p>缓存通过异步的方式将数据批量或合并后更新到DB中 不能时时同步，甚至会丢数据。</p>
<h3 id="缓存高并发脏读的三种情况"><a href="#缓存高并发脏读的三种情况" class="headerlink" title="缓存高并发脏读的三种情况"></a><strong>缓存高并发脏读的三种情况</strong></h3><p>\1. 先更新数据库，再更新缓存，导致update与commit之间，更新缓存，commit失败 则DB与缓存数据不一致。</p>
<p>\2. 先删除缓存，再更新数据库，导致update与commit之间，有新的读，缓存空，读DB数据到缓存数据是旧的数据。</p>
<p>\3. 先更新数据库，再删除缓存(<strong>推荐</strong>)，update与commit之间，有新的读，缓存空，读DB数据到缓存 数据是旧的数据 commit后 DB为新数据 则DB与缓存数据不一致 采用延时双删策略，也就是先更新数据库，再删除缓存，再设定一个定时时间，大概是300ms以内，再删除一次缓存，就算第一次读到了脏数据，第二次再读就能保证缓存与数据库一致。</p>
<h3 id="缓存的架构设计"><a href="#缓存的架构设计" class="headerlink" title="缓存的架构设计"></a><strong>缓存的架构设计</strong></h3><p>\1. 多层次，分布式缓存宕机，本地缓存还可以使用</p>
<p>\2. 数据类型，简单类型用Memcached，复杂类型用Redis</p>
<p>\3. 做集群</p>
<p>\4. 缓存的数据结构设计，缓存的字段会比数据库表少一些，缓存的数据是经常访问的</p>
<p><img src="/posts/40341/asset/v2-26158ce0b0434d1a78f643ad5a99d512_720w.webp" alt="img"></p>
<h3 id="Redis安装"><a href="#Redis安装" class="headerlink" title="Redis安装"></a><strong>Redis安装</strong></h3><p>第一步：安装 C 语言需要的 GCC 环境</p>
<p>yum install -y gcc-c++</p>
<p><img src="/posts/40341/asset/v2-c7539d2cdc9f5120bfbdc227e2f1cf5c_720w.webp" alt="img"></p>
<p>yum install -y wget</p>
<p><img src="/posts/40341/asset/v2-84495792ef62d6910de77de045176035_720w.webp" alt="img"></p>
<p>第二步：下载并解压缩 Redis 源码压缩包</p>
<p>wget <a href="https://link.zhihu.com/?target=http://download.redis.io/releases/redis-5.0.5.tar.gz">http://download.redis.io/releases/redis-5.0.5.tar.gz</a></p>
<p><img src="https://pic4.zhimg.com/80/v2-54d62739390d30ea03e1fa8d2eaa8ecb_720w.webp" alt="img"></p>
<p>tar -zxf redis-5.0.5.tar.gz</p>
<p><img src="/posts/40341/asset/v2-b0f6b8124a16122f0aa6fb6490c60909_720w.webp" alt="img"></p>
<p>第三步：编译 Redis 源码，进入 redis-5.0.5 目录，执行编译命令</p>
<p>cd redis-5.0.5&#x2F;src</p>
<p>make</p>
<p><img src="https://pic4.zhimg.com/80/v2-3cd6fbc096f2c72906646794a68fbf2f_720w.webp" alt="img"></p>
<p>第四步：安装 Redis ，需要通过 PREFIX 指定安装路径</p>
<p>mkdir &#x2F;usr&#x2F;redis -p</p>
<p>make install PREFIX&#x3D;&#x2F;usr&#x2F;redis</p>
<p><img src="/posts/40341/asset/v2-cd8356adf3c3315e3cec041fe7a24d2c_720w.webp" alt="img"></p>
<h3 id="Redis启动命令"><a href="#Redis启动命令" class="headerlink" title="Redis启动命令"></a><strong>Redis启动命令</strong></h3><p><strong>前端启动</strong></p>
<p>启动命令： .&#x2F;redis-server</p>
<p>关闭命令： ctrl+c</p>
<p>客户端窗口关闭则 redis-server 程序结束</p>
<p><strong>后台启动(守护进程启动)</strong></p>
<p>第一步：拷贝 redis-5.0.5&#x2F;redis.conf 配置文件到 Redis 安装目录的 bin 目录</p>
<p>cd redis-5.0.5&#x2F;</p>
<p><img src="/posts/40341/asset/v2-ddd825bad4586281684fde4a59f480f4_720w.webp" alt="img"></p>
<p>cp redis.conf &#x2F;usr&#x2F;redis&#x2F;bin&#x2F;</p>
<p>第二步：修改 redis.conf</p>
<p>vim redis.conf</p>
<p># 将<code>daemonize</code>由<code>no</code>改为<code>yes</code></p>
<p>daemonize yes</p>
<p># 默认绑定的是回环地址，默认不能被其他机器访问</p>
<p># bind 127.0.0.1</p>
<p># 是否开启保护模式，由yes该为no</p>
<p>protected-mode no</p>
<p>第三步：启动服务</p>
<p>.&#x2F;redis-server redis.conf</p>
<p>第四步：后端启动的关闭方式</p>
<p>.&#x2F;redis-cli shutdown</p>
<p><img src="/posts/40341/asset/v2-5e3488c366b1181cad6bea38433d2804_720w.webp" alt="img"></p>
<p>第五步：关闭RedisServer端的防火墙</p>
<p>systemctl stop firewalld（默认）</p>
<p>systemctl disable firewalld.service（设置开启不启动）</p>
<p>systemctl status firewalld.service（查看防火墙是否关闭）</p>
<p><img src="/posts/40341/asset/v2-9b55805dc3d8abdddd4e151169628227_720w.webp" alt="img"></p>
<p>Redis云服务器端口开放访问不到解决办法</p>
<p>1.开启防火墙：systemctl start firewalld.service<br>2.添加端口：firewall-cmd –zone&#x3D;public –add-port&#x3D;6379&#x2F;tcp –permanent<br>3.重启防火墙：firewall-cmd –reload</p>
<h3 id="Redis数据类型"><a href="#Redis数据类型" class="headerlink" title="Redis数据类型"></a><strong>Redis数据类型</strong></h3><p>Redis是一个Key-Value的存储系统，使用ANSI C语言编写。</p>
<p>key的类型是字符串。</p>
<p>value的数据类型有： 常用的：string字符串类型、list列表类型、set集合类型、sortedset（zset）有序集合类型、hash类 型。 不常见的：bitmap位图类型、geo地理位置类型，Redis5.0新增：stream类型。</p>
<p>Redis中命令是忽略大小写，key是不忽略大小写的</p>
<p>Redis中Key的设计：1. 用:分割 2. 把表名转换为key前缀, 比如: user: 3. 第二段放置主键值 4. 第三段放置列名</p>
<p>比如：username 的 key：user:9:username对应{userid:9,username:zhangf}</p>
<p><strong>string字符串类型</strong></p>
<p>Redis的String能表达3种值的类型：字符串、整数、浮点数 100.01 是个六位的串</p>
<p><img src="/posts/40341/asset/v2-048489ca250f424d882a9d1d4a187983_720w.webp" alt="img"></p>
<p>1、key和命令是字符串</p>
<p>2、普通的赋值</p>
<p>3、incr用于乐观锁 incr：递增数字，可用于实现乐观锁 watch(事务)</p>
<p>4、setnx用于分布式锁</p>
<p><strong>list列表类型</strong></p>
<p>list列表类型可以存储有序、可重复的元素</p>
<p><img src="/posts/40341/asset/v2-b50e72078a1cc2c64ee70bb50885afe2_720w.webp" alt="img"></p>
<p><img src="/posts/40341/asset/v2-56653f6104f465330c5498a4f9a7d6f2_720w.webp" alt="img"></p>
<p>1、作为栈或队列使用 列表有序可以作为栈和队列使用</p>
<p>2、可用于各种列表，比如用户列表、商品列表、评论列表等。</p>
<p><strong>set集合类型</strong></p>
<p>Set：无序、唯一元素，适用于不能重复的且不需要顺序的数据结构</p>
<p><img src="https://pic1.zhimg.com/80/v2-2223eaaa645aff786ff46ff377dbdcf8_720w.webp" alt="img"></p>
<p><strong>sortedset有序集合类型</strong></p>
<p>SortedSet(ZSet) 有序集合： 元素本身是无序不重复的 每个元素关联一个分数(score) 可按分数排序，分数可重复</p>
<p><img src="https://pic1.zhimg.com/80/v2-b345d0b59464120e7f75d1632dabec74_720w.webp" alt="img"></p>
<p><img src="https://pic2.zhimg.com/80/v2-52fcf10e48a69f6dcbf405d9d94a0ca1_720w.webp" alt="img"></p>
<p><strong>hash类型（散列表）</strong></p>
<p>Redis hash 是一个 string 类型的 field 和 value 的映射表，它提供了字段和字段值的映射。</p>
<p><img src="/posts/40341/asset/v2-32d82bb0e26212f496ee04a2d43b1c5f_720w.webp" alt="img"></p>
<p><strong>bitmap位图类型</strong></p>
<p>bitmap是进行位操作的 通过一个bit位来表示某个元素对应的值或者状态,其中的key就是对应元素本身。</p>
<p><img src="https://pic3.zhimg.com/80/v2-6ca1f7571d53d41f1eb67c7bead0038e_720w.webp" alt="img"></p>
<p>1、用户每月签到，用户id为key ， 日期作为偏移量 1表示签到</p>
<p>2、统计活跃用户, 日期为key，用户id为偏移量 1表示活跃</p>
<p>3、查询用户在线状态， 日期为key，用户id为偏移量 1表示在线</p>
<p><strong>geo地理位置类型</strong></p>
<p>geo是Redis用来处理位置信息的。在Redis3.2中正式使用。主要是利用了Z阶曲线、Base32编码和 geohash算法。</p>
<p>1、记录地理位置</p>
<p>2、计算距离</p>
<p>3、查找”附近的人”</p>
<p><img src="https://pic1.zhimg.com/80/v2-57fcaa24948169e55cf471ceef792f48_720w.webp" alt="img"></p>
<p><strong>stream数据流类型</strong></p>
<p>stream是Redis5.0后新增的数据结构，用于可持久化的消息队列。</p>
<p><img src="/posts/40341/asset/v2-9edefdbb25250812ac98ee1ac4bfaf66_720w.webp" alt="img"></p>
<h3 id="二、Redis扩展功能"><a href="#二、Redis扩展功能" class="headerlink" title="二、Redis扩展功能"></a><strong>二、Redis扩展功能</strong></h3><h3 id="发布与订阅"><a href="#发布与订阅" class="headerlink" title="发布与订阅"></a><strong>发布与订阅</strong></h3><p>Redis提供了发布订阅功能，可以用于消息的传输，包括三个部分，publisher，subscriber和Channel</p>
<p>发布者和订阅者都是Redis客户端，Channel则为Redis服务器端。</p>
<p>发布者将消息发送到某个的频道，订阅了这个频道的订阅者就能接收到这条消息。</p>
<p><img src="https://pic1.zhimg.com/80/v2-46b0c3716d28aae266d73f0f70857818_720w.webp" alt="img"></p>
<p>在Redis哨兵模式中，哨兵通过发布与订阅的方式与Redis主服务器和Redis从服务器进行通信。</p>
<h3 id="事务特性"><a href="#事务特性" class="headerlink" title="事务特性"></a><strong>事务特性</strong></h3><p><strong>ACID特性与redis事务比较</strong></p>
<p>1.Atomicity（原子性）：构成事务的的所有操作必须是一个逻辑单元，要么全部执行，要么全部不执行。</p>
<p>Redis:一个队列中的命令 执行或不执行</p>
<p>2.Consistency（一致性）：数据库在事务执行前后状态都必须是稳定的或者是一致的。</p>
<p>Redis: 集群中不能保证时时的一致性，只能是最终一致性</p>
<p>3.Isolation（隔离性）：事务之间不会相互影响。</p>
<p>Redis: 命令是顺序执行的，在一个事务中，有可能被执行其他客户端的命令的</p>
<p>4.Durability（持久性）：事务执行成功后必须全部写入磁盘。</p>
<p>Redis有持久化但不保证数据的完整性</p>
<p><strong>Redis事务</strong></p>
<p>Redis的事务是通过multi、exec、discard和watch这四个命令来完成的。</p>
<p>Redis的单个命令都是原子性的，所以这里需要确保事务性的对象是命令集合。</p>
<p>Redis将命令集合序列化并确保处于同一事务的命令集合连续且不被打断的执行</p>
<p>Redis不支持回滚操作</p>
<p><strong>事务命令</strong></p>
<p>multi：用于标记事务块的开始,Redis会将后续的命令逐个放入队列中，然后使用exec原子化地执行这个命令队列</p>
<p>exec：执行命令队列</p>
<p>discard：清除命令队列</p>
<p>watch：监视key，如果监视中发现key变值了清空队列</p>
<p>unwatch：清除监视key</p>
<p><img src="https://pic1.zhimg.com/80/v2-dae8e4f177927937d005a89c9a120750_720w.webp" alt="img"></p>
<h3 id="事务机制"><a href="#事务机制" class="headerlink" title="事务机制"></a><strong>事务机制</strong></h3><p><strong>事务的执行</strong></p>
<p>\1. 事务开始 在RedisClient中，有属性flags，用来表示是否在事务中 flags&#x3D;REDIS_MULTI</p>
<p>\2. 命令入队 RedisClient将命令存放在事务队列中 （EXEC,DISCARD,WATCH,MULTI除外）</p>
<p>\3. 事务队列 multiCmd *commands 用于存放命令</p>
<p>\4. 执行事务 RedisClient向服务器端发送exec命令，RedisServer会遍历事务队列,执行队列中的命令,最后将执 行的结果一次性返回给客户端。</p>
<p>\5. 如果某条命令在入队过程中发生错误，redisClient将flags置为REDIS_DIRTY_EXEC，EXEC命令将会失败 返回。</p>
<p><strong>Watch的执行</strong></p>
<p>redisDb有一个watched_keys字典,key是某个被监视的数据的key,值是一个链表.记录了所有监视这个数 据的客户端。</p>
<p>监视机制的触发</p>
<p>当修改数据后，监视这个数据的客户端的flags置为REDIS_DIRTY_CAS事务执行 RedisClient向服务器端发送exec命令，服务器判断RedisClient的flags，如果为REDIS_DIRTY_CAS，则清空事务队列。</p>
<p>Redis不支持事务回滚的原因</p>
<p>1、大多数事务失败是因为语法错误或者类型错误，这两种错误，在开发阶段都是可以预见的</p>
<p>2、Redis为了性能方面就忽略了事务回滚。</p>
<h3 id="Lua脚本"><a href="#Lua脚本" class="headerlink" title="Lua脚本"></a><strong>Lua脚本</strong></h3><p>从Redis2.6.0版本开始，通过内置的lua编译&#x2F;解释器，可以使用EVAL命令对lua脚本进行求值。</p>
<p>脚本的命令是原子的，RedisServer在执行脚本命令中，不允许插入新的命令</p>
<p>脚本的命令可以复制，RedisServer在获得脚本后不执行，生成标识返回，Client根据标识就可以随时执行</p>
<p><strong>EVAL命令</strong></p>
<p>命令说明：</p>
<p>script参数：是一段Lua脚本程序，它会被运行在Redis服务器上下文中，这段脚本不必(也不应该) 定义为一个Lua函数。</p>
<p>numkeys参数：用于指定键名参数的个数。</p>
<p>key [key …]参数： 从EVAL的第三个参数开始算起，使用了numkeys个键（key），表示在脚本中 所用到的那些Redis键(key)，这些键名参数可以在Lua中通过全局变量KEYS数组，用1为基址的形 式访问( KEYS[1] ， KEYS[2] ，以此类推)。</p>
<p>arg [arg …]参数：可以在Lua中通过全局变量ARGV数组访问，访问的形式和KEYS变量类似( ARGV[1] 、 ARGV[2] ，诸如此类)。</p>
<p>举例：eval “return {KEYS[1],KEYS[2],ARGV[1],ARGV[2]}” 2 key1 key2 first second</p>
<p>lua脚本中调用Redis命令：eval “return redis.call(‘set’,KEYS[1],ARGV[1])” 1 n1 zhaoyun</p>
<p><strong>EVALSHA命令</strong></p>
<p>EVAL 命令要求你在每次执行脚本的时候都发送一次脚本主体，为了减少带宽的消耗， Redis 实现了 EVALSHA 命令，它的作用和 EVAL 一样，都用于对脚本求值，但 它接受的第一个参数不是脚本，而是脚本的 SHA1 校验和(sum)。</p>
<p>SCRIPT FLUSH ：清除所有脚本缓存</p>
<p>SCRIPT EXISTS ：根据给定的脚本校验和，检查指定的脚本是否存在于脚本缓存</p>
<p>SCRIPT LOAD ：将一个脚本装入脚本缓存，返回SHA1摘要，但并不立即运行它</p>
<p>SCRIPT KILL ：杀死当前正在运行的脚本</p>
<p>举例:</p>
<p>script load “return redis.call(‘set’,KEYS[1],ARGV[1])”-&gt; “c686f316aaf1eb01d5a4de1b0b63cd233010e63d”</p>
<p>-&gt;evalsha c686f316aaf1eb01d5a4de1b0b63cd233010e63d 1 n2 zhangfei</p>
<p>其实就是把LUA命令进行缓存并返回一段唯一的sha码，通过码来调用脚本执行命令</p>
<p><strong>脚本复制</strong></p>
<p>Redis 传播 Lua 脚本，在使用主从模式和开启AOF持久化的前提下，当执行lua脚本时，Redis 服务器有两种模式：脚本传播模式和命令传播模式。</p>
<p>脚本传播模式是 Redis 复制脚本时默认使用的模式 Redis会将被执行的脚本及其参数复制到 AOF 文件以及从服务器里面。</p>
<p>命令传播模式的主服务器会将执行脚本产生的所有写命令用事务包裹起来，然后将事务复制到 AOF 文件以及从服务器里面。</p>
<p><strong>管道（pipeline）,事务和脚本(lua)三者的区别</strong></p>
<p>三者都可以批量执行命令</p>
<p>管道无原子性，命令都是独立的，属于无状态的操作</p>
<p>事务和脚本是有原子性的，其区别在于脚本可借助Lua语言可在服务器端存储的便利性定制和简化操作</p>
<p>脚本的原子性要强于事务，脚本执行期间，另外的客户端 其它任何脚本或者命令都无法执行，脚本的执行时间应该尽量短，不能太耗时的脚本。</p>
<h3 id="慢查询日志和监视器"><a href="#慢查询日志和监视器" class="headerlink" title="慢查询日志和监视器"></a><strong>慢查询日志和监视器</strong></h3><p><strong>Redis慢查询日志用于监视和优化查询</strong></p>
<p>1、尽量使用短的key，对于value有些也可精简，能使用int就int。</p>
<p>2、避免使用keys *、hgetall等全量操作。</p>
<p>3、减少大key的存取，打散为小key 100K以上</p>
<p>4、将rdb改为aof模式 rdb fork 子进程 数据量过大 主进程阻塞 redis性能大幅下降 关闭持久化 ， （适合于数据量较小，有固定数据源）</p>
<p>5、想要一次添加多条数据的时候可以使用管道</p>
<p>6、尽可能地使用哈希存储</p>
<p>7、尽量限制下redis使用的内存大小，这样可以避免redis使用swap分区或者出现OOM错误 内存与硬盘的swap</p>
<p><strong>监视器</strong></p>
<p>Redis客户端通过执行MONITOR命令可以将自己变为一个监视器，实时地接受并打印出服务器当前处理的命令请求的相关信息。</p>
<h3 id="三、Redis核心原理"><a href="#三、Redis核心原理" class="headerlink" title="三、Redis核心原理"></a><strong>三、Redis核心原理</strong></h3><h3 id="Redis持久化"><a href="#Redis持久化" class="headerlink" title="Redis持久化"></a><strong>Redis持久化</strong></h3><p>Redis是内存数据库，宕机后数据会消失。Redis重启后快速恢复数据，要提供持久化机制，Redis持久化是为了快速的恢复数据而不是为了存储数据，Redis有两种持久化方式：RDB和AOF。</p>
<h3 id="RDB特性"><a href="#RDB特性" class="headerlink" title="RDB特性"></a><strong>RDB特性</strong></h3><p>RDB（Redis DataBase），是redis默认的存储方式，RDB方式是通过快照（ snapshotting ）完成的。关注的是这一刻的数据，也就是跟拍照一样，抓拍这一刻，不管前后。</p>
<p>在redis.conf中配置：save 多少秒内 数据变了多少，采用漏洞设计，提升性能。</p>
<p><img src="/posts/40341/asset/v2-cd2f5e1523388eb46a2b7b3bc4a32fef_720w.webp" alt="img"></p>
<p><img src="https://pic2.zhimg.com/80/v2-f7c80e91a300ab811cd8aeec687f15e5_720w.webp" alt="img"></p>
<p>\1. Redis父进程首先判断：当前是否在执行save，或bgsave&#x2F;bgrewriteaof（aof文件重写命令）的子进程，如果在执行则bgsave命令直接返回。</p>
<p>\2. 父进程执行fork（调用OS函数复制主进程）操作创建子进程，这个复制过程中父进程是阻塞的，Redis不能执行来自客户端的任何命令。</p>
<p>\3. 父进程fork后，bgsave命令返回”Background saving started”信息并不再阻塞父进程，并可以响应其他命令。</p>
<p>\4. 子进程创建RDB文件，根据父进程内存快照生成临时快照文件，完成后对原有文件进行原子替换。 （RDB始终完整）</p>
<p>\5. 子进程发送信号给父进程表示完成，父进程更新统计信息。</p>
<p>\6. 父进程fork子进程后，继续工作。</p>
<p><strong>优点</strong></p>
<p>RDB是二进制压缩文件，占用空间小，便于传输（传给slaver）</p>
<p>主进程fork子进程，可以最大化Redis性能，主进程不能太大，Redis的数据量不能太大，复制过程中主进程阻塞</p>
<p><strong>缺点</strong></p>
<p>不保证数据完整性，会丢失最后一次快照以后更改的所有数据</p>
<h3 id="AOF特性"><a href="#AOF特性" class="headerlink" title="AOF特性"></a><strong>AOF特性</strong></h3><p>AOF（append only file）是Redis的另一种持久化方式。Redis默认情况下是不开启的。开启AOF持久化后 Redis 将所有对数据库进行过写入的命令（及其参数）记录到 AOF文件， 以此达到记录数据库状态的目的，这样当Redis重启后只要按顺序回放这些命令就会恢复到原始状态了。 AOF会记录过程，RDB只管结果。</p>
<p>在redis.conf中配置</p>
<p><img src="https://pic4.zhimg.com/80/v2-99acb4dcd40a6dea003db87dbfa7e61b_720w.webp" alt="img"></p>
<p><strong>AOF原理</strong></p>
<p>AOF文件中存储的是redis的命令，同步命令到 AOF 文件的整个过程可以分为三个阶段：</p>
<p>命令传播：Redis 将执行完的命令、命令的参数、命令的参数个数等信息发送到 AOF 程序中。</p>
<p>缓存追加：AOF 程序根据接收到的命令数据，将命令转换为网络通讯协议的格式，然后将协议内容追加 到服务器的 AOF 缓存中。</p>
<p>文件写入和保存：AOF 缓存中的内容被写入到 AOF 文件末尾，如果设定的 AOF 保存条件被满足的话， fsync 函数或者 fdatasync 函数会被调用，将写入的内容真正地保存到磁盘中。</p>
<p><strong>AOF 保存模式</strong></p>
<p>Redis 目前支持三种 AOF 保存模式，它们分别是：</p>
<p>AOF_FSYNC_NO ：不保存。</p>
<p>AOF_FSYNC_EVERYSEC ：每一秒钟保存一次。（默认）</p>
<p>AOF_FSYNC_ALWAYS ：每执行一个命令保存一次。（不推荐）</p>
<p><img src="https://pic2.zhimg.com/80/v2-57c7573883534b5b0ed9ef66ce4a145d_720w.webp" alt="img"></p>
<p>Redis可以在 AOF体积变得过大时，自动地在后台（Fork子进程）对 AOF进行重写，Redis 不希望 AOF 重写造成服务器无法处理请求，所以 Redis 决定将 AOF 重写程序放到（后台）子进程里执行，子进程在进行 AOF重写期间，主进程还需要继续处理命令，而新的命令可能对现有的数据进行修改，因此Redis 增加了一个 AOF 重写缓存。</p>
<p><img src="https://pic1.zhimg.com/80/v2-e54243fcf92fc4ff89fc90ce8fe433ac_720w.webp" alt="img"></p>
<h3 id="混合持久化"><a href="#混合持久化" class="headerlink" title="混合持久化"></a><strong>混合持久化</strong></h3><p>RDB和AOF各有优缺点，Redis 4.0 开始支持 rdb 和 aof 的混合持久化。如果把混合持久化打开，aof rewrite 的时候就直接把 rdb 的内容写到 aof 文件开头。在加载时，首先会识别AOF文件是否以 REDIS字符串开头，如果是就按RDB格式加载，加载完RDB后继续按AOF格式加载剩余部分。</p>
<p><strong>RDB与AOF对比</strong></p>
<p>1、RDB存某个时刻的数据快照，采用二进制压缩存储，AOF存操作命令，采用文本存储(混合)</p>
<p>2、RDB性能高、AOF性能较低</p>
<p>3、RDB在配置触发状态会丢失最后一次快照以后更改的所有数据，AOF设置为每秒保存一次，则最多 丢2秒的数据</p>
<p>4、Redis以主服务器模式运行，RDB不会保存过期键值对数据，Redis以从服务器模式运行，RDB会保 存过期键值对，当主服务器向从服务器同步时，再清空过期键值对。</p>
<p><strong>应用场景</strong></p>
<p>内存数据库 rdb+aof 数据不容易丢</p>
<p>有原始数据源：每次启动时都从原始数据源中初始化 ，则不用开启持久化</p>
<p>缓存服务器 rdb 一般性能高</p>
<p>在数据还原时 有rdb+aof 则还原aof，因为RDB会造成文件的丢失，AOF相对数据要完整。</p>
<h3 id="底层数据结构"><a href="#底层数据结构" class="headerlink" title="底层数据结构"></a><strong>底层数据结构</strong></h3><p>Redis没有表的概念，Redis实例所对应的db以编号区分，db本身就是key的命名空间。</p>
<p><img src="https://pic1.zhimg.com/80/v2-4611506e2a8984baba58502dc3818a88_720w.webp" alt="img"></p>
<p>RedisDB结构体源码：</p>
<p><img src="https://pic1.zhimg.com/80/v2-77d54e308eb1eb6699a83ed64884c8a8_720w.webp" alt="img"></p>
<p>RedisObject结构：</p>
<p><img src="https://pic2.zhimg.com/80/v2-2ea3572924182e7acd7e3055a9de3f05_720w.webp" alt="img"></p>
<h3 id="字符串对象"><a href="#字符串对象" class="headerlink" title="字符串对象"></a><strong>字符串对象</strong></h3><p>Redis 使用了 SDS(Simple Dynamic String)。用于存储字符串和整型数据。SDS 在 C 字符串的基础上加入了 free 和 len 字段，SDS 由于记录了长度，在可能造成缓冲区溢出时会自动重新分配内存，杜绝了缓冲区溢出。</p>
<h3 id="跳跃表"><a href="#跳跃表" class="headerlink" title="跳跃表"></a><strong>跳跃表</strong></h3><p>跳跃表是有序集合（sorted-set）的底层实现，效率高，实现简单。</p>
<p><img src="https://pic1.zhimg.com/80/v2-bd150892784506adceed144122f271cc_720w.webp" alt="img"></p>
<h3 id="字典（核心）"><a href="#字典（核心）" class="headerlink" title="字典（核心）"></a><strong>字典（核心）</strong></h3><p>字典dict又称散列表（hash），是用来存储键值对的一种数据结构。 Redis整个数据库是用字典来存储的。（K-V结构） 对Redis进行CURD操作其实就是对字典中的数据进行CURD操作。</p>
<p><strong>数组</strong></p>
<p>数组：用来存储数据的容器，采用头指针+偏移量的方式能够以O(1)的时间复杂度定位到数据所在的内存地址，海量存储效率高的缘由。</p>
<p><strong>Hash函数</strong></p>
<p>Hash（散列），作用是把任意长度的输入通过散列算法转换成固定类型、固定长度的散列值。 hash函数可以把Redis里的key：包括字符串、整数、浮点数统一转换成整数，算出数组下标进行存储。</p>
<p><img src="/posts/40341/asset/v2-85d09a2f409d14f8e458446a85d119eb_720w.webp" alt="img"></p>
<p>Redis字典实现包括：字典(dict)、Hash表(dictht)、Hash表节点(dictEntry)。</p>
<p>字典达到存储上限（阈值 0.75），需要rehash（扩容）</p>
<p>\1. 初次申请默认容量为4个dictEntry，非初次申请为当前hash表容量的一倍。</p>
<p>\2. rehashidx&#x3D;0表示要进行rehash操作。</p>
<p>\3. 新增加的数据在新的hash表h[1]</p>
<p>\4. 修改、删除、查询在老hash表h[0]、新hash表h[1]中（rehash中）</p>
<p>\5. 将老的hash表h[0]的数据重新计算索引值后全部迁移到新的hash表h[1]中，这个过程称为 rehash。</p>
<p><strong>应用场景：</strong></p>
<p>1、主数据库的K-V数据存储</p>
<p>2、散列表对象（hash）</p>
<p>3、哨兵模式中的主从节点管理</p>
<p><strong>压缩列表</strong></p>
<p>压缩列表（ziplist）是由一系列特殊编码的连续内存块组成的顺序型数据结构，节省内存，是一个字节数组，可以包含多个节点（entry）。每个节点可以保存一个字节数组或一个整数。</p>
<p>应用场景：</p>
<p>sorted-set和hash元素个数少且是小整数或短字符串（直接使用）</p>
<p>list用快速链表(quicklist)数据结构存储，而快速链表是双向列表与压缩列表的组合。（间接使用）</p>
<p><strong>整数集合</strong></p>
<p>整数集合(intset)是一个有序的（整数升序）、存储整数的连续存储结构。</p>
<h3 id="快速列表"><a href="#快速列表" class="headerlink" title="快速列表"></a><strong>快速列表</strong></h3><p>快速列表（quicklist）是Redis底层重要的数据结构。是列表的底层实现。（在Redis3.2之前，Redis采用双向链表（adlist）和压缩列表（ziplist）实现。）在Redis3.2以后结合adlist和ziplist的优势Redis设计出了quicklist。</p>
<p><strong>双向列表（adlist）</strong>：</p>
<p><img src="https://pic3.zhimg.com/80/v2-9bff2fceff71badd0f99c7a3a5981e26_720w.webp" alt="img"></p>
<p>\1. 双向：链表具有前置节点和后置节点的引用，获取这两个节点时间复杂度都为O(1)。</p>
<p>\2. 普通链表（单链表）：节点类保留下一节点的引用。链表类只保留头节点的引用，只能从头节点插 入删除</p>
<p>\3. 无环：表头节点的 prev 指针和表尾节点的 next 指针都指向 NULL,对链表的访问都是以 NULL 结 束。 环状：头的前一个节点指向尾节点</p>
<p>\4. 带链表长度计数器：通过 len 属性获取链表长度的时间复杂度为 O(1)。</p>
<p>\5. 多态：链表节点使用 void* 指针来保存节点值，可以保存各种不同类型的值。</p>
<p>快速列表quicklist是一个双向链表，链表中的每个节点时一个ziplist结构。quicklist中的每个节点ziplist都能够存 储多个数据元素。</p>
<p><strong>数据压缩（ziplist）:</strong></p>
<p>quicklist每个节点的实际数据存储结构为ziplist，这种结构的优势在于节省存储空间。为了进一步降低 ziplist的存储空间，还可以对ziplist进行压缩。Redis采用的压缩算法是LZF。其基本思想是：数据与前 面重复的记录重复位置及长度，不重复的记录原始数据。</p>
<h3 id="stream流对象"><a href="#stream流对象" class="headerlink" title="stream流对象"></a><strong>stream流对象</strong></h3><p>stream主要由：消息、生产者、消费者和消费组构成。</p>
<p>Redis Stream的底层主要使用了listpack（紧凑列表）和Rax树（基数树）。</p>
<p>listpack表示一个字符串列表的序列化，listpack可用于存储字符串或整数。用于存储stream的消息内容。</p>
<p>Rax 是一个有序字典树 (基数树 Radix Tree)，按照 key 的字典序排列，支持快速地定位、插入和删除操作。</p>
<h3 id="缓存过期和淘汰策略"><a href="#缓存过期和淘汰策略" class="headerlink" title="缓存过期和淘汰策略"></a><strong>缓存过期和淘汰策略</strong></h3><p>Redis长期使用，key会不断增加，Redis作为缓存使用，物理内存也会满 内存与硬盘交换（swap）虚拟内存 ，频繁IO 性能急剧下降。</p>
<p>Redis默认缓存淘汰策略：禁止驱逐</p>
<p><strong>Maxmemory最大内存</strong></p>
<p>不设置场景</p>
<p>Redis作为DB使用，保证数据的完整性，不能淘汰 ，可以做集群，横向扩展</p>
<p>设置的场景</p>
<p>Redis是作为缓存使用，不断增加Key maxmemory ： 默认为0 不限制</p>
<p>设置maxmemory后，当趋近maxmemory时，通过缓存淘汰策略，从内存中删除对象，一般是物理内存的3&#x2F;4</p>
<p><strong>expire数据结构</strong></p>
<p>在Redis中可以使用expire命令设置一个键的存活时间(ttl: time to live)，过了这段时间，该键就会自动被删除。</p>
<h3 id="删除策略之定时删除"><a href="#删除策略之定时删除" class="headerlink" title="删除策略之定时删除"></a><strong>删除策略之定时删除</strong></h3><p>在设置键的过期时间的同时，创建一个定时器，让定时器在键的过期时间来临时，立即执行对键的删除操作。 需要创建定时器，而且消耗CPU，一般不推荐使用。</p>
<h3 id="删除策略之惰性删除"><a href="#删除策略之惰性删除" class="headerlink" title="删除策略之惰性删除"></a><strong>删除策略之惰性删除</strong></h3><p>在key被访问时如果发现它已经失效，那么就删除它。</p>
<h3 id="删除策略之主动删除"><a href="#删除策略之主动删除" class="headerlink" title="删除策略之主动删除"></a><strong>删除策略之主动删除</strong></h3><p>在redis.conf文件中可以配置主动删除策略,默认是no-enviction（不删除）</p>
<p>maxmemory-policy allkeys-lru</p>
<p><strong>LRU算法</strong></p>
<p>最近最少使用，算法根据数据的历史访问记录来进行淘汰数据，其核心思想 是“如果数据最近被访问过，那么将来被访问的几率也更高”。</p>
<p>\1. 新数据插入到链表头部；</p>
<p>\2. 每当缓存命中（即缓存数据被访问），则将数据移到链表头部；</p>
<p>\3. 当链表满的时候，将链表尾部的数据丢弃。</p>
<p>\4. 在Java中可以使用LinkHashMap（哈希链表）去实现LRU</p>
<p>volatile-lru 从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰</p>
<p>allkeys-lru 从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰</p>
<p><strong>LFU算法</strong></p>
<p>LFU (Least frequently used) 最不经常使用，如果一个数据在最近一段时间内使用次数很少，那么在将来一段时间内被使用的可能性也很小。</p>
<p><strong>Random</strong></p>
<p>volatile-random 从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰</p>
<p>allkeys-random 从数据集（server.db[i].dict）中任意选择数据淘汰</p>
<p><strong>ttl</strong></p>
<p>从过期时间的表中随机挑选几个键值对，取出其中 ttl 最小的键值对淘汰。</p>
<p>volatile-ttl 从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰</p>
<p><strong>缓存淘汰策略的选择</strong></p>
<p>allkeys-lru ： 在不确定时一般采用策略。 冷热数据交换</p>
<p>volatile-lru ： 比allkeys-lru性能差 存 : 过期时间</p>
<p>allkeys-random ： 希望请求符合平均分布(每个元素以相同的概率被访问)</p>
<p>自己控制：volatile-ttl 缓存穿透</p>
<h3 id="通信协议之请求协议响应"><a href="#通信协议之请求协议响应" class="headerlink" title="通信协议之请求协议响应"></a><strong>通信协议之请求协议响应</strong></h3><p>Redis是单进程单线程的。 应用系统和Redis通过Redis协议（RESP）进行交互。</p>
<p>Redis协议位于TCP层之上，即客户端和Redis实例保持双工的连接。</p>
<p><strong>串行的请求响应模式（ping-pong）</strong></p>
<p>串行化是最简单模式，客户端与服务器端建立长连接 连接通过心跳机制检测（ping-pong） ack应答 客户端发送请求，服务端响应，客户端收到响应后，再发起第二个请求，服务器端再响应。telnet和redis-cli 发出的命令 都属于该种模式，性能较低。</p>
<p><strong>双工的请求响应模式(pipeline)</strong></p>
<p>批量请求，批量响应 请求响应交叉进行，不会混淆(TCP双工)</p>
<p>pipeline的作用是将一批命令进行打包，然后发送给服务器，服务器执行完按顺序打包返回。</p>
<p>通过pipeline，一次pipeline（n条命令）&#x3D;一次网络时间 + n次命令时间</p>
<p><strong>原子化的批量请求响应模式（事务）</strong></p>
<p>Redis可以利用事务机制批量执行命令。</p>
<p><strong>发布订阅模式(pub&#x2F;sub)</strong></p>
<p>发布订阅模式是：一个客户端触发，多个客户端被动接收，通过服务器中转。</p>
<p><strong>脚本化的批量执行（lua）</strong></p>
<p>客户端向服务器端提交一个lua脚本，服务器端执行该脚本。</p>
<p><strong>请求数据格式</strong></p>
<p>内联格式：可以使用telnet给Redis发送命令，首字符为Redis命令名的字符，格式为 str1 str2 str3…</p>
<p>规范格式(redis-cli) RESP：</p>
<p>1、间隔符号，在Linux下是\r\n，在Windows下是\n</p>
<p>2、简单字符串 Simple Strings, 以 “+”加号 开头</p>
<p>3、错误 Errors, 以”-“减号 开头</p>
<p>4、整数型 Integer， 以 “:” 冒号开头</p>
<p>5、大字符串类型 Bulk Strings, 以 “$”美元符号开头，长度限制512M</p>
<p>6、数组类型 Arrays，以 “*”星号开头</p>
<h3 id="通信协议之命令处理流程"><a href="#通信协议之命令处理流程" class="headerlink" title="通信协议之命令处理流程"></a><strong>通信协议之命令处理流程</strong></h3><p>整个流程包括：服务器启动监听、接收命令请求并解析、执行命令请求、返回命令回复等。</p>
<p><img src="https://pic3.zhimg.com/80/v2-818aef511ccf7c5427130840354e5aba_720w.webp" alt="img"></p>
<h3 id="事件处理机制之文件事件"><a href="#事件处理机制之文件事件" class="headerlink" title="事件处理机制之文件事件"></a><strong>事件处理机制之文件事件</strong></h3><p>Redis服务器是典型的事件驱动系统。</p>
<p>文件事件即Socket的读写事件，也就是IO事件。客户端的连接、命令请求、数据回复、连接断开。</p>
<p>socket 套接字（socket）是一个抽象层，应用程序可以通过它发送或接收数据。</p>
<p>Reactor Redis事件处理机制采用单线程的Reactor模式，属于I&#x2F;O多路复用的一种常见模式。</p>
<p>IO多路复用( I&#x2F;O multiplexing ）指的通过单个线程管理多个Socket。</p>
<p>Reactor pattern(反应器设计模式)是一种为处理并发服务请求，并将请求提交到一个或者多个服务处理程序的事件设计模式。</p>
<p>Reactor模式是事件驱动的，也就是文件事件。</p>
<p>有一个Service Handler，有多个Request Handlers，这个Service Handler会同步的将输入的请求（Event）多路复用的分发给相应的Request Handler。</p>
<p><img src="/posts/40341/asset/v2-0188075f736b53918eb7c5cc116867fc_720w.webp" alt="img"></p>
<h3 id="4种IO多路复用模型"><a href="#4种IO多路复用模型" class="headerlink" title="4种IO多路复用模型"></a><strong>4种IO多路复用模型</strong></h3><p>select，poll，epoll、kqueue都是IO多路复用的机制。 I&#x2F;O多路复用就是通过一种机制，一个进程可以监视多个描述符（socket），一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。</p>
<p><strong>Select</strong></p>
<p>调用后select函数会阻塞，直到有描述符就绪（有数据 可读、可写、或者有except），或者超时 （timeout指定等待时间，如果立即返回设为null即可），函数返回。当select函数返回后，可以通过遍历fd列表，来找到就绪的描述符，最大监听1024，采用的是线性扫描的方法，即不管这些socket是不是活 跃的，都轮询一遍，效率比较低。</p>
<p><strong>Poll</strong></p>
<p>poll使用一个 pollfd的指针实现，pollfd结构包含了要监视的event和发生的event，不再使用select“参 数-值”传递的方式，没有1024限制，但是仍然采用的是线性扫描的方法，即不管这些socket是不是活跃的，都轮询一遍，效率比较低。。</p>
<p><strong>Epoll</strong></p>
<p>epoll是在linux2.6内核中提出的，是之前的select和poll的增强版本。相对于select和poll来说，epoll更 加灵活，没有描述符限制，并且不会采用线性扫描，只扫描活跃的。</p>
<p><strong>Kqueue</strong></p>
<p>kqueue 是 unix 下的一个IO多路复用库。最初是2000年Jonathan Lemon在FreeBSD系统上开发的一个 高性能的事件通知接口。注册一批socket描述符到 kqueue 以后，当其中的描述符状态发生变化时，kqueue 将一次性通知应用程序哪些描述符可读、可写或出错了。能处理大量数据，性能较高。</p>
<h3 id="事件处理机制之时间事件"><a href="#事件处理机制之时间事件" class="headerlink" title="事件处理机制之时间事件"></a><strong>事件处理机制之时间事件</strong></h3><p>时间事件分为定时事件与周期事件：</p>
<p>id(全局唯一id)</p>
<p>when (毫秒时间戳，记录了时间事件的到达时间)</p>
<p><strong>serverCron</strong></p>
<p>时间事件的最主要的应用是在redis服务器需要对自身的资源与配置进行定期的调整，从而确保服务器的 长久运行，这些操作由redis.c中的serverCron函数实现。该时间事件主要进行以下操作：</p>
<p>1）更新redis服务器各类统计信息，包括时间、内存占用、数据库占用等情况。</p>
<p>2）清理数据库中的过期键值对。</p>
<p>3）关闭和清理连接失败的客户端。</p>
<p>4）尝试进行aof和rdb持久化操作。</p>
<p>5）如果服务器是主服务器，会定期将数据向从服务器做同步操作。</p>
<p>6）如果处于集群模式，对集群定期进行同步与连接测试操作。</p>
<p>timeProc（时间事件处理器，当时间到达时，Redis就会调用相应的处理器来处理事件）</p>
<p><strong>定时事件</strong></p>
<p>定时事件：让一段程序在指定的时间之后执行一次 aeTimeProc（时间处理器）的返回值是AE_NOMORE 该事件在达到后删除，之后不会再重复。</p>
<p><strong>周期性事件</strong></p>
<p>周期性事件：让一段程序每隔指定时间就执行一次 aeTimeProc（时间处理器）的返回值不是AE_NOMORE 当一个时间事件到达后，服务器会根据时间处理器的返回值，对时间事件的 when 属性进行更新，让这 个事件在一段时间后再次达到。 serverCron就是一个典型的周期性事件。</p>
<p><strong>aeEventLoop</strong></p>
<p>aeEventLoop 是整个事件驱动的核心，Redis自己的事件处理机制 它管理着文件事件表和时间事件列表， 不断地循环处理着就绪的文件事件和到期的时间事件。</p>
<p><img src="/posts/40341/asset/v2-88af62216fd8aac5615a88f020c9b50d_720w.webp" alt="img"></p>
<p><strong>aeProcessEvent</strong></p>
<p>首先计算距离当前时间最近的时间事件，以此计算一个超时时间；然后调用 aeApiPoll 函数去等待底层的I&#x2F;O多路复用事件就绪；aeApiPoll 函数返回之后，会处理所有已经产生文件事件和已经达到的时间事件。</p>
<h3 id="四、Redis企业应用"><a href="#四、Redis企业应用" class="headerlink" title="四、Redis企业应用"></a><strong>四、Redis企业应用</strong></h3><h3 id="JVM缓存"><a href="#JVM缓存" class="headerlink" title="JVM缓存"></a><strong>JVM缓存</strong></h3><p>JVM缓存就是本地缓存，设计在应用服务器中（tomcat）。 通常可以采用Ehcache和Guava Cache，在互联网应用中，由于要处理高并发，通常选择Guava Cache。</p>
<p>适用本地（JVM）缓存的场景：</p>
<p>1、对性能有非常高的要求。</p>
<p>2、不经常变化</p>
<p>3、占用内存不大</p>
<p>4、有访问整个集合的需求</p>
<p>5、数据允许不时时一致</p>
<h3 id="文件缓存"><a href="#文件缓存" class="headerlink" title="文件缓存"></a><strong>文件缓存</strong></h3><p>这里的文件缓存是基于http协议的文件缓存，一般放在nginx中。</p>
<p>静态文件（比如css，js， 图片）中，很多都是不经常更新的。nginx使用proxy_cache将用户的请 求缓存到本地一个目录。下一个相同请求可以直接调取缓存文件，就不用去请求服务器了。</p>
<h3 id="Redis缓存"><a href="#Redis缓存" class="headerlink" title="Redis缓存"></a><strong>Redis缓存</strong></h3><p>Redis采用的是基于内存的采用的是单进程单线程模型的 KV 数据库，由C语言编写，官方提供的数据是可以达到110000+的QPS（每秒内查询次数）。80000的写</p>
<p>分布式缓存，采用主从+哨兵或RedisCluster的方式缓存数据库的数据。 在实际开发中作为数据库使用，数据要完整 作为缓存使用，作为Mybatis的二级缓存使用</p>
<p><strong>缓存大小设置</strong></p>
<p>GuavaCache的缓存设置方式:</p>
<p>CacheBuilder.newBuilder().maximumSize(num) &#x2F;&#x2F; 超过num会按照LRU算法来移除缓存</p>
<p>Nginx的缓存设置方式：</p>
<p>http { …</p>
<p>proxy_cache_path &#x2F;path&#x2F;to&#x2F;cache levels&#x3D;1:2 keys_zone&#x3D;my_cache:10m max_size&#x3D;10g inactive&#x3D;60m use_temp_path&#x3D;off;</p>
<p>server { proxy_cache mycache;</p>
<p>location &#x2F; { proxy_pass <a href="http://localhost:8000/">http://localhost:8000</a>; }</p>
<p>}</p>
<p>}</p>
<p>Redis缓存设置：</p>
<p>maxmemory&#x3D;num # 最大缓存量 一般为内存的3&#x2F;4</p>
<p>maxmemory-policy allkeys lru #</p>
<p>key数量：一个key或是value大小最大是512M</p>
<p><strong>命中率</strong></p>
<p>1、缓存的数量越少命中率越高，比如缓存单个对象的命中率要高于缓存集合</p>
<p>2、过期时间越长命中率越高</p>
<p>3、缓存越大缓存的对象越多，则命中的越多</p>
<p><strong>过期策略</strong></p>
<p>Redis的过期策略是定时删除+惰性删除</p>
<p><strong>缓存预热</strong></p>
<p>缓存预热就是系统启动前,提前将相关的缓存数据直接加载到缓存系统。避免在用户请求的时候,先查询 数据库,然后再将数据缓存的问题!用户直接查询实现被预热的缓存数据。</p>
<p>加载缓存思路： 数据量不大，可以在项目启动的时候自动进行加载 利用定时任务刷新缓存，将数据库的数据刷新到缓存中</p>
<h3 id="缓存问题之缓存穿透"><a href="#缓存问题之缓存穿透" class="headerlink" title="缓存问题之缓存穿透"></a><strong>缓存问题之缓存穿透</strong></h3><p>一般的缓存系统，都是按照key去缓存查询，如果不存在对应的value，就应该去后端系统查找（比如 DB）。 缓存穿透是指在高并发下查询key不存在的数据（不存在的key），会穿过缓存查询数据库。导致数据库 压力过大而宕机。</p>
<p>解决方案：</p>
<p>对查询结果为空的情况也进行缓存，缓存时间（ttl）设置短一点，或者该key对应的数据insert了之后清理缓存。 问题：缓存太多空值占用了更多的空间</p>
<p>使用布隆过滤器。在缓存之前在加一层布隆过滤器，在查询的时候先去布隆过滤器查询 key 是否存在，如果不存在就直接返回，存在再查缓存和DB。</p>
<p>布隆过滤器的原理：当一个元素被加入集合时，通过K个Hash函数将这个元素映射成一个数组中的K 个点，把它们置为1。检索时，我们只要看看这些点是不是都是1就（大约）知道集合中有没有它了：如果这些点有任何一个0，则被检元素一定不在；如果都是1，则被检元素很可能在。多个K是为了避免hash碰撞。</p>
<h3 id="缓存问题之缓存雪崩"><a href="#缓存问题之缓存雪崩" class="headerlink" title="缓存问题之缓存雪崩"></a><strong>缓存问题之缓存雪崩</strong></h3><p>当缓存服务器重启或者大量缓存集中在某一个时间段失效，这样在失效的时候，也会给后端系统(比如 DB)带来很大压力。 突然间大量的key失效了或redis重启，大量访问数据库，数据库崩溃</p>
<p>解决方案:</p>
<p>1、key的失效期分散开不同的key设置不同的有效期</p>
<p>2、设置二级缓存（数据不一定一致）</p>
<p>3、高可用（脏读）</p>
<h3 id="缓存问题之缓存击穿"><a href="#缓存问题之缓存击穿" class="headerlink" title="缓存问题之缓存击穿"></a><strong>缓存问题之缓存击穿</strong></h3><p>对于一些设置了过期时间的key，如果这些key可能会在某些时间点被超高并发地访问，是一种非常“热 点”的数据。</p>
<p>缓存在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，这些请求发现缓 存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。</p>
<p>解决方案：</p>
<p>1、用分布式锁控制访问的线程 使用redis的setnx互斥锁先进行判断，这样其他线程就处于等待状态，保证不会有大并发操作去操作数 据库。</p>
<p>2、不设超时时间，volatile-lru 但会造成写一致问题</p>
<p>当数据库数据发生更新时，缓存中的数据不会及时更新，这样会造成数据库中的数据与缓存中的数据的 不一致，应用会从缓存中读取到脏数据。可采用延时双删策略处理。</p>
<h3 id="缓存问题之数据不一致"><a href="#缓存问题之数据不一致" class="headerlink" title="缓存问题之数据不一致"></a><strong>缓存问题之数据不一致</strong></h3><p>缓存和DB的数据不一致的根源 ： 数据源不一样，强一致性很难，追求最终一致性（时间）。</p>
<p>保证数据的最终一致性(延时双删)</p>
<p>1、先更新数据库同时删除缓存项(key)，等读的时候再填充缓存</p>
<p>2、2秒后再删除一次缓存项(key)</p>
<p>3、设置缓存过期时间 Expired Time 比如 10秒 或1小时</p>
<p>4、将缓存删除失败记录到日志中，利用脚本提取失败记录再次删除（缓存失效期过长 7*24）</p>
<h3 id="缓存问题之数据并发竞争"><a href="#缓存问题之数据并发竞争" class="headerlink" title="缓存问题之数据并发竞争"></a><strong>缓存问题之数据并发竞争</strong></h3><p>这里的并发指的是多个redis的client同时set 同一个key引起的并发问题。多客户端（Jedis）同时并发写一个key，一个key的值是1，本来按顺序修改为2,3,4，最后是4，但是顺序变成了4,3,2，最后变成了2。</p>
<p><strong>第一种方案：分布式锁+时间戳</strong></p>
<p>准备一个分布式锁，大家去抢锁，抢到锁就做set操作。加锁的目的实际上就是把并行读写改成串行读写的方式，从而来避免资源竞争。</p>
<p>.Redis分布式锁的实现：主要用到的redis函数是setnx() ，通过SETNX实现分布式锁</p>
<p><img src="/posts/40341/asset/v2-2acdca04bdd468bbfec486daca1fa81e_720w.webp" alt="img"></p>
<p><strong>第二种方案：利用消息队列</strong></p>
<p>在并发量过大的情况下,可以通过消息中间件进行处理,把并行读写进行串行化。 把Redis的set操作放在队列中使其串行化,必须的一个一个执行。</p>
<p><strong>Hot Key</strong></p>
<p>当有大量的请求(几十万)访问某个Redis某个key时，由于流量集中达到网络上限，从而导致这个redis的 服务器宕机。造成缓存击穿，接下来对这个key的访问将直接访问数据库造成数据库崩溃，或者访问数 据库回填Redis再访问Redis，继续崩溃。</p>
<p>如何发现热key</p>
<p>1、预估热key，比如秒杀的商品、火爆的新闻等</p>
<p>2、在客户端进行统计，实现简单，加一行代码即可</p>
<p>3、如果是Proxy，比如Codis，可以在Proxy端收集</p>
<p>4、利用Redis自带的命令，monitor、hotkeys。但是执行缓慢（不要用）</p>
<p>5、利用基于大数据领域的流式计算技术来进行实时数据访问次数的统计，比如 Storm、Spark Streaming、Flink，这些技术都是可以的。发现热点数据后可以写到zookeeper中。</p>
<p>如何处理热Key：</p>
<p>1、变分布式缓存为本地缓存 发现热key后，把缓存数据取出后，直接加载到本地缓存中。可以采用Ehcache、Guava Cache都可以，这样系统在访问热key数据时就可以直接访问自己的缓存了。（数据不要求时时一致）</p>
<p>2、在每个Redis主节点上备份热key数据，这样在读取时可以采用随机读取的方式，将访问压力负载到 每个Redis上。</p>
<p>3、利用对热点数据访问的限流熔断保护措施，每个系统实例每秒最多请求缓存集群读操作不超过 400 次，一超过就可以熔断掉，不让请求缓存集群，直接返回一个空白信息，然后用户稍后会自行再次重新刷新页面之类的。</p>
<p><strong>Big Key</strong></p>
<p>大key指的是存储的值（Value）非常大，比如热门话题下的讨论 大V的粉丝列表 序列化后的图片等等</p>
<p>造成的问题：</p>
<p>大key会大量占用内存，在集群中无法均衡</p>
<p>Redis的性能下降，主从复制异常</p>
<p>在主动删除或过期删除时会操作时间过长而引起服务阻塞</p>
<p>解决办法</p>
<p>1、 string类型的big key，尽量不要存入Redis中，可以使用文档型数据库MongoDB或缓存到CDN上。</p>
<p>2、 hash， set，zset，list 中存储过多的元素，可以将这些元素分拆。</p>
<p>3、 使用 lazy delete(unlink命令)删除，该命令会在另一个线程中 回收内存，因此它是非阻塞的。</p>
<h3 id="缓存与数据库的一致性"><a href="#缓存与数据库的一致性" class="headerlink" title="缓存与数据库的一致性"></a><strong>缓存与数据库的一致性</strong></h3><p><strong>缓存更新策略</strong></p>
<p>利用Redis的缓存淘汰策略被动更新 LRU 、LFU</p>
<p>利用TTL被动更新</p>
<p>在更新数据库时主动更新 （先更数据库再删缓存—-延时双删）</p>
<p>异步更新 定时任务 数据不保证时时一致 不穿DB</p>
<p><img src="/posts/40341/asset/v2-8eafee9abd23a6e9dbe25d84172b642a_720w.webp" alt="img"></p>
<h3 id="Redis乐观锁"><a href="#Redis乐观锁" class="headerlink" title="Redis乐观锁"></a><strong>Redis乐观锁</strong></h3><p><strong>利用Watch实现Redis乐观锁</strong></p>
<p>乐观锁基于CAS（Compare And Swap）思想（比较并替换），是不具有互斥性，不会产生锁等待而消 耗资源，但是需要反复的重试，但也是因为重试的机制，能比较快的响应。</p>
<p>1、利用redis的watch功能，监控这个redisKey的状态值</p>
<p>2、获取redisKey的值</p>
<p>3、创建redis事务</p>
<p>4、给这个key的值+1</p>
<p>5、然后去执行这个事务，如果key的值被修改过则回滚，key不加1</p>
<h3 id="Redis分布式锁"><a href="#Redis分布式锁" class="headerlink" title="Redis分布式锁"></a><strong>Redis分布式锁</strong></h3><p><strong>Setnx</strong></p>
<p>共享资源互斥</p>
<p>共享资源串行化</p>
<p>单应用中使用锁：（单进程多线程） synchronized、ReentrantLock</p>
<p>分布式应用中使用锁：（多进程多线程）。 利用Redis的单线程特性对共享资源进行串行化处理。</p>
<p>方式1（使用set命令实现）–推荐</p>
<p><img src="/posts/40341/asset/v2-524bfcb90bd5a24e1ecf9ac241b357f9_720w.webp" alt="img"></p>
<p>方式2（使用setnx命令实现） – 并发会产生问题</p>
<p><img src="/posts/40341/asset/v2-c67fea0bc85aff7630a4ac49d6c09fa2_720w.webp" alt="img"></p>
<p>释放锁 方式1（del命令实现） – 并发</p>
<p><img src="/posts/40341/asset/v2-177c62b3c565230cedf1fa0e2a6ac2a6_720w.webp" alt="img"></p>
<p>释放锁 方式2（redis+lua脚本实现）–推荐</p>
<p><img src="/posts/40341/asset/v2-e8c96fb5d3de6ec5a022ba57ecab0a54_720w.webp" alt="img"></p>
<p>分布式锁是CP模型，Redis集群是AP模型。 (base) Redis集群不能保证数据的随时一致性，只能保证数据的最终一致性。</p>
<p>为什么还可以用Redis实现分布式锁？</p>
<p>与业务有关 当业务不需要数据强一致性时，比如：社交场景，就可以使用Redis实现分布式锁 当业务必须要数据的强一致性，即不允许重复获得锁，比如金融场景（重复下单，重复转账）就不要使用 可以使用CP模型实现，比如：zookeeper和etcd。</p>
<p><strong>Redisson分布式锁的实现原理</strong></p>
<p>如果该客户端面对的是一个redis cluster集群，他首先会根据hash节点选择一台机器。 发送lua脚本到redis服务器上。</p>
<p>那么在这个时候，如果客户端2来尝试加锁，第一个if判断会执行“exists myLock”，发现myLock这个锁key已经存在了。 接着第二个if判断，判断一下，myLock锁key的hash数据结构中，是否包含客户端2的ID，但是明显不 是的，因为那里包含的是客户端1的ID。此时客户端2会进入一个while循环，不停的尝试加锁。只要客户端1一旦加锁成功，就会启动一个watch dog看门狗，他是一个后台线程，会每隔10秒检查一 下，如果客户端1还持有锁key，那么就会不断的延长锁key的生存时间。</p>
<p><img src="https://pic1.zhimg.com/80/v2-11bf38cb188d27ace6d32cf6d3d3e13c_720w.webp" alt="img"></p>
<p><strong>分布式锁特性</strong></p>
<p>互斥性</p>
<p>任意时刻，只能有一个客户端获取锁，不能同时有两个客户端获取到锁。</p>
<p>同一性</p>
<p>锁只能被持有该锁的客户端删除，不能由其它客户端删除。</p>
<p>可重入性</p>
<p>持有某个锁的客户端可继续对该锁加锁，实现锁的续租 容错性 锁失效后（超过生命周期）自动释放锁（key失效），其他客户端可以继续获得该锁，防止死锁</p>
<p><strong>Zookeeper分布式锁的对比</strong></p>
<p><img src="/posts/40341/asset/v2-d52d2cec402ca1e712ce3e383bac414b_720w.webp" alt="img"></p>
<h3 id="五、Redis高可用方案"><a href="#五、Redis高可用方案" class="headerlink" title="五、Redis高可用方案"></a><strong>五、Redis高可用方案</strong></h3><h3 id="主从复制及实战"><a href="#主从复制及实战" class="headerlink" title="主从复制及实战"></a><strong>主从复制及实战</strong></h3><p>“高可用性”（High Availability）通常来描述一个系统经过专门的设计，从而减少停工时间，而保持其服 务的高度可用性。CAP的A AP模型 单机的Redis是无法保证高可用性的，当Redis服务器宕机后，即使在有持久化的机制下也无法保证不丢失数据。所以我们采用Redis多机和集群的方式来保证Redis的高可用性。</p>
<p><img src="https://pic3.zhimg.com/80/v2-767852afa61c17958e81baeec19b045a_720w.webp" alt="img"></p>
<p><strong>主从配置</strong></p>
<p>主Redis配置无需配置</p>
<p>从Redis配置修改从服务器上的 redis.conf 文件：</p>
<p><img src="/posts/40341/asset/v2-5f6572bc2386e0a5a68e2511d0d67b1c_720w.webp" alt="img"></p>
<p>作用：读写分离、数据容灾</p>
<p>原理与实现：</p>
<p>保存主节点信息，然后slaver与master建立socket连接，slaver关联文件事件处理器，该处理器接收RDB文件（全量复制）、接收Master传播来的写命令（增量复制），Slaver向Master发送ping命令，Master的响应：发送“pong” , 说明正常，主从正常连接后，进行权限验证，在身份验证步骤之后，从服务器将执行命令REPLCONF listening-port ，向主服务器发送从服务器的监听端口号，然后开始同步数据，当同步数据完成后，主从服务器就会进入命令传播阶段，主服务器只要将自己执行的写命令发送给从服务器，而从服务器只要一直执行并接收主服务器发来的写命令。</p>
<p><strong>同步数据集</strong></p>
<p>在Redis 2.8之后使用PSYNC命令，具备完整重同步和部分重同步模式。 Redis 的主从同步，分为全量同步和增量同步。 只有从机第一次连接上主机是全量同步。断线重连有可能触发全量同步也有可能是增量同步（ master 判断 runid 是否一致）。除此之外的情况都是增量同步。</p>
<p>Redis 的全量同步过程主要分三个阶段：同步快照阶段、同步写缓冲阶段、同步增量阶段</p>
<p>增量同步：Redis增量同步主要指Slave完成初始化后开始正常工作时， Master 发生的写操作同步到 Slave 的 过程。 通常情况下，Master 每执行一个写命令就会向 Slave 发送相同的写命令，然后 Slave 接收并执行。</p>
<p><strong>心跳检测</strong></p>
<p>在命令传播阶段，从服务器默认会以每秒一次的频率向主服务器发送命令，进行心跳检测。</p>
<p>\1. 检测主从的连接状态</p>
<p>\2. 辅助实现min-slaves</p>
<p>\3. 检测命令丢失</p>
<p><strong>主从配置实战</strong></p>
<p>第一步：创建master主、salver从文件夹</p>
<p>mkdir redis-master</p>
<p>mkdir redis-slaver1</p>
<p>mkdir redis-slaver2</p>
<p><img src="/posts/40341/asset/v2-ccccdb2ca331473189ef1473841b80ad_720w.webp" alt="img"></p>
<p>第二步：进入redis安装目录安装redis</p>
<p>cd &#x2F;usr&#x2F;local&#x2F;redis-5.0.5&#x2F;src&#x2F;</p>
<p>make install PREFIX&#x3D;&#x2F;var&#x2F;redis-ms&#x2F;redis-master</p>
<p><img src="/posts/40341/asset/v2-d6ac3101f82e703efb51c0ff0d45fb48_720w.webp" alt="img"></p>
<p>第三步：拷贝redis.conf到master</p>
<p>cp &#x2F;usr&#x2F;local&#x2F;redis-5.0.5&#x2F;redis.conf &#x2F;var&#x2F;redis-ms&#x2F;redis-master&#x2F;bin</p>
<p><img src="https://pic3.zhimg.com/80/v2-506ecc88e8fa5f2d35ceda09390f0c62_720w.webp" alt="img"></p>
<p>第四步：编辑redis.conf</p>
<p>vim redis.conf</p>
<p># 将<code>daemonize</code>由<code>no</code>改为<code>yes</code> daemonize yes</p>
<p># bind 127.0.0.1</p>
<p># 是否开启保护模式，由yes该为no protected-mode no</p>
<p>第五步：把所有内容拷贝到从salver文件夹</p>
<p>cp -r &#x2F;var&#x2F;redis-ms&#x2F;redis-master&#x2F;* &#x2F;var&#x2F;redis-ms&#x2F;redis-slaver1cp -r &#x2F;var&#x2F;redis-ms&#x2F;redis-master&#x2F;* &#x2F;var&#x2F;redis-ms&#x2F;redis-slaver2</p>
<p>第六步：修改两从的redis.conf配置文件</p>
<p>cd &#x2F;var&#x2F;redis-ms&#x2F;redis-slaver1&#x2F;bin</p>
<p>vim redis.conf</p>
<p>#端口改为6380 6381</p>
<p>replicaof 127.0.0.1 6379 #添加这段配置，指定主服务器</p>
<p>第七步：启动所有主从节点</p>
<p>.&#x2F;redis-server redis.conf</p>
<p><img src="/posts/40341/asset/v2-af3ddf560077e29599d73532df042d8f_720w.webp" alt="img"></p>
<p><img src="/posts/40341/asset/v2-d0791b85f903d6d479684bf3a6e27088_720w.webp" alt="img"></p>
<p><img src="https://pic1.zhimg.com/80/v2-0eea50a9bfb4302dc70b6aa961e926b0_720w.webp" alt="img"></p>
<h3 id="哨兵模式及实战"><a href="#哨兵模式及实战" class="headerlink" title="哨兵模式及实战"></a><strong>哨兵模式及实战</strong></h3><p>哨兵（sentinel）是Redis的高可用性(High Availability)的解决方案： 由一个或多个sentinel实例组成sentinel集群可以监视一个或多个主服务器和多个从服务器。 当主服务器进入下线状态时，sentinel可以将该主服务器下的某一从服务器升级为主服务器继续提供服 务，从而保证redis的高可用性。</p>
<p><img src="https://pic3.zhimg.com/80/v2-ad84385c36c092d929f009c17d99d37e_720w.webp" alt="img"></p>
<p><strong>哨兵模式实战</strong></p>
<p>第一步：创建哨兵sentinel节点文件夹</p>
<p>mkdir redis-sentinel1</p>
<p>mkdir redis-sentinel2</p>
<p>mkdir redis-sentinel3</p>
<p><img src="https://pic1.zhimg.com/80/v2-952a042ed7eaefe765f884af71719544_720w.webp" alt="img"></p>
<p>第二步：拷贝redis到sentinel文件夹</p>
<p>cp -r &#x2F;var&#x2F;redis-ms&#x2F;redis-master&#x2F;* &#x2F;var&#x2F;redis-ms&#x2F;redis-sentinel1</p>
<p>cp -r &#x2F;var&#x2F;redis-ms&#x2F;redis-master&#x2F;* &#x2F;var&#x2F;redis-ms&#x2F;redis-sentinel2</p>
<p>cp -r &#x2F;var&#x2F;redis-ms&#x2F;redis-master&#x2F;* &#x2F;var&#x2F;redis-ms&#x2F;redis-sentinel2</p>
<p>第三步：拷贝sentinel.conf 配置文件并修改</p>
<p>cp &#x2F;usr&#x2F;local&#x2F;redis-5.0.5&#x2F;sentinel.conf &#x2F;var&#x2F;redis-ms&#x2F;redis-sentinel1&#x2F;bin&#x2F;</p>
<p>cp &#x2F;usr&#x2F;local&#x2F;redis-5.0.5&#x2F;sentinel.conf &#x2F;var&#x2F;redis-ms&#x2F;redis-sentinel2&#x2F;bin&#x2F;</p>
<p>cp &#x2F;usr&#x2F;local&#x2F;redis-5.0.5&#x2F;sentinel.conf &#x2F;var&#x2F;redis-ms&#x2F;redis-sentinel3&#x2F;bin&#x2F;</p>
<p><img src="/posts/40341/asset/v2-8009b7d83f7258e62842753be49814f8_720w.webp" alt="img"></p>
<p>vim sentinel.conf</p>
<p># 哨兵sentinel实例运行的端口 默认26379</p>
<p># 将<code>daemonize</code>由<code>no</code>改为<code>yes</code></p>
<p># 哨兵sentinel监控的redis主节点的 ip port</p>
<p># master-name 可以自己命名的主节点名字 只能由字母A-z、数字0-9 、这三个字符”.-_”组成。</p>
<p># quorum 当这些quorum个数sentinel哨兵认为master主节点失联 那么这时 客观上认为主节点失联了</p>
<p># sentinel monitor</p>
<p>sentinel monitor mymaster 127.0.0.1 6379 2</p>
<p># 当在Redis实例中开启了requirepass foobared 授权密码 这样所有连接Redis实例的客户端都要提 供密码</p>
<p># 设置哨兵sentinel 连接主从的密码 注意必须为主从设置一样的验证密码</p>
<p># sentinel auth-pass</p>
<p>sentinel auth-pass mymaster MySUPER–secret-0123passw0rd</p>
<p># 指定多少毫秒之后 主节点没有应答哨兵sentinel 此时 哨兵主观上认为主节点下线 默认30秒，改成3 秒</p>
<p># sentinel down-after-milliseconds</p>
<p>sentinel down-after-milliseconds mymaster 3000</p>
<p>第四步：依次启动redis主从客户端和哨兵sentinel客户端</p>
<p>Redis主从启动：.&#x2F;redis-server redis.conf</p>
<p>Sentinel哨兵服务启动：.&#x2F;redis-sentinel sentinel.conf</p>
<p><img src="/posts/40341/asset/v2-129116bc96129b6d1e2443ff12009f98_720w.webp" alt="img"></p>
<p><strong>检测原理</strong></p>
<p>获取主服务器信息：Sentinel默认每10s一次，向被监控的主服务器发送info命令，获取主服务器和其下属从服务器的信息。</p>
<p>获取从服务器信息：当Sentinel发现主服务器有新的从服务器出现时，Sentinel还会向从服务器建立命令连接和订阅连接。 在命令连接建立之后，Sentinel还是默认10s一次，向从服务器发送info命令，并记录从服务器的信息。</p>
<p>向主服务器和从服务器发送消息(以订阅的方式)：默认情况下，Sentinel每2s一次，向所有被监视的主服务器和从服务器所订阅的—sentinel—:hello频道 上发送消息，消息中会携带Sentinel自身的信息和主服务器的信息。</p>
<p>接收来自主服务器和从服务器的频道信息：当Sentinel与主服务器或者从服务器建立起订阅连接之后，Sentinel就会通过订阅连接，向服务器发送命令。</p>
<p>检测主观下线状态：Sentinel每秒一次向所有与它建立了命令连接的实例(主服务器、从服务器和其他Sentinel)发送PING命 令 实例在down-after-milliseconds毫秒内返回无效回复(除了+PONG、-LOADING、-MASTERDOWN外) 实例在down-after-milliseconds毫秒内无回复（超时） Sentinel就会认为该实例主观下线(SDown)。</p>
<p>检查客观下线状态：当一个Sentinel将一个主服务器判断为主观下线后 Sentinel会向同时监控这个主服务器的所有其他Sentinel发送查询命令判断它们是否也认为主服务器下线。如果达到Sentinel配置中的quorum数量的Sentinel实例都判断主服 务器为主观下线，则该主服务器就会被判定为客观下线(ODown)。</p>
<p><strong>故障转移</strong></p>
<p>选举Leader Sentinel：当一个主服务器被判定为客观下线后，监视这个主服务器的所有Sentinel会通过选举算法（raft），选 出一个Leader Sentinel去执行failover（故障转移）操作。</p>
<p>Raft协议是用来解决分布式系统一致性问题的协议。 Raft协议描述的节点共有三种状态：Leader, Follower, Candidate。</p>
<p>选举流程： Raft采用心跳机制触发Leader选举 系统启动后，全部节点初始化为Follower，term为0。节点如果收到了RequestVote或者AppendEntries，就会保持自己的Follower身份，节点如果一段时间内没收到AppendEntries消息，在该节点的超时时间内还没发现Leader，Follower就会转换成Candidate，自己开始竞选Leader。如果在计时器超时前，节点收到多数节点的同意投票，就转换成Leader。同时向所有其他节点发送 AppendEntries，告知自己成为了Leader。</p>
<p>当选举出Leader Sentinel后，Leader Sentinel会对下线的主服务器执行故障转移操作，主要有三个步骤：</p>
<p>\1. 它会将失效 Master 的其中一个 Slave 升级为新的 Master , 并让失效 Master 的其他 Slave 改为复制新的 Master ；</p>
<p>\2. 当客户端试图连接失效的 Master 时，集群也会向客户端返回Master的地址，使得集群可以使用现在的 Master 替换失效 Master 。</p>
<p>\3. Master和 Slave服务器切换后， Master的redis.conf 、 Slave的redis.conf 和 sentinel.conf 的配置文件的内容都会发生相应的改变，即Master 主服务器的 redis.conf 配置文件中会多一行replicaof的配置， sentinel.conf 的监控目标会随之调换。</p>
<p><strong>主服务器的选择</strong></p>
<p>\1. 过滤掉主观下线的节点</p>
<p>\2. 选择slave-priority最高的节点，如果由则返回没有就继续选择</p>
<p>\3. 选择出复制偏移量最大的系节点，因为复制偏移量越大则数据复制的越完整，如果由就返回了，没有就继续</p>
<p>\4. 选择run_id最小的节点，因为run_id越小说明重启次数越少</p>
<p><img src="https://pic1.zhimg.com/80/v2-6045599d2798ac5defe24c96b1e772b8_720w.webp" alt="img"></p>
<h3 id="集群和分区特性"><a href="#集群和分区特性" class="headerlink" title="集群和分区特性"></a><strong>集群和分区特性</strong></h3><p>分区是将数据分布在多个Redis实例（Redis主机）上，以至于每个实例只包含一部分数据。</p>
<p>分区的意义：</p>
<p>\1. 单机Redis的网络I&#x2F;O能力和计算资源是有限的，将请求分散到多台机器，充分利用多台机器的计算能力 可网络带宽，有助于提高Redis总体的服务能力。</p>
<p>\2. 即使Redis的服务能力能够满足应用需求，但是随着存储数据的增加，单台机器受限于机器本身的存储 容量，将数据分散到多台机器上存储使得Redis服务可以横向扩展。</p>
<p><strong>分区方式</strong></p>
<p>范围分区：实现简单，方便迁移和扩展，但是热点数据分布不均，性能损失</p>
<p><img src="/posts/40341/asset/v2-d1d92bb6d5ec09f6af043763ebfadfeb_720w.webp" alt="img"></p>
<p>Hash分区</p>
<p>利用简单的hash算法，支持任何类型的key 热点分布较均匀，性能较好，但是迁移复杂，需要重新计算，扩展较差，可以使用一致性hash环解决。</p>
<p><img src="/posts/40341/asset/v2-8db85a8b3eb179bbe8ff617bcd55e20b_720w.webp" alt="img"></p>
<h3 id="Client端分区"><a href="#Client端分区" class="headerlink" title="Client端分区"></a><strong>Client端分区</strong></h3><p>对于一个给定的key，客户端直接选择正确的节点来进行读写。许多Redis客户端都实现了客户端分区 (JedisPool)，也可以自行编程实现。</p>
<p>客户端选择算法：一致性hash</p>
<p>普通hash是对主机数量取模，而一致性hash是对2^32（4 294 967 296）取模。我们把2^32想象成一 个圆，就像钟表一样，钟表的圆可以理解成由60个点组成的圆，而此处我们把这个圆想象成由2^32个 点组成的圆，将缓存服务器与被缓存对象都映射到hash环上以后，从被缓存对象的位置出发，沿顺时针方向遇到的第 一个服务器，就是当前对象将要缓存于的服务器，由于被缓存对象与服务器hash后的值是固定的，所 以，在服务器不变的情况下，数据必定会被缓存到固定的服务器上，那么，当下次想要访问这个数据 时，只要再次使用相同的算法进行计算，即可算出这个数据被缓存在哪个服务器上，直接去对应的服务 器查找对应的数据即可。</p>
<p>优点：添加或移除节点时，数据只需要做部分的迁移，比如上图中把C服务器移除，则数据4迁移到服务器A 中，而其他的数据保持不变。并且通过虚拟节点可解决hash偏移量问题。</p>
<p>缺点 复杂度高 客户端需要自己处理数据路由、高可用、故障转移等问题，且不易扩展</p>
<h3 id="Proxy端分区"><a href="#Proxy端分区" class="headerlink" title="Proxy端分区"></a><strong>Proxy端分区</strong></h3><p>在客户端和服务器端引入一个代理或代理集群，客户端将命令发送到代理上，由代理根据算法，将命令 路由到相应的服务器上。常见的代理有Codis（豌豆荚）和TwemProxy（Twitter）。</p>
<p><strong>优点</strong></p>
<p>对客户端透明,与codis交互方式和redis本身交互一样</p>
<p>支持在线数据迁移,迁移过程对客户端透明有简单的管理和监控界面</p>
<p>支持高可用,无论是redis数据存储还是代理节点</p>
<p>自动进行数据的均衡分配</p>
<p>最大支持1024个redis实例,存储容量海量</p>
<p>高性能</p>
<p><strong>缺点</strong></p>
<p>采用自有的redis分支,不能与原版的redis保持同步</p>
<p>如果codis的proxy只有一个的情况下, redis的性能会下降20%左右</p>
<p>某些命令不支持</p>
<h3 id="官方RedisCluster分区"><a href="#官方RedisCluster分区" class="headerlink" title="官方RedisCluster分区"></a><strong>官方RedisCluster分区</strong></h3><p>Redis3.0之后，Redis官方提供了完整的集群解决方案。</p>
<p>方案采用去中心化的方式，包括：sharding（分区）、replication（复制）、failover（故障转移）。 称为RedisCluster。 Redis5.0前采用redis-trib进行集群的创建和管理，需要ruby支持 Redis5.0可以直接使用Redis-cli进行集群的创建和管理.</p>
<p><img src="/posts/40341/asset/v2-1cf87cd177f946bb5000e76ee711c051_720w.webp" alt="img"></p>
<p><strong>去中心化</strong></p>
<p>RedisCluster由多个Redis节点组构成，是一个P2P无中心节点的集群架构，依靠Gossip协议传播的集群。</p>
<p><strong>Gossip协议</strong></p>
<p>Gossip协议是一个通信协议，一种传播消息的方式。</p>
<p>通过gossip协议，cluster可以提供集群间状态同步更新、选举自助failover等重要的集群功能。</p>
<p><img src="/posts/40341/asset/v2-1db4a83b0bb5fb0efb0700323b8cdc61_720w.webp" alt="img"></p>
<p><strong>Slot</strong></p>
<p>redis-cluster把所有的物理节点映射到[0-16383]个slot上,基本上采用平均分配和连续分配的方式。</p>
<p><img src="/posts/40341/asset/v2-c563aafc319066062773abc8b8ad3d78_720w.webp" alt="img"></p>
<p>当需要在 Redis 集群中放置一个 key-value 时，redis 先对 key 使用 crc16 算法算出一个结果，然后把 结果对 16384 求余数，这样每个 key 都会对应一个编号在 0-16383 之间的哈希槽，redis 会根据节点数 量大致均等的将哈希槽映射到不同的节点。</p>
<p><strong>RedisCluster的优势</strong></p>
<p>\1. 高性能 Redis Cluster 的性能与单节点部署是同级别的。 多主节点、负载均衡、读写分离</p>
<p>\2. 高可用 Redis Cluster 支持标准的 主从复制配置来保障高可用和高可靠。 failover Redis Cluster 也实现了一个类似 Raft 的共识方式，来保障整个集群的可用性。</p>
<p>\3. 易扩展 向 Redis Cluster 中添加新节点，或者移除节点，都是透明的，不需要停机。 水平、垂直方向都非常容易扩展。 数据分区，海量数据，数据存储</p>
<p>\4. 原生 部署 Redis Cluster 不需要其他的代理或者工具，而且 Redis Cluster 和单机 Redis 几乎完全兼 容。</p>
<h3 id="RedisCluster集群搭建实战"><a href="#RedisCluster集群搭建实战" class="headerlink" title="RedisCluster集群搭建实战"></a><strong>RedisCluster集群搭建实战</strong></h3><p>RedisCluster最少需要三台主服务器，三台从服务器。</p>
<p>第一步：创建相应集群目录文件夹，端口号7001-7006</p>
<p>mkdir redis-cluster</p>
<p>mkdir 7001</p>
<p>mkdir 7002</p>
<p>mkdir 7003</p>
<p>mkdir 7004</p>
<p>mkdir 7005</p>
<p>mkdir 7006</p>
<p><img src="/posts/40341/asset/v2-9cf434585c0245b49b986f5f04d32fcf_720w.webp" alt="img"></p>
<p>第二步：进入redis安装目录，给所有端口号文件夹安装redis</p>
<p>cd redis-5.0.5&#x2F;src&#x2F;</p>
<p>make install PREFIX&#x3D;&#x2F;usr&#x2F;local&#x2F;redis-cluster&#x2F;7001</p>
<p><img src="/posts/40341/asset/v2-38418a9d80751b18acc5f24f0d00bee7_720w.webp" alt="img"></p>
<p>第三步：拷贝redis.conf到7001安装目录下</p>
<p>cp &#x2F;usr&#x2F;local&#x2F;redis-5.0.5&#x2F;redis.conf &#x2F;usr&#x2F;local&#x2F;redis-cluster&#x2F;7001&#x2F;bin</p>
<p><img src="https://pic3.zhimg.com/80/v2-5f74eeba3506caf607b1dfc5acb5d0be_720w.webp" alt="img"></p>
<p>第四步：修改redis.conf</p>
<p>vim redis.conf</p>
<p># bind 127.0.0.1 屏蔽127端口</p>
<p>#将<code>daemonize</code>由<code>no</code>改为<code>yes</code> daemonize yes</p>
<p>#是否开启保护模式，由yes该为no protected-mode no</p>
<p>#端口port改为7001</p>
<p>#打开cluster-enable yes</p>
<p><img src="/posts/40341/asset/v2-1041d81d71d342fead2bb2de58d22104_720w.webp" alt="img"></p>
<p>第五步：把redis.conf复制到其他节点并更改相应端口号</p>
<p>cp -r &#x2F;usr&#x2F;local&#x2F;redis-cluster&#x2F;7001&#x2F;* &#x2F;usr&#x2F;local&#x2F;redis-cluster&#x2F;7002</p>
<p>cp -r &#x2F;usr&#x2F;local&#x2F;redis-cluster&#x2F;7001&#x2F;* &#x2F;usr&#x2F;local&#x2F;redis-cluster&#x2F;7003</p>
<p>cp -r &#x2F;usr&#x2F;local&#x2F;redis-cluster&#x2F;7001&#x2F;* &#x2F;usr&#x2F;local&#x2F;redis-cluster&#x2F;7004</p>
<p>cp -r &#x2F;usr&#x2F;local&#x2F;redis-cluster&#x2F;7001&#x2F;* &#x2F;usr&#x2F;local&#x2F;redis-cluster&#x2F;7005</p>
<p>cp -r &#x2F;usr&#x2F;local&#x2F;redis-cluster&#x2F;7001&#x2F;* &#x2F;usr&#x2F;local&#x2F;redis-cluster&#x2F;7006</p>
<p>vim 7002&#x2F;bin&#x2F;redis.conf</p>
<p>第六步：创建start.sh批处理，启动所有的实例</p>
<p>cd 7001&#x2F;bin</p>
<p>.&#x2F;redis-server redis.conf</p>
<p>cd ..</p>
<p>cd ..</p>
<p>cd 7002&#x2F;bin</p>
<p>.&#x2F;redis-server redis.conf</p>
<p>cd ..</p>
<p>cd ..</p>
<p>cd 7003&#x2F;bin</p>
<p>.&#x2F;redis-server redis.conf</p>
<p>cd ..</p>
<p>cd ..</p>
<p>cd 7004&#x2F;bin</p>
<p>.&#x2F;redis-server redis.conf</p>
<p>cd ..</p>
<p>cd ..</p>
<p>cd 7005&#x2F;bin</p>
<p>.&#x2F;redis-server redis.conf</p>
<p>cd ..</p>
<p>cd ..</p>
<p>cd 7006&#x2F;bin</p>
<p>.&#x2F;redis-server redis.conf</p>
<p>cd ..</p>
<p>cd ..</p>
<p>第七步：执行赋写和执行的权限并启动RedisCluster</p>
<p>chmod u+x start.sh</p>
<p><img src="/posts/40341/asset/v2-a7199c1a2ca867ba36827ab386a872d6_720w.webp" alt="img"></p>
<p>.&#x2F;start.sh</p>
<p><img src="https://pic3.zhimg.com/80/v2-f64d79a82cf476a0047442bcd1a29682_720w.webp" alt="img"></p>
<p>第八步：创建Redis集群（创建时Redis里不要有数据）</p>
<p>.&#x2F;redis-cli –cluster create 47.106.138.46:7001 47.106.138.46:7002 47.106.138.46:7003 47.106.138.46:7004 47.106.138.46:7005 47.106.138.46:7006 –cluster-replicas 1</p>
<p>#–cluster create 集群创建</p>
<p>#做三主三从 前面三个ip做主 后面三个ip做从 采用物理IP地址</p>
<p>#–cluster-replicas 1 说明备份一份 也就是一主一从 如果一主两从则数字为2 三主IP后面要跟六从IP</p>
<p><img src="/posts/40341/asset/v2-c47ba9deaa0a586d157c3cab8e7268e9_720w.webp" alt="img"></p>
<p>cat nodes.conf #查看集群节点</p>
<p><img src="/posts/40341/asset/v2-e9c06a38b25227270c74f126a4e29797_720w.webp" alt="img"></p>
<p>第九步：命令客户端连接集</p>
<p>.&#x2F;redis-cli -h 127.0.0.1 -p 7001 -c</p>
<p>cluster nodes</p>
<p><img src="/posts/40341/asset/v2-cdb5d888b56fbed73d5c650164b2321e_720w.webp" alt="img"></p>
<p><img src="/posts/40341/asset/v2-c116ffc24a2c0c2a08cc91d32f297ce9_720w.webp" alt="img"></p>
<p><img src="https://pic3.zhimg.com/80/v2-5d50b23c0d76a5a2ba4d48ce04c0298a_720w.webp" alt="img"></p>
<p><strong>Redis集群扩容实战</strong></p>
<p>第一步：创建新增节点文件夹，并安装redis</p>
<p>mkdir 7007</p>
<p>cd redis-5.0.5&#x2F;src&#x2F;</p>
<p>make install PREFIX&#x3D;&#x2F;usr&#x2F;local&#x2F;redis-cluster&#x2F;7007</p>
<p>cp &#x2F;usr&#x2F;local&#x2F;redis-5.0.5&#x2F;redis.conf &#x2F;usr&#x2F;local&#x2F;redis-cluster&#x2F;7007&#x2F;bin</p>
<p>第二步：修改redis.conf配置文件</p>
<p>vim redis.conf</p>
<p># bind 127.0.0.1 屏蔽127端口</p>
<p>#将<code>daemonize</code>由<code>no</code>改为<code>yes</code> daemonize yes</p>
<p>#是否开启保护模式，由yes该为no protected-mode no</p>
<p>#端口port改为7007</p>
<p>#打开cluster-enable yes</p>
<p>第四步：拷贝至7008修改端口并启动7007客户端</p>
<p>cp -r 7007 7008</p>
<p>.&#x2F;redis-server redis.conf</p>
<p><img src="/posts/40341/asset/v2-fdcf2ae064e13e14cd7359fc76054173_720w.webp" alt="img"></p>
<p>第五步：添加7007结点作为新节点</p>
<p>.&#x2F;redis-cli –cluster add-node 47.106.138.46:7007 47.106.138.46:7001</p>
<p><img src="/posts/40341/asset/v2-070684640d7f3167625c06762321ba75_720w.webp" alt="img"></p>
<p>第六步：hash槽重新分配（数据迁移）</p>
<p>.&#x2F;redis-cli –cluster reshard 47.106.138.46:7007</p>
<p>#输入要分配的槽数量</p>
<p>How many slots do you want to move (from 1 to 16384)? 2000</p>
<p>#输入接收槽的结点id</p>
<p>What is the receiving node ID?</p>
<p>#输入源结点id 也就是那些节点分槽给新节点</p>
<p>Please enter all the source node IDs.</p>
<p>Type ‘all’ to use all the nodes as source nodes for the hash slots. #全部分</p>
<p>Type ‘done’ once you entered all the source nodes IDs.#指定ID</p>
<p>第七步：启动7008从节点并添加进集群</p>
<p>.&#x2F;redis-server redis.conf</p>
<p>#.&#x2F;redis-cli –cluster add-node 新节点的ip和端口 旧节点ip和端口</p>
<p>#–cluster-slave – cluster-master-id 主节点id</p>
<p>.&#x2F;redis-cli –cluster add-node 47.106.138.46:7008 47.106.138.46:7007 –cluster-slave –cluster-master-id f3852ca45a0995b9a02488dbd2672aa1bbe93b55</p>
<p><img src="https://pic4.zhimg.com/80/v2-a54e5081fa0ebef312b83ca688849d6f_720w.webp" alt="img"></p>
<h3 id="分区路由"><a href="#分区路由" class="headerlink" title="分区路由"></a><strong>分区路由</strong></h3><p>不同节点分组服务于相互无交集的分片（sharding），Redis Cluster 不存在单独的proxy或配置服务 器，所以需要将客户端路由到目标的分片。</p>
<p><strong>客户端路由</strong></p>
<p>Redis Cluster的客户端相比单机Redis 需要具备路由语义的识别能力，且具备一定的路由缓存能力。</p>
<p><strong>moved重定向</strong></p>
<p>1.每个节点通过通信都会共享Redis Cluster中槽和集群中对应节点的关系</p>
<p>2.客户端向Redis Cluster的任意节点发送命令，接收命令的节点会根据CRC16规则进行hash运算与 16384取余，计算自己的槽和对应节点</p>
<p>3.如果保存数据的槽被分配给当前节点，则去槽中执行命令，并把命令执行结果返回给客户端</p>
<p>4.如果保存数据的槽不在当前节点的管理范围内，则向客户端返回moved重定向异常</p>
<p>5.客户端接收到节点返回的结果，如果是moved异常，则从moved异常中获取目标节点的信息</p>
<p>6.客户端向目标节点发送命令，获取命令执行结果</p>
<p><img src="/posts/40341/asset/v2-a77d1361a0d83dc769c33a700a551010_720w.webp" alt="img"></p>
<p><strong>ask重定向</strong></p>
<p>在对集群进行扩容和缩容时，需要对槽及槽中数据进行迁移 当客户端向某个节点发送命令，节点向客户端返回moved异常，告诉客户端数据对应的槽的节点信息 如果此时正在进行集群扩展或者缩空操作，当客户端向正确的节点发送命令时，槽及槽中数据已经被迁 移到别的节点了，就会返回ask，这就是ask重定向机制</p>
<p>1.客户端向目标节点发送命令，目标节点中的槽已经迁移支别的节点上了，此时目标节点会返回ask转 向给客户端 2.客户端向新的节点发送Asking命令给新的节点，然后再次向新节点发送命令</p>
<p>3.新节点执行命令，把命令执行结果返回给客户端</p>
<p><img src="https://pic4.zhimg.com/80/v2-7d8473b3427aed33888bd2d413d47b0b_720w.webp" alt="img"></p>
<p><strong>moved和ask的区别</strong></p>
<p>1、moved：槽已确认转移</p>
<p>2、ask：槽还在转移过程中</p>
<h3 id="节点添加"><a href="#节点添加" class="headerlink" title="节点添加"></a><strong>节点添加</strong></h3><p>在RedisCluster中每个slot 对应的节点在初始化后就是确定的。在某些情况下，节点和分片需要变更：</p>
<p>1.新的节点作为master加入；</p>
<p>2.某个节点分组需要下线；</p>
<p>3.负载不均衡需要调整slot 分布。</p>
<p>此时需要进行分片的迁移，迁移的触发和过程控制由外部系统完成。包含下面 2 种：</p>
<p>1.节点迁移状态设置：迁移前标记源&#x2F;目标节点。</p>
<p>2.key迁移的原子化命令：迁移的具体步骤。</p>
<p><img src="https://pic2.zhimg.com/80/v2-3661a2b06a78368064008a4adbb1a2d1_720w.webp" alt="img"></p>
<p>1、向节点B发送状态变更命令，将B的对应slot 状态置为importing。</p>
<p>2、向节点A发送状态变更命令，将A对应的slot 状态置为migrating。</p>
<p>3、向A 发送migrate 命令，告知A 将要迁移的slot对应的key 迁移到B。</p>
<p>4、当所有key 迁移完成后，cluster setslot 重新设置槽位。</p>
<p><strong>扩容实战</strong></p>
<h3 id="集群容灾"><a href="#集群容灾" class="headerlink" title="集群容灾"></a><strong>集群容灾</strong></h3><p><strong>故障检测</strong></p>
<p>集群中的每个节点都会定期地（每秒）向集群中的其他节点发送PING消息 如果在一定时间内(cluster-node-timeout)，发送ping的节点A没有收到某节点B的pong回应，则A将B 标识为pfail。 A在后续发送ping时，会带上B的pfail信息， 通知给其他节点。 如果B被标记为pfail的个数大于集群主节点个数的一半（N&#x2F;2 + 1）时，B会被标记为fail，A向整个集群 广播，该节点已经下线。 其他节点收到广播，标记B为fail。</p>
<p><strong>从节点选举</strong></p>
<p>raft，每个从节点，都根据自己对master复制数据的offset，来设置一个选举时间，offset越大（复制数据越多）的从节点，选举时间越靠前，优先进行选举。</p>
<p><strong>变更通知</strong></p>
<p>当slave 收到过半的master 同意时，会成为新的master。此时会以最新的Epoch 通过PONG 消息广播 自己成为master，让Cluster 的其他节点尽快的更新拓扑结构(node.conf)。</p>
<p><strong>副本漂移</strong></p>
<p>在一主一从的情况下，如果主从同时挂了，那整个集群就挂了，Redis提供了一种方法叫副本漂移，这种方法既能提高集群的可靠性又不用增加太多的从机。</p>
<p><img src="/posts/40341/asset/v2-1076f20417141fb682d70900e832297d_720w.webp" alt="img"></p>
<p>Master1宕机，则Slaver11提升为新的Master1 集群检测到新的Master1是单点的（无从机），集群从拥有最多的从机的节点组（Master3）中，选择节点名称字母顺序最小的从机（Slaver31）漂移 到单点的主从节点组(Master1)。</p>
]]></content>
      <categories>
        <category>基础知识</category>
        <category>redis</category>
      </categories>
      <tags>
        <tag>基础知识</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title>spring框架知识</title>
    <url>/posts/30508/</url>
    <content><![CDATA[<h2 id="一、Spring框架基础知识"><a href="#一、Spring框架基础知识" class="headerlink" title="一、Spring框架基础知识"></a>一、Spring框架基础知识</h2><h3 id="Spring的优势"><a href="#Spring的优势" class="headerlink" title="Spring的优势"></a>Spring的优势</h3><p>1.方便解耦，简化开发：通过spring的ioc容器，将对象间的依赖关系交由Spring进⾏控制，避免硬编码所造成的</p>
<p>过度程序耦合，⽤户也不必再为单例模式类、属性⽂件解析等这些很底层的需求编写代码，可以更专注于上层的应⽤。</p>
<p>\2. AOP编程的⽀持: 通过Spring的AOP功能，⽅便进⾏⾯向切⾯的编程，许多不容易⽤传统OOP实现的功能可以通过</p>
<p>AOP轻松应付。</p>
<p>3.声明式事务的支持：@Transactional 可以将我们从单调烦闷的事务管理代码中解脱出来，通过声明式⽅式灵活的进⾏事务的管理，提⾼开发效率和质量。</p>
<p>4.方便程序的测试</p>
<p>5.方便集成各种框架</p>
<p>6.降低Javaee api的使用难度</p>
<h3 id="Spring的核心结构"><a href="#Spring的核心结构" class="headerlink" title="Spring的核心结构"></a>Spring的核心结构</h3><p>数据处理模块、web模块、aop模块、core container模块、test模块</p>
<p>\1. Spring核⼼容器（Core Container） 容器是Spring框架最核⼼的部分，它管理着Spring应⽤中</p>
<p>bean的创建、配置和管理。在该模块中，包括了Spring bean⼯⼚，它为Spring提供了DI的功能。</p>
<p>基于bean⼯⼚，我们还会发现有多种Spring应⽤上下⽂的实现。所有的Spring模块都构建于核⼼容器之上。</p>
<p>\2. ⾯向切⾯编程（AOP）&#x2F;Aspects Spring对⾯向切⾯编程提供了丰富的⽀持。这个模块是Spring应⽤系统中开发切⾯的基础，与DI⼀样，AOP可以帮助应⽤对象解耦。</p>
<p>\3. 数据访问与集成（Data Access&#x2F;Integration）</p>
<p>Spring的JDBC和DAO模块封装了⼤量样板代码，这样可以使得数据库代码变得简洁，也可以更专注于我们的业务，还可以避免数据库资源释放失败⽽引起的问题。 另外，Spring AOP为数据访问提供了事务管理服务，同时Spring还对ORM进⾏了集成，如Hibernate、MyBatis等。该模块由JDBC、Transactions、ORM、OXM 和 JMS 等模块组成。</p>
<p>\4. Web 该模块提供了SpringMVC框架给Web应⽤，还提供了多种构建和其它应⽤交互的远程调⽤⽅案。 SpringMVC框架在Web层提升了应⽤的松耦合⽔平。</p>
<p>\5. Test 为了使得开发者能够很⽅便的进⾏测试，Spring提供了测试模块以致⼒于Spring应⽤的测试。 通过该模块，Spring为使⽤Servlet、JNDI等编写单元测试提供了⼀系列的mock对象实现。</p>
<h3 id="什么是IOC"><a href="#什么是IOC" class="headerlink" title="什么是IOC"></a>什么是IOC</h3><p>控制反转&#x2F;反转控制：控制指的是对象的创建、管理、实例化权利，反转指的是控制权交给了外部容器Spring框架。Ioc容器</p>
<p>具体实现：我们不⽤⾃⼰去new对象了，⽽是由IoC容器（Spring框架）去帮助我们实例化对象并且管理它，我们需要使⽤哪个对象，去问IoC容器要即可，而传统开发需要通过new对象来获取，依赖性强，通过IOC解决了对象之前的耦合问题。</p>
<h3 id="IOC和DI的区别"><a href="#IOC和DI的区别" class="headerlink" title="IOC和DI的区别"></a>IOC和DI的区别</h3><p>DI其实就是依赖注入，和IOC描述的都是对象实例化和依赖关系维护这件事情，但是角度不同，IOC站在对象的角度，对象实例化及其管理的权利交给了（反转）容器，ID是站在容器的角度，容器会把对象依赖的其他对象注入，比如A对象在实例化过程中声明了一个B类型的属性，就要容器把B对象注入A。</p>
<h3 id="什么是AOP"><a href="#什么是AOP" class="headerlink" title="什么是AOP"></a>什么是AOP</h3><p>Aop是oop的延续，传统oop三大特性封装、继承、多态，成一种垂直继承体系，存在顶级分类代码重复无法优化问题，无法解决横向切面逻辑代码问题，所以就产生了aop，通过横向抽取机制，将横切逻辑代码和业务逻辑代码分析。在不改变原有业务逻辑情况下，增强横切逻辑代码，根本上解耦合，避免横切逻辑代码重复</p>
<h3 id="为什么叫横向界面编程"><a href="#为什么叫横向界面编程" class="headerlink" title="为什么叫横向界面编程"></a>为什么叫横向界面编程</h3><p>「切」：指的是横切逻辑，原有业务逻辑代码我们不能动，只能操作横切逻辑代码，所以⾯向横切逻辑</p>
<p>「⾯」：横切逻辑代码往往要影响的是很多个⽅法，每⼀个⽅法都如同⼀个点，多个点构成⾯，有⼀个⾯的概念在⾥⾯</p>
<h3 id="手写IOC和AOP银行转账项目理解"><a href="#手写IOC和AOP银行转账项目理解" class="headerlink" title="手写IOC和AOP银行转账项目理解"></a>手写IOC和AOP银行转账项目理解</h3><p>问题：</p>
<p>1.service层和dao层具体实现类的调用时，都需要通过new来创建对象，获取对象类的属性和方法，使service层和dao层耦合在了一起。</p>
<p>2.Service层没有事务控制，如果出现异常，将会使数据库数据错乱。</p>
<p>解决：</p>
<p>首先我们在bean.xml里面创建了我们需要使用的各个类以及他的唯一id,在标签内增加property标签来标明他需要调用的接口实现类是哪个。</p>
<p><img src="/posts/30508/asset/v2-951630e1181f1e6af47a4a3cdaff31f0_720w.webp" alt="img"></p>
<p>接着进入具体处理类，通过xml解析获取文件流，通过dom4j把文件流解析成我们需要的Document对象，通过获取所有指定标签元素集合，我们就可以通过遍历这个集合，获取里面的id属性和class属性，有了class属性，就可以通过反射的方式转化成class对象，再把id和对象存入我们事先定义的map集合中待用。接着我们再遍历所有的property标签，element自带element.getParent()方法可以获取他的父级节点是谁，这样就直接从map集合中根据key和value关系获取到对应父级class对象，接着获取父对象所有方法与id拼接字符串进行判断；如果相同就直接根据ref的属性从map中获取他的实例化bean对象，再调用method.invoke把方法参数化建立依赖关系，重新放入map集合中。</p>
<p><img src="/posts/30508/asset/v2-2f4f1eb4a40d7673c416385bb9ad2b34_720w.webp" alt="img"></p>
<p>接着在创建一个线程工具类，此线程用于存储数据库连接，把线程和连接绑定在一起，然后再创建一个事务管理类，获取线程工具类里面的数据库连接，进行事务统一管控，这样就可以让多次更新操作在一个线程管控的连接下面，实现事务管理。</p>
<p><img src="https://pic2.zhimg.com/80/v2-347891102c2b849b836bc29beeb105a9_720w.webp" alt="img"></p>
<p><img src="https://pic4.zhimg.com/80/v2-5caff188edd0eb02691e1c33dcc9bd2b_720w.webp" alt="img"></p>
<p>为了将横切逻辑代码与业务逻辑代码进行分离，我们又创造了一个ProxyFactory代理工厂类，它主要的作用就是通过jdk动态代理重写invoke方法，在执行原方法之前和之后操作事务，异常里回滚事务，实现增强横切代码逻辑，也可以通过cglib方式，通过重写intercept方法对所有父类方法调用进行拦截，然后在method.invoke原方法执行之前和之后进行事务处理。</p>
<p><img src="https://pic2.zhimg.com/80/v2-8a75eae85aa6c41707a736787a5bd5d9_720w.webp" alt="img"></p>
<p><img src="https://pic4.zhimg.com/80/v2-34af364be070e7404d78d7606fc4c94b_720w.webp" alt="img"></p>
<p>最后在实际使用通过声明对应接口类，然后直接通过set注入方式就可以从map里面获取想要的实例化bean进行具体业务的操作。</p>
<p><img src="/posts/30508/asset/v2-91bbeeced880f601d3c329341516d726_720w.webp" alt="img"></p>
<h3 id="二、IOC容器设计实现及Spring源码分析"><a href="#二、IOC容器设计实现及Spring源码分析" class="headerlink" title="二、IOC容器设计实现及Spring源码分析"></a>二、IOC容器设计实现及Spring源码分析</h3><h3 id="Spring框架的IOC实现三种方式"><a href="#Spring框架的IOC实现三种方式" class="headerlink" title="Spring框架的IOC实现三种方式"></a>Spring框架的IOC实现三种方式</h3><p>\1. 纯xml方式</p>
<p>\2. Xml加注解方式</p>
<p>上面两种方式加载相同：JavaEE应用通过new ClassPathXmlApplicationContext(“beas.xml”)或者new FileSystemXmlApplicationContext(“c:beans.xml”)加载；JavaWeb应用通过ContextLoaderListener(监听器去加载xml)</p>
<p>\3. 纯注解方式</p>
<p>加载方式：JavaEE应用通过new AnnotationConfigApplicationContext(SpringConfig.class); JavaWeb应用通过ContextLoaderListener(监听器去加载注解配置类)</p>
<h3 id="BeanFactory与ApplicationCentext区别"><a href="#BeanFactory与ApplicationCentext区别" class="headerlink" title="BeanFactory与ApplicationCentext区别"></a>BeanFactory与ApplicationCentext区别</h3><p>BeanFactory是Spring框架IOC容器顶层接口，定义了基础功能和规范，而ApplicationContect是他的子接口，不仅具备了他的所有功能，并且还对他进行扩展，支持了更多的功能，实现面向接口开发原则。</p>
<h3 id="Spring-IoC纯XML方式实现"><a href="#Spring-IoC纯XML方式实现" class="headerlink" title="Spring IoC纯XML方式实现"></a>Spring IoC纯XML方式实现</h3><p>Xml文件头</p>
<p><img src="/posts/30508/asset/v2-bca35998da9bcf6ef22a8a53001ff0f5_720w.webp" alt="img"></p>
<p><strong>理解</strong>：通过引入Spring IoC容器功能，实现不需要再创建一个专门的BeanFactory来解析xml文件并返回，直接通过WebApplicationContextUtils.getWebApplicationContext就能获取到Spring工具类，再通过getBean方法获取到对应解析的全限定名转化成需要的类对象。</p>
<p><img src="/posts/30508/asset/v2-10a5c8e48bfde1c61e8f451a6eface30_720w.webp" alt="img"></p>
<h3 id="Bean的创建方式及属性标签"><a href="#Bean的创建方式及属性标签" class="headerlink" title="Bean的创建方式及属性标签"></a>Bean的创建方式及属性标签</h3><p>实例化Bean的三种方式</p>
<p>\1. 使用无参构造 推荐</p>
<p><bean id="connectionUtils" class="com.lagou.edu.utils.ConnectionUtils"></bean></p>
<p>\2. 使用静态方法创建 需要自己去new</p>
<bean id="connectionUtils" class="com.lagou.edu.factory.CreateBeanFactory" factory-method="getInstanceStatic"/>

<p>\3. 使用实例化方法创建 需要自己去new</p>
<p><bean id="createBeanFactory" class="com.lagou.edu.factory.CreateBeanFactory"></bean></p>
<bean id="connectionUtils" factory-bean="createBeanFactory" factory-method="getInstance"/>

<p>Scope：定义bean的作用范围</p>
<p>\1. singleton：单例，IOC容器中只有一个该类对象，默认为singleton，单例模式的bean对象⽣命周期与容器相同。</p>
<p>\2. prototype：原型(多例)，每次使用该类的对象（getBean），都返回给你一个新的对象，Spring只创建对象，不管理对象</p>
<p>id属性： ⽤于给bean提供⼀个唯⼀标识。在⼀个标签内部，标识必须唯⼀。</p>
<p>class属性：⽤于指定创建Bean对象的全限定类名。</p>
<p>name属性：⽤于给bean提供⼀个或多个名称。多个名称⽤空格分隔。</p>
<p>factory-bean属性：⽤于指定创建当前bean对象的⼯⼚bean的唯⼀标识。当指定了此属性之后，class属性失效。</p>
<p>factory-method属性：⽤于指定创建当前bean对象的⼯⼚⽅法，如配合factory-bean属性使⽤，则class属性失效。如配合class属性使⽤，则⽅法必须是static的。</p>
<p>scope属性：⽤于指定bean对象的作⽤范围。通常情况下就是singleton。当要⽤到多例模式时，可以配置为prototype。</p>
<p>init-method属性：⽤于指定bean对象的初始化⽅法，此⽅法会在bean对象装配后调⽤。必须是⼀个⽆参⽅法。</p>
<p>destory-method属性：⽤于指定bean对象的销毁⽅法，此⽅法会在bean对象销毁前执⾏。它只能为scope是singleton时起作⽤。</p>
<h3 id="Spring-DI依赖注入配置"><a href="#Spring-DI依赖注入配置" class="headerlink" title="Spring DI依赖注入配置"></a>Spring DI依赖注入配置</h3><p>依赖注入分类：构造函数注入和set方法注入</p>
<p>注入类型：基本类型和String、其他Bean类型、复杂类型（map,list等等）</p>
<p>构造函数注入：constructor-arg标签</p>
<p>依靠构造函数对类成员进行赋值，而且构造函数参数要与配置参数个数相同、类型相同</p>
<p>name：⽤于给构造函数中指定名称的参数赋值。</p>
<p>index：⽤于给构造函数中指定索引位置的参数赋值。</p>
<p>value：⽤于指定基本类型或者String类型的数据。</p>
<p>ref：⽤于指定其他Bean类型的数据。写的是其他bean的唯⼀标识。</p>
<p><img src="/posts/30508/asset/v2-58effd32bd556a928acf0dc85820b411_720w.webp" alt="img"></p>
<p>set⽅法注⼊：property标签</p>
<p>name：指定注⼊时调⽤的set⽅法名称。（注：不包含set这三个字⺟,druid连接池指定属性名称）</p>
<p>value：指定注⼊的数据。它⽀持基本类型和String类型。</p>
<p>ref：指定注⼊的数据。它⽀持其他bean类型。写的是其他bean的唯⼀标识。</p>
<p><img src="/posts/30508/asset/v2-b8d3715bdaac122d5882b5d663ef37ab_720w.webp" alt="img"></p>
<h3 id="Spring-IoC半XML半注解方式实现"><a href="#Spring-IoC半XML半注解方式实现" class="headerlink" title="Spring IoC半XML半注解方式实现"></a>Spring IoC半XML半注解方式实现</h3><p>\1. 实际企业开发中，纯xml开发方式很少用。</p>
<p>\2. 引入注解功能，不需要再引入额外的jar包</p>
<p>\3. Xml+注解结合模式，xml仍然存在，所以springIOC容器仍然从Xml开始加载</p>
<p>\4. 第三方jar的bean定义xml如druid数据库连接池，自己开发的bean定义使用注解</p>
<p><img src="/posts/30508/asset/v2-b84737eb6c11d124cf0fda38ccb675bc_720w.webp" alt="img"></p>
<p>DI 依赖注⼊的注解实现⽅式</p>
<p>@Autowired: 按照类型注⼊,如果按照类型无法唯一锁定对象，结合@Qualifier告诉Spring具体去装配哪一个对象</p>
<p><img src="https://pic4.zhimg.com/80/v2-73787be0333fab7170b8f3b44e45fcdb_720w.webp" alt="img"></p>
<p>@Resource按照 ByName ⾃动注⼊，不过在JDK11以后已经被移除，需要单独引入jar包</p>
<p><img src="/posts/30508/asset/v2-c091dcc7e7d73ebe2721539c0d1d93ee_720w.webp" alt="img"></p>
<h3 id="纯注解模式"><a href="#纯注解模式" class="headerlink" title="纯注解模式"></a>纯注解模式</h3><p>@Configuration 注解，表名当前类是⼀个配置类</p>
<p>@ComponentScan 注解，替代 context:component-scan</p>
<p>@PropertySource，引⼊外部属性配置⽂件</p>
<p>@Import 引⼊其他配置类</p>
<p>@Value 对变量赋值，可以直接赋值，也可以使⽤ ${} 读取资源配置⽂件中的信息</p>
<p>@Bean 将⽅法返回对象加⼊ SpringIOC 容器</p>
<p>注意，开启纯注解模式，需要web.xml里面配置全注解IOC启动方式，并把配置文件引用改成配置类全限定类名引用</p>
<p><img src="/posts/30508/asset/v2-ab344d601c8a09910e87c6c16002e62a_720w.webp" alt="img"></p>
<h3 id="lazy-Init-延迟加载"><a href="#lazy-Init-延迟加载" class="headerlink" title="lazy-Init 延迟加载"></a>lazy-Init 延迟加载</h3><p>Spring在启动时，默认是将所有的singleton bean提前实例化，如果设置了lazy-init&#x3D;”ture”的话，就可以设置这个bean在ApplicationContext启动服务器时不被实例化，在调用他的getBean索取bean时进行实例化，实现延迟加载，注意scope&#x3D;”pototype”时，此设置无效，会采用默认值false立即加载。这么设置的目的是对不常用的bean设置延迟加载，避免一开始启动服务器占用资源</p>
<p><img src="https://pic4.zhimg.com/80/v2-b48f5505e4bbb942eb6c14d09e895b6b_720w.webp" alt="img"></p>
<h3 id="FactoryBean-和-BeanFactory"><a href="#FactoryBean-和-BeanFactory" class="headerlink" title="FactoryBean 和 BeanFactory"></a>FactoryBean 和 BeanFactory</h3><p>BeanFactory接口是容器的顶级接口，定义了容器的一些基础行为和规范，而FactoryBean与前面说的ApplicationContext一样都是他的子接口，但是FactoryBean主要的作用是用它来自定义bean的创建。比如bean传了一个带分隔符号的字符串过来，需要我们进行解析，并装入一个实体类对象，我们就可以在具体工厂类里面实现FactoryBean接口，重写他的getObject,getObjectType,isSingleton方法，对复杂字符串进行处理，然后装入对应实体类中完成解析。</p>
<p><img src="/posts/30508/asset/v2-caa0bcd352f0a91479da0083f8af9ca7_720w.webp" alt="img"></p>
<p><img src="https://pic2.zhimg.com/80/v2-caf8910996e40bc35600ce4c66656e8d_720w.webp" alt="img"></p>
<p><img src="/posts/30508/asset/v2-6128e7b84d095fcca9586549f59efe8c_720w.webp" alt="img"></p>
<h3 id="后置处理器"><a href="#后置处理器" class="headerlink" title="后置处理器"></a>后置处理器</h3><p>Bean的生命周期</p>
<p><img src="https://pic4.zhimg.com/80/v2-e9785ce1ab838745aad8c44a6a8bb41b_720w.webp" alt="img"></p>
<p><img src="https://pic2.zhimg.com/80/v2-b82f780bca78701463144ab90899fda5_720w.webp" alt="img"></p>
<p><img src="https://pic3.zhimg.com/80/v2-86452f1eee065528d68813c4ec817a1e_720w.webp" alt="img"></p>
<p><img src="/posts/30508/asset/v2-315a3a3157b332a38b2088679fb0d4a0_720w.webp" alt="img"></p>
<p><strong>生命周期：</strong></p>
<p>1、Spring 容器根据配置中的 bean 定义中实例化 bean。</p>
<p>2、Spring 使用依赖注入填充所有属性，如 bean 中所定义的配置。</p>
<p>3、如果 bean 实现BeanNameAware 接口，则工厂通过传递 bean 的 ID 来调用setBeanName()。</p>
<p>4、如果 bean 实现 BeanFactoryAware 接口，工厂通过传递自身的实例来调用 setBeanFactory()。</p>
<p>5、如果存在与 bean 关联的任何BeanPostProcessors，则调用 preProcessBeforeInitialization() 方 法。</p>
<p>6、如果为 bean 指定了 init 方法（ 的 init-method 属性），那么将调用它。</p>
<p>7、最后，如果存在与 bean 关联的任何 BeanPostProcessors，则将调用 postProcessAfterInitialization() 方法。</p>
<p>8、如果 bean 实现DisposableBean 接口，当 spring 容器关闭 时，会调用 destory()。</p>
<p>9、如果为bean 指定了 destroy 方法（ 的 destroy-method 属性），那么将调用它。</p>
<p><strong>理解</strong>：Spring将Bean标签按照生命周期方式按顺序加载，最后类名、scope、属性、构造函数参数列表、依赖的bean、是否是单例类、是否是懒加载等等一系列属性解析封装到BeanDefinition对象中，封装完成后通过getBeanDefinition获取属性，后面对bean操作其实就是对BeanDefinition进行，通过拿到类名、构造函数后就可以反射完成对象的创建</p>
<h3 id="三、SpringIOC源码理解"><a href="#三、SpringIOC源码理解" class="headerlink" title="三、SpringIOC源码理解"></a>三、SpringIOC源码理解</h3><h3 id="SpringIOC容器体系"><a href="#SpringIOC容器体系" class="headerlink" title="SpringIOC容器体系"></a>SpringIOC容器体系</h3><p>ApplicationContext是容器的高级接口，BeanFactory是顶级接口，规范和定义了容器的基础行为,Spring应用的上下文，官方称之为IOC容器，map是容器的一个成员叫做单例池，SingletonObjects。容器是一组组件和过程的集合，包括BeanFactory、单例池、BeanPostProcessor等以及之间的协作流程。比如BeanFactory常用的getBean方法，遵循多态原则，定义了多个但参数不同的同名方法。如果需要获取整个bean需要加前缀&amp;，通过内部FACTORY_BEAN_PREFIX来判定。</p>
<p><img src="/posts/30508/asset/v2-692205710601e23829a6a28e9ef2e53a_720w.webp" alt="img"></p>
<p><img src="/posts/30508/asset/v2-adb047630a4dd552ee0d32d2fc7e1d54_720w.webp" alt="img"></p>
<p>ApplicationContext继承的接口：</p>
<p>ListableBeanFactory接口：列出工厂可以生产的所有实例。但没有直接提供返回所有实例的方法。它可以返回指定类型的所有的实例。你可以通过getBeanDefinitionNames()得到工厂所有bean的名字，然后根据这些名字得到所有的Bean。这个工厂接口扩展了BeanFactory的功能，作为上文指出的BeanFactory二级接口，有9个独有的方法，扩展了跟BeanDefinition的功能，提供了BeanDefinition、BeanName、注解有关的各种操作。</p>
<p>MessageSource接口：以用于支持信息的国际化和包含参数的信息的替换。</p>
<p>HierarchicalBeanFactory接口：实现了Bean工厂的分层。继承自BeanFacotory，是一个二级接口，相对于父接口，它只扩展了一个重要的功能——工厂分层。</p>
<p>AutowireCapableBeanFactory接口：继承自BeanFacotory，它扩展了自动装配的功能，根据类定义BeanDefinition装配Bean、执行前、后处理器等。</p>
<p>ConfigurableBeanFactory接口：继承自HierarchicalBeanFactory 和 SingletonBeanRegistry 这两个接口，并额外独有37个方法，这37个方法包含了工厂创建、注册一个Bean的众多细节。</p>
<p>ResourceLoader接口：加载资源的接口，读取xml文件。</p>
<p>以上接口继承关系得出结论：Spring IoC 容器继承体系⾮常聪明，需要使⽤哪个层次⽤哪个层次即可，不必使⽤功能⼤⽽全的。</p>
<h3 id="Bean⽣命周期关键时机点"><a href="#Bean⽣命周期关键时机点" class="headerlink" title="Bean⽣命周期关键时机点"></a>Bean⽣命周期关键时机点</h3><p>Bean对象创建的几个关键点都在调用AbstractApplicationContext 类 的 refresh ⽅法</p>
<p><img src="/posts/30508/asset/v2-ef80599631ffb1fdb7c08ebd676bce57_720w.webp" alt="img"></p>
<p><img src="/posts/30508/asset/v2-cd1bb6829808c525aeb13922eec8b3b8_720w.webp" alt="img"></p>
<p>解析refresh ⽅法：</p>
<p><img src="/posts/30508/asset/v2-f9df5195c86ac5dbe2634cdbae6f43d4_720w.webp" alt="img"></p>
<p><img src="https://pic3.zhimg.com/80/v2-280b883e45189283290a89589b01851a_720w.webp" alt="img"></p>
<p><img src="/posts/30508/asset/v2-4f0629cdd9e018a50d9625bb9b43c89f_720w.webp" alt="img"></p>
<p><img src="https://pic3.zhimg.com/80/v2-1afdae51c4a50019abbc6d8061955876_720w.webp" alt="img"></p>
<p><img src="https://pic4.zhimg.com/80/v2-4268b52f69a1fbd74490da809d366c47_720w.webp" alt="img"></p>
<p><strong>理解</strong>：在通过ClassPathXmlApplicationContext加载对应bean.xml文件时，首先进入到调用的构造器内，执行子类调用父类初始化方法，然后处理传入的配置文件路径，然后refresh判断，进入spring容器初始化方法内。创建工厂，把xml中的信息加载BeanDefition 并注册到 BeanDefitionRegistry（内部map结构，把BeanDefition作为value，id作为key，类似于之前自定义持久层框架中数据库javabean类中configuration类关联mappedstatement类的关系），接着初始化并执行工厂后置处理器，再注册bean的后置处理器，最后初始化bean,调用初始化方法，调用bean的后置处理器，完成容器初始化，产生bean对象。</p>
<h3 id="BeanFactory获取子流程与BeanDefinition加载注册解析"><a href="#BeanFactory获取子流程与BeanDefinition加载注册解析" class="headerlink" title="BeanFactory获取子流程与BeanDefinition加载注册解析"></a>BeanFactory获取子流程与BeanDefinition加载注册解析</h3><p><strong>BeanFactory:</strong></p>
<p><img src="https://pic4.zhimg.com/80/v2-1afb0842d379fdaa943f56cf038f43ff_720w.webp" alt="img"></p>
<p><img src="/posts/30508/asset/v2-fdefb5b63280dbbc0f45b2b9d1bc661c_720w.webp" alt="img"></p>
<p><strong>理解</strong>：通过调取AbstractApplicationContext类的obtainFreshBeanFactory方法，执行调取AbstractRefreshableApplicationContext类的refreshBeanFactory方法，在这个方法内再调用自己内部的createBeanFactory方法进行实列化，并返回DefaultListableBeanFactory，而AbstractApplicationContext类再通过getBeanFactory方法把工厂对象拿回来。</p>
<p><strong>BeanDefinition:</strong></p>
<p><img src="/posts/30508/asset/v2-95ae2b6a31a70b98933e1e86d720635c_720w.webp" alt="img"></p>
<p><strong>理解</strong>：通过AbstractBeanDefinitionReader类调取XmlBeanDefinitionReader内的loadBeanDefinitions方法发送消息，接着调取自己类的doLoadBeanDefinitions方法，完成xml读取为document对象，接着又调取内部的registerBeanDefinitions方法完成注册。接着在这方法内又调取DefaultBeanDefinitionDocumentReader类的registerBeanDefinitions方法，再在内部按吮吸调用doRegisterBeanDefinitions-&gt;parseBeanDefinitions-&gt;processBeanDefinition-&gt;调取BeanDefinitionParserDelegate类的parseBeanDefinitionElement方法再调内部-&gt;parseBeanDefinitionElement方法完成加载注册并返回BeanDefinition对象。</p>
<h3 id="Bean创建流程"><a href="#Bean创建流程" class="headerlink" title="Bean创建流程"></a>Bean创建流程</h3><p><img src="/posts/30508/asset/v2-a4930e79bcbfaa9e8da79af82f994448_720w.webp" alt="img"></p>
<p><strong>理解</strong>：根据入口方法调用自己类的finishBeanFactoryInitialization方法，判断Bean的属性，接着进⼊DefaultListableBeanFactory类的preInstantiateSingletons⽅法，实例化所有立即加载的单例bean，接着声明一个list集合用于存放所有bean的id，然后循环集合，针对数据进行处理，非抽象、单列、非延迟加载的数据进入下一环节，接着判断是否工厂bean,因为工厂bean的前缀有一个&amp;符号规范。如果不是就直接实例化Bean。接着进⼊到了AbstractBeanFactory类的doGetBean⽅法，对上面的BeanName进行解析，接着判断是否是多例bean,即prototype,如果是无法处理，抛出异常。如果不是，先检查父工厂是否存在此对象，没有就创建单例bean,调用构造函数实例化bean,再进行属性填充，最后调用初始化方法，应用BeanPostProcessor后置处理器。</p>
<h3 id="lazy-init-延迟加载机制原理"><a href="#lazy-init-延迟加载机制原理" class="headerlink" title="lazy-init 延迟加载机制原理"></a>lazy-init 延迟加载机制原理</h3><p><img src="/posts/30508/asset/v2-9338b9f3e62d0e9a8b263a15ecf3a487_720w.webp" alt="img"></p>
<p><strong>理解</strong>：在上面bean创建过程中就已经说到了中间环节有一个非抽象，非单例，非延迟加载的判断。如果是延迟加载就直接不处理，就不会完成该bean的创建。</p>
<h3 id="循环依赖问题"><a href="#循环依赖问题" class="headerlink" title="循环依赖问题"></a>循环依赖问题</h3><p>循环依赖其实就是循环引⽤，也就是两个或者两个以上的 Bean 互相持有对⽅，最终形成闭环。⽐如A依赖于B，B依赖于C，C⼜依赖于A。注意，这⾥不是函数的循环调⽤，是对象的相互依赖关系。</p>
<p>场景：</p>
<p>构造器的循环依赖（构造器注⼊）</p>
<p>Field 属性的循环依赖（set注⼊）</p>
<p>其中，构造器的循环依赖问题⽆法解决，因为构造函数里面必须要有东西，但是根本没法完成A的实例化放入缓存中，只能拋出 BeanCurrentlyInCreationException 异常。在解决属性循环依赖时，spring采⽤的是提前暴露对象的⽅法。</p>
<p><img src="/posts/30508/asset/v2-34f75ac1d671e4dfd72466191f6ee72d_720w.webp" alt="img"></p>
<p><strong>理解</strong>：Bean A在实例化后放入三级缓存中，接着A发现B依赖他，于是对B进行实例化，把B也放入三级缓存中，接着B又发现他依赖A，这个时候三级缓存中已经有了A对象，因此使用Bean工厂创建代理对象A放入二级缓存中，然后删除三级缓存中的A对象，B对象拿到了A的代理对象，就可以完成装配，把B放入一级缓存中，并删除三级缓存中的B对象，B实例化完之后就会返回给A，A有了B对象，就可以把二级缓存中的A对象同步到一级缓存中，并删除二级缓存中的A对象，这样就解决了循环依赖问题。</p>
<h3 id="四、SpringAOP应用"><a href="#四、SpringAOP应用" class="headerlink" title="四、SpringAOP应用"></a>四、SpringAOP应用</h3><h3 id="AOP相关术语"><a href="#AOP相关术语" class="headerlink" title="AOP相关术语"></a>AOP相关术语</h3><p>AOP本质：在不改变原有业务逻辑代码的情况下运用动态代理技术（当代理对象不实现接口的情况下采用CGLIB,实现了接口采用官方JDK代理），在运行期间对需要使用的业务逻辑增强横切逻辑，横切逻辑代码往往是权限效验代码、日志代码、事务控制代码、性能监控代码。</p>
<p><img src="/posts/30508/asset/v2-a504ff3d8e163d5317354af962b74a2c_720w.webp" alt="img"></p>
<p>连接点：⽅法开始时、结束时、正常运⾏完毕时、⽅法异常时等这些特殊的时机点，我们称之为连接点，项⽬中每个⽅法都有连接点，连接点是⼀种候选点。</p>
<p>切⼊点：指定AOP思想想要影响的具体⽅法是哪些，描述感兴趣的⽅法。</p>
<p>Advice增强：第⼀个层次：指的是横切逻辑；第⼆个层次：⽅位点（在某⼀些连接点上加⼊横切逻辑，那么这些连接点就叫做⽅位点，描述的是具体的特殊时机）。</p>
<p>Aspect切⾯：切⾯概念是对上述概念的⼀个综合。</p>
<p>Aspect切⾯&#x3D; 切⼊点+增强&#x3D; 切⼊点（锁定⽅法） + ⽅位点（锁定⽅法中的特殊时机）+ 横切逻辑。</p>
<p>组合以上最终的目的就是为了锁定需要在什么地方插入横切逻辑代码。</p>
<p>配置方式：与IOC一样，支持xml、xml+注解、全注解方式。</p>
<p>五种通知类型：前置通知；最终通知；正常执行通知；异常通知；环绕通知。</p>
<p>XML模式</p>
<p><img src="https://pic3.zhimg.com/80/v2-8831f62cbf80b606d143ccb1c38c1b9e_720w.webp" alt="img"></p>
<p>注解模式</p>
<p><img src="https://pic4.zhimg.com/80/v2-84ff749a8a6cd48787f33daf7107cd33_720w.webp" alt="img"></p>
<h3 id="Spring声明式事务支持"><a href="#Spring声明式事务支持" class="headerlink" title="Spring声明式事务支持"></a>Spring声明式事务支持</h3><p>编程式事务：在业务代码中添加事务控制代码，这样的事务控制机制就叫做编程式事务。</p>
<p>声明式事务：通过xml或者注解配置的⽅式达到事务控制的⽬的，叫做声明式事务。</p>
<p>概念：逻辑上的一组操作，操作各个单元，进行控制，要么全部成功，要么全部失败，保证数据的准确和安全。</p>
<p>四大特性之原子性：事务操作要么都发生要么都不发生。</p>
<p>四大特性之隔离性：事务之间互不干扰，并发事务互相隔离</p>
<p>四大特性之一致性：数据库从一个一致性状态到另一个一致性状态，比如A转账给B100块，完成后他们俩钱总和不能变。</p>
<p>四大特性之持久性：事务一旦提交，数据库的数据改变就是永久有效的，不受任何不可控因素影响结果。</p>
<p>事务问题：</p>
<p>脏读：一个线程的事务读取到了另一个线程还未提交的数据。</p>
<p>不可重复读：一个线程的事务读取到另一个线程已经提交update的数据（前后内容不一致）</p>
<p>虚读（幻读）：⼀个线程的事务读到了另外⼀个线程中已经提交的insert或者delete的数据（前后条数不一致）</p>
<p>四种隔离级别：Mysql默认可重复读</p>
<p>Serializable（串⾏化）：可避免脏读、不可重复读、虚读情况的发⽣。（串⾏化） 最⾼效率</p>
<p>Repeatable read（可重复读）：可避免脏读、不可重复读情况的发⽣。(幻读有可能发⽣) 第⼆</p>
<p>该机制下会对要update的⾏进⾏加锁</p>
<p>Read committed（读已提交）：可避免脏读情况发⽣。不可重复读和幻读⼀定会发⽣。 第三</p>
<p>Read uncommitted（读未提交）：最低级别，以上情况均⽆法保证。(读未提交) 最低</p>
<p>事务的传播行为：两个事务控制的service层存在关系调用，进行事务的协商。</p>
<p><img src="/posts/30508/asset/v2-a89d94fb0b553813bbf8d58a974da81c_720w.webp" alt="img"></p>
<h3 id="Spring声明式事务配置"><a href="#Spring声明式事务配置" class="headerlink" title="Spring声明式事务配置"></a>Spring声明式事务配置</h3><p>导入jar包</p>
<p><img src="/posts/30508/asset/v2-aa8fd3f86c71917574ccc48fe83978cc_720w.webp" alt="img"></p>
<p>Xml配置</p>
<p><img src="https://pic4.zhimg.com/80/v2-419d93c4669e1c9e9378c56212d335bf_720w.webp" alt="img"></p>
<p>接口、类、方法添加@Transactional注解</p>
<p><img src="https://pic3.zhimg.com/80/v2-e0f45c33a8a4778200c1fb8c0a9e504e_720w.webp" alt="img"></p>
<h3 id="SpringAOP源码剖析"><a href="#SpringAOP源码剖析" class="headerlink" title="SpringAOP源码剖析"></a>SpringAOP源码剖析</h3><p>AOP代理对象创建过程</p>
<p><img src="/posts/30508/asset/v2-352648f0acc9044ad2b6b06e94e19c01_720w.webp" alt="img"></p>
<p><img src="/posts/30508/asset/v2-8c4775ed58be4e4cd9cd80aaadb459ea_720w.webp" alt="img"></p>
<p>在finishBeanFactoryInitialization方法中实例化原始对象并创建代理对象，进入方法内先创建Bean实例，调用构造方法，处理循环依赖，填充属性，完成后就开始调用初始化方法，创建BeanPostProcessor后置处理器来创建代理对象。具体源码走向：</p>
<p>在AbstractAutowireCapableBeanFactory类的 initializeBean方法调用自己内部applyBeanPostProcessorsAfterInitialization方法，在方法内进入AbstractAutoProxyCreator类的postProcessAfterInitialization方法(后置处理器完成bean对象创建)，在调用自己内部的wrapIfNecessary方法包装代理对象，查找出和当前bean匹配的advisor,再进入createProxy方法调用栈，通过ProxyFactory创建代理对象，再把通用拦截器和增强对象合并，适配advisor,传给统一创建代理对象的工厂，进入createAopProxy方法判断是cglib代理还是jdk动态代理，最后通过Enhancer完成cglib代理对象的创建。</p>
<p>声明式事务源码分析</p>
<p><img src="/posts/30508/asset/v2-cbe134c19e35305ca2f589f63c6229a4_720w.webp" alt="img"></p>
<p>@EnableTransactionManagement 注解使⽤ @Import 标签引⼊了TransactionManagementConfigurationSelector类，这个类⼜向容器中导⼊了两个重要的组件AutoProxyRegistrar 组件和ProxyTransactionManagementConfiguration 组件分别完成后置处理器类和事务增强器类的执行。</p>
]]></content>
      <categories>
        <category>基础知识</category>
        <category>spring</category>
      </categories>
      <tags>
        <tag>基础知识</tag>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title>Nocas配置注册中心和Sentinel分布式流量防卫兵相关知识总结</title>
    <url>/posts/53802/</url>
    <content><![CDATA[<h2 id="一、Nocas配置注册中心"><a href="#一、Nocas配置注册中心" class="headerlink" title="一、Nocas配置注册中心"></a><strong>一、Nocas配置注册中心</strong></h2><p>Nacos是阿里巴巴开源的⼀个针对微服务架构中服务发现、配置管理和服务管理平台，Nacos&#x3D;Eureka+Config+Bus。</p>
<p>Nacos功能特性</p>
<p>1）服务发现与健康检查</p>
<p>2）动态配置管理</p>
<p>3）动态DNS服务</p>
<p>4）服务和元数据管理，动态的服务权重调整、动态服务优雅下线</p>
<p><img src="https://pic1.zhimg.com/80/v2-14b927289c9701aa2968f120934ce6b4_720w.webp" alt="img"></p>
<p><img src="/posts/53802/asset/v2-6e62591b6415ad3a6a58c981672a9111_720w.webp" alt="img"></p>
<p>保护阈值：可以设置为0-1之间的浮点数，它其实是⼀个⽐例值，防止多数服务都处于不可用，少数可用，在流量洪峰到来的时候，引起少量可用服务承受不住导致雪崩效应。</p>
<p><strong>数据模型</strong></p>
<p><img src="https://pic3.zhimg.com/80/v2-ff7814adc958693e7d4ac668709c0eda_720w.webp" alt="img"></p>
<p>Namespace命名空间、Group分组、集群这些都是为了进⾏归类管理，把服务和配置⽂件进行归类，归类之后就可以实现⼀定的效果，⽐如隔离。</p>
<p>Namespace：命名空间，对不同的环境进⾏隔离，⽐如隔离开发环境、测试环境和生成环境</p>
<p>Group：分组，将若干个服务或者若干个配置集归为⼀组，通常习惯⼀个系统归为⼀个组</p>
<p>Service：某⼀个服务，比如简历微服务DataId：配置集或者可以认为是⼀个配置文件</p>
<p>Namespace + Group + Service 如同 Maven 中的GAV坐标，GAV坐标是为了锁定 Jar，二这里是为了锁定服务</p>
<p><strong>配置中心</strong></p>
<p>通过 Namespace + Group + dataId 来锁定配置⽂件，Namespace不指定就默认public，Group不指定就默认 DEFAULT_GROUP，生成dataId：${prefix}-${spring.profile.active}.${file-extension}。</p>
<p><img src="https://pic3.zhimg.com/80/v2-d98d2f57c915754e99e915cddacb9cde_720w.webp" alt="img"></p>
<p>通过 Spring Cloud 原⽣注解 @RefreshScope 实现配置⾃动更新，并且可以实现多个配置文件扩展。</p>
<p><img src="/posts/53802/asset/v2-25cefc0644b5f605917d6662229a6a1d_720w.webp" alt="img"></p>
<h2 id="二、Sentinel分布式流量防卫兵"><a href="#二、Sentinel分布式流量防卫兵" class="headerlink" title="二、Sentinel分布式流量防卫兵"></a>二、Sentinel分布式流量防卫兵</h2><p>Sentinel是一个面向云原⽣微服务的流量控制、熔断降级组件。 替代Hystrix，针对问题：服务雪崩、服务降级、服务熔断、服务限流。</p>
<p><strong>Hystrix：</strong></p>
<p>1）自己搭建监控平台dashboard。</p>
<p>2）没有提供UI界⾯进⾏服务熔断、服务降级等配置（而是写代码，入侵了我们源程序环境）。</p>
<p><strong>Sentinel：</strong></p>
<p>1）独立可部署Dashboard&#x2F;控制台组件。</p>
<p>2）减少代码开发，通过UI界⾯配置即可完成细粒度控制（⾃动投递微服务。</p>
<p><img src="https://pic4.zhimg.com/80/v2-244ec3cfcdd87d8fd0d469efcd12b517_720w.webp" alt="img"></p>
<p>Sentinel两部分：</p>
<p>核心库：（Java 客户端）不依赖任何框架&#x2F;库，能够运行于所有 Java 运行时环境，同时对 Dubbo &#x2F; Spring Cloud 等框架也有较好的⽀持。</p>
<p>控制台：（Dashboard）基于 Spring Boot 开发，打包后可以直接运行，不需要额外的 Tomcat 等应用容器。</p>
<p>Sentinel特征:</p>
<p>1）丰富的应用场景：Sentinel 承接了阿里巴巴近10年的双十一大促流量的核心场景，例如秒杀（即突发流量控制在系统容量可以承受的范围）、消息削峰填谷、集群流量控制、实时熔断下游不可⽤应⽤等。</p>
<p>2）完备的实时监控：Sentinel 同时提供实时的监控功能。您可以在控制台中看到 接入应用的单台机器秒级数据，甚⾄ 500 台以下规模的集群的汇总运行情况。</p>
<p>3）广泛的开源⽣态：Sentinel 提供开箱即用的与其它开源框架&#x2F;库的整合模块，例如与 Spring Cloud、Dubbo的整合。您只需要引入相应的依赖并进⾏简单的配 置即可快速地接入Sentinel。</p>
<p>4）完善的 SPI 扩展点：Sentinel 提供简单易⽤、完善的 SPI 扩展接⼝。您可以通过 实现扩展接⼝来快速地定制逻辑。例如定制规则管理、适配动态数据源等。</p>
<p><img src="/posts/53802/asset/v2-122b6708226e4b3bc49fb03bc15506fb_720w.webp" alt="img"></p>
<p><strong>流量规则模块</strong></p>
<p>资源名：默认请求路径针对来源：Sentinel可以针对调用者进行限流，填写微服务名称，默default（不区分来源）</p>
<p>阈值类型&#x2F;单机阈值</p>
<p>QPS：（每秒钟请求数量）当调用该资源的QPS达到阈值时进行限流</p>
<p>线程数：当调用该资源的线程数达到阈值的时候进行限流（线程处理请求的时候，如果说业务逻辑执行时间很长，流量洪峰来临时，会耗费很多线程资源，这些线程资源会堆积，最终可能造成服务不可用，进⼀步上游服务不可用，最终可能服务雪崩）</p>
<p>是否集群：是否集群限流</p>
<p>流控模式：</p>
<p>直接：资源调用达到限流条件时，直接限流</p>
<p>关联：关联的资源调用达到阈值时候限流自己</p>
<p>链路：只记录指定链路上的流量</p>
<p>流控效果：</p>
<p>快速失败：直接失败，抛出异常</p>
<p>排队等待：匀速排队，让请求匀速通过，阈值类型必须设置为QPS，否则无效</p>
<p>流控模式之关联限流：</p>
<p>关联的资源调用达到阈值时候限流自己，比如用户注册接口，需要调⽤身份证校验接口（往往身份证校验接口），如果身份证校验接口请求达到阈值，使用关联，可 以对用户注册接口进行限流。</p>
<p><img src="https://pic2.zhimg.com/80/v2-dd6bdc1e82bc3d01e64317519333b415_720w.webp" alt="img"></p>
<p>Sentinel流量控制：</p>
<p>关联模式、链路模式、预热、排队等待</p>
<p>Sentinel降级规则（等于Hystrix中的熔断）：</p>
<p>RT策略</p>
<p><img src="/posts/53802/asset/v2-ffd7a599cfa18ed1fe426142e437cb30_720w.webp" alt="img"></p>
<p>异常比例策略</p>
<p><img src="/posts/53802/asset/v2-b2687ff57a9cccd0dc1e545f4dd334f4_720w.webp" alt="img"></p>
<p>异常策略</p>
<p><img src="/posts/53802/asset/v2-18077240785cd6354b65bcdc31c9e1d3_720w.webp" alt="img"></p>
]]></content>
      <categories>
        <category>基础知识</category>
        <category>spring cloud</category>
      </categories>
      <tags>
        <tag>基础知识</tag>
        <tag>spring cloud</tag>
      </tags>
  </entry>
  <entry>
    <title>Sleuth+Zipkin链路追踪和OAuth2统一认证相关知识</title>
    <url>/posts/24605/</url>
    <content><![CDATA[<h2 id="Sleuth-Zipkin链路追踪"><a href="#Sleuth-Zipkin链路追踪" class="headerlink" title="Sleuth+Zipkin链路追踪"></a>Sleuth+Zipkin链路追踪</h2><p>Trace：服务追踪的追踪单元是从客户发起请求（request）抵达被追踪系统的边界开始，到被追踪系统向客户返回响应（response）为止的过程。</p>
<p>Trace ID：实现请求跟踪，⼀个Trace由⼀个或者多个Span组成，每⼀个Span都有⼀个SpanId，Span中会记录 TraceId，同时还有⼀个叫做ParentId，指向了另外⼀个Span的SpanId，表明父子关系，其实本质表达了依赖关系。</p>
<p>Span ID：统计各处理单元的时间延迟，除了时间戳记录之外，它还可以包含⼀些其他元数据，比如时间名称、请求信息等。每⼀个Span都会有⼀个唯⼀跟踪标识 Span ID,若干个有序的 span 就组成了⼀个trace。</p>
<p>分析方式：</p>
<p>耗时分析：通过 Sleuth 了解采样请求的耗时，分析服务性能问题（哪些服务调用比较耗时）。</p>
<p>链路优化：发现频繁调⽤的服务，针对性优化等，Sleuth就是通过记录日志的方式来记录踪迹数据的。</p>
<p>Spring Cloud Sleuth 和 Zipkin ⼀起使用，把 Sleuth 的数据信息发送给 Zipkin 进行聚合，利用 Zipkin 存储并展示数据。</p>
<h2 id="OAuth2统一认证"><a href="#OAuth2统一认证" class="headerlink" title="OAuth2统一认证"></a>OAuth2统一认证</h2><p>认证：验证用户的合法身份，比如输⼊用户名和密码，系统会在后台验证用户名和密码是否合法，合法的前提下，才能够进行后续的操作，访问受保护的资源，微服务下解决多个服务之间单点登录问题。</p>
<p><strong>微服务架构下统⼀认证思路</strong></p>
<p>1）基于Session的认证方式：在分布式的环境下，基于session的认证会出现⼀个问题，每个应用服务都需要 在session中存储用户身份信息，通过负载均衡将本地的请求分配到另⼀个应用服务需要将session信息带过去，否则会重新认证。我们可以使用Session共享、Session黏贴等⽅案。 Session方案也有缺点，比如基于cookie，移动端不能有效使用等</p>
<p>2）基于token的认证方式：基于token的认证方式，服务端不用存储认证数据，易维护扩展性强，客户端可以把token存在任意地方，并且可以实现web和app统⼀认证机制。其缺点也很明显，token由于自包含信息，因此⼀般数据量较⼤，而且每次请求都需要传递，因此比较占带宽。另外，token的签名验签操作也会给cpu带来额外的处理负担。</p>
<p><strong>OAuth2开放授权协议</strong></p>
<p>允许用户授权第三方应用访问他们存储在另外的服务提供者上的信息，而不需要将用户名和密码提供给第三方应用或分享他们数据的所有内容，比如通过QQ登录其他平台。</p>
<p>OAuth2的颁发Token授权方式</p>
<p>1）授权码（authorization-code）</p>
<p>2）密码式（password）提供用户名+密码换取token令牌</p>
<p>3）隐藏式（implicit）</p>
<p>4）客户端凭证（client credentials</p>
<p>使用OAuth2解决问题的本质是，引入了⼀个认证授权层，认证授权层连接了资源的拥有者，在授权层里面，资源的拥有者可以给第三方应用授权去访问我们的某些受保护资源。统⼀认证的场景中，Resource Server其实就是我们的各种受保护的微服务，微服务中的各种API访问接口就是资源，发起http请求的浏览器就是Client 客户端。</p>
]]></content>
      <categories>
        <category>基础知识</category>
        <category>spring cloud</category>
      </categories>
      <tags>
        <tag>基础知识</tag>
        <tag>spring cloud</tag>
      </tags>
  </entry>
  <entry>
    <title>springcloud组件知识</title>
    <url>/posts/30414/</url>
    <content><![CDATA[<h3 id="一、Spring-Cloud基础知识"><a href="#一、Spring-Cloud基础知识" class="headerlink" title="一、Spring Cloud基础知识"></a>一、Spring Cloud基础知识</h3><h3 id="微服务架构"><a href="#微服务架构" class="headerlink" title="微服务架构"></a>微服务架构</h3><p>微服务架构可以说是SOA架构的⼀种拓展，这种架构模式下它拆分粒度更⼩、服务更独⽴。把应⽤拆分成为⼀个个微⼩的服务，不同的服务可以使⽤不同的开发语⾔和存储，服务之间往往通过Restful等轻量级通信。微服务架构关键在于微⼩、独⽴、轻量级通信。微服务是在SOA上做的升华粒度更加细致，微服务架构强调的⼀个重点是“业务需要彻底的组件化和服务化。</p>
<p><img src="/posts/30414/asset/v2-d617be40a57a0068b71abaf5809a6e55_720w.webp" alt="img"></p>
<p><strong>微服务架构的优点</strong></p>
<p>1）微服务很⼩，便于特定业务功能的聚焦 A B C D</p>
<p>2）微服务很⼩，每个微服务都可以被⼀个⼩团队单独实施（开发、测试、部署上线、运维），团队合作⼀定程度解耦，便于实施敏捷开发</p>
<p>3）微服务很⼩，便于重⽤和模块之间的组装</p>
<p>4）微服务很独⽴，那么不同的微服务可以使⽤不同的语⾔开发，松耦合</p>
<p>5）微服务架构下，我们更容易引⼊新技术</p>
<p>6）微服务架构下，我们可以更好的实现DevOps开发运维⼀体化；</p>
<p><strong>微服务架构的缺点</strong></p>
<p>1）微服务架构下，分布式复杂难以管理，当服务数量增加，管理将越加复杂；</p>
<p>2）微服务架构下，分布式链路跟踪难等；</p>
<p><strong>微服务架构的概念</strong></p>
<p>服务注册：服务提供者将所提供服务的信息（服务器IP和端⼝、服务访问协议等） 注册&#x2F;登记到注册中⼼</p>
<p>服务发现：服务消费者能够从注册中⼼获取到较为实时的服务列表，然后根究⼀定 的策略选择⼀个服务访问</p>
<p><img src="https://pic2.zhimg.com/80/v2-84bf0900356e0dda3796cf12efa0ac8d_720w.webp" alt="img"></p>
<p>负载均衡：负载均衡即将请求压⼒分配到多个服务器（应⽤服务器、数据库服务器等），以 此来提⾼服务的性能、可靠性。</p>
<p><img src="/posts/30414/asset/v2-79a7726e269f45f86f0ea3163751a84c_720w.webp" alt="img"></p>
<p>熔断：熔断即断路保护。微服务架构中，如果下游服务因访问压⼒过⼤⽽响应变慢或失 败，上游服务为了保护系统整体可⽤性，可以暂时切断对下游服务的调⽤。这种牺 牲局部，保全整体的措施就叫做熔断。</p>
<p><img src="https://pic2.zhimg.com/80/v2-278ffbedb72d5df6849da39f49242c0d_720w.webp" alt="img"></p>
<p>链路追踪：所谓链路追踪，就是对⼀次请求涉及的很多个服务链路进⾏⽇志记 录、性能监控。</p>
<p><img src="https://pic3.zhimg.com/80/v2-da77b3c5d9931936d55fd851207f109a_720w.webp" alt="img"></p>
<p>API ⽹关：微服务架构下，不同的微服务往往会有不同的访问地址，客户端可能需要调⽤多个服务的接⼝才能完成⼀个业务需求，API请求调用统⼀接⼊API⽹关层，由⽹关转发请求。API⽹关更专注在安全、路由、流量等问题的处理上。</p>
<p>1） 统⼀接⼊（路由）</p>
<p>2） 安全防护</p>
<p>3） ⿊⽩名单</p>
<p>4） 协议适配</p>
<p>5） 流量管控</p>
<p>6） 容错能⼒</p>
<p><img src="https://pic4.zhimg.com/80/v2-58400794e0d81907118d3dac831829c7_720w.webp" alt="img"></p>
<h3 id="体系结构"><a href="#体系结构" class="headerlink" title="体系结构"></a>体系结构</h3><p><img src="/posts/30414/asset/v2-48fef39047c093a99a9d475a62341fd6_720w.webp" alt="img"></p>
<p><img src="https://pic2.zhimg.com/80/v2-2fc134e04511ad56584c71339762ce7d_720w.webp" alt="img"></p>
<p>Spring Cloud中的各组件协同⼯作，才能够⽀持⼀个完整的微服务架构。</p>
<p>1） 注册中⼼负责服务的注册与发现，很好将各服务连接起来</p>
<p>2） API⽹关负责转发所有外来的请求</p>
<p>3） 断路器负责监控服务之间的调⽤情况，连续多次失败进⾏熔断保护。</p>
<p>4） 配置中⼼提供了统⼀的配置信息管理服务,可以实时的通知各个服务获取最新的 配置信息</p>
<h3 id="Spring-Cloud-与-Dubbo"><a href="#Spring-Cloud-与-Dubbo" class="headerlink" title="Spring Cloud 与 Dubbo"></a>Spring Cloud 与 Dubbo</h3><p>Dubbo是阿⾥巴巴公司开源的⼀个⾼性能优秀的服务框架，基于RPC调⽤，对于⽬前使⽤率较⾼的Spring Cloud Netflix来说，它是基于HTTP的，所以效率上没有Dubbo⾼，但问题在于Dubbo体系的组件不全，不能够提供⼀站式解决⽅案。</p>
<h3 id="Spring-Cloud-与-Spring-Boot"><a href="#Spring-Cloud-与-Spring-Boot" class="headerlink" title="Spring Cloud 与 Spring Boot"></a>Spring Cloud 与 Spring Boot</h3><p>Spring Cloud 只是利⽤了Spring Boot 的特点，让我们能够快速的实现微服务组件开发，否则不使⽤Spring Boot的话，我们在使⽤Spring Cloud时，每⼀个组件的相关Jar包都需要我们⾃⼰导⼊配置以及需要开发⼈员考虑兼容性等各种情况。所以Spring Boot是我们快速把Spring Cloud微服务技术应⽤起来的⼀种⽅式</p>
<h3 id="二、Spring-Cloud核心组件"><a href="#二、Spring-Cloud核心组件" class="headerlink" title="二、Spring Cloud核心组件"></a>二、Spring Cloud核心组件</h3><h3 id="Eureka注册服务中心"><a href="#Eureka注册服务中心" class="headerlink" title="Eureka注册服务中心"></a>Eureka注册服务中心</h3><p>分布式微服务架构中，服务注册中⼼⽤于存储服务提供者地址信息、服务发布相关的属性信息，消费者通过主动查询和被动通知的⽅式获取服务提供者的地址信息，⽽不再需要通过硬编码⽅式得到提供者的地址信息。</p>
<p><img src="https://pic2.zhimg.com/80/v2-d5bdb69416eee569f3df31f744b06cf1_720w.webp" alt="img"></p>
<p>1） 服务提供者启动</p>
<p>2） 服务提供者将相关信息主动注册到注册中心</p>
<p>3） 服务消费者获取服务注册信息：</p>
<p>Pull模式：服务消费者可以主动拉去可用的服务提供者清单</p>
<p>Push模式：服务消费者可以主动拉去可用的服务提供者清单</p>
<p>4） 服务消费者直接调用服务提供者</p>
<p><strong>主流服务中心对比</strong></p>
<p>Zookeeper: Zookeeper ⽤来做服务注册中⼼，主要是因为它具有节点变更通知功能，只要客户端监听相关服务节点，服务节点的所有变更，都能及时的通知到监听客户端，这样作为调⽤⽅只要使⽤ Zookeeper 的客户端就能实现服务节点的订阅和 变更通知功能了，zookeeper遵循半数集群可用原则。</p>
<p>Nocas: 注册中⼼ + 配置中⼼的组合，帮助我们解决微服务开发必会涉及到的服务注册与发现，服务配置，服务管理等问题。Nacos 是Spring Cloud Alibaba 核⼼组件之⼀，负责服务注册与发现，还有配置。</p>
<p><img src="https://pic2.zhimg.com/80/v2-bb252d46c865e2a2714060456ef7fb99_720w.webp" alt="img"></p>
<p><strong>基础架构</strong></p>
<p><img src="/posts/30414/asset/v2-85ab767c0b89d2a8ef8f498ee41c2104_720w.webp" alt="img"></p>
<p>Eureka 包含两个组件：Eureka Server 和 Eureka Client，也就是服务端，存储该服务的信息以及客户端</p>
<p>1）图中us-east-1c、us-east-1d，us-east-1e代表不同的区也就是不同的机房</p>
<p>2）图中每⼀个Eureka Server都是⼀个集群。</p>
<p>3）图中Application Service作为服务提供者向Eureka Server中注册服务， Eureka Server接受到注册事件会在集群和分区中进⾏数据同步，Application Client作为消费端（服务消费者）可以从Eureka Server中获取到服务注册信息，进⾏服务调⽤。</p>
<p>4）微服务启动后，会周期性地向Eureka Server发送⼼跳（默认周期为30秒） 以续约⾃⼰的信息</p>
<p>5）Eureka Server在⼀定时间内没有接收到某个微服务节点的⼼跳，Eureka Server将会注销该微服务节点（默认90秒）</p>
<p>6）每个Eureka Server同时也是Eureka Client，多个Eureka Server之间通过复制的⽅式完成服务注册列表的同步 7）Eureka Client会缓存Eureka Server中的信息。即使所有的Eureka Server节点都宕掉，服务消费者依然可以使⽤缓存中的信息找到服务提供者</p>
<p><strong>Euraka客户端详解</strong></p>
<p>服务提供者（也是Eureka客户端）要向EurekaServer注册服务，并完成服务续约等工作</p>
<p>服务注册详解：导⼊了eureka-client依赖坐标，配置Eureka服务注册中⼼地址后，服务在启动时会向注册中⼼发起注册请求，携带服务元数据信息，Eureka注册中⼼接收到了之后会把服务的信息保存在Map中。</p>
<p>服务续约详解：服务每隔30秒会向注册中⼼续约(⼼跳)⼀次（也称为报活），如果没有续约，租约在90秒后到期，然后服务会被失效。</p>
<p>获取服务列表详解：服务消费者启动时，从 EurekaServer服务列表获取只读备份，缓存到本地，每隔30秒，会重新获取并更新数据。</p>
<p><strong>Eurake服务端详解</strong></p>
<p>服务下线：当服务正常关闭操作时，会发送服务下线的REST请求给EurekaServer，服务中⼼接受到请求后，将该服务置为下线状态。</p>
<p>失效剔除：Eureka Server会定时，默认60S检查发现实例在在⼀定时间，默认90S没有收到心跳，注销此实例。</p>
<p>自我保护：如果在15分钟内超过85%的客户端节点都没有正常的⼼跳，那么Eureka就认为客户端与注册中⼼出现了⽹络故障，Eureka Server⾃动进⼊⾃我保护机制。</p>
<p>1） 不会剔除任何服务实例，保证大多数服务可用</p>
<p>2） Eureka Server仍然能够接受新服务的注册和查询请求，但是不会同步，需要等网络稳定再同步。</p>
<p>3） 可配置开关：eureka.server.enable-self-preservation</p>
<h3 id="Ribbon负载均衡"><a href="#Ribbon负载均衡" class="headerlink" title="Ribbon负载均衡"></a>Ribbon负载均衡</h3><p>负载均衡分为服务器端负载均衡和客户端负载均衡</p>
<p>服务器端负载均衡：Nginx、F5等等，请求到达服务器之后由这些负载均衡器根据⼀定的算法将请求路由到⽬标服务器处理。</p>
<p>客户端负载均衡：Ribbon，服务消费者客户端会有⼀个服务器地址列表，调用⽅在请求前通过⼀定的负载均衡算法选择⼀个服务器进⾏访问，负载均衡算法的执行是在请求客户端进⾏。</p>
<p><img src="/posts/30414/asset/v2-327ddb45110b614dbe48472446af0d6b_720w.webp" alt="img"></p>
<p>负载均衡策略，定义在IRule接口</p>
<p><img src="/posts/30414/asset/v2-9976d059b75add3a2bfade6b676825e3_720w.webp" alt="img"></p>
<p><img src="/posts/30414/asset/v2-8d5f5ab9a1f10544fa14e46ea6856226_720w.webp" alt="img"></p>
<p><strong>Ribbon工作原理</strong></p>
<p><img src="https://pic2.zhimg.com/80/v2-676bfe41dbcc3e95de157d23f67defd1_720w.webp" alt="img"></p>
<p>Ribbon给restTemplate添加了⼀个拦截器interceptor方法，通过拦截器进行请求拦截，然后通过负载策略实现请求分发。</p>
<h3 id="Hystrix熔断器"><a href="#Hystrix熔断器" class="headerlink" title="Hystrix熔断器"></a>Hystrix熔断器</h3><p><strong>雪崩效应</strong></p>
<p><img src="/posts/30414/asset/v2-2b514c368d16ece7efea8100e54d34b5_720w.webp" alt="img"></p>
<p>扇⼊：代表着该微服务被调⽤的次数，扇⼊⼤，说明该模块复⽤性好</p>
<p>扇出：该微服务调⽤其他微服务的个数，扇出⼤，说明业务逻辑复杂</p>
<p>在微服务架构中，⼀个应用可能会有多个微服务组成，微服务之间的数据交互通过远程过程调⽤完成。这就带来⼀个问题，假设微服务A调用微服务B和微服务C，微服务B和微服务C又调用其它的微服务，这就是所谓的“扇出”。如果扇出的链路上某个微服务的调用响应时间过⻓或者不可⽤，对微服务A的调用就会占⽤越来越多的系统资源，进⽽引起系统崩溃，所谓的“雪崩效应”。</p>
<p><strong>解决方案</strong></p>
<p>服务熔断：当扇出链路的某个微服务不可⽤或者响应时间太⻓时，熔断该节点微服务的调⽤，进⾏服务的降级，快速返回错误的响应信息。当检测到该节点微服务调⽤响应正常后，恢复调⽤链路。</p>
<p>服务降级：先将⼀些不关紧的服务停掉（调⽤我的时候，给你返回⼀个预留的值，也叫做兜底数据），待渡过难关⾼峰过去，再把那些服务打开。</p>
<p>服务限流：服务降级是当服务出问题或者影响到核⼼流程的性能时，暂时将服务屏蔽掉，待⾼峰或者问题解决后再打开。</p>
<p><strong>Hystrix基础知识</strong></p>
<ol>
<li><p>包裹请求: 使⽤@HystrixCommand注解添加Hystrix控制，包裹对依赖的调用逻辑。⾃动投递微服务方法。</p>
</li>
<li><p>跳闸机制：当某服务的错误率超过⼀定的阈值时，Hystrix可以跳闸，停⽌请求 该服务⼀段时间。</p>
</li>
<li><p>资源隔离：Hystrix为每个依赖都维护了⼀个⼩型的线程池(舱壁模式)。如果该线程池已满，发往该依赖的请求就被⽴即拒绝，⽽不是排队等待，从而加速失败判定。</p>
</li>
<li><p>监控：Hystrix可以近乎实时地监控运⾏指标和配置的变化，如成功、失败、超时等等。</p>
</li>
<li><p>回退机制：当请求失败、超时、被拒绝，或当断路器打开时，执⾏回退逻辑，回退逻辑自定义。</p>
</li>
<li><p>自我修复：断路器打开⼀段时间后，会⾃动进⼊“半开”状态。</p>
</li>
</ol>
<p><strong>舱壁模式（线程池隔离策略）</strong></p>
<p>Hystrix线程池默认线程数是10个，当所有服务共用这个线程池，请求数量超过10个，那么一些服务就不可用了，因此诞生了舱壁模式，每一个控制方法创建一个线程池，也就是各自用自己的线程池。</p>
<p><img src="/posts/30414/asset/v2-bf4ca5a2a06afadea0ea42b7569da5cc_720w.webp" alt="img"></p>
<p><strong>Hystrix跳闸、自我修复</strong></p>
<p><img src="/posts/30414/asset/v2-c43c6c819dfc11ba76e50eeaac5a8634_720w.webp" alt="img"></p>
<p>1）当调用出现问题时，开启⼀个时间窗（10s）。</p>
<p>2）在这个时间窗内，统计调用次数是否达到最小请求数？如果没有达到，则重置统计信息，回到第1步 如果达到了，则统计失败的请求数占所有请求数的百分⽐，是否达到阈值？如果达到，则跳闸（不再请求对应服务） 如果没有达到，则重置统计信息，回到第1步 。</p>
<p>3）如果跳闸，则会开启⼀个活动窗⼝（默认5s），每隔5s，Hystrix会让⼀个请求通过,到达那个问题服务，看是否调用成功，如果成功，重置断路器回到第1步，如果失败，回到第3步。</p>
<p><strong>Hystrix</strong> <strong>DashBoard健康检查</strong></p>
<p>Hystrix官方提供了基于图形化的 DashBoard（仪表板）监控平台。通过搭建一个DashBoard项目实现对Hystrix仪表板每个断路器（被 @HystrixCommand注解的⽅法）的状态监控。</p>
<p><img src="/posts/30414/asset/v2-54783bbacc2a6ea8b65498cf09d7e6a8_720w.webp" alt="img"></p>
<p><strong>Hystrix Turbine聚合监控</strong></p>
<p>在集群环境下，结合dashboard仪表盘就需要每次输⼊⼀个监控数据流url进去查看，通过Hystrix Turbine聚合监控，专门新建一个Turbine监控项目可以实现聚合各个实例上的hystrix监控数据。</p>
<p><img src="/posts/30414/asset/v2-39d3a7346295978466b06f4afcafceda_720w.webp" alt="img"></p>
<h3 id="Feign远程调用组件"><a href="#Feign远程调用组件" class="headerlink" title="Feign远程调用组件"></a>Feign远程调用组件</h3><p>服务消费者调⽤服务提供者的时候使⽤RestTemplate技术需要拼接url以及getForObject存在硬编码。</p>
<p>Feign是Netflix开发的⼀个轻量级RESTful的HTTP服务客户端，以Java接⼝注解的⽅式调⽤Http请求，类似于dubbo，服务消费者拿到服务提供者的接⼝，然后像调用本地接⼝⽅法⼀样去调用，实际发出的是远程的请求。</p>
<p>本质：封装了Http调用流程，更符合⾯向接口化的编程习惯，类似于Dubbo的服务调用，基于代理实现。</p>
<p>Feign &#x3D; RestTemplate+Ribbon+Hystrix</p>
<p><strong>Feign对负载均衡的⽀持</strong></p>
<p>Feign 本身已经集成了Ribbon依赖和⾃动配置，因此我们不需要额外引⼊依赖，可以通过 ribbon.xx 来进⾏全局配置,也可以通过服务名.ribbon.xx 来对指定服务进⾏ 细节配置配置。</p>
<p><img src="/posts/30414/asset/v2-cf381216ebe11e587aa6fe2b50af783a_720w.webp" alt="img"></p>
<p><strong>Feign对熔断器的支持</strong></p>
<p>⾃定义FallBack处理类（需要实现FeignClient接⼝）；Feign集成了Hystrix，但是他们的超时是独立的，使用又是一起的，以最小值触发熔断。</p>
<p><img src="/posts/30414/asset/v2-8ac2c85f9b5e519af6c028992bca4278_720w.webp" alt="img"></p>
<p><img src="https://pic3.zhimg.com/80/v2-ae46d85f7b5f786d470b2c240e26fde2_720w.webp" alt="img"></p>
<p><strong>Feign的日志级别配置</strong></p>
<p>如果我们想看到Feign请求时的⽇志，首先要创建一个能被扫描到的配置类，通过这个类来加载配置的yml日志级别配置来实现。</p>
<p><img src="/posts/30414/asset/v2-027a157d21b9c485e4e069f6b8d30fbc_720w.webp" alt="img"></p>
<p><strong>Feign对请求压缩和响应压缩的⽀持</strong></p>
<p>Feign ⽀持对请求和响应进⾏GZIP压缩，以减少通信过程中的性能损耗，以配置方式实现。</p>
<h3 id="GateWay网关组件"><a href="#GateWay网关组件" class="headerlink" title="GateWay网关组件"></a>GateWay网关组件</h3><p>网关是微服务架构中的重要组成部分，基于Spring5.0+SpringBoot2.0+WebFlux等技术开发，性能比Zuul高，为微服务架构提供⼀种简单有效的统⼀的API路由管理⽅式。不仅可以提供统⼀的路由⽅式，还可以做过滤、鉴权、 流量控制、熔断、路径重写、日志监控等等。</p>
<p><img src="/posts/30414/asset/v2-a8f9cc7d4f683fe50572d252c9c19151_720w.webp" alt="img"></p>
<p><strong>GateWay核心</strong></p>
<p>路由（route）：最基础的部分，由⼀个ID、一个目标URL、⼀系列的断⾔（匹配条件判断）和 Filter过滤器（精细化控制）组成。如果断言为true，则匹配该路由。</p>
<p>断⾔（predicates）：匹配Http请求中的所有内容（包括请求头、请求参数等）</p>
<p>过滤器（filter）：请求之前或者之后执⾏业务逻辑。</p>
<p><img src="https://pic3.zhimg.com/80/v2-1e3cdf3beeec9831082f14ab3d9c88b6_720w.webp" alt="img"></p>
<p>工作流程，核心路由转发+执行过滤链</p>
<p><img src="https://pic3.zhimg.com/80/v2-29a8c0308049f351313d963b025bab62_720w.webp" alt="img"></p>
<p>客户端向Spring Cloud GateWay发出请求，然后在GateWay Handler Mapping中 找到与请求相匹配的路由，将其发送到GateWay Web Handler；Handler再通过指 定的过滤器链来将请求发送到我们实际的服务执⾏业务逻辑，然后返回。</p>
<p><strong>GateWay路由规则</strong></p>
<p><img src="https://pic3.zhimg.com/80/v2-64d3bfd6116f05ab102fb01f6e0b1f9e_720w.webp" alt="img"></p>
<p>可以实现时间前后，区间匹配、Cookie正则匹配、Host匹配、Method匹配、远程地址匹配等等。</p>
<p>GateWay动态路由：GateWay⽀持⾃动从注册中⼼中获取服务列表并访问，即所谓的动态路由。</p>
<p><strong>GateWay过滤器</strong></p>
<p>从过滤器⽣命周期分pre和post</p>
<p><img src="/posts/30414/asset/v2-2736d97614f2033156c3c4e1b934d008_720w.webp" alt="img"></p>
<p>从过滤器类型分GateWayFilter和 GlobalFilter，常用GlobalFilter，即全局过滤器。</p>
<p><img src="/posts/30414/asset/v2-23664497d5af2f4bb6b4b99dbc3a9a3c_720w.webp" alt="img"></p>
<p>GateWay高可用：可以启动多个GateWay实例来实现⾼可⽤，在GateWay 的上游使⽤Nginx等负载均衡设备进⾏负载转发以达到高可用的目的。</p>
<h3 id="Config分布式配置中心"><a href="#Config分布式配置中心" class="headerlink" title="Config分布式配置中心"></a>Config分布式配置中心</h3><p>Config Server是集中式的配置服务，⽤于集中管理应⽤程序各个环境下的配置。默认使⽤Git存储配置⽂件内容，也可以SVN。</p>
<p><strong>配置中心的优点</strong></p>
<p>1） 集中配置管理，多个微服务不同配置统一管控。</p>
<p>2） 不同环境不同配置，对于测试、生产等环境不同配置。</p>
<p>3） 实现运⾏期间可动态调整，如更改数据库连接信息，连接池等。</p>
<p>4） 配置内容发⽣变化，微服务可以⾃动更新配置</p>
<p><img src="https://pic4.zhimg.com/80/v2-67733eda7b7fdd550ee442d40e6d4ccf_720w.webp" alt="img"></p>
<p>Server 端：提供配置⽂件的存储、以接口的形式将配置⽂件的内容提供出去，通过使⽤@EnableConfigServer注解在 Spring boot 应⽤中⾮常简单的嵌⼊。</p>
<p>Client 端：通过接口获取配置数据并初始化自己的应用。</p>
<p>Config配置手动刷新</p>
<p>1）Client客户端添加依赖springboot-starter-actuator（已添加）</p>
<p>2）Client客户端bootstrap.yml中添加配置（暴露通信端点</p>
<p>3）Client客户端使⽤到配置信息的类上添加@RefreshScope</p>
<p>4）⼿动向Client客户端发起POST请求，<a href="http://localhost:8080/actuator/refresh%EF%BC%8C">http://localhost:8080/actuator/refresh，</a> 刷新配置信息</p>
<p><strong>Config配置⾃动更新，结合消息总线BUS，支持（RabbitMq&#x2F;Kafka）</strong></p>
<p>消息总线Bus，即我们经常会使⽤MQ消息代理构建⼀个共⽤的Topic，通过这个Topic连接各个微服务实例，MQ⼴播的消息会被所有在注册中⼼的微服务实例监听和消费。就是通过⼀个主题连接各个微服务，打通脉络。</p>
<p><img src="https://pic2.zhimg.com/80/v2-2109d7b215c50acaf9a90e85482278e9_720w.webp" alt="img"></p>
<ol>
<li>Config Server服务端添加消息总线⽀持</li>
</ol>
<p><img src="https://pic4.zhimg.com/80/v2-7d8e4965360cc36882756a6ed62ffbf3_720w.webp" alt="img"></p>
<ol start="2">
<li>ConfigServer添加配置连接RabbitMq</li>
</ol>
<p><img src="/posts/30414/asset/v2-8a8f95c2920be65f7861873a1b415b26_720w.webp" alt="img"></p>
<ol start="3">
<li>微服务暴露端口</li>
</ol>
<p><img src="https://pic3.zhimg.com/80/v2-38bb7be029177aa2a7d86a96ad8620b2_720w.webp" alt="img"></p>
<ol start="4">
<li>重启各个服务，更改配置之后，向配置中⼼服务端发送post请求<a href="http://localhost:9003/actuator/bus-refresh%EF%BC%8C%E5%90%84%E4%B8%AA%E5%AE%A2%E6%88%B7%E7%AB%AF%E9%85%8D%E7%BD%AE%E5%8D%B3%E5%8F%AF%E2%BE%83%E5%8A%A8%E5%88%B7%E6%96%B0%EF%BC%8C%E4%B9%9F%E6%94%AF%E6%8C%81%E5%AE%9A%E5%90%91%E5%88%B7%E6%96%B0%EF%BC%8C%E8%B7%9F%E6%9C%8D%E5%8A%A1%E5%90%8D:%E7%AB%AF%E5%8F%A3%E5%8F%B7%E5%8D%B3%E5%8F%AF%E3%80%82">http://localhost:9003/actuator/bus-refresh，各个客户端配置即可⾃动刷新，也支持定向刷新，跟服务名:端口号即可。</a></li>
</ol>
<h3 id="Stream消息驱动组件"><a href="#Stream消息驱动组件" class="headerlink" title="Stream消息驱动组件"></a>Stream消息驱动组件</h3><p>Spring Cloud Stream 消息驱动组件帮助我们更快速，更⽅便，更友好的去构建消息驱动微服务的。Spring Cloud Stream进⾏了很好的上层抽象，可以让我们与具体消息中间件解耦合，屏蔽掉了底层具体MQ消息中间件的细节差异，就像Hibernate屏蔽掉了具体数据库（Mysql&#x2F;Oracle⼀样）。</p>
<p>本质：屏蔽掉了底层不同MQ消息中间件之间的差异，统⼀了MQ的编程模型，降低了学习、开发、维护MQ的成本。</p>
<p>Spring Cloud Stream 是⼀个构建消息驱动微服务的框架。应⽤程序通过inputs（相 当于消息消费者consumer）或者outputs（相当于消息⽣产者producer）来与 Spring Cloud Stream中的binder对象交互，⽽Binder对象是⽤来屏蔽底层MQ细节 的，它负责与具体的消息中间件交互。对于我们来说，只需要知道如何使⽤Spring Cloud Stream与Binder对象交互即可。</p>
<p><img src="/posts/30414/asset/v2-1de6621ddcb950941a8d80406bec202c_720w.webp" alt="img"></p>
<p><strong>Binder绑定器</strong></p>
<p>通过它来屏蔽底层不同MQ消息中间件的细节差异，当需要更换为其他消息中间件时，我们需要做的就是更换对应的Binder绑定器。</p>
<p>Stream中的消息通信⽅式遵循了发布—订阅模式。当⼀条消息被投递到消息中间件之后，它会通过共享的Topic 主题进⾏⼴播，消息消费者在订阅的 主题中收到它并触发⾃身的业务逻辑处理。</p>
<p><img src="/posts/30414/asset/v2-2ada75a7b8ad9f5bb647676a6a6b320e_720w.webp" alt="img"></p>
<h3 id="常见问题及解决方案"><a href="#常见问题及解决方案" class="headerlink" title="常见问题及解决方案"></a>常见问题及解决方案</h3><p><strong>Eureka 服务发现慢的原因</strong></p>
<p>Eureka 服务发现慢的原因主要有两个，⼀部分是因为服务缓存导致的，另⼀部分是 因为客户端缓存导致的。</p>
<p><img src="/posts/30414/asset/v2-404fcca6f5e35c8d3b35e3dacc616fe5_720w.webp" alt="img"></p>
<p><strong>服务端缓存</strong></p>
<p>服务注册到注册中⼼后，服务实例信息是存储在内存中，为了提高响应效率，Eureta内部加了两层缓存结构，一二级缓存之间会进行数据同步，默认30S，当Client获取服务实例数据时，会先从⼀级缓存中获取，如果⼀级缓存中不存在，再从⼆级缓存中获取，如果⼆级缓存也不存在，会触发缓存的加载，从存储层拉取数据到缓存中，然后再返回给Client，服务下线、过期、注册、状态变更等操作都会清除二级缓存中的数据，基于Guava，默认过期180S，因此产生的弊端也出现了，同步时间有30S，会导致服务发现慢的问题，解决办法要么缩短更新时间，要么禁用一级缓存。</p>
<p><strong>客户端缓存</strong></p>
<p>Eureka Client负责跟Eureka Server进⾏交互，默认30S拉取一次数据，也可以缩短拉取时间。</p>
<p>Ribbon会从Eureka Client中获取服务信息，默认也是30S，也可以缩短定时更新时间。</p>
<p><strong>Spring Cloud 各组件超时，通过设置超时时间解决</strong></p>
<p>Ribbon 如果采⽤的是服务发现⽅式，就可以通过服务名去进⾏转发，需要配置 Ribbon的超时，Hystrix的超时时间要⼤于Ribbon的超时时间，因为Hystrix将请求包装了起来，特别需要注意的是，如果Ribbon开启了重试机制，⽐如 重试3 次，Ribbon 的超时为 1 秒，那么 Hystrix 的超时时间应该⼤于 3 秒，否则就 会出现 Ribbon 还在重试中，⽽Hystrix已经超时的现象。</p>
<p>Feign Feign本身也有超时时间的设置，如果此时设置了Ribbon的时间就以Ribbon的时间为准，如果没设置Ribbon的时间但配置了Feign的时间，就以Feign的时间为准。</p>
]]></content>
      <categories>
        <category>基础知识</category>
        <category>spring cloud</category>
      </categories>
      <tags>
        <tag>基础知识</tag>
        <tag>spring cloud</tag>
      </tags>
  </entry>
  <entry>
    <title>热部署原理</title>
    <url>/posts/20659/</url>
    <content><![CDATA[<p> <strong>springboot热部署原理</strong> </p>
<p> 基本原理就是我们在编辑器上启动项目，然后改动相关的代码，然后编辑器自动触发编译，替换掉历史的.class文件后，项目检测到有文件变更后会重启srpring-boot项目。内部主要是通过引入的插件对我们的classpath资源变化进行监听，当classpath有变化，才会触发重启。 </p>
<p> <img src="/posts/20659/asset/v2-14d162040ff1c4f5475f2c2cab0de8b3_720w.webp" alt="img"> </p>
<p> 从官方文档可以得知，其实这里对类加载采用了两种类加载器，对于第三方jar包采用baseclassloader来加载，对于开发人员自己开发的代码则使用restartClassLoader来进行加载，这使得比停掉服务重启要快的多，因为使用插件只是重启开发人员编写的代码部分。 </p>
]]></content>
      <categories>
        <category>基础知识</category>
        <category>springboot</category>
      </categories>
      <tags>
        <tag>基础知识</tag>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title>springboot基础</title>
    <url>/posts/55072/</url>
    <content><![CDATA[<p><a href="https://zhuanlan.zhihu.com/p/362984115">https://zhuanlan.zhihu.com/p/362984115</a></p>
<h3 id="Spring-Boot基础"><a href="#Spring-Boot基础" class="headerlink" title="Spring Boot基础"></a>Spring Boot基础</h3><p><strong>概念：</strong></p>
<p>约定优于配置，简单来说就是你所期待的配置与约定的配置一致，那么就可以不做任何配置，约定不符合期待时才需要对约定进行替换配置。</p>
<p><strong>特征：</strong></p>
<p>\1. SpringBoot Starter：他将常用的依赖分组进行了整合，将其合并到一个依赖中，这样就可以一次性添加到项目的Maven或Gradle构建中。</p>
<p>2,使编码变得简单，SpringBoot采用 JavaConfig的方式对Spring进行配置，并且提供了大量的注解，极大的提高了工作效率，比如@Configuration和@bean注解结合，基于@Configuration完成类扫描，基于@bean注解把返回值注入IOC容器。</p>
<p>3.自动配置：SpringBoot的自动配置特性利用了Spring对条件化配置的支持，合理地推测应用所需的bean并自动化配置他们。</p>
<p>4.使部署变得简单，SpringBoot内置了三种Servlet容器，Tomcat，Jetty,undertow.我们只需要一个Java的运行环境就可以跑SpringBoot的项目了，SpringBoot的项目可以打成一个jar包。</p>
<h3 id="Spring-Boot创建"><a href="#Spring-Boot创建" class="headerlink" title="Spring Boot创建"></a>Spring Boot创建</h3><p>Spring Boot项目结构图：</p>
<p> <img src="https://pic2.zhimg.com/80/v2-547fd47b7511da47e58c649b304b57dd_720w.webp" alt="img"> </p>
<h3 id="Spring-Boot热部署"><a href="#Spring-Boot热部署" class="headerlink" title="Spring Boot热部署"></a>Spring Boot热部署</h3><p>通过引入spring-bootdevtools插件，可以实现不重启服务器情况下，对项目进行即时编译。引入热部署插件的步骤如下：</p>
<p> \1. 在pom.xml添加热部署依赖 </p>
<p> <img src="https://pic2.zhimg.com/80/v2-681b63a841ce017d7a63179702e7bccd_720w.webp" alt="img"> </p>
<p> \2. IDEA热部署工具设置 </p>
<p> <img src="https://pic3.zhimg.com/80/v2-4467a1e457af28033b7ec6380f011d4a_720w.webp" alt="img"> </p>
<p> 在项目任意页面中使用组合快捷键“Ctrl+Shift+Alt+&#x2F;”打开Maintenance选项框，选中并打开Registry页面，列表中找到“compiler.automake.allow.when.app.running”，将该选项后的Value值勾选，用于指定IDEA工具在程序运行过程中自动编译，最后单击【Close】按钮完成设置。 </p>
<p> <img src="https://pic3.zhimg.com/80/v2-563eaf5ce882686336c8c0aff07207ce_720w.webp" alt="img"> </p>
<p><strong>排除资源:</strong></p>
<p>默认情况下，改变资源 &#x2F;META-INF&#x2F;maven ， &#x2F;META-INF&#x2F;resources ， &#x2F;resources ， &#x2F;static ， &#x2F;public ，或 &#x2F;templates 不触发重新启动，但确会触发现场重装。如果要自定义这些排除项，则可以使用该spring.devtools.restart.exclude 属性。例如，仅排除 &#x2F;static ， &#x2F;public 在application.properties设置以下属性。</p>
<p>spring.devtools.restart.exclude&#x3D;static&#x2F;<strong>,public&#x2F;</strong>,config&#x2F;**</p>
<h3 id="全局配置文件优先级"><a href="#全局配置文件优先级" class="headerlink" title="全局配置文件优先级"></a>全局配置文件优先级</h3><p>优先级：以下图顺序号代表配置文件的优先级，并且相同配置文件按顺序加载可以实现互补，但是不会被覆盖。</p>
<p><img src="https://pic2.zhimg.com/80/v2-82fed3dc047df18450d04703cfb59d09_720w.webp" alt="img"> 注意：Spring Boot 有application.properties 和 application.yaml 两种配置文件的方式，yaml是一种JSON超文本格式文件，如果是2.4.0之前版本，优先级properties&gt;yaml；但是如果是2.4.0的版本，优先级yaml&gt;properties。 </p>
<h3 id="自定义application-properties-配置文件注入IOC容器"><a href="#自定义application-properties-配置文件注入IOC容器" class="headerlink" title="自定义application.properties 配置文件注入IOC容器"></a>自定义application.properties 配置文件注入IOC容器</h3><p> <img src="/posts/55072/asset/v2-9d6b40b04964e201dce3dbc6641f75d4_720w.webp" alt="img"> </p>
<p> <img src="https://pic1.zhimg.com/80/v2-3c46f5da42820de49e5eb8c7fab65ee0_720w.webp" alt="img"> </p>
<p> 填加相应依赖配置可以实现在自定义配置properties配置提示 </p>
<p> <img src="/posts/55072/asset/v2-92dc165f57f1e236ea6d73653a8db5ad_720w.webp" alt="img"> </p>
<p> @ConfigurationProperties(prefix &#x3D; “person”)注解的作用是将配置文件中以person开头的属性值通过setXX()方法注入到实体类对应属性中。 </p>
<p> @Component注解的作用是将当前注入属性值的Person类对象作为Bean组件放到Spring容器中，只有这样才能被@ConfigurationProperties注解进行赋值。 </p>
<h3 id="application-yaml配置文件"><a href="#application-yaml配置文件" class="headerlink" title="application.yaml配置文件"></a>application.yaml配置文件</h3><p>YAML文件格式是Spring Boot支持的一种JSON超集文件格式，以数据为中心，比properties、xml等更适合做配置文件.</p>
<p>1.yml和xml相比，少了一些结构化的代码，使数据更直接，一目了然</p>
<p>2.相比properties文件更简洁</p>
<p>3.yaml文件的扩展名可以使用.yml或者.yaml。</p>
<p>4.application.yml文件使用 “key:（空格）value”格式配置属性，使用缩进控制层级关系。</p>
<p> <img src="/posts/55072/asset/v2-f8d9419e8254f857d0539b2e146583fc_720w.webp" alt="img"> </p>
<h3 id="属性注入"><a href="#属性注入" class="headerlink" title="属性注入"></a>属性注入</h3><p> 如果配置属性是Spring Boot已有属性，例如服务端口server.port，那么Spring Boot内部会自动扫描并读取这些配置文件中的属性值并覆盖默认属性。 </p>
<p>@Configuration：声明一个类作为配置类。</p>
<p>@Bean：声明在方法上，将方法的返回值加入Bean容器。</p>
<p>@Value：属性注入</p>
<p> <img src="https://pic4.zhimg.com/80/v2-46bc2d61fb489ac6479cc6dc3d904b3f_720w.webp" alt="img"> </p>
<p> <img src="/posts/55072/asset/v2-7d01e58adb8aa9b9e084346fb3457f6f_720w.webp" alt="img"> </p>
<p> @ConfigurationProperties(prefix &#x3D; “jdbc”)：批量属性注入。 </p>
<p> <img src="https://pic4.zhimg.com/80/v2-66cfb71ce0fe557b0f01ee2f5fc962db_720w.webp" alt="img"> </p>
<p> @PropertySource(“classpath:&#x2F;jdbc.properties”)指定外部属性文件，在类上添加。 </p>
<p> <strong>第三方配置：</strong> </p>
<p> @ConfigurationProperties 用于注释类之外，您还可以在公共 @Bean 方法上使用它。将属性绑定到控件之外的第三方组件 </p>
<p> <img src="https://pic3.zhimg.com/80/v2-2a25e9bf2907c9324e02df140a0a479e_720w.webp" alt="img"> </p>
<p> <img src="https://pic3.zhimg.com/80/v2-200a5543f214f7ffc51a355cd8010386_720w.webp" alt="img"> </p>
<p><strong>松散绑定：</strong></p>
<p>Spring Boot使用一些宽松的规则将环境属性绑定到@ConfigurationProperties bean，因此环境属性名和bean属性名之间不需要完全匹配，比如在application.properties文件里定义一个first-name&#x3D;tom，在对应bean类中使用firstName也能获取到对应的值，这就是松散绑定。</p>
<p> <img src="/posts/55072/asset/v2-196fe96ce06902e7edad3a4d2c8f195c_720w.webp" alt="img"> </p>
<p> <img src="https://pic4.zhimg.com/80/v2-5a894b73358fa839b3a62fb2ac1c9d37_720w.webp" alt="img"> </p>
<h3 id="Spring-Boot日志框架"><a href="#Spring-Boot日志框架" class="headerlink" title="Spring Boot日志框架"></a>Spring Boot日志框架</h3><p> <img src="https://pic2.zhimg.com/80/v2-bab52f59e94863057502641359786101_720w.webp" alt="img"> </p>
<p> <strong>SLF4J 的使用：</strong> </p>
<p> <img src="https://pic3.zhimg.com/80/v2-f2280e410b105c13c3e1a6be4c4cdc12_720w.webp" alt="img"> </p>
<p> 注意:由于每一个日志的实现框架都有自己的配置文件，所以在使用 SLF4j 之后，配置文件还是要使用实现日志框架的配置文件。 </p>
<p><strong>统一日志框架使用：</strong></p>
<p>实现步骤</p>
<p>\1. 排除系统中的其他日志框架。</p>
<p>\2. 使用中间包替换要替换的日志框架。</p>
<p>\3. 导入我们选择的 SLF4J 实现。</p>
<p> <img src="/posts/55072/asset/v2-70bb63dd32b6ae135ee44f0a82aa4e12_720w.webp" alt="img"> </p>
<p> 从图中我们得到一种统一日志框架使用的方式，可以使用一种要替换的日志框架类完全一样的 jar 进行替换，这样不至于原来的第三方 jar 报错，而这个替换的 jar 其实使用了 SLF4J API. 这样项目中的日志就都可以通过 SLF4J API 结合自己选择的框架进行日志输出。 </p>
<p> <strong>自定义日志输出：</strong> </p>
<p> 可以在配置文件编写日志相关配置实现自定义日志输出。 </p>
<p> <img src="https://pic4.zhimg.com/80/v2-cb1e6741b77460de2218ff471954e083_720w.webp" alt="img"> </p>
<p> <strong>替换日志框架：</strong> </p>
<p> <img src="https://pic3.zhimg.com/80/v2-cd1bd350c238d0dfaf964490be563cee_720w.webp" alt="img"> </p>
<h3 id="spring-boot-starter-parent"><a href="#spring-boot-starter-parent" class="headerlink" title="spring-boot-starter-parent"></a>spring-boot-starter-parent</h3><p> Spring Boot项目的统一版本父项目依赖管理。 </p>
<p> <img src="/posts/55072/asset/v2-5627b3a03583ea6364b89d39d4864970_720w.webp" alt="img"> </p>
<p> 在底层源文件定义了工程的Java版本；工程代码的编译源文件编码格式；工程编译后的文件编码格式；Maven打包编译的版本。 </p>
<p> <img src="https://pic2.zhimg.com/80/v2-81d3560f78fa1d53e0476fe26ca62a4d_720w.webp" alt="img"> </p>
<p> 接着在build节点做了资源过滤 </p>
<p> <img src="https://pic3.zhimg.com/80/v2-efbdd5a6b19c41cf74eb48480555ad1a_720w.webp" alt="img"> </p>
<p> 接着从spring-boot-starter-parent找到他父依赖 spring-boot-dependencies，从里面就可以发现里面定义了各种版本声明，通过这里声明可以让部分依赖不需要写版本号，一些没有引入的第三方jar包仍然需要自己声明版本号。 </p>
<p> <img src="/posts/55072/asset/v2-0ee0fcbd1904be49bd45070a54d9eaf9_720w.webp" alt="img"> </p>
<h3 id="spring-boot-starter-web"><a href="#spring-boot-starter-web" class="headerlink" title="spring-boot-starter-web"></a>spring-boot-starter-web</h3><p> Spring Boot项目的所依赖jar包进行打包起步依赖管理 </p>
<p> 在spring-boot-starter-web的父依赖spring-boot-starters包中，可以发现在他的dependencies标签有着各种依赖包引入，点进去就是具体包的导入配置管理。 </p>
<p> <img src="/posts/55072/asset/v2-69cc508febb9538441aede0170b18873_720w.webp" alt="img"> </p>
<p> 注意：Spring Boot官方并不是针对所有场景开发的技术框架都提供了场景启动器，例如阿里巴巴的Druid数据源等，Spring Boot官方就没有提供对应的依赖启动器。为了充分利用Spring Boot框架的优势，在Spring Boot官方没有整合这些技术框架的情况下，Druid等技术框架所在的开发团队主动与Spring Boot框架进行了整合，实现了各自的依赖启动器，例如druid-spring-boot-starter等。我们在pom.xml文件中引入这些第三方的依赖启动器时，切记要配置对应的版本号。 </p>
<h3 id="自动配置-SpringBootApplication"><a href="#自动配置-SpringBootApplication" class="headerlink" title="自动配置@SpringBootApplication"></a>自动配置@SpringBootApplication</h3><p> 他是一个组合注解，核心代码： </p>
<p> <img src="/posts/55072/asset/v2-ab6e7c4d9197aa1ea09d82e7f00178cc_720w.webp" alt="img"> </p>
<h3 id="自动配置-SpringBootConfiguration"><a href="#自动配置-SpringBootConfiguration" class="headerlink" title="自动配置@SpringBootConfiguration"></a>自动配置@SpringBootConfiguration</h3><h3 id="通过上面可以发现我们的核心启动类注解源码中含此注解，这个注解标注在某个类上，表示这是一个-Spring-Boot的配置类。他的核心代码中，内部有一个核心注解-Configuration来表明当前类是配置类，并且可以被组件扫描器扫到，所以-SpringBootConfiguration与-Configuration具有相同作用，只是前者又做了一次封装。"><a href="#通过上面可以发现我们的核心启动类注解源码中含此注解，这个注解标注在某个类上，表示这是一个-Spring-Boot的配置类。他的核心代码中，内部有一个核心注解-Configuration来表明当前类是配置类，并且可以被组件扫描器扫到，所以-SpringBootConfiguration与-Configuration具有相同作用，只是前者又做了一次封装。" class="headerlink" title="通过上面可以发现我们的核心启动类注解源码中含此注解，这个注解标注在某个类上，表示这是一个 Spring Boot的配置类。他的核心代码中，内部有一个核心注解@Configuration来表明当前类是配置类，并且可以被组件扫描器扫到，所以@SpringBootConfiguration与@Configuration具有相同作用，只是前者又做了一次封装。"></a>通过上面可以发现我们的核心启动类注解源码中含此注解，这个注解标注在某个类上，表示这是一个 Spring Boot的配置类。他的核心代码中，内部有一个核心注解@Configuration来表明当前类是配置类，并且可以被组件扫描器扫到，所以@SpringBootConfiguration与@Configuration具有相同作用，只是前者又做了一次封装。</h3><h3 id="自动配置-EnableAutoConfiguration"><a href="#自动配置-EnableAutoConfiguration" class="headerlink" title="自动配置@ EnableAutoConfiguration"></a>自动配置@ EnableAutoConfiguration</h3><p>Spring 中有很多以 Enable 开头的注解，其作用就是借助 @Import 来收集并注册特定场景相关的Bean ，并加载到 IOC 容器。而这个注解就是借助@Import来收集所有符合自动配置条件的bean定义，并加载到IoC容器，他的核心源码如下：</p>
<p> <img src="/posts/55072/asset/v2-2179ecd3c26db2e07b22c501b92799d4_720w.webp" alt="img"> </p>
<p> 通过@AutoConfigurationPackage注解进入类别，发现他通过import引入了一个AutoConfigurationPackages.Registrar.class，在Registrar.class中就重写了一个registerBeanDefinitions方法，在方法内部调用了一个register方法来实现将注解标注的元信息传入，获取到相应的包名。通俗点就是注册bean，然后根据 @AutoConfigurationPackage找到需要注册bean的类路径，这个路径就被自动保存了下来，后面需要使用bean，就直接获取使用，比如Spring Boot整合JPA可以完成一些注解扫描。 </p>
<p> <img src="/posts/55072/asset/v2-ed7df0ce4f9bf2b1e44dd98a10f7bfb0_720w.webp" alt="img"> </p>
<h3 id="自动配置-Import-AutoConfigurationImportSelector-class"><a href="#自动配置-Import-AutoConfigurationImportSelector-class" class="headerlink" title="自动配置@Import(AutoConfigurationImportSelector.class)"></a>自动配置@Import(AutoConfigurationImportSelector.class)</h3><p>该注解是Spring boot的底层注解，AutoConfigurationImportSelector类可以帮助 Springboot 应用将所有符合条件的 @Configuration配置都加载到当前Spring Boot创建并使用的IOC容器( ApplicationContext )中。</p>
<p><img src="/posts/55072/asset/v2-aebe7f29357a93dfa7d3e8583c3704d4_720w.webp" alt="img"></p>
<p><img src="/posts/55072/asset/v2-921a13c0228d4e55da498b0418c7196c_720w.webp" alt="img"></p>
<p>该注解实现了实现了 DeferredImportSelector 接口和各种Aware 接口，在源码中截图中，通过四个接口回调，把值返回给了</p>
<p>定义的四个成员变量。</p>
<p>1.自动配置逻辑相关的入口方法在 DeferredImportSelectorGrouping 类的 getImports 方法。</p>
<p><img src="https://pic2.zhimg.com/80/v2-1a3d199490c191d25e0f709ce4b16c85_720w.webp" alt="img"></p>
<p>2.自动配置的相关的绝大部分逻辑全在第一处也就是this.group.proces方法里，主要做的事就是在方法中，传入的 AutoConfigurationImportSelector对象来选择一些符合条件的自动配置类，过滤掉一些不符合条件的自动配置类，而第二处的this.group.selectImports的方法主要是针对前面的process方法处理后的自动配置类再进一步有选择的选择导入。</p>
<p><img src="/posts/55072/asset/v2-1408952343e2c4cf8055fa0c4b2a91c6_720w.webp" alt="img"></p>
<p>3.进入getAutoConfigurationEntry方法，这个方法主要是用来获取自动配置类有关，承担了自动配置的主要逻辑。AutoConfigurationEntry 方法主要做的事情就是获取符合条件的自动配置类，避免加载不必要的自动配置类从而造成内存浪费</p>
<p><img src="/posts/55072/asset/v2-ea80b4ce6df3e4f6566e529500b6e6d9_720w.webp" alt="img"></p>
<p><img src="/posts/55072/asset/v2-af8820e9cbd3bcf8c2d62d0a315b4bac_720w.webp" alt="img"></p>
<p>4.进入getCandidateConfigurations方法，里面有一个重要方法 loadFactoryNames ，这个方法是让 SpringFactoryLoader 去加载一些组件的名字。</p>
<p><img src="/posts/55072/asset/v2-75d35b6d5596b483dadac68cedc3b68c_720w.webp" alt="img"></p>
<p>5.进入 loadFactoryNames方法，获取到出入的键factoryClassName。</p>
<p><img src="https://pic2.zhimg.com/80/v2-868085c7957d052673fc4e8b4e0b7185_720w.webp" alt="img"></p>
<p>6.进入loadSpringFactories方法，加载配置文件，而这个配置文件就是spring.factories文件</p>
<p><img src="https://pic4.zhimg.com/80/v2-a470c307d7fd48396a578ffb742601db_720w.webp" alt="img"></p>
<p><img src="https://pic3.zhimg.com/80/v2-bc946ff6b39e3cb434d3debcc30d23a2_720w.webp" alt="img"></p>
<p>由此我们可以知道，在这个方法中会遍历整个ClassLoader中所有jar包下的spring.factories文件。spring.factories里面保存着springboot的默认提供的自动配置类。</p>
<p><strong>AutoConfigurationEntry 方法主要做的事情：</strong></p>
<p>【1】从 spring.factories 配置文件中加载 EnableAutoConfiguration 自动配置类）,获取的自动配置类如图所示。</p>
<p>【2】若 @EnableAutoConfiguration 等注解标有要 exclude 的自动配置类，那么再将这个自动配置类排除掉；</p>
<p>【3】排除掉要 exclude 的自动配置类后，然后再调用 filter 方法进行进一步的过滤，再次排除一些不符合条件的自动配置类；</p>
<p>【4】经过重重过滤后，此时再触发 AutoConfigurationImportEvent 事件，告诉ConditionEvaluationReport 条件评估报告器对象来记录符合条件的自动配置类；</p>
<p>【5】 最后再将符合条件的自动配置类返回。</p>
<p><strong>AutoConfigurationImportSelector 的 filter 方法</strong></p>
<p>主要做的事情就是调用AutoConfigurationImportFilter 接口的 match 方法来判断每一个自动配置类上的条件注解（若有的话） @ConditionalOnClass , @ConditionalOnBean 或 @ConditionalOnWebApplication 是否满足条件，若满足，则返回true，说明匹配，若不满足，则返回false说明不匹配。其实就是排除自动配置类，因为全部加载出来的类太多，不需要全部都反射成对象，而这个方法就是通过注解进行该自动配置类是否有相应匹配的类的判断，存在即加入，不存在即过滤。</p>
<p>@Conditional是Spring4新提供的注解，它的作用是按照一定的条件进行判断，满足条件给容器注册bean。</p>
<p>@ConditionalOnBean：仅仅在当前上下文中存在某个对象时，才会实例化一个Bean。</p>
<p>@ConditionalOnClass：某个class位于类路径上，才会实例化一个Bean。</p>
<p>@ConditionalOnExpression：当表达式为true的时候，才会实例化一个Bean。基于SpEL表达式的条件判断。</p>
<p>@ConditionalOnMissingBean：仅仅在当前上下文中不存在某个对象时，才会实例化一个Bean。</p>
<p>@ConditionalOnMissingClass：某个class类路径上不存在的时候，才会实例化一个Bean。</p>
<p>@ConditionalOnNotWebApplication：不是web应用，才会实例化一个Bean。</p>
<p>@ConditionalOnWebApplication：当项目是一个Web项目时进行实例化。</p>
<p>@ConditionalOnNotWebApplication：当项目不是一个Web项目时进行实例化。</p>
<p>@ConditionalOnProperty：当指定的属性有指定的值时进行实例化。</p>
<p>@ConditionalOnJava：当JVM版本为指定的版本范围时触发实例化。</p>
<p>@ConditionalOnResource：当类路径下有指定的资源时触发实例化。</p>
<p>@ConditionalOnJndi：在JNDI存在的条件下触发实例化。</p>
<p>@ConditionalOnSingleCandidate：当指定的Bean在容器中只有一个，或者有多个但是指定了首选的Bean时触发实例化。</p>
<p><strong>有选择的导入自动配置类</strong></p>
<p>在第一步最后的一个方法this.group.selectImports主要是针对经过排除掉 exclude 的和被AutoConfigurationImportFilter 接口过滤后的满足条件的自动配置类再进一步排除 exclude 的自动配置类，然后再排序，至此实现了自动配置。</p>
<p> <img src="/posts/55072/asset/v2-ccbdb3c4674074d54a32a5b165eb7475_720w.webp" alt="img"> </p>
<p> <img src="https://pic4.zhimg.com/80/v2-70b19eb776556de1c01454ff58de3e17_720w.webp" alt="img"> </p>
<h3 id="自动配置HttpEncodingAutoConfiguration实例"><a href="#自动配置HttpEncodingAutoConfiguration实例" class="headerlink" title="自动配置HttpEncodingAutoConfiguration实例"></a>自动配置HttpEncodingAutoConfiguration实例</h3><p><img src="https://pic2.zhimg.com/80/v2-3a37ceedb2cc9d19a13ef7a34bf8f7d1_720w.webp" alt="img"></p>
<p><img src="https://pic1.zhimg.com/80/v2-6935ab05923e55d2e938200e3a12b988_720w.webp" alt="img"></p>
<p>\1. SpringBoot 启动会加载大量的自动配置类</p>
<p>2.我们看我们需要实现的功能有没有 SpringBoot 默认写好的自动配置类</p>
<p>3.我们再来看这个自动配置类中到底配置了哪些组件；（只要我们有我们要用的组件，我们就不需要再来配置了）</p>
<p>4.给容器中自动配置类添加组件的时候，会从 properties 类中获取某些属性，我们就可以在配置文件中指定这些属性的值。</p>
<p>xxxAutoConfiguration ：自动配置类，用于给容器中添加组件从而代替之前我们手动完成大量繁琐的配置。</p>
<p>xxxProperties : 封装了对应自动配置类的默认属性值，如果我们需要自定义属性值，只需要根据xxxProperties 寻找相关属性在配置文件设值即可。</p>
<h3 id="ComponentScan注解"><a href="#ComponentScan注解" class="headerlink" title="@ComponentScan注解"></a>@ComponentScan注解</h3><p>主要作用是从定义的扫描路径中，找出标识了需要装配的类自动装配到spring 的bean容器中。默认扫描路径是为@ComponentScan注解的类所在的包为基本的扫描路径（也就是标注了@SpringBootApplication注解的项目启动类所在的路径），所以这里就解释了之前spring boot为什么只能扫描自己所在类的包及其子包。</p>
<p>常用属性：</p>
<p>basePackages、value：指定扫描路径，如果为空则以@ComponentScan注解的类所在的包为基本的扫描路径。</p>
<p>basePackageClasses：指定具体扫描的类。</p>
<p>includeFilters：指定满足Filter条件的类。</p>
<p>excludeFilters：指定排除Filter条件的类。</p>
<p><img src="https://pic3.zhimg.com/80/v2-0b9745335e09d707774295329dd2f0da_720w.webp" alt="img"></p>
<p>SpringApplication() 构造方法</p>
<p><img src="/posts/55072/asset/v2-e547ed4682934cadb3153aff2604b1af_720w.webp" alt="img"></p>
<p>第二步getSpringFactoriesInstances方法解析</p>
<p><img src="https://pic4.zhimg.com/80/v2-bb5291c3b15d677b91e58af4f9916907_720w.webp" alt="img"></p>
<p>主要就是 loadFactoryNames()方法，这个方法是spring-core中提供的从META-INF&#x2F;spring.factories中获取指定的类（key）的同一入口方法，获取的是key为 org.springframework.context.ApplicationContextInitializer 的类，是Spring框架的类, 这个类的主要目的就是在ConfigurableApplicationContext 调用refresh()方法之前，回调这个类的initialize方法。通过 ConfigurableApplicationContext 的实例获取容器的环境Environment，从而实现对配置文件的修改完善等工作。</p>
<p><img src="https://pic3.zhimg.com/80/v2-dab2c72f5a1f878026c75aa1a51a9e6a_720w.webp" alt="img"></p>
<p><img src="/posts/55072/asset/v2-1dc9669949a7ac5b9eaf0a8c3f36171a_720w.webp" alt="img"></p>
<h3 id="源码剖析Run方法整体流程"><a href="#源码剖析Run方法整体流程" class="headerlink" title="源码剖析Run方法整体流程"></a>源码剖析Run方法整体流程</h3><p>重要六步：</p>
<p>第一步：获取并启动监听器</p>
<p>第二步：构造应用上下文环境</p>
<p>第三步：初始化应用上下文</p>
<p>第四步：刷新应用上下文前的准备阶段</p>
<p>第五步：刷新应用上下文</p>
<p>第六步：刷新应用上下文后的扩展接口</p>
<p><img src="https://pic4.zhimg.com/80/v2-1e6100b11d0252991089d6764d65cbfb_720w.webp" alt="img"></p>
<p><img src="https://pic2.zhimg.com/80/v2-94ecab2625048a815b5d8231dcea5c81_720w.webp" alt="img"></p>
<p><img src="https://pic3.zhimg.com/80/v2-0823169e8e7cd2ccdb3cf9d5110a180a_720w.webp" alt="img"></p>
<h3 id="Run方法第一步：获取并启动监听器"><a href="#Run方法第一步：获取并启动监听器" class="headerlink" title="Run方法第一步：获取并启动监听器"></a>Run方法第一步：获取并启动监听器</h3><p>事件机制在Spring是很重要的一部分内容，通过事件机制我们可以监听Spring容器中正在发生的一些事件，同样也可以自定义监听事件。Spring的事件为Bean和Bean之间的消息传递提供支持。当一个对象处理完某种任务后，通知另外的对象进行某些处理，常用的场景有进行某些操作后发送通知，消息、邮件等情况。</p>
<p><img src="https://pic4.zhimg.com/80/v2-11fd5acfa745d0b7c33f0c6c30aae50f_720w.webp" alt="img"></p>
<p>通过getRunListeners方法来获取监听器，在getRunListeners方法内部调用了一个getSpringFactoriesInstances方法，返回值是一个SpringApplicationRunListeners有参构造的监听器类，这个方法加载SpringApplicationRunListener类，把这个类当做key,这个类的作用就是负责在SpringBoot启动的不同阶段，广播出不同的消息，传递给ApplicationListener监听器实现类。</p>
<p><img src="/posts/55072/asset/v2-0791d3fc7432e2fa2a83ec9f39a87b70_720w.webp" alt="img"></p>
<p>getSpringFactoriesInstances方法被重复使用。</p>
<p><img src="https://pic3.zhimg.com/80/v2-f03ae84183ddc2644f347e493277af6e_720w.webp" alt="img"></p>
<p>总结：如何获取到监听器并进行启动开启监听。</p>
<h3 id="Run方法第二步：构造应用上下文环境"><a href="#Run方法第二步：构造应用上下文环境" class="headerlink" title="Run方法第二步：构造应用上下文环境"></a>Run方法第二步：构造应用上下文环境</h3><p>应用上下文环境包括什么呢？包括计算机的环境，Java环境，Spring的运行环境，Spring项目的配置（在SpringBoot中就是那个熟悉的application.properties&#x2F;yml）等等。</p>
<p><img src="https://pic3.zhimg.com/80/v2-e53f2643f3a0606937cc7baf0ebf8886_720w.webp" alt="img"></p>
<p>通过prepareEnvironment方法创建并按照相应的应用类型配置相应的环境，然后根据用户的配置，配置系统环境，然后启动监听器，并加载系统配置文件。</p>
<p>主要步骤方法：</p>
<p>getOrCreateEnvironment方法</p>
<p>configureEnvironment方法</p>
<p>listeners.environmentPrepared方法</p>
<p><img src="https://pic4.zhimg.com/80/v2-89a1924292b8390a144718807ed97b8f_720w.webp" alt="img"></p>
<p>总结：最终目的就是把环境信息封装到environment对象中，方便后面使用。</p>
<h3 id="Run方法第三步：初始化应用上下文"><a href="#Run方法第三步：初始化应用上下文" class="headerlink" title="Run方法第三步：初始化应用上下文"></a>Run方法第三步：初始化应用上下文</h3><p>通过createApplicationContext方法构建应用上下文对象context，而context中有一个属性beanFactory他是一个DefaultListableBeanFactory类，这就是我们所说的IoC容器。应用上下文对象初始化的同时IOC容器也被创建了。</p>
<p> 通过createApplicationContext方法构建应用上下文对象context，而context中有一个属性beanFactory他是一个DefaultListableBeanFactory类，这就是我们所说的IoC容器。应用上下文对象初始化的同时IOC容器也被创建了。</p>
<p><img src="https://pic4.zhimg.com/80/v2-dc58004a87011062fb8cb341c354b9df_720w.webp" alt="img"></p>
<p>在SpringBoot工程中，应用类型分为三种</p>
<p><img src="https://pic4.zhimg.com/80/v2-757bf1e06eb243c698991599314efbb3_720w.webp" alt="img"></p>
<p>通过反射拿到配置类的字节码对象并通过BeanUtils.instantiateClass方法进行实例化并返回。</p>
<p><img src="https://pic3.zhimg.com/80/v2-b0231e81c593502a788c0fa7ec71ce0e_720w.webp" alt="img"></p>
<p>总结：就是创建应用上下文对象同时创建了IOC容器。</p>
<h3 id="Run方法第四步：刷新应用上下文前的准备阶段"><a href="#Run方法第四步：刷新应用上下文前的准备阶段" class="headerlink" title="Run方法第四步：刷新应用上下文前的准备阶段"></a>Run方法第四步：刷新应用上下文前的准备阶段</h3><p>主要的目的就是为前面的上下文对象context进行一些属性值的设置，在执行过程中还要完成一些Bean对象的创建，其中就包含核心启动类的创建。</p>
<p><img src="https://pic4.zhimg.com/80/v2-7f6d3c5722c9674e3250045553f92423_720w.webp" alt="img"></p>
<p>属性设置</p>
<p><img src="https://pic4.zhimg.com/80/v2-f58152cb940e9f6975db26a80874c30f_720w.webp" alt="img"></p>
<p>Bean对象创建</p>
<p><img src="https://pic2.zhimg.com/80/v2-542814d1a89f8ab7f6d966be93f19a59_720w.webp" alt="img"></p>
<p>Spring容器在启动的时候，会将类解析成Spring内部的beanDefintion结构，并将beanDefintion存储到DefaultListableBeanFactory的Map中。BeanDefinitionLoader方法就是完成赋值。</p>
<p><img src="https://pic3.zhimg.com/80/v2-b907de96388ba5d329b230dbf3e318a6_720w.webp" alt="img"></p>
<p><img src="https://pic3.zhimg.com/80/v2-ab266871b53a12740877843c927b8a2e_720w.webp" alt="img"></p>
<p>总结：就是应用上下文属性的设置并把核心启动类生成实例化对象存储到容器中。</p>
<h3 id="Run方法第五步：刷新应用上下文"><a href="#Run方法第五步：刷新应用上下文" class="headerlink" title="Run方法第五步：刷新应用上下文"></a>Run方法第五步：刷新应用上下文</h3><p>Spring Boot的自动配置原理：通常来说主要就是依赖核心启动类上面的@SpringBootApplication注解，这个注解是一个组合注解，他组合了@EnableAutoConfiguration这个注解，在run方法启动会执行getImport方法，最终找到process方法，进行注解的扫描，通过注解组合关系，在底层借助@Import注解向容器导入AutoConfigurationImportSelector.class组件类，这个类在执行过程中他会去加载WEB-INF下名称为spring.factories的文件，从这个文件中根据EnableAutoConfiguration这个key来加载pom.xml引入的所有对应自动配置工厂类的全部路径配置，在经过过滤，选出真正生效的自动配置工厂类去生成实例存到容器中，从而完成自动装配。如果从Main方法的Run方法出发，了解实际实现的原理，就能知道他是怎么通过Main方法找到主类，然后再扫描主类注解，完成一系列操作。而在刷新应用上下文这步就是根据找到的主类来执行解析注解，完成自动装配的一系列过程。</p>
<p>通过refreshContext()方法一路跟下去，最终来到AbstractApplicationContext类的refresh()方法，其中最重要的方法就是invokeBeanFactoryPostProcessors方法，他就是在上下文中完成Bean的注册。</p>
<p><img src="https://pic3.zhimg.com/80/v2-63c4fa85ff2494daf3bbce66ba53b18e_720w.webp" alt="img"></p>
<p><strong>运行步骤：</strong></p>
<p>1.prepareRefresh()刷新上下文</p>
<p>2.obtainFreshBeanFactory()在第三步初始化应用上下文中我们创建了应用的上下文，并触发了GenericApplicationContext类的构造方法如下所示，创建了beanFactory，也就是创建了DefaultListableBeanFactory类，这里就是拿到之前创建的beanFactory。</p>
<p>3.prepareBeanFactory()对上面获取的beanFactory，准备bean工厂，以便在此上下文中使用。</p>
<p>4.postProcessBeanFactory()向上下文中添加了一系列的Bean的后置处理器。</p>
<p>接着就进入到我们最重要的invokeBeanFactoryPostProcessors()方法，完成了IoC容器初始化过程的三个步骤：</p>
<p>1） 第一步：Resource定位</p>
<p><img src="/posts/55072/asset/v2-db59491e6362196eaa484927b8300472_720w.webp" alt="img"></p>
<p>2） 第二步：BeanDefinition的载入</p>
<p><img src="https://pic3.zhimg.com/80/v2-ec058905218e8316dda9999fa534af6a_720w.webp" alt="img"></p>
<p>3） 第三个过程：注册BeanDefinition</p>
<p><img src="https://pic1.zhimg.com/80/v2-7a2302437a9a09e4bfddeec9904eed30_720w.webp" alt="img"></p>
<p>总结：spring启动过程中，就是通过各种扫描，获取到对应的类，然后将类解析成spring内部的BeanDefition结构，存到容器中(注入到ConCurrentHashMap中)，也就是最后的beanDefinitionMap中。</p>
<p><strong>第一步分析：</strong></p>
<p>主要方法，从invokeBeanFactoryPostProcessors方法一直往下跟，直到ConfigurationClassPostProcessor类的parse方法，会发现他把核心启动类传入了这个方法中。</p>
<p><img src="https://pic1.zhimg.com/80/v2-6dac40a4c057c30652ebee8dd78e98d0_720w.webp" alt="img"></p>
<p>在这个方法内部，他判断这个类上知否存在注解，如果存在继续进入下一个方法，直到真正做事的doProcessConfigurationClass方法，在这个方法类，他就开始处理@ComponentScan注解，获取到componentScans对象，然后调用this.componentScanParser.parse方法对他进行解析。</p>
<p><img src="https://pic3.zhimg.com/80/v2-110be9e066c85757b0b8f4988db4e772_720w.webp" alt="img"></p>
<p>在方法内部根据basePackages获取对应类全限定集合，如果集合为空，就把当前的核心启动类全限定名的包名即com.lg加入，设置为basePackages(扫描的包范围)，这里就完成了第一步，获取扫描路径。</p>
<p><img src="https://pic2.zhimg.com/80/v2-221356e1a3b48e21e5b7796c4734f1e1_720w.webp" alt="img"></p>
<p><strong>第二步分析</strong></p>
<p>接着再跳到doScan方法，开始把他转成BeanDefition并注入IOC容器。</p>
<p><img src="https://pic4.zhimg.com/80/v2-886203bc7497163c3b430965d3dcf78f_720w.webp" alt="img"></p>
<p>在doScan方法中第一个关键点findCandidateComponents方法，根据传入的初始路径地址扫描该包及其子包所有的class，并封装成BeanDefinition并存入一个Set集合中，完成第二步。</p>
<p><img src="https://pic1.zhimg.com/80/v2-2913ef8d3f9de278faff8a33ad02bfd4_720w.webp" alt="img"></p>
<p><strong>第三步分析</strong></p>
<p>有了BeanDefinition集合之后，对他进行遍历，在遍历的最后调用了一个registerBeanDefinition方法进行注册BeanDefinition。</p>
<p><img src="https://pic2.zhimg.com/80/v2-efdeaf3907d34324c98e3bcf04a52401_720w.webp" alt="img"></p>
<p>在方法内部，执行到他的实现类DefaultListableBeanFactory中的registerBeanDefinition方法，就直接通过put方式把BeanDefinition注册进了beanDefinitionMap中。</p>
<p><img src="https://pic4.zhimg.com/80/v2-aa0336560f0e349e5966b2514c8f8853_720w.webp" alt="img"></p>
<p><strong>@Import注解指定类解析</strong></p>
<p>解析完主类扫描包之后，接着又开始解析@import注解指定类。</p>
<p><img src="https://pic1.zhimg.com/80/v2-78b8e1008e1bb87088de9e9cce56aae8_720w.webp" alt="img"></p>
<p>首先参数里面有一个getImports方法，他作用就是根据@import注解来获取到要导入到容器中的组件类。他从核心启动类中找到对应的@Import注解。在内部最终要的collectImports方法中，进行递归调用一直找到有@import注解的全类名，最后返回所有有@Import注解的组件类。</p>
<p><img src="https://pic1.zhimg.com/80/v2-d10a7b4bb6fa282af8cc5228edbba92c_720w.webp" alt="img"></p>
<p>获取到注解组件类之后，就需要去执行组件类了，回到ConfigurationClassParser类的parse方法，执行this.deferredImportSelectorHandler.process方法。</p>
<p><img src="https://pic1.zhimg.com/80/v2-91a2a844807619655cf374d1bc51cf7c_720w.webp" alt="img"></p>
<p>接着往下走最后到processGroupImports方法内，里面有非常重要的一步grouping.getImports()。</p>
<p><img src="/posts/55072/asset/v2-94e3df046e0ec7c271dbc389e8f3f0f5_720w.webp" alt="img"></p>
<p>先通过grouping.getImports()方法里面调用了process方法，加载spring.factories文件配置所有类，一步步过滤，最后封装成AutoConfigurationEntry对象返回，把这些对象放入Map&lt;String, AnnotationMetadata&gt; entries集合中。</p>
<p><img src="https://pic1.zhimg.com/80/v2-791dcbe38404ce499c7fe9827f7e1ba0_720w.webp" alt="img"></p>
<p><img src="https://pic3.zhimg.com/80/v2-bf315b92ded859ce1dfa007eaec2cdf6_720w.webp" alt="img"></p>
<p>最后通过this.group.selectImports()方法再进行过滤排序，返回要生效的自动装配对象全路径集合，最后通过this.reader.loadBeanDefinitions(configClasses)方法使这些自动装配类全部生效。</p>
<h3 id="Run方法第六步：刷新应用上下文后的扩展接口"><a href="#Run方法第六步：刷新应用上下文后的扩展接口" class="headerlink" title="Run方法第六步：刷新应用上下文后的扩展接口"></a>Run方法第六步：刷新应用上下文后的扩展接口</h3><p>afterRefresh方法，他其实就是一个扩展接口，设计模式中的模板方法，默认为空实现。如果有自定义需求，可以重写该方法。比如打印一些启动结束log，或者一些其它后置处理。</p>
<p><img src="https://pic1.zhimg.com/80/v2-f3521450557074b44d319a72a2e8b6f0_720w.webp" alt="img"></p>
]]></content>
      <categories>
        <category>基础知识</category>
        <category>springboot</category>
      </categories>
      <tags>
        <tag>基础知识</tag>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title>tomcat相关知识</title>
    <url>/posts/2320/</url>
    <content><![CDATA[<h2 id="一、-Tomcat系统架构和原理剖析"><a href="#一、-Tomcat系统架构和原理剖析" class="headerlink" title="一、 Tomcat系统架构和原理剖析"></a>一、 Tomcat系统架构和原理剖析</h2><h3 id="浏览器访问服务器的流程"><a href="#浏览器访问服务器的流程" class="headerlink" title="浏览器访问服务器的流程"></a>浏览器访问服务器的流程</h3><p><img src="https://pic3.zhimg.com/80/v2-bcc32c3b6cb7a2ba6b1a272b2c0c3fe2_720w.webp" alt="img"></p>
<p>浏览器访问服务器使⽤的是Http协议，Http是应⽤层协议，⽤于定义数据通信的格式，具体的数据传输使⽤的是TCP&#x2F;IP协议。</p>
<h3 id="Tomcat-系统总体架构"><a href="#Tomcat-系统总体架构" class="headerlink" title="Tomcat 系统总体架构"></a>Tomcat 系统总体架构</h3><p><strong>Tomcat的两个身份：</strong></p>
<p>1）http服务器</p>
<p>2）Tomcat是⼀个Servlet容器</p>
<p>Tomcat是⼀个Http服务器，HTTP 服务器接收到请求之后把请求交给Servlet容器来处理，Servlet 容器通过Servlet接⼝调⽤业务类，避免tomcat和业务类耦合在一起。Servlet接⼝和Servlet容器这⼀整套内容就是Servlet规范。</p>
<p><strong>Tomcat Servlet容器处理流程：</strong></p>
<p>1）HTTP服务器会把请求信息使⽤ServletRequest对象封装起来</p>
<p>2）进⼀步去调⽤Servlet容器中某个具体的Servlet</p>
<p>3）Servlet容器拿到请求后，根据URL和Servlet的映射关系，找到相应的Servlet</p>
<p>4）如果Servlet还没有被加载，就⽤反射机制创建这个Servlet，并调⽤Servlet的init⽅法来完成初始化</p>
<p>5）接着调⽤这个具体Servlet的service⽅法来处理请求，请求处理结果使⽤ServletResponse对象封装</p>
<p>6）把ServletResponse对象返回给HTTP服务器，HTTP服务器会把响应发送给客户端</p>
<p><img src="/posts/2320/asset/v2-ee60ca4269df3c0cd4cab06a5fda162c_720w.webp" alt="img"></p>
<p>总结：Tomcat主要干两个事情</p>
<p>1）和客户端浏览器进⾏交互，进⾏socket通信，将字节流和Request&#x2F;Response等对象进⾏转换</p>
<p>2）Servlet容器处理业务逻辑</p>
<p><img src="/posts/2320/asset/v2-c13efe3143f8b39f8eb8f0140ce6d808_720w.webp" alt="img"></p>
<p>Tomcat设计了两个核心组件：连接器（Connector）和容器（Container）来干上面的两个事情</p>
<p>连接器，负责对外交流： 处理Socket连接，负责⽹络字节流与Request和Response对象的转化</p>
<p>容器，负责内部处理：加载和管理Servlet，以及具体处理Request请求</p>
<h3 id="Tomcat-两大组件之连接器组件-Coyote"><a href="#Tomcat-两大组件之连接器组件-Coyote" class="headerlink" title="Tomcat 两大组件之连接器组件 Coyote"></a>Tomcat 两大组件之连接器组件 Coyote</h3><p>客户端通过Coyote与服务器建⽴连接、发送请求并接受响应：</p>
<p>（1）Coyote 封装了底层的⽹络通信（Socket 请求及响应处理）</p>
<p>（2）Coyote 使Catalina 容器（Container容器组件）与具体的请求协议及IO操作⽅式完全解 耦</p>
<p>（3）Coyote 将Socket 输⼊转换封装为 Request 对象，进⼀步封装后交由Catalina 容器进⾏处理，处理请求完成后, Catalina 通过Coyote 提供的Response 对象将结果写⼊输出流。</p>
<p>（4）Coyote 负责的是具体协议（应⽤层）和IO（传输层）相关内容</p>
<p><img src="/posts/2320/asset/v2-c759466c59b5bef458bb03e6e6fed860_720w.webp" alt="img"></p>
<p><img src="https://pic3.zhimg.com/80/v2-18b84208b91eb96c8a86e3321d88819a_720w.webp" alt="img"></p>
<p>注意： 8.0 之前 ，Tomcat 默认采⽤的I&#x2F;O⽅式为 BIO，之后改为 NIO。 ⽆论 NIO、NIO2 还是 APR， 在性能⽅⾯均优于以往的BIO。 如果采⽤APR， 甚⾄可以达到 Apache HTTP Server 的影响性能。</p>
<p><strong>Coyote 的内部组件及流程</strong></p>
<p><img src="https://pic4.zhimg.com/80/v2-39c0a3f4f15e3145b027642fe58b18a7_720w.webp" alt="img"></p>
<p><img src="/posts/2320/asset/v2-53e20b5df0ff36af93d1f6966754c572_720w.webp" alt="img"></p>
<h3 id="Tomcat-两大组件之Servlet容器组件Catalina"><a href="#Tomcat-两大组件之Servlet容器组件Catalina" class="headerlink" title="Tomcat 两大组件之Servlet容器组件Catalina"></a>Tomcat 两大组件之Servlet容器组件Catalina</h3><p>Tomcat是由⼀系列可配置（conf&#x2F;server.xml）的组件构成的Web容器，⽽Catalina是Tomcat的servlet容器。</p>
<p>Tomcat 本质上就是⼀款 Servlet 容器， 因此Catalina 才是 Tomcat 的核⼼ ， 其他模块都是为Catalina 提供⽀撑的。 ⽐如 ： 通过 Coyote 模块提供链接通信，Jasper 模块提供 JSP 引擎，Naming 提供JNDI 服务，Juli 提供⽇志服务。</p>
<p><img src="/posts/2320/asset/v2-13a2961e40c91c570c266bca59975da4_720w.webp" alt="img"></p>
<p>整个Tomcat就是⼀个Catalina实例，一个Catalina实例有一个Server实例，一个Server实例可以有多个Service实例, 每⼀个Service实例下可以有多个Connector实例和⼀个Container实例。</p>
<p><img src="/posts/2320/asset/v2-510fd9477057e5a52a756bd8ef793219_720w.webp" alt="img"></p>
<p><strong>Catalina</strong></p>
<p>负责解析Tomcat的配置⽂件（server.xml） , 以此来创建服务器Server组件并进⾏管理</p>
<p><strong>Server</strong></p>
<p>服务器表示整个Catalina Servlet容器以及其它组件，负责组装并启动Servlaet引擎,Tomcat连接器。Server通过实现Lifecycle接⼝，提供了⼀种优雅的启动和关闭整个系统的⽅式</p>
<p><strong>Service</strong></p>
<p>服务是Server内部的组件，⼀个Server包含多个Service。它将若⼲个Connector组件绑定到⼀个</p>
<p><strong>Container</strong></p>
<p>Container容器，负责处理⽤户的servlet请求，并返回对象给web⽤户的模块</p>
<p>Container组件下有四种具体的组件，分别是Engine、Host、Context和Wrapper，他们是层级关系。</p>
<p>Engine：表示整个Catalina的Servlet引擎，⽤来管理多个虚拟站点，⼀个Service最多只能有⼀个Engine，但是⼀个引擎可包含多个Host。</p>
<p>Host：代表⼀个虚拟主机，或者说⼀个站点，可以给Tomcat配置多个虚拟主机地址，⽽⼀个虚拟主机下可包含多个Context。</p>
<p>Context：表示⼀个Web应⽤程序， ⼀个Web应⽤可包含多个Wrapper。</p>
<p>Wrapper：表示⼀个Servlet，Wrapper 作为容器中的最底层，不能包含⼦容器。</p>
<h3 id="Tomcat-服务器核⼼配置Server标签"><a href="#Tomcat-服务器核⼼配置Server标签" class="headerlink" title="Tomcat 服务器核⼼配置Server标签"></a>Tomcat 服务器核⼼配置Server标签</h3><p><img src="/posts/2320/asset/v2-622f76582bd94b47974270835ceaa099_720w.webp" alt="img"></p>
<h3 id="Tomcat-服务器核⼼配置Service标签"><a href="#Tomcat-服务器核⼼配置Service标签" class="headerlink" title="Tomcat 服务器核⼼配置Service标签"></a>Tomcat 服务器核⼼配置Service标签</h3><p><img src="/posts/2320/asset/v2-21c4cb12633df3bdfacce9cca08cb1fe_720w.webp" alt="img"></p>
<h3 id="Tomcat-服务器核⼼配置Executor标签"><a href="#Tomcat-服务器核⼼配置Executor标签" class="headerlink" title="Tomcat 服务器核⼼配置Executor标签"></a>Tomcat 服务器核⼼配置Executor标签</h3><p><img src="/posts/2320/asset/v2-8dcb6a0b0ac86d8d747f003460ec0013_720w.webp" alt="img"></p>
<h3 id="Tomcat-服务器核⼼配置Connector标签"><a href="#Tomcat-服务器核⼼配置Connector标签" class="headerlink" title="Tomcat 服务器核⼼配置Connector标签"></a>Tomcat 服务器核⼼配置Connector标签</h3><p>Connector 标签⽤于创建链接器实例默认情况下，server.xml 配置了两个链接器，⼀个⽀持HTTP协议，⼀个⽀持AJP协议</p>
<p>⼤多数情况下，我们并不需要新增链接器配置，只是根据需要对已有链接器进⾏优化.</p>
<p><img src="https://pic2.zhimg.com/80/v2-73127870fcce3df98ba75cf41be8b951_720w.webp" alt="img"></p>
<p>共享线程池:配置共享线程池，多个connector共用，节约资源。</p>
<p><img src="/posts/2320/asset/v2-b50d8789d9bc5aa78a05ff0e8f17d4a0_720w.webp" alt="img"></p>
<h3 id="Tomcat-服务器核⼼配置Engine标签"><a href="#Tomcat-服务器核⼼配置Engine标签" class="headerlink" title="Tomcat 服务器核⼼配置Engine标签"></a>Tomcat 服务器核⼼配置Engine标签</h3><p>Engine 表示 Servlet 引擎</p>
<p><img src="/posts/2320/asset/v2-d9ee115004f4f524cd6857a60df57614_720w.webp" alt="img"></p>
<h3 id="Tomcat-服务器核⼼配置Host标签"><a href="#Tomcat-服务器核⼼配置Host标签" class="headerlink" title="Tomcat 服务器核⼼配置Host标签"></a>Tomcat 服务器核⼼配置Host标签</h3><p><img src="/posts/2320/asset/v2-6b75de029050e1aa324cde5f5aabea06_720w.webp" alt="img"></p>
<h3 id="Tomcat-服务器核⼼配置Context标签"><a href="#Tomcat-服务器核⼼配置Context标签" class="headerlink" title="Tomcat 服务器核⼼配置Context标签"></a>Tomcat 服务器核⼼配置Context标签</h3><p><img src="https://pic4.zhimg.com/80/v2-f3e5efed8367c39cabf0763d86b89587_720w.webp" alt="img"></p>
<h2 id="二、手写实现Tomcat服务器与源码剖析"><a href="#二、手写实现Tomcat服务器与源码剖析" class="headerlink" title="二、手写实现Tomcat服务器与源码剖析"></a>二、手写实现Tomcat服务器与源码剖析</h2><h3 id="手写实现Tomcat服务器需求及实现步骤"><a href="#手写实现Tomcat服务器需求及实现步骤" class="headerlink" title="手写实现Tomcat服务器需求及实现步骤"></a>手写实现Tomcat服务器需求及实现步骤</h3><p>1）提供服务，接收请求（Socket通信）</p>
<p>2）请求信息封装成Request对象（Response对象）</p>
<p>3）客户端请求资源，资源分为静态资源（html）和动态资源（Servlet）</p>
<p>4）资源返回给客户端浏览器</p>
<p>\1. 创建一个启动类Bootstrap，通过main方法调用启动start方法</p>
<p><img src="/posts/2320/asset/v2-61a5871db4f3f28e04aaf504c791ae9b_720w.webp" alt="img"></p>
<p><img src="/posts/2320/asset/v2-7c947faf5f164264a3a9ea7b1bc77329_720w.webp" alt="img"></p>
<p>\2. 通过dom4j加载解析web.xml存入map集合中，此map存储的是地址和自定义的HttpServlet类</p>
<p><img src="/posts/2320/asset/v2-1d54ac3676ea9e2bf5ce567dae5a1084_720w.webp" alt="img"></p>
<p>\3. 定义端口号，创建一个ServerSocket，通过accept获取Socket类,把Socket和map集合传入多线程处理类。</p>
<p><img src="https://pic2.zhimg.com/80/v2-d556554d799b10a0728b275749d59b89_720w.webp" alt="img"></p>
<p>\4. 通过Socket获取输入流封装Request对象</p>
<p><img src="/posts/2320/asset/v2-2a168f12e73d759611d3778900a2f8ba_720w.webp" alt="img"></p>
<p>\5. 通过Socket获取输出流封装Response对象。</p>
<p><img src="/posts/2320/asset/v2-d43618b507deddc75eacd14176fa1500_720w.webp" alt="img"></p>
<p>\6. 根据请求查询map集合是否为空判断静态资源，静态资源处理</p>
<p><img src="https://pic2.zhimg.com/80/v2-c7ef8d1509d33955578f6d48fcc34af5_720w.webp" alt="img"></p>
<p>\7. 动态资源处理，调用自定义的LgServlet继承HttpServlet重写doGet和doPost进行输出</p>
<p><img src="/posts/2320/asset/v2-852b259f7c1b19b81fb744dee51fbd56_720w.webp" alt="img"></p>
<p>\8. 关闭socket，获取已经创建好的多线程类，放入调用定义线程池threadPoolExecutor中调用execute执行。</p>
<p><img src="/posts/2320/asset/v2-2e1a03a19d1e15d2c9150090084d2d2a_720w.webp" alt="img"></p>
<h3 id="Tomcat启动流程"><a href="#Tomcat启动流程" class="headerlink" title="Tomcat启动流程"></a>Tomcat启动流程</h3><p>从脚本start.sh找到Bootstap类的main方法从父容器开始把组件一个个初始化再逐级启动</p>
<p><img src="/posts/2320/asset/v2-1867d6894d8443a35fab5411d933b086_720w.webp" alt="img"></p>
<h3 id="Tomcat请求流程"><a href="#Tomcat请求流程" class="headerlink" title="Tomcat请求流程"></a>Tomcat请求流程</h3><p>请求处理流程分析图</p>
<p><img src="https://pic2.zhimg.com/80/v2-46cdf77a7c957192ef2582e542453829_720w.webp" alt="img"></p>
<p>Mapper组件体系结构</p>
<p><img src="/posts/2320/asset/v2-a344ed506ed16675ba3a4a896e3ae4ed_720w.webp" alt="img"></p>
<p>请求处理流程示意图</p>
<p><img src="https://pic2.zhimg.com/80/v2-95e2ba7c2cd2061adcdd10a058081169_720w.webp" alt="img"></p>
<h3 id="三、Tomcat类加载机制剖析"><a href="#三、Tomcat类加载机制剖析" class="headerlink" title="三、Tomcat类加载机制剖析"></a>三、Tomcat类加载机制剖析</h3><p>类加载过程：Java类（.java）文件被编译成字节码文件（.class），然后通过类加载器（classloader）加载到jvm内存中。</p>
<h3 id="JVM类加载机制"><a href="#JVM类加载机制" class="headerlink" title="JVM类加载机制"></a>JVM类加载机制</h3><p>Jvm内置了⼏种类加载器，包括：引导类加载器、扩展类加载器、系统类加载器，他们之间形成⽗⼦关系，通过 Parent 属性来定义这种关系，最终可以形成树形结构，同时我们自己也可以自定义类加载器。</p>
<p><img src="/posts/2320/asset/v2-d50654436de6c1247c8b9350caac355b_720w.webp" alt="img"></p>
<p><img src="/posts/2320/asset/v2-ad9d306b2f4a020aaeb310d081526086_720w.webp" alt="img"></p>
<p>⽤户可以⾃定义类加载器（Java编写，⽤户⾃定义的类加载器，可加载指定路径的 class ⽂件）当 JVM 运⾏过程中，⽤户⾃定义了类加载器去加载某些类时，会按照下⾯的步骤（⽗类委托机制）</p>
<p>1） ⽤户⾃⼰的类加载器，把加载请求传给⽗加载器，⽗加载器再传给其⽗加载器，⼀直到加载器树的顶层</p>
<p>2 ）最顶层的类加载器⾸先针对其特定的位置加载，如果加载不到就转交给⼦类</p>
<p>3 ）如果⼀直到底层的类加载都没有加载到，那么就会抛出异常 ClassNotFoundException</p>
<p>因此，按照这个过程可以想到，如果同样在 classpath 指定的⽬录中和⾃⼰⼯作⽬录中存放相同的class，会优先加载 classpath ⽬录中的⽂件。</p>
<h3 id="JVM双亲委派机制"><a href="#JVM双亲委派机制" class="headerlink" title="JVM双亲委派机制"></a>JVM双亲委派机制</h3><p>当某个类加载器需要加载某个.class⽂件时，它⾸先把这个任务委托给他的上级类加载器，递归这个操作，如果上级的类加载器没有加载，⾃⼰才会去加载这个类。</p>
<p><strong>作用：</strong></p>
<p>防⽌重复加载同⼀个.class。通过委托去向上⾯问⼀问，加载过了，就不⽤再加载⼀遍。保证数据安全。</p>
<p>保证核⼼.class不能被篡改。通过委托⽅式，不会去篡改核⼼.class，即使篡改也不会去加载，即使加载也不会是同⼀个.class对象了。不同的加载器加载同⼀个.class也不是同⼀个.class对象。这样保证了class执⾏安全（如果⼦类加载器先加载，那么我们可以写⼀些与java.lang包中基础类同名的类， 然后再定义⼀个⼦类加载器，这样整个应⽤使⽤的基础类就都变成我们⾃⼰定义的类了）。</p>
<h3 id="Tomcat类加载机制"><a href="#Tomcat类加载机制" class="headerlink" title="Tomcat类加载机制"></a>Tomcat类加载机制</h3><p>Tomcat 的类加载机制相对于 Jvm 的类加载机制做了⼀些改变<strong>，</strong>因为如果同时存在两个应用，然后他们有相同的全限定类名，如果遵循双亲委派机制，tomcat加载了应用1的全限定类之后就不会再加载应用2的类，但是这两个类虽然全限定类名相同，里面的逻辑却是不同的，所以JVM的双亲委派机制就不适合Tomcat了。因此在原来Jvm类加载机制上做了扩展和改变。增加了Commons、Catalina、Shared、WebApp类加载器。</p>
<p><img src="/posts/2320/asset/v2-d31f72e50587b81e911f3cf372d86788_720w.webp" alt="img"></p>
<p><img src="/posts/2320/asset/v2-14fe30b2359a6bb020c46799410daae8_720w.webp" alt="img"></p>
<p>引导类加载器 和 扩展类加载器 的作⽤不变。</p>
<p>系统类加载器正常情况下加载的是 CLASSPATH 下的类，但是 Tomcat 的启动脚本并未使⽤该变量，⽽是加载tomcat启动的类，⽐如bootstrap.jar，通常在catalina.bat或者catalina.sh中指定，位于CATALINA_HOME&#x2F;bin下。</p>
<p>Common 通⽤类加载器加载Tomcat使⽤以及应⽤通⽤的类，位于CATALINA_HOME&#x2F;lib下，⽐如servlet-api.jar。</p>
<p>Catalina ClassLoader ⽤于加载服务器内部可⻅类，这些类应⽤程序不能访问。</p>
<p>Shared ClassLoader ⽤于加载应⽤程序共享类，这些类服务器不会依赖。</p>
<p>Webapp ClassLoader，每个应⽤程序都会有⼀个独⼀⽆⼆的Webapp ClassLoader，他⽤来加载本应⽤程序 &#x2F;WEB-INF&#x2F;classes 和 &#x2F;WEB-INF&#x2F;lib 下的类。</p>
<p><strong>加载顺序：</strong></p>
<p>⾸先从 Bootstrap Classloader加载指定的类-&gt;</p>
<p>如果未加载到，则从 &#x2F;WEB-INF&#x2F;classes加载-&gt;</p>
<p>如果未加载到，则从 &#x2F;WEB-INF&#x2F;lib&#x2F;*.jar 加载-&gt;</p>
<p>如果未加载到，则依次从 System、Common、Shared 加载（在这最后⼀步，遵从双亲委派机制）</p>
<h2 id="四、Tomcat-对-Https-的支持及-Tomcat-性能优化策略"><a href="#四、Tomcat-对-Https-的支持及-Tomcat-性能优化策略" class="headerlink" title="四、Tomcat 对 Https 的支持及 Tomcat 性能优化策略"></a>四、Tomcat 对 Https 的支持及 Tomcat 性能优化策略</h2><h3 id="Tomcat-对-HTTPS-的支持"><a href="#Tomcat-对-HTTPS-的支持" class="headerlink" title="Tomcat 对 HTTPS 的支持"></a>Tomcat 对 HTTPS 的支持</h3><p>Https是⽤来加强数据传输安全的。Http超⽂本传输协议，明⽂传输 ，传输不安全，https在传输数据的时候会对数据进⾏加密，也就是在http的基础上增加了ssl协议。</p>
<p><strong>HTTPS和HTTP的主要区别：</strong></p>
<p>HTTPS协议使⽤时需要到电⼦商务认证授权机构（CA）申请SSL证书。</p>
<p>HTTP默认使⽤8080端⼝，HTTPS默认使⽤8443端⼝。</p>
<p>HTTPS则是具有SSL加密的安全性传输协议，对数据的传输进⾏加密，效果上相当于HTTP的升级版。</p>
<p>HTTP的连接是⽆状态的，不安全的；HTTPS协议是由SSL+HTTP协议构建的可进⾏加密传输、身份认证的⽹络协议，⽐HTTP协议安全。</p>
<p><strong>HTTPS⼯作原理：</strong></p>
<p><img src="/posts/2320/asset/v2-880606081ccd88d34d784e729e3ee64b_720w.webp" alt="img"></p>
<p>使用：生成秘钥库文件xx.keystore，把绝对路径地址配置到conf&#x2F;server.xml即可。</p>
<h3 id="JVM内存调优"><a href="#JVM内存调优" class="headerlink" title="JVM内存调优"></a>JVM内存调优</h3><p>系统性能的衡量指标，主要是响应时间和吞吐量。</p>
<p>1）响应时间：执行某个操作的耗时；</p>
<ol start="2">
<li>吞吐量：系统在给定时间内能够⽀持的事务数量，单位为TPS（Transactions PerSecond的缩写，也就是事务数&#x2F;秒，⼀个事务是指⼀个客户机向服务器发送请求然后服务器做出反应的过程。</li>
</ol>
<p>Java 虚拟机的运⾏优化主要是内存分配和垃圾回收策略的优化</p>
<p>1）内存直接影响服务的运⾏效率和吞吐量</p>
<p>2）垃圾回收机制会不同程度地导致程序运⾏中断（垃圾回收策略不同，垃圾回收次数和回收效率都是不同的）</p>
<p><img src="/posts/2320/asset/v2-40790d3fbb612b9446c646b504222a50_720w.webp" alt="img"></p>
<p>JVM内存模型</p>
<p><img src="/posts/2320/asset/v2-3a4a35f84c13aa0adf65639a517ecc1f_720w.webp" alt="img"></p>
<p><strong>使用：配置在catalina.sh的脚本</strong></p>
<p><img src="/posts/2320/asset/v2-5911e1cfc260c272d5081c14ff35fbe8_720w.webp" alt="img"></p>
<h3 id="JVM垃圾收集策略"><a href="#JVM垃圾收集策略" class="headerlink" title="JVM垃圾收集策略"></a>JVM垃圾收集策略</h3><p>垃圾回收性能指标</p>
<p>吞吐量：⼯作时间（排除GC时间）占总时间的百分⽐， ⼯作时间并不仅是程序运⾏的时间，还包含内存分配时间。</p>
<p>暂停时间：由垃圾回收导致的应⽤程序停⽌响应次数&#x2F;时间。</p>
<p><strong>垃圾收集器：</strong></p>
<p>串⾏收集器（Serial Collector）</p>
<p>单线程执⾏所有的垃圾回收⼯作， 适⽤于单核CPU服务器⼯作进程—–|（单线程）垃圾回收线程进⾏垃圾收集|—⼯作进程继续</p>
<p>并⾏收集器（Parallel Collector）</p>
<p>⼯作进程—–|（多线程）垃圾回收线程进⾏垃圾收集|—⼯作进程继续⼜称为吞吐量收集器（关注吞吐量）， 以并⾏的⽅式执⾏年轻代的垃圾回收， 该⽅式可以显著降低垃圾回收的开销(指多条垃圾收集线程并⾏⼯作，但此时⽤户线程仍然处于等待状态)。适⽤于多处理器或多线程硬件上运⾏的数据量较⼤的应⽤</p>
<p>并发收集器（Concurrent Collector）</p>
<p>以并发的⽅式执⾏⼤部分垃圾回收⼯作，以缩短垃圾回收的暂停时间。适⽤于那些响应时间优先于吞吐量的应⽤， 因为该收集器虽然最⼩化了暂停时间(指⽤户线程与垃圾收集线程同时执⾏,但不⼀定是并⾏的，可能会交替进⾏)， 但是会降低应⽤程序的性能</p>
<p>CMS收集器（Concurrent Mark Sweep Collector）</p>
<p>并发标记清除收集器， 适⽤于那些更愿意缩短垃圾回收暂停时间并且负担的起与垃圾回收共享处理器资源的应⽤</p>
<p>G1收集器（Garbage-First Garbage Collector）</p>
<p>适⽤于⼤容量内存的多核服务器， 可以在满⾜垃圾回收暂停时间⽬标的同时， 以最⼤可能性实现⾼吞吐量(JDK1.7之后)</p>
<p><strong>垃圾回收器参数：</strong></p>
<p><img src="/posts/2320/asset/v2-53a6dd136f90cb2444290a3e794be9dc_720w.webp" alt="img"></p>
<p><strong>使用：配置在catalina.sh的脚本</strong></p>
<p><img src="/posts/2320/asset/v2-96807c3e24747e055c1ed795501cc66b_720w.webp" alt="img"></p>
<h3 id="Tomcat调优"><a href="#Tomcat调优" class="headerlink" title="Tomcat调优"></a>Tomcat调优</h3><p>Tomcat优化从两个⽅⾯进⾏</p>
<p>1）JVM虚拟机优化（优化内存模型）</p>
<p>2）Tomcat⾃身配置的优化（⽐如是否使⽤了共享线程池？IO模型？）</p>
<p><strong>优化一调整线程池</strong></p>
<p><img src="/posts/2320/asset/v2-9cf7907d9a33e28fdcfa03b790c6316e_720w.webp" alt="img"></p>
<p><strong>优化二调整tomcat的连接器：调整tomcat&#x2F;conf&#x2F;server.xml 中关于链接器的配置可以提升应⽤服务器的性能。</strong></p>
<p><img src="/posts/2320/asset/v2-abdfc5b856db6635ddbb5fb68291f074_720w.webp" alt="img"></p>
<p><strong>优化三禁用 AJP 连接器</strong></p>
<p><img src="https://pic2.zhimg.com/80/v2-00461d1c0704ebb062852639a0f3b97d_720w.webp" alt="img"></p>
<p><strong>优化四调整 IO 模式</strong></p>
<p>Tomcat8之前的版本默认使⽤BIO（阻塞式IO），对于每⼀个请求都要创建⼀个线程来处理，不适合⾼并发；Tomcat8以后的版本默认使⽤NIO模式（⾮阻塞式IO）</p>
<p><img src="/posts/2320/asset/v2-412945a59e7783aeb0946c9cf8e91d34_720w.webp" alt="img"></p>
<p>当Tomcat并发性能有较⾼要求或者出现瓶颈时，我们可以尝试使⽤APR模式，APR（Apache PortableRuntime）是从操作系统级别解决异步IO问题，使⽤时需要在操作系统上安装APR和Native（因为APR原理是使⽤使⽤JNI技术调⽤操作系统底层的IO接⼝）</p>
<p><strong>优化五动静分离</strong></p>
<p>可以使⽤Nginx+Tomcat相结合的部署⽅案，Nginx负责静态资源访问，Tomcat负责Jsp等动态资源访问处理（因为Tomcat不擅⻓处理静态资源）。</p>
]]></content>
      <categories>
        <category>基础知识</category>
        <category>tomcat</category>
      </categories>
      <tags>
        <tag>基础知识</tag>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title>springmvc知识</title>
    <url>/posts/3559/</url>
    <content><![CDATA[<h2 id="一、Spring-MVC基础"><a href="#一、Spring-MVC基础" class="headerlink" title="一、Spring MVC基础"></a>一、Spring MVC基础</h2><h3 id="Spring-MVC简介"><a href="#Spring-MVC简介" class="headerlink" title="Spring MVC简介"></a>Spring MVC简介</h3><p>基于java的实现MVC设计模式的请求驱动类型的轻量级Web框架，通过注解，无需实现任何接口，处理请求，支持restful。</p>
<p>三层结构：表现层、业务层、持久层</p>
<p>设计模式：Model（模型）、View(视图)、Controller（控制器）</p>
<h3 id="Spring-Web-MVC工作流程"><a href="#Spring-Web-MVC工作流程" class="headerlink" title="Spring Web MVC工作流程"></a>Spring Web MVC工作流程</h3><p>SpringMvc请求处理流程：</p>
<p>\1. 前端用户发送请求到前端控制器DispatcherServlet</p>
<p>\2. DispatcherServlet收到请求之后调用处理映射器HandlerMapping</p>
<p>\3. 处理映射器根据url找到对应的后端控制器handler,生成处理器对象和处理器拦截器返回前端控制器</p>
<p>\4. 前端控制器再去调用处理适配器HandlerAdapter去调用具体的后端控制器</p>
<p>\5. 后端控制器执行完毕之后，把ModelAndView返回给处理适配器</p>
<p>\6. 处理适配器把ModelAndView返回给前端控制器。</p>
<p>\7. 前端控制器调用视图解析器ViewResolver进行解析，解析完毕返回视图view</p>
<p>\8. 前端控制器进行视图渲染，就是数据填充</p>
<p>\9. 前端控制器向用户响应结果</p>
<p><img src="https://pic2.zhimg.com/80/v2-99b2e5db9ea125bd4c80aff6d43be2ed_720w.webp" alt="img"></p>
<p>SpringMvc九大组件：</p>
<p>HandlerMapping（处理器映射器）、</p>
<p>HandlerAdapter（处理器适配器）、</p>
<p>HandlerExceptionResolver（异常处理）、</p>
<p>ViewResolver（视图解析器）、</p>
<p>RequestToViewNameTranslator（请求在查找视图名称，视图名转化器组件）</p>
<p>LocaleResolver（区域化解析，表示所在地）、ThemeResolver（主题解析）</p>
<p>MultipartResolver（多部件解析器文件上传处理）、FlashMapManager（flash属性管理组件 重定向参数传递）</p>
<p>web.xml中url-pattern配置三种方式：</p>
<p>方式一：带后缀，比如*.action *.do *.aaa</p>
<p>方式二：&#x2F; 不会拦截 .jsp，但是会拦截.html等静态资源（静态资源：除了servlet和jsp之外的js、css、png等）</p>
<p>因为tomcat容器中有一个web.xml（父），你的项目中也有一个web.xml（子），是一个继承关系父web.xml中有一个DefaultServlet, url-pattern 是一个 &#x2F;此时我们自己的web.xml中也配置了一个 &#x2F; ,覆写了父web.xml的配置</p>
<p>为什么不拦截.jsp呢？</p>
<p>因为父web.xml中有一个JspServlet，这个servlet拦截.jsp文件，而我们并没有覆写这个配置，所以springmvc此时不拦截jsp，jsp的处理交给了tomcat</p>
<p>方式三：&#x2F;* 拦截所有，包括.jsp</p>
<p><img src="https://pic2.zhimg.com/80/v2-e9642fff56f030db5d9a9f4ea8e47729_720w.webp" alt="img"></p>
<p>数据输入类型ModelMap、Model、Map</p>
<p>运行的时候都会使用BindingAwareModelMap类型，而这个类型是上面三种接口的实现</p>
<h3 id="Spring-MVC请求参数绑定"><a href="#Spring-MVC请求参数绑定" class="headerlink" title="Spring MVC请求参数绑定"></a>Spring MVC请求参数绑定</h3><p>前后端交互传输数据都是http,简称超文本传输协议。SpringMvc对serlvet封装，接收整形参数时直接在Handler⽅法中声明形参。</p>
<p>简单数据类型：⼋种基本数据类型及其包装类型</p>
<p>参数类型推荐使⽤包装数据类型，因为基础数据类型不可以为null</p>
<p>整型：Integer、int</p>
<p>字符串：String</p>
<p>单精度：Float、float</p>
<p>双精度：Double、double</p>
<p>布尔型：Boolean、boolean</p>
<p>说明：对于布尔类型的参数，请求的参数值为true或false。或者1或0</p>
<p>注意：绑定简单数据类型参数，只需要直接声明形参即可（形参参数名和传递的参数名要保持⼀致，建议 使⽤包装类型，当形参参数名和传递参数名不⼀致时可以使⽤@RequestParam注解进⾏⼿动映射）</p>
<p>自定义类型，比如日期处理，需要实现Converter接口，并注册自定义转换器</p>
<p><img src="https://pic4.zhimg.com/80/v2-9e8be62e7d268c243a3e60f3d54c9ccb_720w.webp" alt="img"></p>
<h3 id="Restful请求支持"><a href="#Restful请求支持" class="headerlink" title="Restful请求支持"></a>Restful请求支持</h3><p>Restful 是⼀种 web 软件架构⻛格，它不是标准也不是协议，它倡导的是⼀个资源定位及资源操作的⻛格。</p>
<p>优点：</p>
<p>结构清晰、符合标准、易于理解、扩展⽅便</p>
<p>特性：</p>
<p>⽹络上的⼀个实体，或者说是⽹络上的⼀个具体信息。它可以是⼀段⽂本、⼀张图⽚、⼀⾸歌曲、⼀种服务，总之就是⼀个具体的存在。可以⽤⼀个 URI（统⼀资源定位符）指向它，每种资源对应⼀个特定的 URI 。要获取这个资源，访问它的 URI 就可以，因此URI 即为每⼀个资源的独⼀⽆⼆的识别符。</p>
<p><img src="https://pic2.zhimg.com/80/v2-86c1234262dec2460e5fa8cacee45dd5_720w.webp" alt="img"></p>
<p>乱码过滤器web.xml配置，如果是put和delete请求需要配置请求方式转换，但是此方式不常用</p>
<p><img src="https://pic4.zhimg.com/80/v2-0f961a547e15f98ddedba7acd6a12c47_720w.webp" alt="img"></p>
<h3 id="Ajax-Json交互"><a href="#Ajax-Json交互" class="headerlink" title="Ajax Json交互"></a>Ajax Json交互</h3><p>Json是⼀种与语⾔⽆关的数据交互格式，就是⼀种字符串，只是⽤特殊符号{}内表示对象、[]内表示数组、””内是属性或值、：表示后者是前者的值。</p>
<p>{“name”: “Michael”}可以理解为是⼀个包含name为Michael的对象</p>
<p>[{“name”: “Michael”},{“name”: “Jerry”}]就表示包含两个对象的数组</p>
<p>前端到后台：前端ajax发送json格式字符串，后台直接接收为pojo参数，使⽤注解@RequstBody</p>
<p>后台到前端：后台直接返回pojo对象，前端直接接收为json对象或者字符串，使⽤注解@ResponseBody，此注解不走视图解析器，而是直接将数据写入流中。</p>
<h3 id="Spring高级技术之监听器、拦截器、过滤器"><a href="#Spring高级技术之监听器、拦截器、过滤器" class="headerlink" title="Spring高级技术之监听器、拦截器、过滤器"></a>Spring高级技术之监听器、拦截器、过滤器</h3><p>过滤器（Filter）：对Request请求起到过滤的作⽤，作⽤在Servlet之前，如果url-pattern配置为&#x2F;*可以对所有的资源访问（servlet、js&#x2F;css静态资源等）进⾏过滤处理</p>
<p>监听器（Listener）：实现了javax.servlet.ServletContextListener 接⼝的服务器端组件，它随Web应⽤的启动⽽启动，只初始化⼀次，然后会⼀直运⾏监视，随Web应⽤的停⽌⽽销毁，做一些初始化工作以及监听特定事件对其处理，比如从A方法进入B方法，A方法需要知道B方法执行完继续进行下一步，那么A方法就可以监听B方法的运行情况。</p>
<p>拦截器（Interceptor）：拦截访问的控制器⽅法（Handler），一个拦截器拦截三次。</p>
<p>\1. 在Handler业务逻辑执⾏之前拦截⼀次</p>
<p>\2. 在Handler逻辑执⾏完毕但未跳转⻚⾯之前拦截⼀次</p>
<p>\3. 在跳转⻚⾯之后拦截⼀次</p>
<p><img src="https://pic2.zhimg.com/80/v2-c99b9742aa72c620d57fe9e6d962b0cd_720w.webp" alt="img"></p>
<p>拦截器执行流程：多个拦截器执行顺序是按照配置文件拦截器的前后顺序执行的，按照先进后出的顺序，第一个拦截器先进去最后出来。</p>
<p>\1. 程序先执⾏preHandle()⽅法，如果该⽅法的返回值为true，则程序会继续向下执⾏处理器中的⽅法，否则将不再向下执⾏。</p>
<p>\2. 在业务处理器（即控制器Controller类）处理完请求后，会执⾏postHandle()⽅法，然后会通过DispatcherServlet向客户端返回响应。</p>
<p>\3. 在DispatcherServlet处理完请求后，才会执⾏afterCompletion()⽅法。</p>
<p><img src="https://pic2.zhimg.com/80/v2-9df905a7d4523e1d8f940e5397144a6d_720w.webp" alt="img"></p>
<p><img src="/posts/3559/asset/v2-ef3150b70e3b13fea16e040fcbbbb26c_720w.webp" alt="img"></p>
<p><img src="/posts/3559/asset/v2-f3526da00a00b51a3a4c20f4d37d4916_720w.webp" alt="img"></p>
<h3 id="multipart形式-文件上传-数据、异常捕获、重定向参数传递"><a href="#multipart形式-文件上传-数据、异常捕获、重定向参数传递" class="headerlink" title="multipart形式(文件上传)数据、异常捕获、重定向参数传递"></a>multipart形式(文件上传)数据、异常捕获、重定向参数传递</h3><p><strong>文件上传</strong></p>
<p>客户端：POST请求；enctype&#x3D;multipart;file组件</p>
<p>服务端: 重命名uuid;存储到磁盘，按日期建文件夹；把文件储存路径存入数据库，方便根据路径获取想要的资源。</p>
<p><img src="https://pic2.zhimg.com/80/v2-b1df46cd3b549a26d34c592c989290bd_720w.webp" alt="img"></p>
<p><img src="https://pic4.zhimg.com/80/v2-11ff4c212c0d24f459cafd8f60834aa3_720w.webp" alt="img"></p>
<p><strong>异常捕获</strong></p>
<p>需要实现HandlerExceptionResolver接口把程序所有或者单一异常都捕获做统一返回处理，比如专门做一个错误页面告知用户，给用户更好的反馈和体验。单类捕获就写在当前类就行了，全局捕获自定义一个类添加@ControllerAdvice注解。</p>
<p><img src="/posts/3559/asset/v2-935f7ba798a43cd5cafbc1b96bdc92b0_720w.webp" alt="img"></p>
<p><strong>重定向参数传递</strong></p>
<p>重定向时请求参数会丢失，我们往往需要重新携带请求参数，在路径中手动拼接，解决办法声明RedirectAttributes类，可以添加flash属性，框架会在session中记录该属性值，进行重定向参数传递，而且完成之后会自动被清理。</p>
<p><img src="https://pic4.zhimg.com/80/v2-73f459798a255155710a8190eb207a1f_720w.webp" alt="img"></p>
<h3 id="二、自定义MVC框架"><a href="#二、自定义MVC框架" class="headerlink" title="二、自定义MVC框架"></a>二、自定义MVC框架</h3><h3 id="MVC框架运行原理"><a href="#MVC框架运行原理" class="headerlink" title="MVC框架运行原理"></a>MVC框架运行原理</h3><p>\1. Tomcat加载web.xml，前端控制器DispatcherServlet加载指定的配置文件springmvc.xml</p>
<p>\2. 根据配置文件扫描包和注解</p>
<p><img src="https://pic2.zhimg.com/80/v2-52e5fed94f0a89eb5972e54621890ebd_720w.webp" alt="img"></p>
<p>\3. IOC容器进行相应的Bean初始化和依赖注入维护</p>
<p>\4. SpringMvc相关组件的初始化,建立url和method之间的映射关系，也就是处理映射器HandlerMapping</p>
<p><img src="https://pic2.zhimg.com/80/v2-4ddd7b6d8fbf0cfeeb0b2f0108e70669_720w.webp" alt="img"></p>
<p>\5. 等待请求进来，处理请求。</p>
<h3 id="自定义框架实现步骤"><a href="#自定义框架实现步骤" class="headerlink" title="自定义框架实现步骤"></a>自定义框架实现步骤</h3><p>\1. 加载配置文件springmvc.properties，把文件加载成字节流然后转化成字符流存入properties。</p>
<p><img src="https://pic3.zhimg.com/80/v2-16c1340cbb50a03cbcceef834bb7411e_720w.webp" alt="img"></p>
<p>\2. 从properties中取出配置的地址，拼接成绝对路径，扫描该路径下所有文件，找到class文件对应集合中</p>
<p><img src="/posts/3559/asset/v2-ed5215dd47e3c52241ca8de0e56defc0_720w.webp" alt="img"></p>
<p>\3. 初始化Bean对象，变量全限定类名集合中每一个元素，进行注解判断，如果存在注解，进行反射实例化，然后存入bean对象集合中。</p>
<p><img src="https://pic4.zhimg.com/80/v2-f220d2649222cd8b428c452f25219d6f_720w.webp" alt="img"></p>
<p>\4. 实现依赖注入，遍历上面的beanMap集合，然后再对遍历出来的类，取出所有属性再遍历，判断属性上面是否存在@Autowired注解，存在再进行相应处理。</p>
<p><img src="https://pic4.zhimg.com/80/v2-c0b503a5265f5f60128ec00942ebb937_720w.webp" alt="img"></p>
<p>\5. 构造一个HandlerMapping处理映射器，将配置好的url和method建立映射关系，遍历beanMap集合，判断类和方法上面是否存在@Controller注解，如果存在取出两个值拼接成url存入一个自定义的普通类中，类里面有所属类、方法、url以及参数位置四个属性。</p>
<p><img src="/posts/3559/asset/v2-ebc6f2601147919c4089290528c09073_720w.webp" alt="img"></p>
<p><img src="/posts/3559/asset/v2-a5c52b40a3d4b139be763bd9d16daf30_720w.webp" alt="img"></p>
<p><img src="https://pic2.zhimg.com/80/v2-59d6807884f8f105b05b95530f543b65_720w.webp" alt="img"></p>
<p>\6. 执行dopost方法，接受前端请求，执行自定义MVC框架，从handler中取出参数，进行请求处理，进行参数绑定最后调用该handler所属方法的invoke方法，执行到控制层。</p>
<p><img src="https://pic3.zhimg.com/80/v2-dc0f27c67cbb05606c5d2faca1e66c66_720w.webp" alt="img"></p>
<p><img src="/posts/3559/asset/v2-d3efa099859876ff6b0b1fd61670c675_720w.webp" alt="img"></p>
<h3 id="三、Spring-MVC源码剖析"><a href="#三、Spring-MVC源码剖析" class="headerlink" title="三、Spring MVC源码剖析"></a>三、Spring MVC源码剖析</h3><h3 id="前端控制器DispatcherServlet继承结构"><a href="#前端控制器DispatcherServlet继承结构" class="headerlink" title="前端控制器DispatcherServlet继承结构"></a>前端控制器DispatcherServlet继承结构</h3><p>前端控制配置在web.xml中，执行前后端交互的重要组件，比如接收请求，调用处理器，渲染视图等等，他的继承结构如下：DispatcherServlet extends FrameworkServlet extends HttpServletBean extends HttpServlet。</p>
<p>\1. HttpServlet里面定义两个方法doGet、doPost方法用于获取协议等等参数，但是并没有进行具体的业务逻辑处理</p>
<p><img src="https://pic3.zhimg.com/80/v2-1f02372224f8665e9b76b07867b6e3ca_720w.webp" alt="img"></p>
<p>\2. 在继承类FrameworkServlet中，重写了doGet、doPost方法，在这两个方法内对前端发送的请求调用自己内部定义的processRequest方法进行处理。</p>
<p><img src="/posts/3559/asset/v2-45778bcb37551dd3c5215458df356078_720w.webp" alt="img"></p>
<p><img src="https://pic3.zhimg.com/80/v2-28391e30c4b6df2976e70ce1a5577dfe_720w.webp" alt="img"></p>
<p>\3. 在processRequest方法结束调用了一个doSercive方法，他是一个抽象方法，交给了最底层类DispatcherServlet来实现。在方法内进行参数存储，设置属性值以及重定向参数管理，结尾又调用了自己内部的doDispatch方法进行请求派发。</p>
<p><img src="https://pic2.zhimg.com/80/v2-595c09254d36fac8bda5644382913e09_720w.webp" alt="img"></p>
<p><img src="/posts/3559/asset/v2-9fde5624e35de7b274958091dc33f786_720w.webp" alt="img"></p>
<p>\4. 在doDispatch方法内主要是检查是否是文件上传请求，获取处理当前请求的处理器handler，再获取处理请求的适配器，处理请求返回视图对象，最后对视图对象进行处理。</p>
<p><img src="/posts/3559/asset/v2-bebaa3c64b37bab6f0be4123996be450_720w.webp" alt="img"></p>
<p><img src="/posts/3559/asset/v2-76e4ee516bee80fa1a3ca843b66f29e2_720w.webp" alt="img"></p>
<p>完整走向图</p>
<p><img src="https://pic4.zhimg.com/80/v2-2293205c4504046c022831da1e20fb8b_720w.webp" alt="img"></p>
<h3 id="SpringMVC请求处理大致走向流程"><a href="#SpringMVC请求处理大致走向流程" class="headerlink" title="SpringMVC请求处理大致走向流程"></a>SpringMVC请求处理大致走向流程</h3><p>\1. 前端用户发送请求，执行到控制层</p>
<p><img src="https://pic4.zhimg.com/80/v2-28953922d961a975c36326000d872cfb_720w.webp" alt="img"></p>
<p>\2. 接着走doGet&#x2F;doPost请求，跟上面DispatcherServlet继承结构走向一致，进入到doDispatch方法开始真正的执行逻辑处理。doDispatch方法核心步骤:</p>
<p>1)调取getHandler()获取到能够处理当前请求的执行链HandlerExecutionChain</p>
<p><img src="https://pic2.zhimg.com/80/v2-69bae507d0c6769558e82f7376a4d4a1_720w.webp" alt="img"></p>
<p>2)调用getHandlerAdapter方法获取能够执行1)的Handler的适配器</p>
<p><img src="/posts/3559/asset/v2-72253dd47a2b11ab249a7c0b41e53100_720w.webp" alt="img"></p>
<p>3）适配器调用Handler执行ha.handle，返回一个视图ModelAndView对象</p>
<p><img src="/posts/3559/asset/v2-e7091f4869575a88f3994fec8c52901c_720w.webp" alt="img"></p>
<p>4)调用processDispatchResult方法完成视图渲染调转</p>
<p><img src="/posts/3559/asset/v2-7453b14b72538896de3079f20792fbdd_720w.webp" alt="img"></p>
<p>\3. getHandler方法剖析</p>
<p>如何获取适配器Handler对象？</p>
<p>在容器启动初始化过程中，扫描@RequestMapping注解建立url和Handler方法的对应映射关系，handlerMappings是一个接口，里面有两个实现类，通过遍历获取requestHandlerMapping实现类，通过传进来的请求request进行筛选，得到匹配的handlder并返回。</p>
<p><img src="https://pic2.zhimg.com/80/v2-191609ddeaf0775ffbb558729ab9ede1_720w.webp" alt="img"></p>
<p>\4. getHandlerAdapter方法剖析</p>
<p>如何获取处理器getHandlerAdapter对象</p>
<p>HandlerInterceptor也是一个接口，里面有三个实现类，对不同方式请求进行分别处理，遍历获取能处理当前handler的处理器，通过supports方法内是否是这个接口的实现就能判断是否是他的处理器，返回是否处理的布尔值结果。</p>
<p><img src="/posts/3559/asset/v2-b498c64fab3f642caa5e78aa58ef7e80_720w.webp" alt="img"></p>
<h3 id="SpringMVC九大组件初始化"><a href="#SpringMVC九大组件初始化" class="headerlink" title="SpringMVC九大组件初始化"></a>SpringMVC九大组件初始化</h3><p>九大组件，全部定义在DispatcherServlet中，他们都定义成了接口，接口定义了规范。</p>
<p><img src="https://pic3.zhimg.com/80/v2-41aca86bb26cb93f93e1f6cd4e65301a_720w.webp" alt="img"></p>
<p>Spring容器启动时，AbstractApplicationContext类中的核心方法refresh中调用了onRefresh方法，由子类实现了DispatcherServlet做了实现(完成九大件初始化)，通过onRefresh方法内调用initStrategies方法完成.</p>
<p><img src="/posts/3559/asset/v2-242bfd0bc730872f1f758f69c53ccab9_720w.webp" alt="img"></p>
<p>多部件解析的id是固定multipartResolver，因为内部定义了一个常量就叫multipartResolver</p>
<p><img src="/posts/3559/asset/v2-44b048407e375cbd2b1bf88ef329e3e4_720w.webp" alt="img"></p>
<h3 id="Handler方法执行细节剖析"><a href="#Handler方法执行细节剖析" class="headerlink" title="Handler方法执行细节剖析"></a>Handler方法执行细节剖析</h3><p>此方法就是上面doDispatch方法核心步骤第三步，调用ha.handle方法，针对他内部实现进行剖析。根据外部这个方法进入handleInternal方法，创建一个视图，然后判断这个session是否需要同步处理，因为session是线程不安全的，如果需要同步，则获取当前session对象并且一个唯一key增加synchronized关键字进行锁定保证线程安全。在锁里面调用invokeHandlerMethod方法对handler进行适配，如果不需要同步处理则直接进入此方法。在该方法内部进行一系列检查和前置处理，走到invokeAndHandle方法这里，开始对请求参数进行处理，调用目标的HandlerMethod，将返回值封装返回成一个ModelAndView对象。</p>
<p><img src="https://pic2.zhimg.com/80/v2-24e7c455f70721262ed7b0f032500681_720w.webp" alt="img"></p>
<p><img src="/posts/3559/asset/v2-a18c34abe168eb706407eef014ac5098_720w.webp" alt="img"></p>
<p>在invokeAndHandle方法内部又请求了自己类的invokeForRequest方法，，把参数和请求以及类传递下去调用doInvoke方法使用反射对目标方法调用，并且一个Object来接收并返回。</p>
<p><img src="/posts/3559/asset/v2-3fb665441bd4458708b42dadfec21096_720w.webp" alt="img"></p>
<p>接着回到invokeHandlerMethod方法，进行下一步，调用getModelAndView方法对上面获取的ModelAndView对象进行处理。</p>
<p><img src="https://pic3.zhimg.com/80/v2-9865d857e7c2a4af9bc63c6c961c13d6_720w.webp" alt="img"></p>
<h3 id="视图渲染细节剖析"><a href="#视图渲染细节剖析" class="headerlink" title="视图渲染细节剖析"></a>视图渲染细节剖析</h3><p>此方法就是上面doDispatch方法核心步骤第四步，调用processDispatchResult方法，针对他内部实现进行剖析。</p>
<p>进入方法内部，进行异常判断和非空判断走到render方法进行渲染</p>
<p><img src="/posts/3559/asset/v2-77678ee563586e336c4060ad6eafbfb7_720w.webp" alt="img"></p>
<p>在方法内部定义了一个视图对象，从getViewName方法中取出视图名称，比如success，如果不为空根据视图名进行内部视图封装方法。</p>
<p><img src="/posts/3559/asset/v2-360cbee8997dcd190012c892856d4cb1_720w.webp" alt="img"></p>
<p>在方法内部用视图解析器viewResolver进行封装。在内部的buildView方法根据配置的视图解析器在内部进行组装完整视图名称。</p>
<p><img src="https://pic4.zhimg.com/80/v2-704d11b3360c373613447e55f2692c1f_720w.webp" alt="img"></p>
<p><img src="https://pic3.zhimg.com/80/v2-ae9ea6dd0112591ff3dd40fd816b7d0e_720w.webp" alt="img"></p>
<p>当完成一系列数据填充后，我们的modelMap中就有了对应数据，这时候他会把里面的数据暴露到request域中，所以当model.add完成之后，jsp就可以直接从请求域中获取数据的原因。完成数据暴露之后就调用RequestDispatcher进行请求分发，根据前面拼接的jsp完整路径调转到对应页面。</p>
<p><img src="https://pic3.zhimg.com/80/v2-a799530957f2e7b9e030e1c872396096_720w.webp" alt="img"></p>
<p>注意：转发和重定向都会走不同的视图解析，并且视图解析是走缓存的，缓存存在就直接返回，没有才重新创建。</p>
<p><img src="https://pic3.zhimg.com/80/v2-ab8917a29047a5e20323ca19c6ce9a1a_720w.webp" alt="img"></p>
<h3 id="四、Spring-Spring-MVC-Mybatis整合"><a href="#四、Spring-Spring-MVC-Mybatis整合" class="headerlink" title="四、Spring + Spring MVC + Mybatis整合"></a>四、Spring + Spring MVC + Mybatis整合</h3><h3 id="整合目标"><a href="#整合目标" class="headerlink" title="整合目标"></a>整合目标</h3><p>数据库连接池以及事务管理都交给Spring容器来完成</p>
<p>SqlSessionFactory对象应该放到Spring容器中作为单例对象管理</p>
<p>Mapper动态代理对象交给Spring管理，我们从Spring容器中直接获得Mapper的代理对象</p>
<p>把SpringMVC的⼊⻔案例整合进来</p>
<p><strong>所需jar包</strong></p>
<p>Junit测试jar（4.12版本）</p>
<p>Mybatis的jar（3.4.5）</p>
<p>Spring相关jar（spring-context、spring-test、spring-jdbc、spring-tx、spring-aop、</p>
<p>aspectjweaver）</p>
<p>Mybatis&#x2F;Spring整合包jar（mybatis-spring-xx.jar）</p>
<p>Mysql数据库驱动jar</p>
<p>Druid数据库连接池的jar</p>
<p><strong>完整整合项目截图</strong></p>
<p><img src="/posts/3559/asset/v2-0c704f47d1672ce718beca419539b0f1_720w.webp" alt="img"></p>
<h3 id="具体引入jir包"><a href="#具体引入jir包" class="headerlink" title="具体引入jir包"></a>具体引入jir包</h3><!--junit-->

<dependency>

<p><groupId>junit</groupId></p>
<p><artifactId>junit</artifactId></p>
<p><version>4.12</version></p>
<p><scope>test</scope></p>
</dependency>

<!--⽇志坐标-->

<dependency>

<p><groupId>log4j</groupId></p>
<p><artifactId>log4j</artifactId></p>
<p><version>1.2.12</version></p>
</dependency>

<!--mybatis-->

<dependency>

<p><groupId>org.mybatis</groupId></p>
<p><artifactId>mybatis</artifactId></p>
<p><version>3.4.5</version></p>
</dependency>

<!--spring相关-->

<dependency>

<p><groupId>org.springframework</groupId></p>
<p><artifactId>spring-context</artifactId></p>
<p><version>5.1.12.RELEASE</version></p>
</dependency>

<dependency>

<p><groupId>org.springframework</groupId></p>
<p><artifactId>spring-test</artifactId></p>
<p><version>5.1.12.RELEASE</version></p>
</dependency>

<dependency>

<p><groupId>org.springframework</groupId></p>
<p><artifactId>spring-jdbc</artifactId></p>
<p><version>5.1.12.RELEASE</version></p>
</dependency>

<dependency>

<p><groupId>org.springframework</groupId></p>
<p><artifactId>spring-tx</artifactId></p>
<p><version>5.1.12.RELEASE</version></p>
</dependency>

<dependency>

<p><groupId>org.springframework</groupId></p>
<p><artifactId>spring-aop</artifactId></p>
<p><version>5.1.12.RELEASE</version></p>
</dependency>

<dependency>

<p><groupId>org.aspectj</groupId></p>
<p><artifactId>aspectjweaver</artifactId></p>
<p><version>1.8.9</version></p>
</dependency>

<!--mybatis与spring的整合包-->

<dependency>

<p><groupId>org.mybatis</groupId></p>
<p><artifactId>mybatis-spring</artifactId></p>
<p><version>2.0.3</version></p>
</dependency>

<!--数据库驱动jar-->

<dependency>

<p><groupId>mysql</groupId></p>
<p><artifactId>mysql-connector-java</artifactId></p>
<p><version>5.1.46</version></p>
</dependency>

<!--druid连接池-->

<dependency>

<p><groupId>com.alibaba</groupId></p>
<p><artifactId>druid</artifactId></p>
<p><version>1.1.21</version></p>
</dependency>

<!--SpringMVC-->

<dependency>

<p><groupId>org.springframework</groupId></p>
<p><artifactId>spring-webmvc</artifactId></p>
<p><version>5.1.12.RELEASE</version></p>
</dependency>

<!--jsp-api&servlet-api-->

<dependency>

<p><groupId>javax.servlet</groupId></p>
<p><artifactId>jsp-api</artifactId></p>
<p><version>2.0</version></p>
<p><scope>provided</scope></p>
</dependency>

<dependency>

<p><groupId>javax.servlet</groupId></p>
<p><artifactId>javax.servlet-api</artifactId></p>
<p><version>3.1.0</version></p>
<p><scope>provided</scope></p>
</dependency>

<!--⻚⾯使⽤jstl表达式-->

<dependency>

<p><groupId>jstl</groupId></p>
<p><artifactId>jstl</artifactId></p>
<p><version>1.2</version></p>
</dependency>

<dependency>

<p><groupId>taglibs</groupId></p>
<p><artifactId>standard</artifactId></p>
<p><version>1.1.2</version></p>
</dependency>

<!--json数据交互所需jar，start-->

<dependency>

<p><groupId>com.fasterxml.jackson.core</groupId></p>
<p><artifactId>jackson-core</artifactId></p>
<p><version>2.9.0</version></p>
</dependency>

<dependency>

<p><groupId>com.fasterxml.jackson.core</groupId></p>
<p><artifactId>jackson-databind</artifactId></p>
<p><version>2.9.0</version></p>
</dependency>

<dependency>

<p><groupId>com.fasterxml.jackson.core</groupId></p>
<p><artifactId>jackson-annotations</artifactId></p>
<p><version>2.9.0</version></p>
</dependency>

<!--json数据交互所需jar，end-->

<!--⽂件上传所需jar坐标-->

<dependency>

<p><groupId>commons-fileupload</groupId></p>
<p><artifactId>commons-fileupload</artifactId></p>
<p><version>1.3.1</version></p>
</dependency>

<h3 id="applicationContext-xml配置"><a href="#applicationContext-xml配置" class="headerlink" title="applicationContext.xml配置"></a>applicationContext.xml配置</h3><!--包扫描-->

<p>&lt;context:component-scan base-package&#x3D;”com.lg”&#x2F;&gt;</p>
<!--数据库连接池以及事务管理都交给Spring容器来完成-->

<!--引⼊外部资源⽂件-->

<p>&lt;context:property-placeholder location&#x3D;”classpath:jdbc.properties”&#x2F;&gt;</p>
<!--第三⽅jar中的bean定义在xml中-->

<bean id="dataSource" class="com.alibaba.druid.pool.DruidDataSource">

<property name="driverClassName" value="${jdbc.driver}"/>

<property name="url" value="${jdbc.url}"/>

<property name="username" value="${jdbc.username}"/>

<property name="password" value="${jdbc.password}"/>

</bean>

<!--spring声明式事务配置，声明式事务无非就是配置一个aop，只不过有些标签不一样罢了-->

<!--横切逻辑-->

<bean id="transactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager">

<p><property name="dataSource" ref="dataSource"></property></p>
</bean>

<!--声明式事务的注解驱动-->

<p>&lt;tx:annotation-driven transaction-manager&#x3D;”transactionManager”&gt;</tx:annotation-driven></p>
<!--SqlSessionFactory对象应该放到Spring容器中作为单例对象管理 代替mybatis的：SqlMapConfig.xml文件-->

<bean id="sqlSessionFactory" class="org.mybatis.spring.SqlSessionFactoryBean">

<!--扫描别名映射-->

<p><property name="typeAliasesPackage" value="com.lg.pojo"></property></p>
<!--数据源dataSource-->

<p><property name="dataSource" ref="dataSource"></property></p>
</bean>

<!--Mapper动态代理对象交给Spring管理，我们从Spring容器中直接获得Mapper的代理对象-->

<!--扫描mapper接⼝，⽣成代理对象，⽣成的代理对象会存储在ioc容器中-->

<bean class="org.mybatis.spring.mapper.MapperScannerConfigurer">

<!--扫描mapper接口包路径配置-->

<p><property name="basePackage" value="com.lg.mapper"></property></p>
<property name="sqlSessionFactoryBeanName" value="sqlSessionFactory"/>

</bean>

<h3 id="springmvc-xml配置"><a href="#springmvc-xml配置" class="headerlink" title="springmvc.xml配置"></a>springmvc.xml配置</h3><!--开启controller扫描-->

<p>&lt;context:component-scan base-package&#x3D;”com.lg.controller”&gt;</context:component-scan></p>
<!--配置springmvc的视图解析器-->

<bean class="org.springframework.web.servlet.view.InternalResourceViewResolver">

<p><property name="prefix" value="/WEB-INF/jsp/"></property></p>
<p><property name="suffix" value=".jsp"></property></p>
</bean>

<!--配置spring注解驱动 自动注册合适的组件handleMapping和handlerAdapter -->

<p><a href="mvc:annotation-driven">mvc:annotation-driven</a></mvc:annotation-driven></p>
<!---->

<p>&lt;mvc:annotation-driven conversion-service&#x3D;”conversionServiceBean”&gt;</mvc:annotation-driven></p>
<!--注册自定义日期处理转换器-->

<bean id="conversionServiceBean" class="org.springframework.format.support.FormattingConversionServiceFactoryBean">

<property name="converters">

<set>

<p><bean class="com.lg.converter.DateConverter"></bean></p>
</set>

</property>

</bean>

<!--静态资源配置方案-->

<p><a href="mvc:default-servlet-handler">mvc:default-servlet-handler</a></mvc:default-servlet-handler></p>
<p>&lt;mvc:resources location&#x3D;”&#x2F;WEB-INF&#x2F;js&#x2F;“ mapping&#x3D;”&#x2F;js&#x2F;**”&#x2F;&gt;</p>
<p><a href="mvc:interceptors">mvc:interceptors</a></p>
<!--拦截所有的handle-->

<!-- <bean class="com.lg.interceptor.MyInterceptor"></bean>-->

<p><a href="mvc:interceptor">mvc:interceptor</a></p>
<!--拦截所有-->

<p>&lt;mvc:mapping path&#x3D;”&#x2F;**”&#x2F;&gt;</p>
<!--可以放行不拦截的请求-->

<!--<mvc:exclude-mapping path="/demo/**"/>-->

<!--拦截器 有先后顺序 放在最后-->

<p><bean class="com.lg.interceptor.MyInterceptor"></bean></p>
<p></mvc:interceptor></p>
<p></mvc:interceptors></p>
<!--配置⽂件上传解析器，id是固定的multipartResolver-->

<bean id="multipartResolver" class="org.springframework.web.multipart.commons.CommonsMultipartResolver">

<!--设置上传⼤⼩，单位字节-->

<property name="maxUploadSize" value="5000000"/>

<property name="maxInMemorySize" value="4096" />

<p><property name="defaultEncoding" value="UTF-8"></property></p>
</bean>

<h3 id="web-xml配置"><a href="#web-xml配置" class="headerlink" title="web.xml配置"></a>web.xml配置</h3><context-param>

<p><param-name>contextConfigLocation</param-name></p>
<p><param-value>classpath*:applicationContext.xml</param-value></p>
</context-param>

<!--spring框架启动-->

<listener>

<p><listener-class>org.springframework.web.context.ContextLoaderListener</listener-class></p>
</listener>

<!--springmvc启动-->

<servlet>

<p><servlet-name>springmvc</servlet-name></p>
<p><servlet-class>org.springframework.web.servlet.DispatcherServlet</servlet-class></p>
<init-param>

<p><param-name>contextConfigLocation</param-name></p>
<p><param-value>classpath*:springmvc.xml</param-value></p>
</init-param>

</servlet>

<servlet-mapping>

<p><servlet-name>springmvc</servlet-name></p>
<p><url-pattern>&#x2F;*</url-pattern></p>
</servlet-mapping>]]></content>
      <categories>
        <category>基础知识</category>
        <category>springmvc</category>
      </categories>
      <tags>
        <tag>基础知识</tag>
        <tag>springmvc</tag>
      </tags>
  </entry>
  <entry>
    <title>zookeeper相关知识</title>
    <url>/posts/26268/</url>
    <content><![CDATA[<h2 id="一、Zookeeper基础"><a href="#一、Zookeeper基础" class="headerlink" title="一、Zookeeper基础"></a>一、Zookeeper基础</h2><h3 id="Zookeeper定位"><a href="#Zookeeper定位" class="headerlink" title="Zookeeper定位"></a>Zookeeper定位</h3><p>分布式系统是同时跨越多个物理主机，独⽴运⾏的多个软件所组成系统，而ZooKeeper主要的使⽤场景，就是作为分布式系统的分布式协同服务。分布式系统的协调⼯作就是通过某种⽅式，让每个节点的信息能够同步和共享，这依赖于服务进程之间的通信。</p>
<p>两种通信方式：通过网络进行信息共享、通过共享储存（Zookeeper）。</p>
<p><img src="https://pic2.zhimg.com/80/v2-d75675da81f6deb6d4b551e45118ac09_720w.webp" alt="img"></p>
<h3 id="Zookeeper基本概念"><a href="#Zookeeper基本概念" class="headerlink" title="Zookeeper基本概念"></a>Zookeeper基本概念</h3><p>Zookeeper是⼀个典型的分布式数据⼀致性的解决⽅案，分布式应⽤程序可以基于它实现诸如数据订阅&#x2F;发布、负载均衡、命名服务、集群管理、分布式锁和分布式队列等功能。</p>
<p><strong>集群角色</strong>：Zookeeper没用传统的主备模式，即Master&#x2F;Slave模式，而是引⼊了Leader、Follower、Observer三种⻆⾊，Leader通过选举产生，所有机子都可能成为Leader，Follower就是跟随者，Observer也相当于跟随者，但是没有投票权，Observer的意义在于不参与选举，减低投票压力，因为投票者越少，选出Leader越快，并且不参与写操作的过半写策略，提高集群性能。</p>
<p><img src="/posts/26268/asset/v2-f3b3d487ef2e4d1ef5089df1a38384ce_720w.webp" alt="img"></p>
<p><strong>会话</strong>：Session指客户端会话，⼀个客户端连接是指客户端和服务端之间的⼀个TCP⻓连接，通过心跳机制来保持有效会话。</p>
<p><strong>数据节点</strong>（Znode）: 构成集群的机器，我们称之为机器节点，数据模型中的数据单元，数据节点——ZNode，他是一颗树状的数据模型。</p>
<p><strong>版本</strong>：每个ZNode，Zookeeper都会为其维护⼀个叫作Stat的数据结构，Stat记录了这个ZNode的三个数据版本，分别是version（当前ZNode的版本）、cversion（当前ZNode⼦节点的版本）、aversion（当前ZNode的ACL版本）。</p>
<p><strong>Watcher（事件监听器）</strong>：就是特定的事件监听机制，进行特殊化通知某个服务器协同处理某些逻辑。</p>
<p><strong>ACL策略</strong>：用于权限控制，五种分类权限：　</p>
<p>1）CREATE：创建⼦节点的权限。</p>
<p>2）READ：获取节点数据和⼦节点列表的权限。</p>
<p>3）WRITE：更新节点数据的权限。</p>
<p>4）DELETE：删除⼦节点的权限。</p>
<p>5）ADMIN：设置节点ACL的权限。</p>
<h3 id="Zookeeper环境搭建"><a href="#Zookeeper环境搭建" class="headerlink" title="Zookeeper环境搭建"></a>Zookeeper环境搭建</h3><p><img src="https://pic4.zhimg.com/80/v2-b8a42e6fb0140cdd33d8cd158f9a2343_720w.webp" alt="img"></p>
<p><img src="/posts/26268/asset/v2-1def7b696b709aeabd31f71dee1455bd_720w.webp" alt="img"></p>
<p>伪集群搭建注意事项，当前zookeeper的节点配置不能写ip地址，要写成0.0.0.0</p>
<h3 id="Znode系统模型"><a href="#Znode系统模型" class="headerlink" title="Znode系统模型"></a>Znode系统模型</h3><p>ZNode 是Zookeeper 中最⼩数据单位，在 ZNode 下面又可以再挂 ZNode，这样⼀层层下去就形成了⼀个层次化</p>
<p>命名空间 ZNode 树，我们称为 ZNode Tree，它采用类似⽂件系统的层级树状结构进行管理。</p>
<p><img src="/posts/26268/asset/v2-b2a56d460fe5fc09d554baa94683fc11_720w.webp" alt="img"></p>
<p>Znode类型：持久性节点（创建后一直存在，除非主动删除）、临时性节点（会自动被清理）、顺序性节点（带顺序的持久或者临时节点）</p>
<p>事务：每个事务请求，ZooKeeper都会为其分配⼀个全局唯⼀的事务ID，⽤ZXID来表示，通常是⼀个64位的数字，</p>
<p>每⼀个ZXID对应⼀次更新操作，通过他来知道执行顺序，从而保证事务执行。</p>
<p><img src="/posts/26268/asset/v2-2b220661c6ae3de06a9fd501d668823e_720w.webp" alt="img"></p>
<h3 id="Watcher系统模型"><a href="#Watcher系统模型" class="headerlink" title="Watcher系统模型"></a>Watcher系统模型</h3><p>ZooKeeper 允许客户端向服务端注册⼀个 Watcher 监听，当服务端的⼀些指定事件触发了这个 Watcher，那么就会向指定客户端发送⼀个事件通知来实现分布式的通知功能。</p>
<p>Watcher机制：客户端线程、客户端WatcherManager、Zookeeper服务器。</p>
<p><img src="https://pic3.zhimg.com/80/v2-b44d917871121fe5270c941081c0653e_720w.webp" alt="img"></p>
<p>客户端在向Zookeeper服务器注册的同时，会将Watcher对象存储在客户端的WatcherManager当中。当Zookeeper服务器触发Watcher事件后，会向客户端发送通知，客户端线程从WatcherManager中取出对应的Watcher对象来执⾏回调逻辑。</p>
<h3 id="ACL系统模型"><a href="#ACL系统模型" class="headerlink" title="ACL系统模型"></a>ACL系统模型</h3><p>ACL权限控制机制用来保障数据的安全，这部分数据就是内部存储的分布式系统运⾏时状态的元数据。</p>
<p>ACL机制三部分：权限模式（Scheme）、授权对象（ID）、权限（Permission）</p>
<p>权限模式：权限验证的检验策略，分Ip（IP地址模式）、Digest（常用模式，即用户名：密码模式）、World（开放模式）、Super（超级管理员模式）</p>
<p>授权对象：权限赋予的⽤户或⼀个指定实体，例如 IP 地址或是机器等。</p>
<p>权限：通过权限检查后可以被允许执⾏的操作，也就是前面提到的那五种分类权限。</p>
<h2 id="二、Zookeeper应用"><a href="#二、Zookeeper应用" class="headerlink" title="二、Zookeeper应用"></a>二、Zookeeper应用</h2><h3 id="数据发布-x2F-订阅"><a href="#数据发布-x2F-订阅" class="headerlink" title="数据发布&#x2F;订阅"></a>数据发布&#x2F;订阅</h3><p>ZooKeeper是⼀个典型的发布&#x2F;订阅模式的分布式数据管理与协调框架，我们可以使⽤它来进⾏分布式数据的发布与订阅。另⼀⽅⾯，通过对ZooKeeper中丰富的数据节点类型进⾏交叉使⽤，配合Watcher事件通知机制，可以⾮常⽅便的构建⼀系列分布式应⽤中都会涉及的核⼼功能，如数据发布&#x2F;订阅、命名服务、集群管理、Master选举、分布式锁和分布式队列等。</p>
<p>数据发布&#x2F;订阅（Publish&#x2F;Subscribe）系统，即所谓的配置中⼼，顾名思义就是发布者将数据发布到ZooKeeper的⼀个或⼀系列节点上，供订阅者进⾏数据订阅，进⽽达到动态获取数据的⽬的，实现配置信息的集中式管理和数据的动态更新。</p>
<p>两种设计模式：推（Push）模式和拉（Pull）模式。</p>
<p>推模式：服务端主动将数据更新发送给所有订阅的客户端。</p>
<p>拉模式：客户端主动发起请求来获取最新数据，常用轮询方式。</p>
<p>ZooKeeper 采⽤的是推拉相结合的⽅式：客户端向服务端注册⾃⼰需要关注的节点，⼀旦该节点的数据发⽣变更，那么服务端就会向相应客户端发送Watcher事件通知，客户端接收到这个消息通知之后，需要主动到服务端获取最新的数据。</p>
<p>比如通过zookeeper配置数据库连接信息，通过zookeeper的watcher事件通知机制，在集群环境下，当集群中的每台机子初始化阶段，就会从配置节点上读取数据库配置信息，并通过在该节点注册的watcher监听，一旦数据发生改变，所有订阅的客户端都能获取到变更通知，然后重新读取最新配置信息。</p>
<h3 id="命名服务"><a href="#命名服务" class="headerlink" title="命名服务"></a>命名服务</h3><p>命名服务就是集群中的机器、提供的服务地址或远程对象等等一系列的名称，通过使⽤命名服务，客户端应⽤能够根据指定名字来获取资源的实体、服务地址和提供者的信息等，比如RPC中的服务地址列表。</p>
<p>比如创建全局唯一ID，首先客户端会根据任务类型创建一个顺序节点，如job-0000000001，前缀是任务类型，接着客户端拿到这个值后还会拼接上type类型，最终形成一个全局唯一ID，如type-job-0000000001。</p>
<h3 id="集群管理"><a href="#集群管理" class="headerlink" title="集群管理"></a>集群管理</h3><p>集群管理，包括集群监控与集群控制两⼤块，前者侧重对集群运⾏时状态的收集，后者则是对集群进⾏操作与控制。</p>
<p>集群管理主要干的事：统计多少台机器、获取上下线机器情况、监控每台机器运行时状况。</p>
<p>传统集群管理基于Agent进行分布式集群管理，在每台机子上部署一个Agent，每个 Agent 主动向指定的⼀个监控中⼼系统汇报自己所在机器的状态，但是具有局限性，只能监控大局观上的内容，比如负载、CPU使用率、吞吐量等等，至于内部的一些业务状态，任务执行情况等等没办法监控。</p>
<p><strong>Zookeeper实现集群管理（分布式日志收集系统）</strong></p>
<p>特点</p>
<p>1）客户端如果对Zookeeper的数据节点注册Watcher监听，那么当该数据节点的内容或是其⼦节点列表发⽣变更时，Zookeeper服务器就会向订阅的客户端发送变更通知。</p>
<p>2）对在Zookeeper上创建的临时节点，如果客户端与服务器之间的会话失效，那么临时节点也会被⾃动删除。</p>
<p>实现</p>
<p>1） 注册收集器机器：创建一个节点作为收集器根节点，其他机器纷纷在这个主节点下创建自己的子节点。</p>
<p>2） 任务分发：系统根据收集器节点下面的数量，进行分组，然后组内的机器日志都写到当前组下面创建的子节点上。</p>
<p>3） 状态汇报：每个收集器还要创建一个状态节点，这个节点是持久节点，因为临时节点在服务器挂掉后会被自动删除，按时写入状态信息，日志系统定时，也就是主动轮询策略根据状态节点信息更新时间来判断该节点是否存活，类似于心跳机制检测，如果采用Watcher，通知量会很高，因为一更新就会触发，对于检测来说没必要。</p>
<p>4） 动态分配：当收集器集群机器存在扩展或者挂掉，第一种方式就是全局动态分配，即重新开始分组，影响较大，风险较高。第二种局部动态分配，这也是为什么要分组的原因，当某组的某台机器挂掉或者扩容，对当前组进行重新分配，把挂掉机器的任务分配到其他负载低的机器上或者新加进来的机器分担一些负载高机器的任务。</p>
<h3 id="Master选举"><a href="#Master选举" class="headerlink" title="Master选举"></a>Master选举</h3><p>所有集群机器通过选举产生一个主机器，成为Master，他的作用就是对其他集群机器进行协调，就最大控制权，同时一些重要业务逻辑和读写分离的写操作由Master执行，Zookeeper是通过所有机器同时创建一个相同的节点，这个节点是临时节点，谁创建成功，谁就是Master的机制进行选举，当确定了Master之后，其他机器就在Master节点后面创建子节点，对Master进行Watcher进行监听，当Master服务器挂了，那么 Master创建的临时节点也会被删除，通过Watcher机制其他集群机器就马上知道了结果，于是重新选举。</p>
<h3 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h3><p>分布式锁是控制分布式系统之间同步访问共享资源的⼀种⽅式，其实就是对共享资源的访问保持一致性。</p>
<p><strong>排他锁</strong></p>
<p>排他锁又称写锁或独占锁，是⼀种基本的锁类型。就是事务1对资源1加了锁，那么只有事务1能对他进行操作，直到他释放了锁之后，其他事务才能操作。</p>
<p>Zookeeper中排他锁实现：</p>
<p>1） 定义锁：定义一个lock锁节点</p>
<p>2） 获取锁：所有客户端都尝试在这个lock节点下创建临时子节点，当谁成功创建临时子节点，就是谁持有了排他锁，其他机器在lock注册监听，监听临时子节点变化。</p>
<p>3） 释放锁：当临时子节点被删除，也就是当前获取锁客户端宕机或者已经完成操作，其他机器监听到了子节点状态变化，过来争抢创建临时子节点，进行锁的获取。</p>
<p><img src="/posts/26268/asset/v2-c386f183fe4245f441da8de866038b84_720w.webp" alt="img"></p>
<p><strong>共享锁</strong></p>
<p>共享锁又称为读锁，同样是一种基本锁类型，和排他锁不一样，事务1对资源1加了共享锁，但是资源1对其他事务也可见，资源1是共享的，如果是读，资源2也可以加共享锁获取数据，也就是可以并行读，如果是写，就需要排斥。</p>
<p>Zookeeper中共享锁实现：</p>
<p>1） 定义锁：定义一个lock锁节点</p>
<p>2） 获取锁：所有客户端都往这个锁节点创建子节点，并往lock锁注册watcher事件监听，这时候就不是只允许一个创建了，是大家都可以创建，不过创建的是临时顺序节点，并且读、写请求的别名不一样，分别是R、W。当读节点前面都是读，那么就可以进行读，当读前面有写，那就等待，当写前面有读，等读完，直到自己是第一顺位写再执行。</p>
<p>3） 释放锁：因为都是临时顺序节点，宕机和执行完都会被删除，然后被监听的其他节点获取，相当于就完成了锁的交替。</p>
<h3 id="羊群效应"><a href="#羊群效应" class="headerlink" title="羊群效应"></a>羊群效应</h3><p>当集群规模扩大，这种watcher监听事件通知就会消耗很大的资源。如果第一个是读请求，第二个是写请求，只需要通知第二个节点即可，而通过watcher监听，通知的是所有集群机器，所以就造成了不必须的资源浪费。</p>
<p>改进：很简单，不对lock进行注册事件监听，只需要对当前节点的前面一个节点，也就是序号比自己小的前一位注册watcher事件监听，来监听前面的节点是读还是写请求，并且监听节点的状态变化。</p>
<p><img src="https://pic2.zhimg.com/80/v2-a254c8c41249ce1c944295e545a4e80d_720w.webp" alt="img"></p>
<h3 id="分布式队列"><a href="#分布式队列" class="headerlink" title="分布式队列"></a>分布式队列</h3><p>分布式队列可以简单分为两⼤类：⼀种是常规的FIFO先⼊先出队列模型，还有⼀种是等待队列元素聚集后统⼀安排处理执⾏的Barrier模型。</p>
<p><strong>FIFO先入先出队列</strong></p>
<p>先进⼊队列的请求操作先完成后，才会开始处理后⾯的请求。</p>
<p>Zookeeper实现FIFO队列：跟前面的共享锁类似，在一个主节点下面按顺序创建临时顺序子节点，第二个子节点在第一个子节点注册Watcher事件监听，监听前一个子节点变化，当第一个子节点消失，也就是执行完毕，马上执行，这样按顺序挂接下去，实现FIFO。</p>
<p><strong>Barrier分布式屏障</strong></p>
<p>FIFO的增强，同样的在主节点下面创建子节点，并注册监听到主节点中，通过getData判断子节点创建的数量是否到达10，如果到达了10个就解除屏障，进行事务处理，未达到就等待，对资源集中处理利用的一种方式。</p>
<h3 id="ZAB协议"><a href="#ZAB协议" class="headerlink" title="ZAB协议"></a>ZAB协议</h3><p>ZAB协议其实就是一种算法，跟Paxos算法一样，作为数据⼀致性的核⼼算法，不过ZAB协议是zookeeper专⻔设计的⼀种⽀持崩溃恢复的原子广播协议，内部实现的是主备模型。即主进程来接收并处理客户端的所有事务请求，并采⽤ZAB的原⼦⼴播协议，以事务 Proposal的形式广播给所有副本进程，处理大量并发请求。</p>
<p>ZAB核心：定义了对于那些会改变Zookeeper服务器数据状态的事务请求的处理⽅式，所有事务请求必须由⼀个全局唯⼀的服务器来协调处理，这样的服务器被称为Leader服务器，余下的服务器则称为Follower服务器，通过广播进行调度，并且根据反馈的ACK命令，以半数原则来判断是否可以下达提交命令。</p>
<p>ZAB协议分两种基本的模式：崩溃恢复和消息⼴播</p>
<p>崩溃恢复模式：即Leader服务器出现⽹络中断、崩溃退出或重启等异常情况，重新选举新的Leader</p>
<p>消息⼴播模式：过半的Follower服务器完成了和Leader服务器的状态同步，进入消息广播模式，这时新加入到集群的服务器会自觉进入数据恢复模式，即和Leader服务器数据进行同步，并加入到消息广播模式中。</p>
<p><strong>消息广播</strong></p>
<p>ZAB协议的消息⼴播过程使⽤原⼦⼴播协议，类似于⼀个⼆阶段提交过程，针对客户端的事务请求，Leader服务器会为其⽣成对应的事务Proposal，并将其发送给集群中其余所有的机器，这是是基于FIFO队列发送，然后再分别收集各⾃的选票，最后进⾏事务提交。当时ZAB协议移除了中断机制，也就是不需要等每台机子响应，只要过半机子响应了就执行提交事务，而数据不一致的问题就通过崩溃恢复模式来解决了。</p>
<p><strong>崩溃恢复</strong></p>
<p>选举算法：能够确保提交已经被 Leader 提交的事务 Proposal，同时丢弃已经被跳过的事务 Proposal。针对这个要求，如果让Leader选举算法能够保证新选举出来的Leader服务器拥有集群中所有机器最⾼编号（即ZXID最⼤）的事务Proposal，那么就可以保证这个新选举出来的Leader⼀定具有所有已经提交的提案。更为重要的是，如果让具有最⾼编号事务Proposal 的机器来成为 Leader，就可以省去 Leader 服务器检查Proposal的提交和丢弃⼯作的这⼀步操作了。</p>
<p>数据同步：Leader服务器会为每⼀个Follower服务器都准备⼀个队列，并将那些没有被各Follower服务器同步的事务以Proposal消息的形式逐个发送给Follower服务器， 并在每⼀个Proposal消息后⾯紧接着再发送⼀个Commit消息，以表示该事务已经被提交。等到 Follower服务器将所有其尚未同步的事务 Proposal 都从 Leader 服务器上同步过来并成功应⽤到本地数据库中后，Leader服务器就会将该Follower服务器加⼊到真正的可⽤Follower列表中，并开始之后的其他流程。</p>
<p><strong>运行时分析</strong></p>
<p>ZAB协议的三种状态：LOOKING：Leader选举阶段、FOLLOWING：Follower服务器和Leader服务器保持同步状态、LEADING：Leader服务器作为主进程领导状态。</p>
<p>所有进程初始状态都是LOOKING状态，此时不存在Leader，接下来，进程会试图选举出⼀个新的 Leader，之后如果进程发现已经选举出新的Leader了，那么它就会切换到FOLLOWING状态，并开始 和Leader保持同步，处于FOLLOWING状态的进程称为Follower，LEADING状态的进程称为Leader，当 Leader崩溃或放弃领导地位时，其余的Follower进程就会转换到LOOKING状态开始新⼀轮的Leader选举。</p>
<h3 id="运行流程"><a href="#运行流程" class="headerlink" title="运行流程"></a>运行流程</h3><p><strong>单机模式</strong></p>
<p>1、注册jmx</p>
<p>2、解析ServerConfig配置对象</p>
<p>3、根据配置对象，运⾏单机zk服务</p>
<p>4、创建管理事务⽇志和快照FileTxnSnapLog对象，zookeeperServer对象，并设置zkServer的统计对象</p>
<p>5、设置zk服务钩⼦，原理是通过设置CountDownLatch，调⽤ZooKeeperServerShutdownHandler的 handle⽅法，可以将触发shutdownLatch.await⽅法继续执⾏，即调⽤shutdown关闭单机服务</p>
<p>6、基于jetty创建zk的admin服务</p>
<p>7、创建连接对象cnxnFactory和secureCnxnFactory（安全连接才创建该对象），⽤于处理客户端的请求</p>
<p>8、创建定时清除容器节点管理器，⽤于处理容器节点下不存在⼦节点的清理容器节点⼯作等</p>
<p><img src="/posts/26268/asset/v2-b3e7bb1d5e65c62a63b9bbbb1e7c2827_720w.webp" alt="img"></p>
<p><strong>集群模式</strong></p>
<p>集群模式执行流程跟单机也是差不多的，只是在单机集群判断不同而已。</p>
<p><img src="/posts/26268/asset/v2-4ee7dbc1adb69148b0690a0cad4c76e0_720w.webp" alt="img"></p>
]]></content>
      <categories>
        <category>基础知识</category>
        <category>zookeeper</category>
      </categories>
      <tags>
        <tag>基础知识</tag>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式架构知识总结</title>
    <url>/posts/8228/</url>
    <content><![CDATA[<h2 id="一、分布式理论"><a href="#一、分布式理论" class="headerlink" title="一、分布式理论"></a>一、分布式理论</h2><h3 id="分布式系统概念和存在的问题"><a href="#分布式系统概念和存在的问题" class="headerlink" title="分布式系统概念和存在的问题"></a>分布式系统概念和存在的问题</h3><p>分布式系统，就是一个业务拆分成多个子业务，分布在不同的服务器节点，共同构成的系统称为分布式系统。</p>
<p>集群：多个人在一起作同样的事。</p>
<p>分布式：多个人在一起作不同的事。</p>
<p><img src="https://pic2.zhimg.com/80/v2-825769041326e65e785019cfb3ef0f79_720w.webp" alt="img"></p>
<p>特点：分布性、对等性、并发性、缺乏全局时钟、故障总数会发生</p>
<p><img src="/posts/8228/asset/v2-12d698e6ac791f27380da658631fd710_720w.webp" alt="img"></p>
<p><strong>分布式系统存在的问题</strong></p>
<p>通信异常：网络不确定性导致分布式系统无法顺利进行一次网络通信</p>
<p>网络分区：整个系统网络被切分，导致分布式系统出现局部小集群，小集群要完成整个分布式系统的功能。</p>
<p>节点故障：组成分布式系统的某个服务器出现宕机</p>
<p>三态：每次请求都存在的三种状态，失败、成功、超时。超时通常是发送过程中丢失或者响应过程中丢失。</p>
<h3 id="分布式理论：一致性"><a href="#分布式理论：一致性" class="headerlink" title="分布式理论：一致性"></a>分布式理论：一致性</h3><p>数据在多份副本中存储时，各副本中的数据是一致的。</p>
<p>数据的ACID四原则：原子性、一致性、隔离性、持续性。</p>
<p><strong>一致性分类</strong></p>
<p>强一致性：要求系统写入什么，读出来的也会是什么，对系统性能影响最大，难实现。</p>
<p>弱一致性：约束了系统在写入成功后，不承诺立即可以读到写入的值，也不承诺多久之后数据能够达到一致， 但会尽可能地保证到某个时间级别（比如秒级别）后，数据能够达到一致状态。</p>
<p><img src="https://pic3.zhimg.com/80/v2-c9a718da2208703fb9aba49e76a3aeea_720w.webp" alt="img"></p>
<p>弱一致性之读写一致性：用户读取自己写入结果的一致性，保证用户永远能够第一时间看到自己更新的内容，也就是写到了主库，但是读却走了从库，导致读写可能不一致，通过设定时间戳，让更新后一段时间都从主库读来实现。</p>
<p>弱一致性之单调读一致性：本次读到的数据不能比上次读到的旧，也就是第一次读主库最新值，第二次读从库还是旧值，通过根据用户ID计算一个hash值，再通过hash值映射到机器，让用户每次都访问一台机子来实现。</p>
<p>弱一致性之因果一致性：节点 A 在更新完某个数据后通知了节点 B，那么节点 B 之后对该数据的访问和修改都是基于 A 更新后的值。</p>
<p>弱一致性之最终一致性：最弱一致性模型，不考虑所有的中间状态的影响，只保证当没有新的更新之后，经过一段时间之后，最终系统内所有副本的数据是正确的。它最大程度上保证了系统的并发能力，在高并发的场景下，它也是使用最广的一致性模型。</p>
<h3 id="分布式理论：CAP定理"><a href="#分布式理论：CAP定理" class="headerlink" title="分布式理论：CAP定理"></a>分布式理论：CAP定理</h3><p>一个分布式系统不可能同时满足一致性（C:Consistency)，可用性（A: Availability）和分区容错性（P：Partition tolerance）这三个基本需求，最多只能同时满足其中的2个。</p>
<p><img src="https://pic4.zhimg.com/80/v2-fb12a3fafa88ab9bc0fef88938019b5f_720w.webp" alt="img"></p>
<p><img src="https://pic2.zhimg.com/80/v2-5493bff9d6f30e539d3949fd45a7a87d_720w.webp" alt="img"></p>
<p><strong>一致性</strong></p>
<p>目标：</p>
<p>1.商品服务写入主数据库成功, 则想从数据库查询数据也成功</p>
<p>2.商品服务写入主数据库失败,则向从数据库查询也失败</p>
<p>实现：</p>
<p>1.写入主数据库后要数据同步到从数据库，同步有一定延迟。</p>
<p>2.写入主数据库后,在向从数据库同步期间要将从数据库锁定, 等待同步完成后在释放锁,以免在写新数据后,向从数据库查询到旧的数据。</p>
<p><strong>可用性</strong></p>
<p>目标：</p>
<p>1.从数据库接收到数据库查询的请求则立即能够响应数据查询结果</p>
<p>2.从数据库不允许出现响应超时或错误</p>
<p>实现：</p>
<p>1.写入主数据库后要将数据同步到从数据</p>
<p>2.由于要保证数据库的可用性,不可以将数据库中资源锁定</p>
<p>3.即使数据还没有同步过来,从数据库也要返回查询数据, 哪怕是旧数据,但不能返回错误和超时.</p>
<p><strong>分区容错性</strong></p>
<p>目标：</p>
<p>1.主数据库想从数据库同步数据失败不影响写操作</p>
<p>2.其中一个节点挂掉不会影响另一个节点对外提供服务</p>
<p>实现：</p>
<p>1.尽量使用异步取代同步操作,如使用异步方式将数据从主数据库同步到从数据库, 这样节点之间能有效的实现松 耦合;</p>
<p>2.添加数据库节点,其中一个从节点挂掉,由其他从节点提供服务。</p>
<p><img src="https://pic2.zhimg.com/80/v2-7e8a4c084879e9ee10f8477fb3420ff9_720w.webp" alt="img"></p>
<h3 id="分布式理论：BASE理论"><a href="#分布式理论：BASE理论" class="headerlink" title="分布式理论：BASE理论"></a>分布式理论：BASE理论</h3><p>BASE：全称：Basically Available(基本可用)，Soft state（软状态）,和 Eventually consistent（最终一致性）</p>
<p>对CAP中一致性和可用性权衡的结果，即无法做到强一致性，但每个应用都可以根据自身业务特点，采用适当的方式来使系统达到最终一致性。</p>
<p>Basically Available(基本可用)：</p>
<p>分布式系统在出现不可预知故障的时候，允许损失部分可用性，比如12306抢票，他给你延时查询，响应非常久，又比如双十一抢购，订单付款时内部出现某种错误，网页这边提示你数据加载失败，让你重试，即不失败也不成果，进入降级处理。</p>
<p>Soft state（软状态）：允许系统中的数据存在中间状态，并认为该状态不影响系统的整体可用性，即允许系统在多个不同节点的数据副本之间进行数据同步的过程中存在延迟。</p>
<p>Eventually consistent（最终一致性）：最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性。</p>
<h3 id="分布式理论：一致性协议2PC"><a href="#分布式理论：一致性协议2PC" class="headerlink" title="分布式理论：一致性协议2PC"></a>分布式理论：一致性协议2PC</h3><p>两阶段提交协议，是将整个事务流程分为两个阶段，准备阶段（Preparephase）、提交阶段（commit phase），2是指两个阶段，P是指准备阶段，C是指提交阶段。</p>
<p>准备阶段（Prepare phase）：</p>
<p>事务管理器给每个参与者发送Prepare消息，每个数据库参与者在本地执行事务，并写本地的Undo&#x2F;Redo日志，此时事务没有提交。（Undo日志是记录修改前的数据，用于数据库回滚， Redo日志是记录修改后的数据，用于提交事务后写入数据文件）</p>
<p>提交阶段（commit phase）：</p>
<p>如果事务管理器收到了参与者的执行失败或者超时消息时，直接给每个参与者发送回滚(Rollback)消息；否则，发送提交(Commit)消息；参与者根据事务管理器的指令执行提交或者回滚操作，并释放事务处理过程中使用的锁资源。</p>
<p><img src="https://pic2.zhimg.com/80/v2-a2fe571e0d5960121295a0aa87676e89_720w.webp" alt="img"></p>
<p><strong>缺点</strong></p>
<p>同步阻塞：他需要等第一阶段所有节点全部完成之后才能执行第二阶段。</p>
<p>单点问题：严重依赖于事务管理协调者，一旦协调者出现问题导致整个流程无法完成。</p>
<p>数据不一致：第二阶段事务管理器逐个向资源节点发生提交请求，当发送到一半，事务管理器宕机了，前面的资源节点会提交，后面的回滚，导致数据不一致。而且当资源节点出现问题无法向协调者发送响应信息，事务管理者只能依赖超时机制进行事务中断。</p>
<h3 id="分布式理论：一致性协议3PC"><a href="#分布式理论：一致性协议3PC" class="headerlink" title="分布式理论：一致性协议3PC"></a>分布式理论：一致性协议3PC</h3><p>将 2PC 的提交阶段过程一分为三，形成了由 CanCommit、PreCommit和doCommit三个阶段组成的事务处理协议。</p>
<p><img src="/posts/8228/asset/v2-4bc3d4385193271ae4198ad38c421d58_720w.webp" alt="img"></p>
<p>CanCommit：协调者给参与者发送事务响应等待全部回应。</p>
<p>PreCommit：协调者收到全部参与者响应，yes发送执行事务预提交，并反馈ACK，如果有一个参与者未反馈或者反馈no，中断事务。</p>
<p>doCommit：协调者收到所有参数值ACK反馈，向所有参与者发送提交指令，参与者完成之后向协调者发送ACK响应，但是有一个问题，也就是进入第三阶段，如果协调者因宕机等原因没有向参与者发送提交doCommit请求或回滚abort请求，参与者到达超时时间自动提交，也就是如果是要准备回滚的话，就出现了问题。</p>
<p><strong>2PC对比3PC</strong></p>
<p>1） 协调者和参与者都设置了超时机制，降低了整个事务的阻塞时间和范围，解决了之前的同步阻塞。</p>
<p>2） 通过CanCommit、PreCommit、DoCommit三个阶段的设计，相较 于2PC而言，多设置了一个缓冲阶段保证了在最后提交阶段之前各参与节点的状态是一致的。</p>
<p>3） 3PC协议并没有完全解决数据不一致问题。</p>
<h3 id="分布式理论：一致性算法Paxos"><a href="#分布式理论：一致性算法Paxos" class="headerlink" title="分布式理论：一致性算法Paxos"></a>分布式理论：一致性算法Paxos</h3><p>此算法用于解决分布式系统一致性问题。</p>
<p><img src="https://pic2.zhimg.com/80/v2-75228427b192b012289ab4266f6f0cf9_720w.webp" alt="img"></p>
<p>当出现多个参与者，要保证数据事务一致性，就引入了3PC进行协调，协调者也可能宕机，所以协调者也做了集群，当每个参与者发送了不同的指令给协调者，协调者就必须有一个真正的决策者来保证数据的一致性。</p>
<p><strong>提案（Proposal）</strong></p>
<p>提案 (Proposal)：Proposal信息包括提案编号 (Proposal ID) 和提议的值 (Value)，最终要达成一致的value就在提案里。</p>
<p><strong>Paxos算法的角色</strong></p>
<p>Client：客户端向分布式系统发出请求 ，并等待响应。</p>
<p>Proposer：提案发起者提倡客户请求，试图说服Acceptor对此达成一致，并在发生冲突时充当协调者以推动协议向前发展。</p>
<p>Acceptor：决策者可以接受（accept）提案；如果某个提案被选定（chosen），那么该提案里的value就被选定了。</p>
<p>Learners：最终决策学习者充当该协议的复制因素。</p>
<p><strong>一致性算法的保证</strong></p>
<p>1）在这些被提出的提案中，只有一个会被选定 。</p>
<p>2）如果没有提案被提出，就不应该有被选定的提案。</p>
<p>3）当一个提案被选定后，那么所有进程都应该能学习（learn）到这个被选定的value。</p>
<p><strong>Paxos算法提案规则</strong></p>
<p><img src="/posts/8228/asset/v2-1a4b429b28bb3704767b73044399a750_720w.webp" alt="img"></p>
<p>总结：提案规则P2c &#x3D;&gt;P2b&#x3D;&gt;P2a&#x3D;&gt;P2，通过P2和P1来保证一致性，概括就是决策者必须接受收到的第一个提案，当只有一个决策者，那么第一个提案就是最终提案，当多个决策者，以半数以上决策者接收的提案为最终提案，当决策者选定了一个提案，后续提案只能增长序列编号，不能更改提案的值。</p>
<p><strong>Proposer生成提案规则-&gt;Acceptor接受提案规则</strong></p>
<p>Proposer生成提案之前，应该先去『学习』已经被选定或者可能被选定的value，然后以 该value作为自己提出的提案的value。如果没有value被选定，Proposer才可以自己决定value的值。</p>
<p><img src="/posts/8228/asset/v2-7ef968cd32cb83c7a23858547c89bdd0_720w.webp" alt="img"></p>
<p>理解：提案者1先发送一个prepare给决策者，并携带一个map，这个map只有key，编号n，value是null，当决策者接受了这个提案，就把当做了最终提案保存了下来，并返回了一个空value回来，这里有一个规则，如果决策者是多个，需要超过半数返回才行，如果没有超过半数，重新提交prepare给决策者，接着提案者1再往map里面放入值，提交给决策者，决策者就把这个map替换了之前的空null的map，并返回ack，如果超过半数返回了ack，此value就被确定，否则重新提交prepare给决策者，当完成后如果又有另一个提案者2提交了提案，他的编号是n+1，决策者接收了，但是决策者已经有最终提案了，这时候他会把value返回给提案者2，让提案者2学习，把自己map集合的value值替换成决策者返回的值，提案者学习完毕，再次提交，这时候决策者就接受了提案者2的提案，把之前的提案进行了替换，而且编号低于n+1的提案会被决策者直接拒绝，这样值没变，保证了数据的一致性，还可以通过编号实现对不符合规则的提案过滤。</p>
<p><img src="/posts/8228/asset/v2-719ebc0cdbbc23541f50bb1bf7ece826_720w.webp" alt="img"></p>
<p><strong>Learner学习被选定的value</strong></p>
<p>当决策者接受了一个提案，就会把这个提案发给所有学习者，来保证数据一致性。</p>
<p><img src="https://pic4.zhimg.com/80/v2-82dd45dd395ea215e2eebfd003a41c7f_720w.webp" alt="img"></p>
<p><strong>保证Paxos算法的活性</strong></p>
<p>两个Proposer依次提出了一系列编号递增的提案，但是每次根据响应塞值提交又因为编号不一致，被另一个提案者编号给递增，导致又恢复到最开始提交prepare，最终陷入死循环，没有value被选定。</p>
<p>解决：通过选取主Proposer，并规定只有主Proposer才能提出议案。这样一来只要主Proposer和过半的Acceptor能够正常进行网络通信，那么只能是主Proposer提出一个编号更高的提案，该提案终将会被批准，这样通过选择一个主 Proposer，整套Paxos算法就能够保持活性。</p>
<h3 id="分布式理论：一致性算法Raft"><a href="#分布式理论：一致性算法Raft" class="headerlink" title="分布式理论：一致性算法Raft"></a>分布式理论：一致性算法Raft</h3><p>Raft算法分为两个阶段，首先是选举过程，然后在选举出来的领导人带领进行正常操作，主要用于管理复制日志的一致性算法。</p>
<p>Raft算法三模块：领导人选举、日志复制、安全性。</p>
<p><strong>领导人Leader选举</strong></p>
<p>Raft通过选举一个领导人，然后给予他全部的管理复制日志的责任来实现一致性。</p>
<p>三个角色(任何服务器都可以当三个角色之一)：</p>
<p>领导者(leader)：处理客户端交互，日志复制等动作，一般一次只有一个领导者</p>
<p>候选者(candidate)：候选者就是在选举过程中提名自己的实体，一旦选举成功，则成为领导者</p>
<p>跟随者(follower)：类似选民，完全被动的角色，这样的服务器等待被通知投票</p>
<p><img src="/posts/8228/asset/v2-4fb85cd549cfa1a7873f865a83ed3c94_720w.webp" alt="img"></p>
<p>理解：当服务启动的时候，所有服务器follower都是初始状态，每个服务器都有一个定时器，超时时间为election timeout（一般为150-300ms），当某个服务器达到超时时间，他就成为了候选者，先给自己投上一票，然后发送消息给其他服务器，当其他服务器超过半数收到了他的消息，相当于获取到了选票，他就成了领导者，而其他服务器全部成了跟随者，这时候领导者就开始根据间隔时间向跟随者发送心跳检测包，证明我还活在，也就是心跳机制，而跟随者每次接受到消息，就初始化自己内部的定时器，当某个服务器定时器达到超时时间，没有收到领导者的消息，那么跟随者会觉得领导者挂了，他就摇身一变称为候选者，开始篡位，重复之前的过程，成为领导者，当他成为领导者之后，当前任领导者就算回来了，也只能变成跟随者。</p>
<p>特殊情况：四个服务器，当其中两个服务器同时达到超时成为候选者，并且每个服务器拿到自己一票，另外一个服务器一票，这时候的机制就是这两个服务器重新定时，先达到超时的服务器成为候选者，并发送通知进一步成为选举者。</p>
<p><strong>日志复制（保证数据一致性）</strong></p>
<p>Leader选出后，就开始接收客户端的请求。Leader把请求作为日志条目（Log entries）加入到它的日志中，然后并行的向其他服务器发起 AppendEntries RPC复制日志条目。当这条日志被复制到大多数服务器上，Leader将这条 日志应用到它的状态机并向客户端返回执行结果。</p>
<p><img src="https://pic3.zhimg.com/80/v2-bb308fb5ccc46915f0cb13a9875bcc4e_720w.webp" alt="img"></p>
<p>1）客户端的每一个请求都包含被复制状态机执行的指令。</p>
<p>2）leader把这个指令作为一条新的日志条目添加到日志中，然后并行发起 RPC 给其他的服务器，让他们复制这条 信息。</p>
<p>3）跟随者响应ACK,如果 follower 宕机或者运行缓慢或者丢包，leader会不断的重试，直到所有的 follower 最终都 复制了所有的日志条目。</p>
<p>4）通知所有的Follower提交日志，同时领导人提交这条日志到自己的状态机中，并返回给客户端。</p>
<h2 id="二、分布式系统设计策略"><a href="#二、分布式系统设计策略" class="headerlink" title="二、分布式系统设计策略"></a>二、分布式系统设计策略</h2><p>分布式常用设计策略：如何检测当前节点还活着？ 如何保障高可用？ 容错处理？ 负载均衡？</p>
<h3 id="心跳检测机制"><a href="#心跳检测机制" class="headerlink" title="心跳检测机制"></a>心跳检测机制</h3><p>心跳顾名思义，就是以固定的频率向其他节点汇报当前节点状态的方式。收到心跳，一般可以认为一个节点和现在的网络拓扑是良好的。心跳汇报时，一般也会携带一些附加的状态、元数据信息，以便管理。</p>
<p><img src="/posts/8228/asset/v2-3b756fe340dd37a79d661489e6491eb0_720w.webp" alt="img"></p>
<p>理解：Client请求Server，Server转发请求到具体的Node获取请求结果。Server需要与三个Node节点保持心跳连接，确保Node可以正常工作，若Server没有收到Node3的心跳时，Server认为Node3失联，当Node3不一定是宕机了，可能是网络中断、任务繁忙导致检测超时等等，通过周期检测心跳机制、累计失效检测机制来判断节点是否挂掉，如果真正挂掉，从集群中移除，等恢复后再加进来。</p>
<h3 id="高可用设计"><a href="#高可用设计" class="headerlink" title="高可用设计"></a>高可用设计</h3><p>系统架构设计中必须考虑的因素之一，通常是指经过设计来减少系统不能提供服务的时间。</p>
<p><img src="https://pic3.zhimg.com/80/v2-3ddfce4f1f68ac247e09773ad7f6b842_720w.webp" alt="img"></p>
<p>系统高可用性的常用设计模式包括三种：主备（Master-SLave）、互备（Active-Active）和集群（Cluster）模式。</p>
<p><strong>主备模式</strong></p>
<p>最常用的模式，当主机宕机时，备机接管主机的一切工作，待主机恢复正常后，按使用者的设定以自动（热备）或手动（冷备）方式将服务切换到主机上运行，数据库称为MS模式，MySQL、Redis就采用MS模式实现主从复制，保证高可用。</p>
<p><img src="/posts/8228/asset/v2-b2293a1e286a7c2943ed51bb7d1f065c_720w.webp" alt="img"></p>
<p>master中所有操作都会以“事件”的方式记录在二进制日志中，也就是bin-log，其他数据库作为slave通过一个I&#x2F;O线程与主服务器保持通信，并监控master的二进制日志文件的变化，如果发现master二进制日志文件发生变化，则会把变化复制到自己的relay-log日志中，然后slave的一个SQL线程会把相关的“事件”执行到自己的数据库中，以此实现从数据库和主数据库的一致性，也就实现了主从复制。</p>
<p><strong>互备模式</strong></p>
<p>两台主机同时运行各自的服务工作且相互监测情况，开启互相备份同步，只有对写要求较高，需要多台数据库服务器存储写入数据，比如微博之类的网站。</p>
<p><img src="/posts/8228/asset/v2-c6d79f9fd7bbf0820e82b0a084b92524_720w.webp" alt="img"></p>
<p><strong>集群模式</strong></p>
<p>集群模式是指有多个节点在运行，同时可以通过主控节点分担服务请求。如Zookeeper。集群模式需要解决主控节 点本身的高可用问题，一般采用主备模式来把某个节点当做master。</p>
<h3 id="容错性设计"><a href="#容错性设计" class="headerlink" title="容错性设计"></a>容错性设计</h3><p>提高系统对于错误包容的能力，保障分布式环境下相应系统的高可用或者健壮性，也提升了系统的安全性。</p>
<p>比如Redis的缓存穿透。</p>
<p><img src="https://pic3.zhimg.com/80/v2-67c70a7596cfd5981cae1e002baa944a_720w.webp" alt="img"></p>
<p>当一个请求进来时，从缓存中查询不到，这时候就会进去数据库查，如果是一个恶意的请求，比如id为-1，这个值根本不存在，制造大量请求进行攻击，越过缓存，数据库服务器可能就会承受不住压力而宕机，这时候就需要一个容错性设计来保证数据库的安全，可以通过布隆过滤器或者在第一次请求，为null时仍然返回一个值存储缓存，并设置一定的过期时间，再次请求就会直接经过缓存返回，来保证系统的高可用。</p>
<h3 id="负载均衡策略"><a href="#负载均衡策略" class="headerlink" title="负载均衡策略"></a>负载均衡策略</h3><p>使用多台集群服务器共同分担计算任务，把网络请求及计算分配到集群可用的不同服务器节 点上，从而达到高可用性及较好的用户操作体验。</p>
<p><img src="/posts/8228/asset/v2-1950fd06eee44a7902b67e2ebe79d6cc_720w.webp" alt="img"></p>
<p>负载均衡器有硬件解决方案F5，也有软件解决方案Nginx、LVS等等。</p>
<p>负载均衡策略：</p>
<p>1） 轮询：默认就是轮询，根据Nginx配置文件中的顺序，依次把客户端的Web请求分发到不同的后端服务器。</p>
<p>2） 最少连接：当前谁连接最少，分发给谁。</p>
<p>3） IP地址哈希：确定相同IP请求可以转发给同一个后端节点处理，以方便session保持。</p>
<p>4） 基于权重的负载均衡：配置Nginx把请求更多地分发到高配置的后端服务器上，把相对较少的请求分发到低配服务器。</p>
<h3 id="三、分布式架构网络通信"><a href="#三、分布式架构网络通信" class="headerlink" title="三、分布式架构网络通信"></a>三、分布式架构网络通信</h3><h3 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h3><p>网络通信就是将流从一台计算机传输到另外一台计算机，基于传输协议和网络IO来实现，其中传输协议比较出名的有tcp、udp等等，tcp、udp都是在基于Socket概念上为某类应用场景而扩展出的传输协议，网络IO，主要有bio、nio、aio三种方式。其实就是使用不同的传输协议和IO技术实现服务器之间的远程方法调用。</p>
<p>TCP:面向连接的协议，速度不快，安全，因为他要经过三次握手，安全性要求更高四次握手。</p>
<p>UDP:广播协议，面向无连接，速度快，不安全，就是相当于广播一样只管发出去就完事了。</p>
<p>BIO:阻塞IO NIO:非阻塞IO AIO:非阻塞IO</p>
<p><img src="/posts/8228/asset/v2-64a9ae595fa9ae27805fe0c2f1241bc9_720w.webp" alt="img"></p>
<h3 id="RPC基本概念"><a href="#RPC基本概念" class="headerlink" title="RPC基本概念"></a>RPC基本概念</h3><p>RPC远程过程调用，核心模块就是通讯和序列化，他不是具体的技术，而是指整个网络远程调用过程，常用RPC实现框架Dubbo、Hessian、HSF等等。</p>
<p>RPC四个核心的组件，分别是Client，Client Stub，Server以及Server Stub，即客户端、客户端存根、服务端、服务端存根。</p>
<p><img src="/posts/8228/asset/v2-bfb6adf12bd64e2d3cc12f14d17f1db6_720w.webp" alt="img"></p>
<p>1） 客户端以接口方式调用客户端存根。</p>
<p>2） 客户端存根收到调用后，把方法、参数等封装成消息体进行序列化成二进制文件，从而在网络中传输。</p>
<p>3） 客户端存根将请求发送给服务器存根。</p>
<p>4） 服务器存根收到消息后对消息体进行反向序列化。</p>
<p>5） 服务端存根根据解码结果调用本地服务端。</p>
<p>6） 服务端进行服务处理，即执行方法并返回结果。</p>
<p>7） 服务端存根收到结果，将结果封装成消息体，并进行序列化成二进制文件。</p>
<p>8） 服务端存根返回消息给客户端存根。</p>
<p>9） 客户端存根收到消息后对消息体进行反序列化解码。</p>
<p>10）客户端存根返回解码结果，客户端得到最终结果。</p>
<p>RPC的目标是要把2、3、4、7、8、9这些步骤都封装起来。</p>
<h3 id="RMI远程方法调用"><a href="#RMI远程方法调用" class="headerlink" title="RMI远程方法调用"></a>RMI远程方法调用</h3><p>远程方法调用 (Remote Method Invocation)，是java原生支持的远程调用 ,采用JRMP（Java Remote Messageing protocol）作为通信协议，纯java版本的分布式远程调用解决方案。</p>
<p><strong>客户端</strong></p>
<p>1）存根&#x2F;桩(Stub)：远程对象在客户端上的代理。</p>
<p>2）远程引用层(Remote Reference Layer)：解析并执行远程引用协议。</p>
<p>3）传输层(Transport)：发送调用、传递远程方法参数、接收远程方法执行结果。</p>
<p><strong>服务端</strong></p>
<p>1） 骨架(Skeleton)：读取客户端传递的方法参数，调用服务器方的实际对象方法，并接收方法执行后的返回值。</p>
<p>2） 远程引用层(Remote Reference Layer)：处理远程引用后向骨架发送远程方法调用。</p>
<p>3） 传输层(Transport)：监听客户端的入站连接，接收并转发调用到远程引用层。</p>
<p><strong>注册表</strong></p>
<p>URL形式注册远程对象，并向客户端回复对远程对象的引用。</p>
<p><img src="https://pic4.zhimg.com/80/v2-a023b13a3f2a2acee0cd6b76b0e3d8ff_720w.webp" alt="img"></p>
<p>运行过程：首先启动server服务端，向注册表发布对象，再启动客户端，客户端就从注册表获取远程对象引用，接着客户端生成对应的代理对象，也就是Stub桩对象，他和远程对象具有相同的接口和方法列表，接着通过远程引用层Remote Reference Layer进行转化成远程引用对象，传递给传输层Transport，由传输层发送TCP协议到服务端的传输层Transport，接着服务端的传输层调用远程引用层Remote Reference Layer，把远程引用对象转化成服务端本地对象，然后传递给骨架Skeleton，骨架根据请求去调用服务端进行对应方法执行，并获取返回结果，接着骨架Skeleton又一层一层往回返，最终客户端获取结果。</p>
<h3 id="同步、异步、阻塞、非阻塞"><a href="#同步、异步、阻塞、非阻塞" class="headerlink" title="同步、异步、阻塞、非阻塞"></a>同步、异步、阻塞、非阻塞</h3><p>同步：用户进程触发IO操作等待或者轮训的方式查看IO操作是否就绪。</p>
<p>异步：当一个异步进程调用发出之后，调用者不会立刻得到结果。而是在调用发出之后，被调用者通过状态、通知来通知调用者，或者通过回调函数来处理这个调用。</p>
<p>阻塞：当一个线程需要获取一把锁，一直等待这个锁释放。</p>
<p>非阻塞：当一个线程需要获取一把锁，并不会一直等待，他跑去做其他事，等通知者告知他锁被释放，他在回来获取锁接着干事。</p>
<h3 id="BIO"><a href="#BIO" class="headerlink" title="BIO"></a>BIO</h3><p>同步阻塞IO，B代表blocking，jdk1.4之前唯一IO模型。</p>
<p>一个连接一个线程，即客户端有连接请求时服务器端就启动一个线程进行处理，如果这个连接不做任何事情会造成不必要的线程开销，可以通过线程池改善，但是同样的无法避免大量线程的创建，并发请求效率低。</p>
<p><img src="https://pic3.zhimg.com/80/v2-c49b9904811043869f760deb25e9a00a_720w.webp" alt="img"></p>
<h3 id="NIO"><a href="#NIO" class="headerlink" title="NIO"></a>NIO</h3><p>同步非阻塞IO，JDK 1.4 及以上版本。</p>
<p>一个请求一个通道，即客户端发送的连接请求都会注册到多路复用器上，多路复用器（也称为选择器）轮询到连接有IO请求时才启动一个线程进行处理。</p>
<p><strong>通道（Channels）</strong></p>
<p>NIO 新引入的最重要的抽象是通道的概念。Channel数据连接的通道。 数据可以从Channel读到Buffer，也可以从buffer写到Channel中。</p>
<p><strong>缓冲区（Buffer）</strong></p>
<p>就是存数据的地方，通过缓冲区提高读写效率，通道channel可以向缓冲区Buffer中写数据，也可以向buffer中存数据。</p>
<p><strong>选择器（Selector）</strong></p>
<p>使用选择器，借助单一线程，就可对数量庞大的活动 I&#x2F;O 通道实时监控和维护。</p>
<p><img src="/posts/8228/asset/v2-f4968f3959229d13d596da485473b998_720w.webp" alt="img"></p>
<p>BIO模型中，一个连接来了，会创建一个线程，对应一个while死循环，死循环的目的就是不断监测这条连接上是否有数据可以读，而NIO他创建了一个多路复用器selector，连接来了之后现进多路复用器，通过检查这个selector，不需要再批量死循环，就可以批量监测出有数据可读的连接，进而读取数据。</p>
<h3 id="AIO"><a href="#AIO" class="headerlink" title="AIO"></a>AIO</h3><p>异步非阻塞IO，JDK7开始支持。</p>
<p>当有流可以读时，操作系统会将可以读的流传入read方法的缓冲区，并通知应用程序，对于写操作，OS将write方法的流写入完毕，操作系统会主动通知应用程序。因此read和write都是异步的，完成后调用回调函数通知。</p>
<p><img src="/posts/8228/asset/v2-dfb33c828b92671e254103d93bca6463_720w.webp" alt="img"></p>
<h3 id="Netty"><a href="#Netty" class="headerlink" title="Netty"></a>Netty</h3><p>Netty 是由 JBOSS 提供一个异步的、 基于事件驱动的网络编程框架。</p>
<p><img src="/posts/8228/asset/v2-ce0278b1a9460c29c5351b5fd104c470_720w.webp" alt="img"></p>
<p><strong>NIO缺点</strong></p>
<p>1）NIO 的类库和 API 繁杂，使用麻烦。</p>
<p>2）可靠性不强，开发工作量和难度都非常大。</p>
<p>3）NIO 的 Bug。例如 Epoll Bug，它会导致 Selector 空轮询，最终导致 CPU 100%。</p>
<p><strong>Netty优点</strong></p>
<p>1）对各种传输协议提供统一的API 。</p>
<p>2）高度可定制的线程模型——单线程模型、一个或多个线程池模型。</p>
<p>3）更好的吞吐量，更低的等待延迟 。</p>
<p>4）更少的资源消耗 。</p>
<p>5）最小化不必要的内存拷贝。</p>
<p><strong>netty模型</strong></p>
<p><img src="/posts/8228/asset/v2-99dbc3f51f27af193c3626dde74cbf4e_720w.webp" alt="img"></p>
<p>Netty 抽象出两组线程池， BossGroup 专门负责接收客 户端连接， WorkerGroup 专门负责网络读写操作。 NioEventLoop 表示一个不断循环执行处理 任务的线程， 每个 NioEventLoop 都有一个 selector， 用于监听绑定在其 上的 socket 网络通道。 NioEventLoop 内部采用串行化设计， 从消息的读取-&gt;解码-&gt;处理-&gt;编码-&gt;发送， 始终由 IO 线 程 NioEventLoop 负责。</p>
<p><strong>Netty核心组件</strong></p>
<p><strong>ChannelHandler</strong> 接口及其实现类，相当于之前NIO里面的accept、read、write方法。</p>
<p><img src="/posts/8228/asset/v2-24a1e2f29156fcac15f78847826a5da3_720w.webp" alt="img"></p>
<p><strong>ChannelPipeline</strong> 是一个Handler的集合，它负责处理和拦截 inbound 或者 outbound 的事件和操作，相当于一个 贯穿 Netty 的链。</p>
<p><img src="/posts/8228/asset/v2-42ec7b46331778d6305f42fc5338ec48_720w.webp" alt="img"></p>
<p><strong>ChannelHandlerContext</strong>这是事件处理器上下文对象，Pipeline链中的实际处理节点。每个处理节点ChannelHandlerContext中包含一个 具 体 的 事 件 处 理 器 ChannelHandler ， 同 时 ChannelHandlerContext 中也绑定了对应的 pipeline 和 Channel 的信息，方便对 ChannelHandler 进行调用。</p>
<p><img src="https://pic3.zhimg.com/80/v2-f0113e80cba78bd225fd01ac135936c2_720w.webp" alt="img"></p>
<p><strong>ChannelFuture</strong> 核心，表示Channel 中异步 I&#x2F;O 操作的结果，在 Netty 中所有的 I&#x2F;O 操作都是异步的， I&#x2F;O 的调用会直接返回，调用者并不能立刻获得结果，但是可以通过 ChannelFuture 来获取 I&#x2F;O 操作的处理状态，结果要等执行完毕后获取。</p>
<p><img src="https://pic3.zhimg.com/80/v2-c713b674238ea17647fe98e5603d29e6_720w.webp" alt="img"></p>
<p><strong>EventLoopGroup</strong> 和其实现类 <strong>NioEventLoopGroup</strong>，EventLoopGroup(最上面模型中的Boss Group) 是一组 EventLoop（可以理解成一个线程，最上面模型中的NIOEventLoop） 的抽象， Netty 为了更好的利用多核 CPU 资源， 一般会有多个 EventLoop 同时工作，每个EventLoop 维护着一个Selector实例，线程池一般是两个，一次处理连接，一次进行操作。</p>
<p><img src="https://pic2.zhimg.com/80/v2-2b4ed67d6478e7bb894465e305733c3d_720w.webp" alt="img"></p>
<p><strong>ServerBootstrap</strong> 和 <strong>Bootstrap</strong> ServerBootstrap 是 Netty 中的服务器端启动助手，通过它可以完成服务器端的各种配置；Bootstrap是Netty 中的客户端启动助手，通过它可以完成客户端的各种配置。</p>
<p><img src="/posts/8228/asset/v2-eded268dd5435cd4c53298739c559668_720w.webp" alt="img"></p>
<p><img src="/posts/8228/asset/v2-0aaaced054fbe892c16fa944c4df1489_720w.webp" alt="img"></p>
<p><img src="https://pic2.zhimg.com/80/v2-ea9c3edc34aea7630b9e304f0a849a1d_720w.webp" alt="img"></p>
<p><img src="https://pic3.zhimg.com/80/v2-2177b146d9ac635cd8a6415db8055f5e_720w.webp" alt="img"></p>
<h3 id="基于Netty自定义RPC"><a href="#基于Netty自定义RPC" class="headerlink" title="基于Netty自定义RPC"></a>基于Netty自定义RPC</h3><p><strong>两种常用远程调用</strong></p>
<p>1）是基于HTTP的restful形式的广义远程调用，以spring could的feign和restTemplate为代表，采用的协议是HTTP的7层 调用协议，并且协议的参数和响应序列化基本以JSON格式和XML格式为主。</p>
<p>2）是基于TCP的狭义的RPC远程调用，以阿里的Dubbo为代表，主要通过netty来实现4层网络协议，NIO来异步传输， 序列化也可以是JSON或者hessian2以及java自带的序列化等，可以配置。</p>
<p><strong>运转实现图</strong></p>
<p><img src="/posts/8228/asset/v2-15c5a16e367e0c56787e17e9fea8257c_720w.webp" alt="img"></p>
<p><strong>服务端</strong></p>
<p>1） 通过main方法启动服务器，设定ip和端口，调用实现类的startServer方法。</p>
<p><img src="/posts/8228/asset/v2-55b184d2af02dfdf8dc2a0c488a4f3d8_720w.webp" alt="img"></p>
<p>2） 在startServer方法创建启动引导类并监听要做的事，通过自定义UserServiceHandler来实现自定义逻辑的监听来并加到启动引导类的通道中。</p>
<p><img src="/posts/8228/asset/v2-60e60234515affaae594e2b6c6359dff_720w.webp" alt="img"></p>
<p>3） 当有读操作出现，就会进入自定义处理器，执行相应逻辑并返回结果，最后把结果写回客户端。</p>
<p><img src="/posts/8228/asset/v2-203d9fd7a8ace9d5495c54b4e084f627_720w.webp" alt="img"></p>
<p><strong>客户端</strong></p>
<p>1） 通过main方法启动服务器，首先调用createProxy，传递接口类和参数，进行代理对象的构造。</p>
<p><img src="/posts/8228/asset/v2-963f71a978a962c1430312dba915abb3_720w.webp" alt="img"></p>
<p>2） 当代理对象创建之后，调用代理对象对应的方法时，就会进去JDK动态代理的invoke拦截方法内部进行客户端初始化。</p>
<p><img src="https://pic4.zhimg.com/80/v2-390e6740d34cfff45c3c2dbb554c82eb_720w.webp" alt="img"></p>
<p>3） 初始完毕之后，开始设置参数，即最开始定义参数拼接方法传递参数</p>
<p><img src="https://pic3.zhimg.com/80/v2-20d2d079e377020a25f4a57c4a696f3a_720w.webp" alt="img"></p>
<p>4） 当参数也设置完毕之后就可以通过线程池对call方法进行调度，进行写操作，写完阻塞，等待服务器返回数据之后唤醒继续写，这是通过互斥锁来实现读写交替。</p>
<p><img src="/posts/8228/asset/v2-0e272f813249e7737c36871d3b13d75e_720w-1686999149870.webp" alt="img"></p>
<p>5） 最后返回结果给客户端。</p>
<p><img src="/posts/8228/asset/v2-6fdcd783b6cd0dae98852bb28e1363ed_720w.webp" alt="img"></p>
]]></content>
      <categories>
        <category>基础知识</category>
        <category>分布式架构设计</category>
      </categories>
      <tags>
        <tag>基础知识</tag>
        <tag>分布式架构设计</tag>
      </tags>
  </entry>
  <entry>
    <title>java并发</title>
    <url>/posts/2408/</url>
    <content><![CDATA[<p>1.如何确定线程池参数</p>
]]></content>
      <categories>
        <category>基础知识</category>
        <category>思考</category>
      </categories>
      <tags>
        <tag>基础知识</tag>
        <tag>思考</tag>
      </tags>
  </entry>
  <entry>
    <title>jvm</title>
    <url>/posts/37319/</url>
    <content><![CDATA[<p>1.会出现新生代没满，老年代满的情况吗</p>
<p>2.永久代为什么会为gc带来不必要的复杂度</p>
<p>3.为什么会采用双亲委派机制</p>
<p>4.自定义类加载器如何实现模块隔离</p>
<p>5.为什么是选那些类作为GC Roots</p>
<p>6.为什么cpu占用率有时会超过100%</p>
]]></content>
      <categories>
        <category>基础知识</category>
        <category>思考</category>
      </categories>
      <tags>
        <tag>基础知识</tag>
        <tag>思考</tag>
      </tags>
  </entry>
  <entry>
    <title>mybatis</title>
    <url>/posts/62590/</url>
    <content><![CDATA[<p>什么是mybatis的一对多、多对多?</p>
]]></content>
      <categories>
        <category>基础知识</category>
        <category>思考</category>
      </categories>
      <tags>
        <tag>基础知识</tag>
        <tag>思考</tag>
      </tags>
  </entry>
  <entry>
    <title>集群模式相关知识</title>
    <url>/posts/45764/</url>
    <content><![CDATA[<h2 id="一、一致性Hash算法"><a href="#一、一致性Hash算法" class="headerlink" title="一、一致性Hash算法"></a>一、一致性Hash算法</h2><h3 id="分布式和集群"><a href="#分布式和集群" class="headerlink" title="分布式和集群"></a>分布式和集群</h3><p>分布式一定是集群，但是集群不一定是分布式，集群是多个实例一起工作，分布式是将一个系统拆分成多个，就是多个实例，而集群的满足条件不一定是系统拆分，也可以是复制，相同服务多部署，提高程序性能。</p>
<p><img src="https://pic3.zhimg.com/80/v2-8f1d0598d0f2c6d78a99a9310d5cb45e_720w.webp" alt="img"></p>
<p>理解：比如一个电商网站，里面的业务复杂，于是就进行了拆分，把每个模块拆成了一个个子系统，然后一起协调工作运行，这就是分布式，而集群呢，可以是另一种，当一个服务器已经不能满足访问要求的时候，我可以这个用户子系统，我复制部署在多个服务器，通过Nginx进行负载均衡，可以对用户请求进行分流，这就没有拆分系统，所以他只能是集群。</p>
<h3 id="Hash算法简介"><a href="#Hash算法简介" class="headerlink" title="Hash算法简介"></a>Hash算法简介</h3><p>Hash算法应用广泛，如加密算法MD5、SHA，数据储存和查找的Hash表等，而平常我们接触最多的就是Hash表，比如有一个数组，需要对他的数据进行查找，常用的一些查找法比如顺序查找、二分查找，如果是数据量大了，效率就非常低下，因此又有一种直接寻址法，把数组下标和值直接绑定在一起，通过下标来直接查找，但是如果两个值中间值差大，对空间又非常浪费；接着又有开放寻址法，对每一个数据进行取模，然后放入对应的下标中，但是如果是相同的取模值，就会产生hash冲突，他就把冲突值往前或后移，但是也有问题，无法扩展，长度为5的数组只能放5个值，因此数组加链表的Hash表就出现了，也就是我们常用的HashMap的设计结构。</p>
<p>数组：数组存储空间是连续的，占用内存严重，空间复杂度大，二分法时间复杂度小，查找容易，插入和删除困难。</p>
<p>链表：链表存储空间离散，占用内存比较宽松，空间复杂度小，时间复杂度大，查找困难，插入和删除简单。</p>
<p>Hash表又称为哈希表：由数组和链表构成，既满足了数据查找方便，又不用占用太多内存，通过key获取hashcode值，再取模的规则存储到数组中。Hashmap是一个线性数组实现，里面实现了一个静态内部类entry(键值对对象)，其重要属性有key、value、next，从属性key、value就可以看出来entry是hashmap键值对实现的一个继承bean(类)。这个线性数组被保存在entry[]中。</p>
<p><img src="https://pic2.zhimg.com/80/v2-d5fc9255b227cd28141e2c222251fee1_720w.webp" alt="img"></p>
<h3 id="Hash算法应用场景"><a href="#Hash算法应用场景" class="headerlink" title="Hash算法应用场景"></a>Hash算法应用场景</h3><p>Hash算法在分布式集群架构Redis、Hadoop、ElasticSearch，Mysql分库分表，Nginx负载均衡都有应用。</p>
<p>主要应用场景</p>
<p>1）请求的负载均衡（如Nginx的Ip_hash策略）</p>
<p>Nginx的Ip_hash策略可以在客户端ip不变的情况下，将其发出的请求始终路由到同⼀个⽬标服务器上，实现会话粘滞（会话保持），避免处理多服务器之间的session共享问题，</p>
<p>如果没有Ip_hash策略就需要自己维护一张映射表，存储客户端IP或者sessionid与具体目标服务器的映射关系。</p>
<p>缺点：</p>
<p>针对大体量级系统，客户端众多，这个映射表需要储存的数据就非常多，浪费内存空间。</p>
<p>客户端上下线，目标服务器上下线都会导致重新维护映射表，维护成本高。</p>
<p><img src="https://pic3.zhimg.com/80/v2-bdee8eeac3176add6174a1726916fcd6_720w.webp" alt="img"></p>
<p>如果使用hash算法，可以直接对ip地址或者sessionid进行计算哈希值，哈希值与服务器数量进行取模运算，得到的值就是当前请求应该被路由到的服务器编号，如此，一个客户端ip发送的请求就可以路由到同一个目标服务器，实现会话粘带。</p>
<p>2）分布式存储</p>
<p>以分布式内存数据库Redis为例,集群中有redis1，redis2，redis3 三台Redis服务器，在数据储存时，&lt;key,value&gt;数据，根据key进行hash处理，hash(key)%3&#x3D;index，使用余数来锁定存储的具体服务节点。</p>
<h3 id="一致性Hash算法"><a href="#一致性Hash算法" class="headerlink" title="一致性Hash算法"></a>一致性Hash算法</h3><p>普通hash算法存在一个问题，如果服务器宕机了，服务器的数量就会减少，之前的所有求模运算都将重新来，缩容和扩容也是一样的，大量用户的请求都将被重新分发，原来服务器会话都会丢失，因此诞生了一致性hash算法。</p>
<p><img src="https://pic3.zhimg.com/80/v2-c9b19735268cdd69b785a235cf37cc7a_720w.webp" alt="img"></p>
<p>一致性hash算法实现原理</p>
<p><img src="/posts/45764/asset/v2-220089aa76d825297e6234809f5d5e53_720w.webp" alt="img"></p>
<p>首先有一条直线，他的开头和结尾分别定为为0和2的32次⽅减1，对应IP地址的长度，服务器的IP地址是32位，所以是2^32-1次方的数值空间，对于这样⼀条线，弯过来构成⼀个圆环形成闭环，这样的⼀个圆环称为hash环。我们把服务器的ip或者主机名求hash值然后对应到hash环上，那么针对客户端⽤户，也根据它的ip进⾏hash求值，对应到环上某个位置。客户端路由服务器就按照顺时针找离他最近的服务器节点。</p>
<p><img src="/posts/45764/asset/v2-859f28579d8d308ed07129eca8af964d_720w.webp" alt="img"></p>
<p>如果某台服务器宕机或者需要进行扩容之类，客户端就按照顺时针接着往下顺延或者缩短定位最近服务器节点。</p>
<p><img src="https://pic3.zhimg.com/80/v2-7e8c1503450ff632a55d1e288d7a8b82_720w.webp" alt="img"></p>
<p><img src="https://pic4.zhimg.com/80/v2-c5c4014a81b335b35fd31993e6a3371b_720w.webp" alt="img"></p>
<p>每台服务器负责⼀段，⼀致性哈希算法对于节点的增减都只需重定位环空间中的⼀⼩部分数据，具有较好的容错性和可扩展性。但是，⼀致性哈希算法在服务节点太少时，容易因为节点分部不均匀⽽造成数据倾斜问题。例如系统中只有两台服务器，其环分布如下，节点2只能负责⾮常⼩的⼀段，⼤量的客户端请求落在了节点1上，这就是<strong>数据（请求）倾斜问题</strong></p>
<p>为了解决这种数据倾斜问题，⼀致性哈希算法引⼊了虚拟节点机制，即对每⼀个服务节点计算多个哈希，每个计算结果位置都放置⼀个此服务节点，称为虚拟节点。</p>
<p>具体实现：以在服务器ip或主机名的后面增加编号来实现。⽐如，可以为每台服务器计算三个虚拟节点，于是可以分别计算 “节点1的ip#1”、“节点1的ip#2”、“节点1的ip#3”、“节点2的ip#1”、“节点2的ip#2”、“节点2的ip#3”的哈希值，于是形成六个虚拟节点，当客户端被路由到虚拟节点的时候其实是被路由到该虚拟节点所对应的真实节点。</p>
<p><img src="/posts/45764/asset/v2-83125865aa522fe24ab05f4603f4f7c1_720w.webp" alt="img"></p>
<h3 id="手写三种一致性hash算法"><a href="#手写三种一致性hash算法" class="headerlink" title="手写三种一致性hash算法"></a>手写三种一致性hash算法</h3><p>普通hash算法实现</p>
<p><img src="/posts/45764/asset/v2-623fbe800b54a4445f68de72bf5ff48e_720w.webp" alt="img"></p>
<p>一致性hash算法实现 不含虚拟节点</p>
<p><img src="https://pic3.zhimg.com/80/v2-c76785187cc1eeee70b36c31bd63cca2_720w.webp" alt="img"></p>
<p><img src="/posts/45764/asset/v2-ada122920fb6beac782da29abbad61cc_720w.webp" alt="img"></p>
<p>一致性hash算法实现 含虚拟节点（就在前面的基础上引入虚拟节点就好了）</p>
<p><img src="/posts/45764/asset/v2-c616940c5775fba4dfa2cc3f3ca94b82_720w.webp" alt="img"></p>
<h3 id="Nginx配置一致性Hash负载均衡策略"><a href="#Nginx配置一致性Hash负载均衡策略" class="headerlink" title="Nginx配置一致性Hash负载均衡策略"></a>Nginx配置一致性Hash负载均衡策略</h3><p>ngx_http_upstream_consistent_hash 模块是⼀个负载均衡器，使⽤⼀个内部⼀致性hash算法来选择合适的后端节点。</p>
<p>1） github下载nginx⼀致性hash负载均衡模块 <a href="https://link.zhihu.com/?target=https://github.com/replay/ngx_http_consistent_hash">https://github.com/replay/ngx_http_consistent_hash</a></p>
<p>2） 将下载的压缩包上传到nginx服务器，并解压</p>
<p>3） 进⼊nginx的源码⽬录，顺序执⾏如下命令.&#x2F;configure —add-module&#x3D;&#x2F;root&#x2F;ngx_http_consistent_hash-master</p>
<p>è Make</p>
<p>è make install</p>
<p>4） Nginx就可以使⽤啦，在nginx.conf⽂件中配置</p>
<p><img src="https://pic3.zhimg.com/80/v2-b10a19847f5302777fc2563903222942_720w.webp" alt="img"></p>
<h2 id="二、集群时钟同步问题"><a href="#二、集群时钟同步问题" class="headerlink" title="二、集群时钟同步问题"></a>二、集群时钟同步问题</h2><h3 id="时钟不同步导致的问题"><a href="#时钟不同步导致的问题" class="headerlink" title="时钟不同步导致的问题"></a>时钟不同步导致的问题</h3><p>时钟此处指服务器时间，如果集群中各个服务器时钟不⼀致势必导致⼀系列问题。电商⽹站业务中，新增⼀条订单，那么势必会在订单表中增加了⼀条记录，该条记录中应该会有“下单时间”这样的字段，往往我们会在程序中获取当前系统时间插⼊到数据库或者直接从数据库服务器获取时间。那我们的订单子系统是集群部署，或者我们的数据库也是分库分表的集群部署，然⽽他们的系统时钟不⼀致，比如有⼀台服务器的时间是昨天，那么这个时候下单时间就成了昨天，那我们的数据将会混乱。</p>
<p><img src="https://pic3.zhimg.com/80/v2-01ed630f00d542e20d3b67107671aafe_720w.webp" alt="img"></p>
<h3 id="集群时钟同步配置"><a href="#集群时钟同步配置" class="headerlink" title="集群时钟同步配置"></a>集群时钟同步配置</h3><p>第一种：分布式集群中各个服务器节点都可以连接互联网直接通过互联网国家授时中心获取正确时间并制定定时计划，按时间计划进行刷新同步。</p>
<p><img src="/posts/45764/asset/v2-b5ae41694a2cf98a93ce101417b44b94_720w.webp" alt="img"></p>
<p>操作⽅式：</p>
<p><img src="/posts/45764/asset/v2-32de5d962f23954fa3c2eb19facdc048_720w.webp" alt="img"></p>
<p>第二种：只有一台服务器可以连接互联网或者所有服务器都不能连接互联网。</p>
<p>选取一台服务器作为时间服务器，整个集群时间从这台服务器同步，如果这台服务器能够访问互联⽹，可以让这台服务器和⽹络时间保持同步，如果不能就⼿动设置⼀个时间。</p>
<p><img src="/posts/45764/asset/v2-4a531643f424ead872a51dc65ba9d0ab_720w.webp" alt="img"></p>
<p>实现步骤：</p>
<p>1）设置服务器的时间</p>
<p>2）把当前服务器设置为时间服务器（修改&#x2F;etc&#x2F;ntp.conf文件）</p>
<p><img src="/posts/45764/asset/v2-14b4d6fe6970d3a2daf31474a2663690_720w.webp" alt="img"></p>
<p>3）集群中其他节点通过命令从A服务器同步时间</p>
<p><img src="/posts/45764/asset/v2-cf17f1e20ac47cfbb9623ef4b8dc97a0_720w.webp" alt="img"></p>
<h2 id="三、分布式DI解决方案"><a href="#三、分布式DI解决方案" class="headerlink" title="三、分布式DI解决方案"></a>三、分布式DI解决方案</h2><h3 id="需求场景"><a href="#需求场景" class="headerlink" title="需求场景"></a>需求场景</h3><p>当单表已经不能满足数据储存要求的时候，就需要对单表进行分表，以Mysql为准，单表储存量最佳500万，超过性能就会慢慢下降，因此搭建Mysql集群进行分表就势在必行，而分表带来了一个无法回避的问题，多表之间数据的唯一序列号该如何处理。</p>
<p><img src="/posts/45764/asset/v2-96ce970151421b7f717dcaa389295650_720w.webp" alt="img"></p>
<h3 id="UUID解决方案"><a href="#UUID解决方案" class="headerlink" title="UUID解决方案"></a>UUID解决方案</h3><p>UUID 是指Universally Unique Identifier，翻译为中文是通⽤唯⼀识别码，他的生成规则客户端地址+时间戳+一个随机数，重复的概率是非常低的，不过他有一个缺点，没有规律，作为主键建立索引的话，查询效率不高。</p>
<p><img src="https://pic3.zhimg.com/80/v2-c1b4f7a56c281059b9300da149a3538a_720w.webp" alt="img"></p>
<h3 id="独立数据库的自增ID解决方案"><a href="#独立数据库的自增ID解决方案" class="headerlink" title="独立数据库的自增ID解决方案"></a>独立数据库的自增ID解决方案</h3><p>创建⼀个Mysql数据库，在这个数据库中创建⼀张表，这张表的ID设置为⾃增，其他地⽅需要全局唯⼀ID的时候，就模拟向这个Mysql数据库的这张表中模拟插⼊⼀条记录，此时ID会⾃增，然后我们可以通过Mysql的select last_insert_id() 获取到刚刚这张表中⾃增⽣成的ID。</p>
<p><img src="/posts/45764/asset/v2-87d3fd9d8023d602260bd35b007e8d48_720w.webp" alt="img"></p>
<p>缺点：性能和可靠性都不够好，因为你需要代码连接到数据库才能获取到id，性能⽆法保障，另外mysql数据库实例挂掉了，那么就⽆法获取分布式id了。</p>
<h3 id="SnowFlake-雪花算法解决方案"><a href="#SnowFlake-雪花算法解决方案" class="headerlink" title="SnowFlake 雪花算法解决方案"></a>SnowFlake 雪花算法解决方案</h3><p>雪花算法是Twitter（推特）推出的⼀个⽤于⽣成分布式ID的策略。</p>
<p>雪花算法是⼀个算法，基于这个算法可以⽣成ID，⽣成的ID是⼀个long型，那么在Java中⼀个long型是8个字节，算下来是64bit，由符号位加时间戳（毫秒级）加机器id最后拼接一个随机序列号（一毫秒产生四千多个不重复得序列号，）生成，换算成秒也就是一秒内能产生四百万个不重复id，而且在一台机子上可以运行七十多年生成不重复得ID，可靠性非常高。</p>
<p><img src="https://pic4.zhimg.com/80/v2-42e7c3322b15345e23f0614cbeb9626b_720w.webp" alt="img"></p>
<p>雪花算法原理理解：机器ID给了10位，而在实现得时候，拆分成了两部分，一部分集群编号占5位，另一部分集群机器编号占5位，组合起来拼接成完整的机器ID，接着获取当前得时间戳，如果获取当前时间戳小于上次时间戳，违背雪花算法核心原则，直接抛出异常，不能生成ID。如果当前时间戳等于当前时间戳，就代表当前请求还在同一毫秒内，进入同一毫秒生成规则，但是里面有一个限制，一毫秒内最大生成唯一ID数量是4095，进行位与运算判断，如果超了4095边界，就等待，里面有一个方法在疯狂刷新时间戳，当下个时间戳到来，取下一毫秒的时间戳来生成唯一ID，这一毫秒又可以生成4095个唯一ID.</p>
<p><img src="/posts/45764/asset/v2-4e2b39a3f94dd8c26d65c0b6c754125a_720w.webp" alt="img"></p>
<p><img src="https://pic2.zhimg.com/80/v2-3aaed5ac88afbd765b43e06b0f15fae1_720w.webp" alt="img"></p>
<h3 id="Redis的Incr命令获取全局唯⼀ID解决方案"><a href="#Redis的Incr命令获取全局唯⼀ID解决方案" class="headerlink" title="Redis的Incr命令获取全局唯⼀ID解决方案"></a>Redis的Incr命令获取全局唯⼀ID解决方案</h3><p>Redis Incr 命令将 key 中储存的数字值增⼀。如果 key 不存在，那么 key 的值会先被初始化为 0，然后再执⾏ INCR 操作。</p>
<p><img src="/posts/45764/asset/v2-7740edcfdd71dd122ffa4dc9e44ae04d_720w.webp" alt="img"></p>
<p>Redis安装</p>
<p>1）官⽹下载redis-3.2.10.tar.gz <a href="https://link.zhihu.com/?target=http://download.redis.io/releases/redis-3.2.10.tar.gz">http://download.redis.io/releases/redis-3.2.10.tar.gz</a></p>
<p>2）上传到linux服务器解压 tar -zxvf redis-3.2.10.tar.gz</p>
<p>3）cd 解压⽂件⽬录，对解压的redis进⾏编译</p>
<p>4）make</p>
<p>5）然后cd 进⼊src⽬录，执⾏make install</p>
<p>6）修改解压⽬录中的配置⽂件redis.conf，关掉保护模式</p>
<p><img src="/posts/45764/asset/v2-57361c3d207d3ea4d53f4bc32a9d29cc_720w.webp" alt="img"></p>
<p><img src="https://pic2.zhimg.com/80/v2-f33c5a6b5b3b47facce30ac24e83088d_720w.webp" alt="img"></p>
<p>7）在src⽬录下执⾏ .&#x2F;redis-server ..&#x2F;redis.conf 启动redis服务</p>
<p><img src="/posts/45764/asset/v2-1a14e3800a7f10bf183f0aa0f0a4a94a_720w.webp" alt="img"></p>
<h2 id="四、分布式调度问题解决方案"><a href="#四、分布式调度问题解决方案" class="headerlink" title="四、分布式调度问题解决方案"></a>四、分布式调度问题解决方案</h2><h3 id="定时任务的场景"><a href="#定时任务的场景" class="headerlink" title="定时任务的场景"></a>定时任务的场景</h3><p>调度—&gt;定时任务，分布式调度—&gt;在分布式集群环境下定时任务</p>
<p>定时任务就是每隔一段时间或者特定时间执行</p>
<p>比如：订单审核、物流信息推送、日志监控、定时备份数据、报表数据分析、数据积压检测等等</p>
<h3 id="分布式调度"><a href="#分布式调度" class="headerlink" title="分布式调度"></a>分布式调度</h3><p>1） 运行在分布式集群环境下的调度任务（多个实例同时运行，但是同一时间只有一个实例生效，比如统计报表定时任务多实例部署，调用的时候只需要一个就行了，另外一个相当于备用）</p>
<p>2） 分布式调度-&gt;进行任务的分布式-&gt;定时任务拆分（比如我一个单体应用有很多定时任务，我对他进行拆分，为了提高性能，进行集群部署，比如拆分出来的统计报表定时任务，数据备份定时任务等等，执行的时候应该是一起执行，而不是一个个执行）</p>
<p><img src="https://pic4.zhimg.com/80/v2-da2c24ba09e41234f3468d02f9425c17_720w.webp" alt="img"></p>
<h3 id="定时任务与消息队列的区别"><a href="#定时任务与消息队列的区别" class="headerlink" title="定时任务与消息队列的区别"></a>定时任务与消息队列的区别</h3><p><strong>共同点</strong></p>
<p>1）异步处理：比如注册、下单事件，比如下单完成后台只是做了一个标记，并不是同步就完成了整个订单的处理流程，你看到的订单完成只是显示的一个标记状态，如果是消息队列，后台就按消息顺序处理这些订单，而定时任务的话，就按间隔时间去扫描订单表，获取标记进行订单处理。</p>
<p>2）应用解耦：定时任务和MQ都可以作为两个应用之间的齿轮实现应用解耦，比如两个系统需要数据交互，就可以通过mq当做中转；定时任务的话，就是把数据存储到一张中间表，进行定时扫描获取数据。</p>
<p>3）流量削峰：双十一的时候，流量很大，定时任务作业和MQ都可以用来扛流量，如果直接全部发送到后台，后台是处理不过来的，会直接崩掉，有了他们，后台就可以根据服务能力定时处理订单或者从MQ抓取订单事件触发处理，而前端用户看到的结果是下单成功。</p>
<p><strong>本质不同</strong></p>
<p>定时任务是时间驱动，消息队列是事件驱动</p>
<p>时间驱动不可代替，比如金融系统每日利息结算，不是利息到来事件就算一下，而是批量处理，所以定时任务作业更倾向于批量处理，MQ倾向于逐条处理。</p>
<h3 id="定时任务Quartz实现方式"><a href="#定时任务Quartz实现方式" class="headerlink" title="定时任务Quartz实现方式"></a>定时任务Quartz实现方式</h3><p>定时任务的实现⽅式有多种。早期没有定时任务框架的时候，我们会使⽤JDK中的Timer机制和多线程机制（Runnable+线程休眠）来实现定时或者间隔⼀段时间执⾏某⼀段程序；后来有了定时任务框架，⽐如Quartz任务调度框架，使⽤时间表达式（包括：秒、分、时、⽇、周、年）配置某⼀个任务什么时间去执⾏。</p>
<p>引入Quartz的jar包</p>
<p><img src="/posts/45764/asset/v2-7ac7780c1bc4d908ea1600df4e4c5a3c_720w.webp" alt="img"></p>
<p>编写定时任务作业主调度程序分为四步：</p>
<p>1）创建任务调度器 如公交调度站</p>
<p><img src="https://pic3.zhimg.com/80/v2-1d0c517391da7f45fcf1499a42794d0a_720w.webp" alt="img"></p>
<p>2）创建一个任务 如公交车出行</p>
<p><img src="/posts/45764/asset/v2-70916815ca2b680e90716ab258a762ef_720w.webp" alt="img"></p>
<p><img src="https://pic2.zhimg.com/80/v2-82bd804deb650dd5596608a1e66663b1_720w.webp" alt="img"></p>
<p>3）创建任务的时间触发器 如公交车出行时间表</p>
<p><img src="/posts/45764/asset/v2-295cdeafe0729c869d276113d83d23d8_720w.webp" alt="img"></p>
<p>cron表达式由七个位置组成，空格分隔</p>
<p>* 1、Seconds（秒） 0~59</p>
<p>* 2、Minutes（分） 0~59</p>
<p>* 3、Hours（⼩时） 0~23</p>
<p>* 4、Day of Month（天）1~31,注意有的⽉份不⾜31天</p>
<p>* 5、Month（⽉） 0~11,或者JAN,FEB,MAR,APR,MAY,JUN,JUL,AUG,SEP,OCT,NOV,DEC</p>
<p>* 6、Day of Week(周) 1~7,1&#x3D;SUN或者 SUN,MON,TUE,WEB,THU,FRI,SAT</p>
<p>* 7、Year（年）1970~2099 可选项</p>
<p>4）使用任务调度器根据时间触发器执行我们的任务</p>
<p><img src="https://pic2.zhimg.com/80/v2-a20d5e62780ba0e9d8583d61746b51f9_720w.webp" alt="img"></p>
<h3 id="Elastic-Job简介"><a href="#Elastic-Job简介" class="headerlink" title="Elastic-Job简介"></a>Elastic-Job简介</h3><p>Elastic-Job是当当⽹开源的⼀个分布式调度解决⽅案，基于Quartz⼆次开发的，由两个相互独⽴的⼦项⽬Elastic-Job-Lite和Elastic-Job-Cloud组成，Elastic-Job-Lite，它定位为轻量级⽆中⼼化解决⽅案，使⽤Jar包的形式提供分布式任务的协调服务，⽽Elastic-Job-Cloud⼦项⽬需要结合Mesos以及Docker在云环境下使⽤。</p>
<p>主要功能：</p>
<p>1）分布式调度协调：在分布式环境中，任务能够按指定的调度策略执⾏，并且能够避免同⼀任务多实例重复执⾏。</p>
<p>2）丰富的调度策略：基于成熟的定时任务作业框架Quartz cron表达式执⾏定时任务</p>
<p>3）弹性扩容缩容：当集群中增加某⼀个实例，它应当也能够被选举并执⾏任务；当集群减少⼀个实例时，它所执⾏的任务能被转移到别的实例来执⾏。</p>
<p>4）失效转移：某实例在任务执⾏失败后，会被转移到其他实例执⾏</p>
<p>5）错过执⾏作业重触发：若因某种原因导致作业错过执⾏，⾃动记录错过执⾏的作业，并在上次作业完成后⾃动触发。</p>
<p>6）⽀持并⾏调度：⽀持任务分⽚，任务分⽚是指将⼀个任务分为多个⼩任务项在多个实例同时执⾏。</p>
<p>7）作业分⽚⼀致性：当任务被分⽚后，保证同⼀分⽚在分布式环境中仅⼀个执⾏实例。</p>
<h3 id="安装Zookeeper"><a href="#安装Zookeeper" class="headerlink" title="安装Zookeeper"></a>安装Zookeeper</h3><p>Elastic-Job依赖于Zookeeper进⾏分布式协调，Zookeeper的本质功能：存储+通知。</p>
<p>1）我们使⽤3.4.10版本，在linux平台解压下载的zookeeper-3.4.10.tar.gz</p>
<p>2）进⼊conf⽬录，cp zoo_sample.cfg zoo.cfg</p>
<p>3）修改目录地址dataDir&#x3D;&#x2F;usr&#x2F;local&#x2F;zookeeper-3.4.10&#x2F;data</p>
<ol start="4">
<li>进⼊bin⽬录，启动zk服务</li>
</ol>
<p>启动 .&#x2F;zkServer.sh start</p>
<p>停⽌ .&#x2F;zkServer.sh stop</p>
<p>查看状态 .&#x2F;zkServer.sh status</p>
<p><img src="/posts/45764/asset/v2-c614ec7ce891c8c2a8667b33c1c1c127_720w.webp" alt="img"></p>
<h3 id="Elastic-job应用"><a href="#Elastic-job应用" class="headerlink" title="Elastic-job应用"></a>Elastic-job应用</h3><p>需求：每隔两秒钟执⾏⼀次定时任务（resume表中未归档的数据归档到resume_bak表中，每次归档1条记录）</p>
<p>1） 定义定时任务业务逻辑处理类ArchivieJob实现SimpleJob接口，重写execute方法，封装核心逻辑</p>
<p><img src="/posts/45764/asset/v2-fc8ac8df9c6aaf09d98f71c6d7c08eb4_720w.webp" alt="img"></p>
<p>2）配置注册中心，连接云主机上的zookeeper，进行任务配置（时间事件10秒执行、调用定时任务逻辑处理类、任务调度器开启任务）</p>
<p><img src="/posts/45764/asset/v2-f104e206290302b5f9dac029e971f545_720w.webp" alt="img"></p>
<p>3）测试结果，每隔十秒执行一次逻辑处理，完成单例定时任务执行。如果多个应用启动，多个实例同时创建一个leader节点，谁创建了谁就是领导者，其他就不能创建了，而当前领导者就负责执行对应实例定时任务，另外的相当于备份，当集群服务扩容或者缩减，zookeeper的领导者leader会重新选举，找出新的执行者。</p>
<p><img src="https://pic4.zhimg.com/80/v2-675a15c9b4401a525f9b713e9741009b_720w.webp" alt="img"></p>
<h3 id="Elastic-job轻量级和去中⼼化"><a href="#Elastic-job轻量级和去中⼼化" class="headerlink" title="Elastic-job轻量级和去中⼼化"></a>Elastic-job轻量级和去中⼼化</h3><p>轻量级：</p>
<p>不需要引入或安装其他服务或者组件，把jar包引入调用即可。</p>
<p>不需要独立部署，就是一个jar程序。</p>
<p>去中心化：</p>
<p>执行节点对等。</p>
<p>定时调度自触发，不需要中心节点分配，谁该执行什么任务等等。</p>
<p>服务自发现，通过注册中心服务发现。</p>
<p>主节点非固定，通过leader选举产生。</p>
<p><img src="https://pic2.zhimg.com/80/v2-18c41d9459623532de69643913485d3d_720w.webp" alt="img"></p>
<h3 id="Elastic-job任务分片及扩容"><a href="#Elastic-job任务分片及扩容" class="headerlink" title="Elastic-job任务分片及扩容"></a>Elastic-job任务分片及扩容</h3><p>ElasticJob可以把作业分为多个的task（每⼀个task就是⼀个任务分⽚），每⼀个task交给具体的⼀个机器实例去处理（⼀个机器实例是可以处理多个task的），但是具体每个task执⾏什么逻辑由我们⾃⼰来指定，比如把批量处理的数据按类型分开，然后多个实例各自执行不同类型的数据，提高并发处理效率。</p>
<p><img src="https://pic3.zhimg.com/80/v2-4d1c6fb313edbc5452e6f8af2470cc16_720w.webp" alt="img"></p>
<p>设置3个分片，设置3个分片对应逻辑参数</p>
<p><img src="/posts/45764/asset/v2-58b068658775b58993e7483ce2ddcbd4_720w.webp" alt="img"></p>
<p>获取参数，在业务逻辑类进行处理</p>
<p><img src="https://pic4.zhimg.com/80/v2-c4128f5582cda72b419946a006cbaf53_720w.webp" alt="img"></p>
<p><strong>扩容：</strong></p>
<p>新增加⼀个运⾏实例，它会⾃动注册到注册中⼼，注册中⼼发现新的服务上线，注册中⼼会通知ElasticJob 进⾏重新分⽚，总分⽚项有多少，就可以搞多少个实例机器。</p>
<p>1）分⽚项也是⼀个JOB配置，修改配置，重新分⽚，在下⼀次定时运⾏之前会重新调⽤分⽚算法，那么这个分⽚算法的结果就是：哪台机器运⾏哪⼀个分⽚，这个结果存储到zk中的，主节点会把分⽚给分好放到注册中⼼去，然后执⾏节点从注册中⼼获取信息(执⾏节点在定时任务开启的时候获取相应的分⽚)。</p>
<p>2）如果所有节点挂掉只剩下⼀个节点时，所有分⽚都会指向剩下的⼀个节点，这就是ElasticJob的⾼可⽤。</p>
<h2 id="五、Session共享问题"><a href="#五、Session共享问题" class="headerlink" title="五、Session共享问题"></a>五、Session共享问题</h2><h3 id="Session问题原因分析"><a href="#Session问题原因分析" class="headerlink" title="Session问题原因分析"></a>Session问题原因分析</h3><p>Session共享及Session保持或者叫做Session⼀致性</p>
<p>http协议是无状态的协议，而页面具有动态的内容，就需要有状态，保持http状态的技术就是cookie和session，但是客户端和服务器又不会把会话数据保留，因此当nginx进行集群tomcat登录请求的时候，由于nginx的轮询策略，就会产生第一次登录请求分发到第一台tomcat服务器，登录成功，当前服务器session保存了当前登录信息，第二次请求来了，获取业务数据，跳转数据列表，对页面渲染，但是第二次缺请求到了第二台服务器，而第二台服务器是没得session的，于是又重定向到了登录界面。</p>
<p><img src="/posts/45764/asset/v2-f0b7510601cedf97032808943d3bfdb7_720w.webp" alt="img"></p>
<p><img src="/posts/45764/asset/v2-2f13e5af21c0a0f7593b334515a9eba7_720w.webp" alt="img"></p>
<h3 id="解决Session⼀致性的⽅案"><a href="#解决Session⼀致性的⽅案" class="headerlink" title="解决Session⼀致性的⽅案"></a>解决Session⼀致性的⽅案</h3><p><strong>Nginx的 IP_Hash 策略</strong></p>
<p>前面Nginx有讲述，同一个客户端的IP的请求都会被路由到同一个目标服务器，也叫会话保持。</p>
<p>优点：</p>
<p>配置简单，不⼊侵应⽤，不需要额外修改代码</p>
<p>缺点：</p>
<p>服务器重启Session丢失</p>
<p>存在单点负载⾼的⻛险</p>
<p>单点故障问题</p>
<p><strong>Session复制</strong></p>
<p><img src="/posts/45764/asset/v2-b7777a6111c5e8e1e2dd15ea83649ff6_720w.webp" alt="img"></p>
<p>优点：</p>
<p>不侵入应用</p>
<p>便于服务器水平扩展</p>
<p>能适应各种负载均衡策略</p>
<p>服务器重启或者宕机不会造成session丢失</p>
<p>缺点：</p>
<p>性能低</p>
<p>内存消耗</p>
<p>不能存储太多数据，数据越多性能越低</p>
<p>延迟性</p>
<p><strong>Session共享，Session集中储存</strong></p>
<p><img src="/posts/45764/asset/v2-e381f06ffdd88f1a783a383d641e08a4_720w.webp" alt="img"></p>
<p>优点</p>
<p>能适应各种负载均衡策略</p>
<p>服务器重启或者宕机不会造成session丢失</p>
<p>扩展能力强</p>
<p>适合大集群数量使用</p>
<p>缺点</p>
<p>对应用有入侵，引入了和Redis的交互代码</p>
<p><img src="https://pic2.zhimg.com/80/v2-d03322ded558347c9b3c5fdf83129d7d_720w.webp" alt="img"></p>
]]></content>
      <categories>
        <category>基础知识</category>
        <category>集群模式知识总结</category>
      </categories>
      <tags>
        <tag>基础知识</tag>
        <tag>集群模式知识总结</tag>
      </tags>
  </entry>
  <entry>
    <title>BigDecimal类</title>
    <url>/posts/b3564305/</url>
    <content><![CDATA[<h2 id="1、BigDecimal简介"><a href="#1、BigDecimal简介" class="headerlink" title="1、BigDecimal简介"></a>1、BigDecimal简介</h2><p>借用《Effactive Java》书中的一句话，float和double类型设计的主要目标是为了科学计算和工程计算。它们主要用于执行二进制浮点运算，这是为了在广域数值范围上提供较为精确的快速近似计算而精心设计的。</p>
<p>罢特，它们没有提供完全精确的计算结果，所以不应该被用于要求精确结果的场合。但是，在商业计算中往往要求结果精确，这时候BigDecimal就派上大用场啦。</p>
<p><strong>Java在java.math包中提供的API类BigDecimal 由<code>任意精度的整数非标度值</code>和<code>32 位的整数标度 (scale)</code> 组成。如果为零或正数，则标度是小数点后的位数。如果为负数，则将该数的非标度值乘以 10 的负scale 次幂。因此，BigDecimal表示的数值是(unscaledValue × 10 -scale)。</strong></p>
<p><strong>BigDecimal用来对超过16位有效位的数进行精确的运算。双精度浮点型变量double可以处理16位有效数，但在实际应用中，可能需要对更大或者更小的数进行运算和处理。一般情况下，对于那些不需要准确计算精度的数字，我们可以直接使用Float和Double处理，但是Double.valueOf(String) 和Float.valueOf(String)会丢失精度。所以在开发中，如果你所做的业务跟财务相关需要精确计算的结果，那必须使用BigDecimal类来操作啦！</strong></p>
<p><strong><code>BigDecimal</code>所创建的是<code>对象</code>，我们不能使用传统的<code>+、-、\*、/</code>等算术运算符直接对其对象进行数学运算，而必须调用其相对应的方法。方法中的参数也必须是BigDecimal的对象。构造器是类的特殊方法，专门用来创建对象，特别是带有参数的对象。</strong></p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>java数据结构与高级类型</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>java数据结构与高级类型</tag>
      </tags>
  </entry>
  <entry>
    <title>BigInteger</title>
    <url>/posts/5bf56c5f/</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>java数据结构与高级类型</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>java数据结构与高级类型</tag>
      </tags>
  </entry>
  <entry>
    <title>BitSet类</title>
    <url>/posts/f3bbf6f0/</url>
    <content><![CDATA[<h3 id="适合场景"><a href="#适合场景" class="headerlink" title="适合场景"></a>适合场景</h3><p>整数，无重复；</p>
<h3 id="BitSet基础"><a href="#BitSet基础" class="headerlink" title="BitSet基础"></a>BitSet基础</h3><p>BitSet，也就是weitu，由于可以用非常紧凑的格式来表示给定范围的连续数据而经常出现在各种算法设计中。</p>
<p><img src="/posts/f3bbf6f0/asset/20161219103322771" alt="img"></p>
<p>####基本原理</p>
<p>用1位来表示一个数据是否出现过，0为没有出现过，1表示出现过。使用的时候既可根据某一个是否为0表示此数是否出现过（<strong>具有两种状态的数据</strong>）</p>
<p>1G的空间，有$1024<em>1024</em>1024<em>8&#x3D;8.58</em>10^9$ 位，也就是可以表示85亿个不同数的状态。</p>
<p>常见的应用是那些需要进行统计的数据，将40亿个不同数据进行排序(采用技术排序的思想)等。</p>
<h4 id="常见扩展"><a href="#常见扩展" class="headerlink" title="常见扩展"></a>常见扩展</h4><p>采用2位或者更多位来表示此数据的更多信息，比如出现了多少次等。</p>
<h3 id="java中的BitSit的实现"><a href="#java中的BitSit的实现" class="headerlink" title="java中的BitSit的实现"></a>java中的BitSit的实现</h3><h4 id="构造函数"><a href="#构造函数" class="headerlink" title="构造函数"></a>构造函数</h4><p>底层使用long数组作为内部存储结构，因此Bitset至少为一个long的大小，一个long 8 个字节，8*8 &#x3D; 64位</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">   <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * Creates a new bit set. All bits are initially &#123;<span class="doctag">@code</span> false&#125;.</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">   <span class="keyword">public</span> <span class="title function_">BitSet</span><span class="params">()</span> &#123;</span><br><span class="line">       initWords(BITS_PER_WORD);</span><br><span class="line">       sizeIsSticky = <span class="literal">false</span>;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="title function_">BitSet</span><span class="params">(<span class="type">int</span> nbits)</span> &#123;</span><br><span class="line">       <span class="comment">// nbits can&#x27;t be negative; size 0 is OK</span></span><br><span class="line">       <span class="keyword">if</span> (nbits &lt; <span class="number">0</span>)</span><br><span class="line">           <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">NegativeArraySizeException</span>(<span class="string">&quot;nbits &lt; 0: &quot;</span> + nbits);</span><br><span class="line"></span><br><span class="line">       initWords(nbits);</span><br><span class="line">       sizeIsSticky = <span class="literal">true</span>;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>不指定初始值大小，则默认为BITS_PRE_WORD, $2^6&#x3D;64$位</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">    * BitSets are packed into arrays of &quot;words.&quot;  Currently a word is</span></span><br><span class="line"><span class="comment">    * a long, which consists of 64 bits, requiring 6 address bits.</span></span><br><span class="line"><span class="comment">    * The choice of word size is determined purely by performance concerns.</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> <span class="type">int</span> <span class="variable">ADDRESS_BITS_PER_WORD</span> <span class="operator">=</span> <span class="number">6</span>;</span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> <span class="type">int</span> <span class="variable">BITS_PER_WORD</span> <span class="operator">=</span> <span class="number">1</span> &lt;&lt; ADDRESS_BITS_PER_WORD;</span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> <span class="type">int</span> <span class="variable">BIT_INDEX_MASK</span> <span class="operator">=</span> BITS_PER_WORD - <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">   <span class="comment">/* Used to shift left or right for a partial word mask */</span></span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">long</span> <span class="variable">WORD_MASK</span> <span class="operator">=</span> <span class="number">0xffffffffffffffffL</span>;</span><br></pre></td></tr></table></figure>

<h4 id="清空BitSet"><a href="#清空BitSet" class="headerlink" title="清空BitSet"></a>清空BitSet</h4><p>通过循环方式来置0</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Sets all of the bits in this BitSet to &#123;<span class="doctag">@code</span> false&#125;.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@since</span> 1.4</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">clear</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">while</span> (wordsInUse &gt; <span class="number">0</span>)</span><br><span class="line">            words[--wordsInUse] = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">     <span class="comment">//清空某一位</span></span><br><span class="line">     <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">clear</span><span class="params">(<span class="type">int</span> bitIndex)</span> &#123;</span><br><span class="line">         </span><br><span class="line">     <span class="comment">//清空指定范围</span></span><br><span class="line">     <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">clear</span><span class="params">(<span class="type">int</span> fromIndex, <span class="type">int</span> toIndex)</span> &#123;</span><br></pre></td></tr></table></figure>

<h4 id="反转位"><a href="#反转位" class="headerlink" title="反转位"></a>反转位</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">flip</span><span class="params">(<span class="type">int</span> bitIndex)</span> &#123;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">flip</span><span class="params">(<span class="type">int</span> fromIndex, <span class="type">int</span> toIndex)</span> &#123;</span><br></pre></td></tr></table></figure>

<h4 id="设置位"><a href="#设置位" class="headerlink" title="设置位"></a>设置位</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">   <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * Sets the bit at the specified index to &#123;<span class="doctag">@code</span> true&#125;.</span></span><br><span class="line"><span class="comment">    *</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span>  bitIndex a bit index</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@throws</span> IndexOutOfBoundsException if the specified index is negative</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@since</span>  JDK1.0</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">set</span><span class="params">(<span class="type">int</span> bitIndex)</span> &#123;</span><br><span class="line">       </span><br><span class="line">     <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * Sets the bit at the specified index to the specified value.</span></span><br><span class="line"><span class="comment">    *</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span>  bitIndex a bit index</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span>  value a boolean value to set</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@throws</span> IndexOutOfBoundsException if the specified index is negative</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@since</span>  1.4</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">set</span><span class="params">(<span class="type">int</span> bitIndex, <span class="type">boolean</span> value)</span> &#123;</span><br><span class="line">       <span class="keyword">if</span> (value)</span><br><span class="line">           set(bitIndex);</span><br><span class="line">       <span class="keyword">else</span></span><br><span class="line">           clear(bitIndex);</span><br><span class="line">   &#125;  </span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * Sets the bits from the specified &#123;<span class="doctag">@code</span> fromIndex&#125; (inclusive) to the</span></span><br><span class="line"><span class="comment">    * specified &#123;<span class="doctag">@code</span> toIndex&#125; (exclusive) to &#123;<span class="doctag">@code</span> true&#125;.</span></span><br><span class="line"><span class="comment">    *</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span>  fromIndex index of the first bit to be set</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span>  toIndex index after the last bit to be set</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@throws</span> IndexOutOfBoundsException if &#123;<span class="doctag">@code</span> fromIndex&#125; is negative,</span></span><br><span class="line"><span class="comment">    *         or &#123;<span class="doctag">@code</span> toIndex&#125; is negative, or &#123;<span class="doctag">@code</span> fromIndex&#125; is</span></span><br><span class="line"><span class="comment">    *         larger than &#123;<span class="doctag">@code</span> toIndex&#125;</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@since</span>  1.4</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">set</span><span class="params">(<span class="type">int</span> fromIndex, <span class="type">int</span> toIndex)</span> &#123;</span><br><span class="line">       </span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">    * Sets the bits from the specified &#123;<span class="doctag">@code</span> fromIndex&#125; (inclusive) to the</span></span><br><span class="line"><span class="comment">    * specified &#123;<span class="doctag">@code</span> toIndex&#125; (exclusive) to the specified value.</span></span><br><span class="line"><span class="comment">    *</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span>  fromIndex index of the first bit to be set</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span>  toIndex index after the last bit to be set</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span>  value value to set the selected bits to</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@throws</span> IndexOutOfBoundsException if &#123;<span class="doctag">@code</span> fromIndex&#125; is negative,</span></span><br><span class="line"><span class="comment">    *         or &#123;<span class="doctag">@code</span> toIndex&#125; is negative, or &#123;<span class="doctag">@code</span> fromIndex&#125; is</span></span><br><span class="line"><span class="comment">    *         larger than &#123;<span class="doctag">@code</span> toIndex&#125;</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@since</span>  1.4</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">set</span><span class="params">(<span class="type">int</span> fromIndex, <span class="type">int</span> toIndex, <span class="type">boolean</span> value)</span> &#123;</span><br></pre></td></tr></table></figure>

<h4 id="获取位"><a href="#获取位" class="headerlink" title="获取位"></a>获取位</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">    * Returns the value of the bit with the specified index. The value</span></span><br><span class="line"><span class="comment">    * is &#123;<span class="doctag">@code</span> true&#125; if the bit with the index &#123;<span class="doctag">@code</span> bitIndex&#125;</span></span><br><span class="line"><span class="comment">    * is currently set in this &#123;<span class="doctag">@code</span> BitSet&#125;; otherwise, the result</span></span><br><span class="line"><span class="comment">    * is &#123;<span class="doctag">@code</span> false&#125;.</span></span><br><span class="line"><span class="comment">    *</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span>  bitIndex   the bit index</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@return</span> the value of the bit with the specified index</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@throws</span> IndexOutOfBoundsException if the specified index is negative</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">   <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">get</span><span class="params">(<span class="type">int</span> bitIndex)</span> &#123;</span><br><span class="line">       </span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * Returns a new &#123;<span class="doctag">@code</span> BitSet&#125; composed of bits from this &#123;<span class="doctag">@code</span> BitSet&#125;</span></span><br><span class="line"><span class="comment">    * from &#123;<span class="doctag">@code</span> fromIndex&#125; (inclusive) to &#123;<span class="doctag">@code</span> toIndex&#125; (exclusive).</span></span><br><span class="line"><span class="comment">    *</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span>  fromIndex index of the first bit to include</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span>  toIndex index after the last bit to include</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@return</span> a new &#123;<span class="doctag">@code</span> BitSet&#125; from a range of this &#123;<span class="doctag">@code</span> BitSet&#125;</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@throws</span> IndexOutOfBoundsException if &#123;<span class="doctag">@code</span> fromIndex&#125; is negative,</span></span><br><span class="line"><span class="comment">    *         or &#123;<span class="doctag">@code</span> toIndex&#125; is negative, or &#123;<span class="doctag">@code</span> fromIndex&#125; is</span></span><br><span class="line"><span class="comment">    *         larger than &#123;<span class="doctag">@code</span> toIndex&#125;</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@since</span>  1.4</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">   <span class="keyword">public</span> BitSet <span class="title function_">get</span><span class="params">(<span class="type">int</span> fromIndex, <span class="type">int</span> toIndex)</span> &#123;</span><br></pre></td></tr></table></figure>

<h4 id="获取当前bitset总bit的大小-最高位true的位置"><a href="#获取当前bitset总bit的大小-最高位true的位置" class="headerlink" title="获取当前bitset总bit的大小(最高位true的位置)"></a>获取当前bitset总bit的大小(最高位true的位置)</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line">    * Returns the &quot;logical size&quot; of this &#123;@code BitSet&#125;: the index of</span><br><span class="line">    * the highest set bit in the &#123;@code BitSet&#125; plus one. Returns zero</span><br><span class="line">    * if the &#123;@code BitSet&#125; contains no set bits.</span><br><span class="line">    *</span><br><span class="line">    * @return the logical size of this &#123;@code BitSet&#125;</span><br><span class="line">    * @since  1.2</span><br><span class="line">    */</span><br><span class="line">   public int length() &#123;</span><br></pre></td></tr></table></figure>

<h4 id="返回true的数目"><a href="#返回true的数目" class="headerlink" title="返回true的数目"></a>返回true的数目</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line">    * Returns the number of bits set to &#123;@code true&#125; in this &#123;@code BitSet&#125;.</span><br><span class="line">    *</span><br><span class="line">    * @return the number of bits set to &#123;@code true&#125; in this &#123;@code BitSet&#125;</span><br><span class="line">    * @since  1.4</span><br><span class="line">    */</span><br><span class="line">   public int cardinality() &#123;</span><br></pre></td></tr></table></figure>



<p>####返回第一个false的位置</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line">    * Returns the index of the first bit that is set to &#123;@code false&#125;</span><br><span class="line">    * that occurs on or after the specified starting index.</span><br><span class="line">    *</span><br><span class="line">    * @param  fromIndex the index to start checking from (inclusive)</span><br><span class="line">    * @return the index of the next clear bit</span><br><span class="line">    * @throws IndexOutOfBoundsException if the specified index is negative</span><br><span class="line">    * @since  1.4</span><br><span class="line">    */</span><br><span class="line">   public int nextClearBit(int fromIndex) &#123;</span><br><span class="line">   </span><br><span class="line">    /**</span><br><span class="line">    * Returns the index of the nearest bit that is set to &#123;@code false&#125;</span><br><span class="line">    * that occurs on or before the specified starting index.</span><br><span class="line">    * If no such bit exists, or if &#123;@code -1&#125; is given as the</span><br><span class="line">    * starting index, then &#123;@code -1&#125; is returned.</span><br><span class="line">    *</span><br><span class="line">    * @param  fromIndex the index to start checking from (inclusive)</span><br><span class="line">    * @return the index of the previous clear bit, or &#123;@code -1&#125; if there</span><br><span class="line">    *         is no such bit</span><br><span class="line">    * @throws IndexOutOfBoundsException if the specified index is less</span><br><span class="line">    *         than &#123;@code -1&#125;</span><br><span class="line">    * @since  1.7</span><br><span class="line">    */</span><br><span class="line">   public int previousClearBit(int fromIndex) &#123;</span><br><span class="line">   </span><br></pre></td></tr></table></figure>

<h4 id="返回第一个true的位置"><a href="#返回第一个true的位置" class="headerlink" title="返回第一个true的位置"></a>返回第一个true的位置</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line">     * Returns the index of the first bit that is set to &#123;@code true&#125;</span><br><span class="line">     * that occurs on or after the specified starting index. If no such</span><br><span class="line">     * bit exists then &#123;@code -1&#125; is returned.</span><br><span class="line">     *</span><br><span class="line">     * &lt;p&gt;To iterate over the &#123;@code true&#125; bits in a &#123;@code BitSet&#125;,</span><br><span class="line">     * use the following loop:</span><br><span class="line">     *</span><br><span class="line">     *  &lt;pre&gt; &#123;@code</span><br><span class="line">     * for (int i = bs.nextSetBit(0); i &gt;= 0; i = bs.nextSetBit(i+1)) &#123;</span><br><span class="line">     *     // operate on index i here</span><br><span class="line">     *     if (i == Integer.MAX_VALUE) &#123;</span><br><span class="line">     *         break; // or (i+1) would overflow</span><br><span class="line">     *     &#125;</span><br><span class="line">     * &#125;&#125;&lt;/pre&gt;</span><br><span class="line">     *</span><br><span class="line">     * @param  fromIndex the index to start checking from (inclusive)</span><br><span class="line">     * @return the index of the next set bit, or &#123;@code -1&#125; if there</span><br><span class="line">     *         is no such bit</span><br><span class="line">     * @throws IndexOutOfBoundsException if the specified index is negative</span><br><span class="line">     * @since  1.4</span><br><span class="line">     */</span><br><span class="line">    public int nextSetBit(int fromIndex) &#123;</span><br><span class="line">    </span><br><span class="line">     /**</span><br><span class="line">     * Returns the index of the nearest bit that is set to &#123;@code true&#125;</span><br><span class="line">     * that occurs on or before the specified starting index.</span><br><span class="line">     * If no such bit exists, or if &#123;@code -1&#125; is given as the</span><br><span class="line">     * starting index, then &#123;@code -1&#125; is returned.</span><br><span class="line">     *</span><br><span class="line">     * &lt;p&gt;To iterate over the &#123;@code true&#125; bits in a &#123;@code BitSet&#125;,</span><br><span class="line">     * use the following loop:</span><br><span class="line">     *</span><br><span class="line">     *  &lt;pre&gt; &#123;@code</span><br><span class="line">     * for (int i = bs.length(); (i = bs.previousSetBit(i-1)) &gt;= 0; ) &#123;</span><br><span class="line">     *     // operate on index i here</span><br><span class="line">     * &#125;&#125;&lt;/pre&gt;</span><br><span class="line">     *</span><br><span class="line">     * @param  fromIndex the index to start checking from (inclusive)</span><br><span class="line">     * @return the index of the previous set bit, or &#123;@code -1&#125; if there</span><br><span class="line">     *         is no such bit</span><br><span class="line">     * @throws IndexOutOfBoundsException if the specified index is less</span><br><span class="line">     *         than &#123;@code -1&#125;</span><br><span class="line">     * @since  1.7</span><br><span class="line">     */</span><br><span class="line">    public int previousSetBit(int fromIndex) &#123;</span><br></pre></td></tr></table></figure>

<h4 id="位运算"><a href="#位运算" class="headerlink" title="位运算"></a>位运算</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">public void and(BitSet set) &#123;</span><br><span class="line"></span><br><span class="line">public void or(BitSet set) &#123;</span><br><span class="line"></span><br><span class="line">public void xor(BitSet set) &#123;</span><br><span class="line"></span><br><span class="line"> /**</span><br><span class="line">    * Clears all of the bits in this &#123;@code BitSet&#125; whose corresponding</span><br><span class="line">    * bit is set in the specified &#123;@code BitSet&#125;.</span><br><span class="line">    *</span><br><span class="line">    * @param  set the &#123;@code BitSet&#125; with which to mask this</span><br><span class="line">    *         &#123;@code BitSet&#125;</span><br><span class="line">    * @since  1.2</span><br><span class="line">    */</span><br><span class="line">public void andNot(BitSet set) &#123;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="判空-是否有true"><a href="#判空-是否有true" class="headerlink" title="判空 (是否有true)"></a>判空 (是否有true)</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line">    * Returns true if this &#123;@code BitSet&#125; contains no bits that are set</span><br><span class="line">    * to &#123;@code true&#125;.</span><br><span class="line">    *</span><br><span class="line">    * @return boolean indicating whether this &#123;@code BitSet&#125; is empty</span><br><span class="line">    * @since  1.4</span><br><span class="line">    */</span><br><span class="line">   public boolean isEmpty() &#123;</span><br></pre></td></tr></table></figure>

<h4 id="交集"><a href="#交集" class="headerlink" title="交集"></a>交集</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line">    * Returns true if the specified &#123;@code BitSet&#125; has any bits set to</span><br><span class="line">    * &#123;@code true&#125; that are also set to &#123;@code true&#125; in this &#123;@code BitSet&#125;.</span><br><span class="line">    *</span><br><span class="line">    * @param  set &#123;@code BitSet&#125; to intersect with</span><br><span class="line">    * @return boolean indicating whether this &#123;@code BitSet&#125; intersects</span><br><span class="line">    *         the specified &#123;@code BitSet&#125;</span><br><span class="line">    * @since  1.4</span><br><span class="line">    */</span><br><span class="line">   public boolean intersects(BitSet set) &#123;</span><br></pre></td></tr></table></figure>

<h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">public class BitSetDemo &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        BitSet bitSet = new BitSet(64);</span><br><span class="line">        bitSet.set(1,9,true);</span><br><span class="line">//        bitSet.clear();</span><br><span class="line">        bitSet.clear(1,2);</span><br><span class="line">//        bitSet.set(60,true);</span><br><span class="line">        System.out.println(bitSet.nextClearBit(0));</span><br><span class="line">        System.out.println(bitSet.previousClearBit(10));</span><br><span class="line">        System.out.println(bitSet.nextSetBit(0));</span><br><span class="line">        System.out.println(bitSet.previousSetBit(10));</span><br><span class="line">        System.out.println(bitSet.length());</span><br><span class="line">        System.out.println(bitSet.size());</span><br><span class="line">        System.out.println(bitSet.cardinality());</span><br><span class="line">        System.out.println(bitSet.isEmpty());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><img src="/posts/f3bbf6f0/asset/1688303879699.png" alt="1688303879699"></p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>java数据结构与高级类型</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>java数据结构与高级类型</tag>
      </tags>
  </entry>
  <entry>
    <title>hash表</title>
    <url>/posts/6e9d639a/</url>
    <content><![CDATA[<h2 id="哈希冲突"><a href="#哈希冲突" class="headerlink" title="哈希冲突"></a><strong>哈希冲突</strong></h2><p>在哈希表中，我们可以利用哈希函数快速访问到数组中的目标数据。如果发生<strong>哈希冲突</strong>，就使用链表进行存储，这样一来，不管数据量为多少，我们都能够灵活应对。</p>
<p>如果数组的空间太小，使用哈希表的时候就容易发生冲突，线性查找的使用频率也会更高；反过来，如果数组的空间太大，就会出现很多空箱子，造成内存的浪费。因此，给数组设定合适的空间非常重要。</p>
<p>在存储数据的过程中，如果发生冲突，可以利用链表在已有数据的后面插入新数据来解决冲突，这种方法被称为<strong>链表法</strong>，也被称为<strong>链地址法</strong>。</p>
<p>其中在 Java 集合类的 HashMap 中解决冲突的方法就是采用的<strong>链表法</strong>，建议阅读 HashMap 源码。</p>
<p>除了链地址法以外，还有几种解决冲突的方法。其中，应用较为广泛的是<strong>开放地址法</strong>，或称为<strong>开放寻址法</strong>。<strong>这种方法是指当冲突发生时，立刻计算出一个候补地址（数组上的位置）并将数据存进去。如果仍然有冲突，便继续计算下一个候补地址，直到有空地址为止，可以通过多次使用哈希函数或线性探测法等方法计算候补地址。</strong></p>
<p>在 Java 中，ThreadLocal 所使用的就是<strong>开放地址法</strong>。</p>
<p>哈希函数设计的好坏决定了哈希冲突的概率，也就决定哈希表的性能。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h2><p>这篇文章主要讲了一些比较基础的哈希表知识，包括哈希表的由来、哈希冲突的解决方法。</p>
<p>哈希表也叫散列表，来源于数组]它借助哈希函数对数组这种数据结构进行扩展，利用的是数组支持按照下标随机访问元素的特性，是存储 Key-Value 映射的集合。</p>
<p>哈希表两个核心问题是哈希函数设计和哈希冲突解决。对于某一个 Key，哈希表可以在接近 O(1) 的时间内进行读写操作。哈希表通过哈希函数实现 Key 和数组下标的转换，通过开放寻址法和链表法来解决哈希冲突。哈希函数设计的好坏决定了哈希冲突的概率，也就决定哈希表的性能。</p>
<p>有兴趣的可以在 JDK 中阅读 HashMap 的源码，在 JDK 8 和之前的版本的实现还有许多不多，比如在 JDK 8 中，引入红黑树，当链表长度太长（默认超过 8）时，链表就转换为红黑树，就可以利用红黑树快速增删改查的特点，提高 HashMap 的性能。</p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>java数据结构与高级类型</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>java数据结构与高级类型</tag>
      </tags>
  </entry>
  <entry>
    <title>栈和队列</title>
    <url>/posts/8d66b5f2/</url>
    <content><![CDATA[<h2 id="栈"><a href="#栈" class="headerlink" title="栈"></a>栈</h2><p> Java中有Stack类，但现在已经过时了，不推荐使用。一个更好的方法是使用Deque接口实现栈（Deque意为双端队列，double ended queue）。具体来说又有ArrayDeuqe和LinkedList两种具体类来实现，两者的区别体现在底层分别使用数组和链表来实现。 </p>
<blockquote>
<p> 常用的重要函数包括：<br>push(); &#x2F;&#x2F; 向stack栈顶压入一个元素<br>pop(); &#x2F;&#x2F; 从stack中弹出栈顶元素<br>peek(); &#x2F;&#x2F; 查看stack中栈顶元素，不弹出 </p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// deque接口实现stack</span></span><br><span class="line"> Deque&lt;Integer&gt; stack = <span class="keyword">new</span> <span class="title class_">LinkedList</span>&lt;&gt;();</span><br><span class="line"></span><br><span class="line"> stack.push(<span class="number">1</span>);</span><br><span class="line"> stack.push(<span class="number">2</span>);</span><br><span class="line"> stack.push(<span class="number">3</span>);</span><br><span class="line"></span><br><span class="line"> <span class="keyword">while</span>(!stack.isEmpty()) &#123;</span><br><span class="line">     System.out.println(stack.pop());</span><br><span class="line"> &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="队列"><a href="#队列" class="headerlink" title="队列"></a>队列</h2><p> 使用Queue接口实现，具体的实现类有LinkedList。 </p>
<blockquote>
<p>常用的重要函数包括：<br>向队列尾部添加元素：<br>offer(); &#x2F;&#x2F; 如果因为长度不够等原因插入失败，返回false<br>add(); &#x2F;&#x2F; 如果插入失败会抛出异常：IllegalStateException;<br>查看头部元素 ，不改变队列：<br>peek(); &#x2F;&#x2F; 如果队列中没有元素，返回null;<br>element(); &#x2F;&#x2F; 如果队列中没有元素，则抛出异常：NoSuchElementException;<br>取出队首元素（返回队首元素，队列中不再包含此元素）：<br>poll(); &#x2F;&#x2F; 会在没元素时返回null;<br>remove(); &#x2F;&#x2F; 会在没元素时抛出异常：NoSuchElementException;</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// queue接口实现queue</span></span><br><span class="line">Queue&lt;Integer&gt; queue = <span class="keyword">new</span> <span class="title class_">LinkedList</span>&lt;&gt;();</span><br><span class="line">queue.offer(<span class="number">1</span>);</span><br><span class="line">queue.offer(<span class="number">2</span>);</span><br><span class="line">queue.offer(<span class="number">3</span>);</span><br><span class="line">	</span><br><span class="line"><span class="keyword">while</span> (!queue.isEmpty()) &#123;</span><br><span class="line">    System.out.println(queue.poll());</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="小根堆"><a href="#小根堆" class="headerlink" title="小根堆"></a>小根堆</h2><p> PriorityQueue类实现了优先队列，默认是一个小根堆的形式，如果要定义大根堆，需要在初始化的时候加入一个自定义的比较器。 </p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// PriorityQueue 实现heap</span></span><br><span class="line"><span class="comment">// minHeap：PriorityQueue默认实现小根堆</span></span><br><span class="line">PriorityQueue&lt;Integer&gt; minHeap = <span class="keyword">new</span> <span class="title class_">PriorityQueue</span>&lt;&gt;();</span><br><span class="line">minHeap.offer(<span class="number">5</span>);</span><br><span class="line">minHeap.offer(<span class="number">3</span>);</span><br><span class="line">minHeap.offer(<span class="number">4</span>);</span><br><span class="line">minHeap.offer(<span class="number">1</span>);</span><br><span class="line">minHeap.offer(<span class="number">2</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span>(!minHeap.isEmpty()) &#123;</span><br><span class="line">    System.out.println(minHeap.poll());</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="大根堆"><a href="#大根堆" class="headerlink" title="大根堆"></a>大根堆</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// maxHeap</span></span><br><span class="line"><span class="comment">// 自定义比较器：当compare函数中第一个参数（这里是较大的元素）需要排在前面时，返回一个负数；反之返回一个正数。</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">maxComparator</span> <span class="keyword">implements</span> <span class="title class_">Comparator</span>&lt;Integer&gt; &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">compare</span><span class="params">(Integer num1, Integer num2)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> num1 &gt;= num2 ? -<span class="number">1</span> : <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 初始化PriorityQueue的时候new一个自定义比较器的对象</span></span><br><span class="line">PriorityQueue&lt;Integer&gt; maxHeap = <span class="keyword">new</span> <span class="title class_">PriorityQueue</span>&lt;Integer&gt;(<span class="keyword">new</span> <span class="title class_">maxComparator</span>());</span><br><span class="line">maxHeap.offer(<span class="number">5</span>);</span><br><span class="line">maxHeap.offer(<span class="number">3</span>);</span><br><span class="line">maxHeap.offer(<span class="number">4</span>);</span><br><span class="line">maxHeap.offer(<span class="number">1</span>);</span><br><span class="line">maxHeap.offer(<span class="number">2</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span>(!maxHeap.isEmpty()) &#123;</span><br><span class="line">    System.out.println(maxHeap.poll());</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>java数据结构与高级类型</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>java数据结构与高级类型</tag>
      </tags>
  </entry>
  <entry>
    <title>B+树</title>
    <url>/posts/17426722/</url>
    <content><![CDATA[<h1 id="B-树看这一篇就够了（B-树查找、插入、删除全上）"><a href="#B-树看这一篇就够了（B-树查找、插入、删除全上）" class="headerlink" title="B+树看这一篇就够了（B+树查找、插入、删除全上）"></a>B+树看这一篇就够了（B+树查找、插入、删除全上）</h1><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a><strong>基本概念</strong></h2><p>为了实现动态多层索引，通常采用 B-树 和 B+树。但是，用于索引的 B-树 存在缺陷，它的所有中间结点均存储的是数据指针（指向包含键值的磁盘文件块的指针），与该键值一起存储在B-树的结点中。这就会导致可以存储在 B-树中的结点目数极大地减少了，从而增加 B-树的层数，进而增加了记录的搜索时间。</p>
<p>B+树通过仅在树的叶子结点中存储数据指针而消除了上述缺陷。因此，B+树的叶结点的结构与 B-树的内部结点的结构完全不同。在这里应该注意，由于数据指针仅存在于叶子结点中，因此叶子结点必须将所有键值及其对应的数据指针存储到磁盘文件块以便访问。此外，叶子结点被链接磁盘的某个位置，以提供对记录的有序访问。因此，叶子结点形成第一级索引，而内部结点形成多层索引的其他层。叶子结点的某些关键字 key 也出现在内部结点中，充当控制搜索记录的媒介。</p>
<p>与 B-树不同，B+树中的结点存在两个阶（order）：对于阶 “a” 和 “ b”，一个用于内部结点，另一个用于外部（或叶）结点。</p>
<h3 id="阶为-a-的-B-树内部结点的结构如下："><a href="#阶为-a-的-B-树内部结点的结构如下：" class="headerlink" title="阶为 a 的 B+树内部结点的结构如下："></a><strong>阶为 a 的 B+树内部结点的结构如下：</strong></h3><p><img src="https://pic4.zhimg.com/80/v2-705cee41307cbf12d84d2dc9c9c1dae7_720w.webp" alt="img"></p>
<ol>
<li>对于每一个形如：&lt;P1,K1,P2,K2,……,Pc−1,Kc−1,Pc&gt;的内部结点，其中 c≤a ，每一个 Pi 表示指向子树根结点的指针，Ki 表示关键字值</li>
<li>对于每一个内部结点中的关键字值均满足：K1&lt;K2&lt;…&lt;Kc−1.(内部结点的关键字由小到大有序排列)</li>
<li>对于一个位于 Pi 所指向的子树中的结点 X 而言，满足：<br>当 1&lt;i&lt;c 时，均有 Ki−1&lt;X&lt;&#x3D;Ki.<br>当 i&#x3D;c 时，X&gt;Kc−1 .<br>当 i&#x3D;1 时， X&lt;&#x3D;K1 .</li>
<li>每一个内部结点最多有 <code>a</code> 个指向子树的指针，即 <code>c</code> 最大取 <code>a</code> .</li>
<li>根结点至少包含两个指向子树的结点指针，即对于根结点而言 2≥c≤a ; 除了根之外的每个结点都包含最少 ceil(a&#x2F;2) 个指向子树的指针。</li>
<li>如果任意一个内部结点包含 <code>c</code> 个指向孩子结点的指针且 c≤a ，则该结点包含 c−1 的关键字。</li>
</ol>
<h3 id="阶为-b-的-B-树叶子结点的结构："><a href="#阶为-b-的-B-树叶子结点的结构：" class="headerlink" title="阶为 b 的 B+树叶子结点的结构："></a><strong>阶为 b 的 B+树叶子结点的结构：</strong></h3><p><img src="https://pic2.zhimg.com/80/v2-e623d8c85e5dde67eb9948484d4305f9_720w.webp" alt="img"></p>
<ol>
<li>对于每一个形如：，&lt;&lt;K1,D1&gt;,&lt;K2,D2&gt;,……,&lt;Kc−1，Dc−1&gt;,Pnext&gt;的叶子结点，其中 c≤b ， Di 是一个数据指针（指向磁盘上的值等于 Ki 的真实记录的指针，或者包含记录 Ki 的磁盘文件块）， Ki 是一个关键字，Pnext 表示 B+树中指向下一个叶子结点的指针。</li>
<li>对任意一个叶子结点均有：K1&lt;K2&lt;…&lt;Kc−1，c≤b .</li>
<li>每一个叶子结点至少包含 ceil(a&#x2F;2) 个值.</li>
<li>所有的叶子结点在同一层。</li>
</ol>
<p>使用 Pnext 指针可以遍历所有的叶子结点，就和单链表一样，从而实现对磁盘上记录的有序访问。</p>
<p>下图为一颗完整的 B+树的结构示例：</p>
<p><img src="/posts/17426722/asset/v2-7a83d0068331c5fe82ae2557b97e52d8_720w.webp" alt="img"></p>
<h3 id="B-树的优点"><a href="#B-树的优点" class="headerlink" title="B+树的优点"></a><strong>B+树的优点</strong></h3><p>同为 h 层的 B-树和 B+树，B+树可以存储更多的结点元素，更加 ”矮胖“。这也是 B+树最大的优势坐在，极大地改善了 B-树的查找效率。对于同样多的记录，B+树的高度会更矮，并且 Pnext 指针的出现可以帮助 B+树快速访问磁盘记录且效率非常高。总之，就是 B+树比 B-树更加好，B+树的磁盘 I &#x2F; O 会更少，相比于 B-树的中序遍历，B+树只需要像遍历单链表一样扫描一遍叶子结点。</p>
<h2 id="查找操作"><a href="#查找操作" class="headerlink" title="查找操作"></a><strong>查找操作</strong></h2><p>前面谈了 B+树的基本概念，今日主要说一下 B+树的查找操作。</p>
<p><img src="/posts/17426722/asset/v2-8133213bd9817012f8a8e95b079c6817_720w.webp" alt="img"></p>
<p>下面所有的查找操作都是在上面这颗 B+树上进行了，为此，我们先仔细观察一下这颗B+树（毫不隐瞒，这颗 B+树出自于严蔚敏老师的数据结构教材）。</p>
<p>第一点：B+树中的所有数据均保存在叶子结点，且根结点和内部结点均只是充当控制查找记录的媒介，并不代表数据本身，所有的内部结点元素都同时存在于子结点中，是子节点元素中是最大（或最小）元素。</p>
<p><img src="/posts/17426722/asset/v2-25c1c0b8a4ea8c300e180e3d87339bfb_720w.webp" alt="img"></p>
<p>比如 B+ 树中的结点 <code>59</code> （结点 <code>15、44、97、72</code> 类似），是其子结点 <code>[15、44、59]</code> 中的最大元素，也是叶子结点 <code>[51、59]</code> 中的最大元素。所有的数据 <code>[10、15、21、37、44、51、59、63、72、85、91、97]</code> 均保存在叶子结点之中，而根结点 <code>[59、97]</code> 及内部结点 <code>[15、44、59]</code> 与 <code>[72、97]</code> 均不是数据本身，只是充当控制查找记录的媒介。</p>
<p>需要注意的是，根结点的最大元素 <code>97</code> 是整颗 B+树当中最大的元素，无论之后在叶子结点中插入或删除多少元素，始终要保证最大元素在根结点当中，这个讲插入和删除时还会看到。</p>
<p>第二点：每一个叶子结点都有指向下一个叶子结点的 Pnext 指针，便捷之处就在于之后我们将看到的区间查找。</p>
<p><img src="/posts/17426722/asset/v2-efa3f8f327b9e55930e8a772f8183ab7_720w.webp" alt="img"></p>
<h2 id="查询单个元素"><a href="#查询单个元素" class="headerlink" title="查询单个元素"></a><strong>查询单个元素</strong></h2><p><img src="https://pic4.zhimg.com/80/v2-8133213bd9817012f8a8e95b079c6817_720w.webp" alt="img"></p>
<p>我们以查询 <code>59</code> 为例进行说明。</p>
<p>第一次磁盘 I&#x2F;O ：访问根结点 <code>[59、97]</code> ，发现 <code>59</code> 小于等于 <code>[59、97]</code> 中的 <code>59</code> ，则访问根结点的第一个孩子结点。</p>
<p><img src="/posts/17426722/asset/v2-efc68940b3f85ba0b6f6a2352df43bff_720w.webp" alt="img"></p>
<p>第二次磁盘 I&#x2F;O : 访问结点 <code>[15、44、59]</code> ，发现 <code>59</code> 大于 <code>44</code> 且小于等于 <code>59</code> ，则访问当前结点的第三个孩子结点 <code>[51、59]</code> .</p>
<p><img src="/posts/17426722/asset/v2-54282f355f16664a05863e764135ace0_720w.webp" alt="img"></p>
<p>第三次磁盘 I&#x2F;O ：访问叶子结点 <code>[51、59]</code> ，顺序遍历结点内部，找到要查找的元素 <code>59</code> .</p>
<p><img src="/posts/17426722/asset/v2-65789684f319ca8675040ee7044e365c_720w.webp" alt="img"></p>
<p>我想你已经注意到了和 B-树的区别，对于 B+树中单个元素的查找而言，每一个元素都有相同的磁盘 I&#x2F;O操作次数，即使查询的元素出现在根结点中，但那只是一个充当控制查找记录的媒介，并不是数据本身，数据真正存在于叶子结点当中，所以 B+树中查找任何一个元素都要从根结点一直走到叶子结点才可以。</p>
<p><img src="/posts/17426722/asset/v2-7a83d0068331c5fe82ae2557b97e52d8_720w-1682999964107.webp" alt="img"></p>
<p>B+树的非叶子结点均不存储 <code>Data</code> (即 Di ，官方将其称为卫星数据) ，所以与 B-树相比，同样大小的磁盘页，B+树的非叶子结点可以存储更多的索引（关键字），这也就意味着在数据量相同的情况下，B+树的结构比 B-树更加 “矮胖”，查询时磁盘 I&#x2F;O 次数会更少。</p>
<p><strong>注意：</strong> B-树的查询性能并不稳定，对于根结点中关键字可能只有一次磁盘 I&#x2F;O，而对于叶子结点中的关键字需要树的高度次磁盘 I&#x2F;O 操作。</p>
<p><img src="/posts/17426722/asset/v2-fdafe8150dd643e9cddaf2baa0620d2e_720w.webp" alt="img"></p>
<p>比如查找上图 B-树中的关键字 <code>59</code> 仅需要一次磁盘 I&#x2F;O 操作，关键字 <code>21</code> 需要 3 次磁盘 I&#x2F;O，关键字 <code>72</code> 需要 2 次磁盘 I&#x2F;O.</p>
<p>B+树所有查询所有关键字的磁盘 I&#x2F;O 的次数都是树的高度。</p>
<h2 id="区间查询"><a href="#区间查询" class="headerlink" title="区间查询"></a><strong>区间查询</strong></h2><p>为了更清楚地看到 B+树进行区间查询的优势，我们以查询下面的 B-树中大于等于21 ，小于等于63的关键字为例进行说明。</p>
<p><img src="https://pic3.zhimg.com/80/v2-fdafe8150dd643e9cddaf2baa0620d2e_720w.webp" alt="img"></p>
<p>第一步：访问 B-树的根结点 <code>[59]</code> ，发现 <code>21</code> 比 <code>59</code> 小，则访问根结点的第一个孩子 <code>[15、44]</code> .</p>
<p><img src="https://pic4.zhimg.com/80/v2-f321ea715713688814de6c8321bf2e9f_720w.webp" alt="img"></p>
<p>第二步：访问结点 <code>[15、44]</code> ，发现 <code>21</code> 大于 <code>15</code> 且小于 <code>44</code> ，则访问当前结点的第二个孩子结点 <code>[21、37]</code> 。</p>
<p><img src="https://pic2.zhimg.com/80/v2-041d9222310de902358977058addfe71_720w.webp" alt="img"></p>
<p>第三步：访问结点 <code>[21、37]</code> , 找到区间的左端点 <code>21</code> ，然后从该关键字 <code>21</code> 开始，进行中序遍历，依次为关键字 <code>37 、44、51、59</code>，直到遍历到区间的右端点 <code>63</code> 为止， 不考虑中序遍历过程的压栈和入栈操作，光磁盘 I&#x2F;O 次数就多了 2次，即访问结点 <code>72</code> 和结点 <code>63</code> .</p>
<p><img src="https://pic4.zhimg.com/80/v2-c31896690180841d853bec194d1967b7_720w.webp" alt="img"></p>
<p>而 B+树进行区间查找，简直要舒服的不要不要的。同样是查找区间 <code>[21,63]</code> 之间的关键字。</p>
<p><img src="https://pic4.zhimg.com/80/v2-8133213bd9817012f8a8e95b079c6817_720w.webp" alt="img"></p>
<p>第一步：访问根结点 <code>[59、97]</code> , 发现区间的左端点 <code>21</code> 小于 <code>59</code>， 则访问第一个左孩子 <code>[15、44、59]</code> .</p>
<p><img src="https://pic4.zhimg.com/80/v2-efc68940b3f85ba0b6f6a2352df43bff_720w.webp" alt="img"></p>
<p>第二步：访问结点 <code>[15、44、59]</code> ，发现 <code>21</code> 大于 <code>15</code> 且小于 <code>44</code> ，则访问第二个孩子结点 <code>[21、37，44]</code> .</p>
<p><img src="/posts/17426722/asset/v2-8983cbb9d66810682c09a9569889b365_720w.webp" alt="img"></p>
<p>第三步：访问结点 <code>[21、37，44]</code> ，找到了左端点 <code>21</code> ，此时 B+树的优越性就出来了，不再需要中序遍历，而是相当于单链表的遍历，直接从左端点 <code>21</code> 开始一直遍历到左端点 <code>63</code> 即可，没有任何额外的磁盘 I&#x2F;O 操作。</p>
<p><img src="/posts/17426722/asset/v2-3a8747b104851276e92ecd3c26284db0_720w.webp" alt="img"></p>
<p>综合来看 B+树的优势就是：</p>
<ol>
<li>查找时磁盘 I&#x2F;O 次数更少，因为 B+树的非叶子结点可以存储更多的关键字，数据量相同的情况下，B+树更加 “矮胖” ，效率更高。</li>
<li>B+树查询所有关键字的磁盘 I&#x2F;O 次数都一样，查询效率稳定。</li>
<li>B+树进行区间查找时更加简便实用。</li>
</ol>
<p>此外给大家推荐一篇博文 <strong><a href="https://link.zhihu.com/?target=http://blog.codinglabs.org/articles/theory-of-mysql-index.html">MySQL索引背后的数据结构及算法原理</a></strong> ，其中对于MySQL 索引为什么采用 B+树，以及InnoDB表为什么必须有主键，并且为什么推荐使用自增主键都有解释，需要的朋友可以自提，我就不再造轮子了。</p>
<h2 id="插入和删除操作"><a href="#插入和删除操作" class="headerlink" title="插入和删除操作"></a><strong>插入和删除操作</strong></h2><p>大部分教材和分享中都会将 B+树的插入和删除操作一笔带过，但这并不意味着你真的懂了或者说是不重要，因为我觉得有些朋友可能都没有看过 B-树，一句 “<strong>B+树的插入和删除操作与 B-树的插入和删除操作类似</strong>“ 又怎么说的过去，相信你看完这篇 B+树的插入和删除操作一定会有收获，一起加油呀~</p>
<h2 id="B-树的插入操作"><a href="#B-树的插入操作" class="headerlink" title="B+树的插入操作"></a><strong>B+树的插入操作</strong></h2><p>在B+树中插入关键字时，需要注意以下几点：</p>
<ul>
<li>插入的操作全部都在叶子结点上进行，且不能破坏关键字自小而大的顺序；</li>
<li>由于 B+树中各结点中存储的关键字的个数有明确的范围，做插入操作可能会出现结点中关键字个数超过阶数的情况，此时需要将该结点进行 “分裂”；</li>
</ul>
<p>我们依旧以之前介绍查找操作时使用的图对插入操作进行说明，需要注意的是，B+树的阶数 <code>M = 3</code> ，且 <code>⌈M/2⌉ = 2（取上限）</code> 、<code>⌊M/2⌋ = 1（取下限）</code> ：</p>
<p><img src="/posts/17426722/asset/v2-8133213bd9817012f8a8e95b079c6817_720w-1683000051786.webp" alt="img"></p>
<p>B+树中做插入关键字的操作，有以下 3 种情况：</p>
<p>1、 若被插入关键字所在的结点，其含有关键字数目小于阶数 M，则直接插入；</p>
<p>比如插入关键字 <code>12</code> ，插入关键字所在的结点的 <code>[10，15]</code> 包含两个关键字，小于 <code>M</code> ，则直接插入关键字 <code>12</code> 。</p>
<p> <img src="/posts/17426722/asset/v2-386cefe3c3c93b726387ee2abc577691_b.webp" alt="动图"> </p>
<p>2、 若被插入关键字所在的结点，其含有关键字数目等于阶数 M，则需要将该结点分裂为两个结点，一个结点包含 <code>⌊M/2⌋</code> ，另一个结点包含 <code>⌈M/2⌉</code> 。同时，将<code>⌈M/2⌉</code>的关键字上移至其双亲结点。假设其双亲结点中包含的关键字个数小于 M，则插入操作完成。</p>
<p>插入关键字 <code>95</code> ，插入关键字所在结点 <code>[85、91、97]</code> 包含 3 个关键字，等于阶数 <code>M</code> ，则将 <code>[85、91、97]</code> 分裂为两个结点 <code>[85、91]</code> 和结点 <code>[97]</code> , 关键字 <code>95</code> 插入到结点 <code>[95、97]</code> 中，并将关键字 <code>91</code> 上移至其双亲结点中，发现其双亲结点 <code>[72、97]</code> 中包含的关键字的个数 2 小于阶数 <code>M</code> ，插入操作完成。</p>
<p><img src="/posts/17426722/asset/v2-4e621ab9044dcb42643066f6031226b0_b.jpg" alt="动图封面"></p>
<p>3、在第 2 情况中，如果上移操作导致其双亲结点中关键字个数大于 M，则应继续分裂其双亲结点。</p>
<p>插入关键字 <code>40</code> ，按照第 2 种情况将结点分裂，并将关键字 <code>37</code> 上移到父结点，发现父结点 <code>[15、37、44、59]</code> 包含的关键字的个数大于 <code>M</code> ，所以将结点 <code>[15、37、44、59]</code> 分裂为两个结点 <code>[15、37]</code> 和结点 <code>[44、59]</code> ，并将关键字 <code>37</code> 上移到父结点中 <code>[37、59、97]</code> . 父结点包含关键字个数没有超过 <code>M</code> ，插入结束。</p>
<p><img src="https://pic4.zhimg.com/v2-467b2c27f41bad29b01be13e1e5cd1bb_b.webp" alt="动图"></p>
<p>4、若插入的关键字比当前结点中的最大值还大，破坏了B+树中从根结点到当前结点的所有索引值，此时需要及时修正后，再做其他操作。</p>
<p>插入关键字 <code>100</code>，由于其值比最大值 <code>97</code> 还大，插入之后，从根结点到该结点经过的所有结点中的所有值都要由 <code>97</code> 改为 <code>100</code>。改完之后再做分裂操作。</p>
<p> <img src="https://pic3.zhimg.com/v2-85fb69b1f6d5134f45808fc884ad2e4a_b.webp" alt="动图"> </p>
<h2 id="B-树的删除操作"><a href="#B-树的删除操作" class="headerlink" title="B+树的删除操作"></a><strong>B+树的删除操作</strong></h2><p>“对于 B+的删除操作而言，与 B-树类似”，我想你笑了，那我们接着看，哈哈！</p>
<p>在 B+树中删除关键字时，有以下几种情况：</p>
<p>1、 找到存储有该关键字所在的结点时，由于该结点中关键字个数大于<code>⌈M/2⌉</code>，做删除操作不会破坏 B+树，则可以直接删除。</p>
<p>删除关键字 <code>91</code>，包含关键字 <code>91</code> 的结点 <code>[85、91、97]</code> 中关键字的个数 3 大于 <code>⌈M/2⌉ = 2</code> ，做删除操作不会破坏 B+树的特性，直接删除。</p>
<p> <img src="/posts/17426722/asset/v2-7607b34265b14b3527101d53ce9c2b70_b.webp" alt="动图"> </p>
<p>2、 当删除某结点中最大或者最小的关键字，就会涉及到更改其双亲结点一直到根结点中所有索引值的更改。</p>
<p>以删除整颗 B+树中最大的关键字 <code>97</code> 为例，查找并删除关键字 <code>97</code> ， 然后向上回溯，将所有关键字 <code>97</code> 替换为次最大的关键字 <code>91</code> :</p>
<p> <img src="/posts/17426722/asset/v2-3aee225a4ba3e3a1b428e3f30e312637_b.webp" alt="动图"> </p>
<p>3、 当删除该关键字，导致当前结点中关键字个数小于 <code>⌈M/2⌉</code>，若其兄弟结点中含有多余的关键字，可以从兄弟结点中借关键字完成删除操作。</p>
<p>当删除某个关键字之后，结点中关键字个数小于 <code>⌈M/2⌉</code> ，则不符合 B+树的特性，则需要按照 3 he 4 两种情况分别处理。以删除关键字 <code>51</code> 为例，由于其兄弟结点 <code>[21、37、44]</code> 中含有 3 个关键字，所以可以选择借一个关键字 <code>44</code>，同时将双亲结点中的索引值 <code>44</code> 修改 <code>37</code> ，删除过程如下图所示：</p>
<p> <img src="https://pic2.zhimg.com/v2-8dae05b8aa006d6d1fc6bb54c24169a5_b.webp" alt="动图"> </p>
<p>4、 第 3 种情况中，如果其兄弟结点没有多余的关键字，则需要同其兄弟结点进行合并。</p>
<p>为了说明这种情况，我们在第 3 种情况最终得到的 B+树之上进行删除操作。第 3 种情况删除关键字 <code>51</code> 之后得到如下所示 B+树：</p>
<p> <img src="/posts/17426722/asset/v2-909e556bc9375489e5f975f90b25dfa8_720w.webp" alt="img"> </p>
<p>我们以删除上面这个 B+树中的关键字 <code>59</code> 说明第 4 种情况，首先查找到关键 <code>59</code> 所在结点 <code>[44、59]</code> ，发现该结点的兄弟结点 <code>[21、37]</code> 包含的关键字的个数 2 等于 <code>⌈M/2⌉</code>， 所以删除关键字 <code>59</code> ，并将结点 <code>[21、37]</code> 和 <code>[44]</code> 进行合并 <code>[21、37、44]</code> ，然后向上回溯，将所有关键字 <code>59</code> 替换为次最大的关键字 <code>44</code> :</p>
<p><img src="/posts/17426722/asset/v2-c33a70c8eaa38e96c3052a6bddc9d0d4_b.webp" alt="动图"></p>
<p>5、 当进行合并时，可能会产生因合并使其双亲结点破坏 B+树的结构，需要依照以上规律处理其双亲结点。</p>
<p>删除关键字 <code>63</code>，当删除关键字后，该结点中只剩关键字 <code>72</code>，且其兄弟结点 <code>[85、91]</code> 中只有 2 个关键字，所以将 <code>[72]</code> 和 <code>[85、91]</code> 进行合并，向上回溯，删除结点 <code>[72、91]</code> 当中的关键字 <code>72</code> ，此时结点中只有关键 <code>91</code> ，不满足 B+树中结点关键字个数要求，但其兄弟结点 <code>[15、44、59]</code> 中包含的 3 个关键字，所以从其兄弟结点当中借一个关键字 <code>59</code> , 再对其兄弟结点的父结点中的关键字进行调整，将关键字 <code>59</code> 替换为 <code>44</code> .</p>
<p> <img src="/posts/17426722/asset/v2-ae4011609fdf74e80d10fefb9e47dbb8_b.webp" alt="动图"> </p>
<p>总之，在 B+树中做删除关键字的操作，采取如下的步骤：</p>
<ol>
<li>删除该关键字，如果不破坏 B+树本身的性质，直接完成删除操作（情况 1）；</li>
<li>如果删除操作导致其该结点中最大（或最小）值改变，则应相应改动其父结点中的索引值（情况 2）；</li>
<li>在删除关键字后，如果导致其结点中关键字个数不足，有两种方法：一种是向兄弟结点去借，另外一种是同兄弟结点合并（情况 3、4 和 5）。（注意这两种方式有时需要更改其父结点中的索引值。）</li>
</ol>
<h2 id="B-树复杂度分析"><a href="#B-树复杂度分析" class="headerlink" title="B+树复杂度分析"></a><strong>B+树复杂度分析</strong></h2><p>B+树 是 B-树的一个升级版本，在存储结构上的变化，由于磁盘页的大小限制，只能读取少量的B-树结点到内存中（因为B-树结点就带有数据，占用更多空间，所以说是 <strong>少量</strong>）；而B+树就不一样了。因为非叶子结点不带数据，能够一次性读取更多结点进去处理，所以对于同样的数据量， B+树更加 “矮胖”， 性能更好。但是两者在查找、插入和删除等操作的时间复杂度的量级是一致的，均为 O(log⁡n) 。</p>
<p>这个量级是如何得来的呢？我们一起来看看 1970 年计算机的先驱们是如何计算的。</p>
<p>首先假定 h≥0 的整数（事实上就是树高），k 是一个自然数（也就是B-树当中提到的最小度数，这里不懂的可以回头看看之前的文章 <strong><a href="https://link.zhihu.com/?target=https://mp.weixin.qq.com/s/Q29CgcnnudePQ0l2UyshUw">图解：什么是B树（心中有 B树，做人要谦虚）？</a></strong> ).</p>
<p>一颗最小度为 k ，高度为 h 的 B-树 T ，或为空树，或者满足下面三个特性：</p>
<ol>
<li>从根结点到任意一个叶子结点有着相同的长度 h , 也称为树的高度。</li>
<li>除根结点和叶子节点外，每一个内部结点至少有 k+1 个孩子结点。根结点要么为叶子，要么至少包含两个孩子。</li>
<li>每个结点至多有 2k+1 个孩子结点。</li>
</ol>
<p>设 Nmin 和 Nmax 分别表示 B-树中可以最少包含与最多包含的结点数目，则：</p>
<p><img src="/posts/17426722/asset/v2-db2875f18aac102d3ea9304d9d7d5350_720w.webp" alt="img"></p>
<p>其中 h≥2 ，当 h&#x3D;1 依然成立， Nmin 至少包含一个结点，即根结点，之后每一层所包含的结点数目则为 (k+1)h−2 ，其中 k+1 表示每一个内部结点最少拥有的孩子结点数。类似的：</p>
<p><img src="https://pic2.zhimg.com/80/v2-477ea4abe5a04efdd14d4700f23e05d9_720w.webp" alt="img"></p>
<p>则对于一颗 B-树所能包含的结点数目的上下限为：</p>
<p><img src="/posts/17426722/asset/v2-32b20d2fbeaa405a5b425833d9455184_720w.webp" alt="img"></p>
<p>则对于一颗 B-树所能包含的关键字的最大数目和最小数目分别为 Imax 和 Imin :</p>
<p><img src="https://pic2.zhimg.com/80/v2-e386d9b46e21e3c5b88c796acf3ec9e1_720w.webp" alt="img"></p>
<p>则可以得到 B-树高度的一个上下限：</p>
<p><img src="https://pic2.zhimg.com/80/v2-afd9b8fa08fa80a9f5dc8827d422ccc1_720w.webp" alt="img"></p>
<p>这也就是我们所期待的对数级别的时间复杂度。对于上面的这个过程不清楚的可以跳过看下面。</p>
<p>对于一颗结束为 m 的B-树而言，每一个结点最多可以存储 m 个关键字，假设总共有 N 个关键字，树的高度为 h ，且这颗树完全填满，则 N&#x3D;mh ，继而得到 h&#x3D;logm⁡(N) ，也就是树的高度为 logm(N) ，可能有的人又会问，那一个结点中包含 m 个关键字，这 m 个关键字只有进行顺序遍历才能知道接着选择哪一个孩子结点，需要 O(m) 的时间，你说的对也不对，对是因为一个结点内的关键字的遍历确实是需要 O(m) 的时间复杂度，但是这个遍历是在内存当中进行的，时间一般可以忽略。我们通常更加关注的是磁盘 I&#x2F;O 的次数，也就是 logm(N) ，所以 B-树或者 B+树的时间复杂度就是 O(logm(N)) 。</p>
<p>对于 B+树而言，树的高度一般不超过 4 层，就 MySQL 的 InnoDB 存储引擎而言，一个结点默认的存储空间为 16Kb ( 可以通过这个命令查看<code>SHOW GLOBAL STATUS like &#39;Innodb_page_size&#39;;</code> )， MySQL 的 InnoDB 存储引擎的索引一般用 bigint 存储，占用 8 个 byte，一个索引又会关联一个指向孩子结点的指针，这个指针占用 6 个 byte，也就是说结点中的一个关键字大概要用 14 byte 的空间，而一个结点的默认大小为 16kb ，那么一个结点可以存储关键的个数最多为 16384&#x2F;14&#x3D;1170 , 就相当于阶数 m&#x3D;1170 ，那么对于一颗高度为 3 的 B+树而言保守估计可以存储 1170×1170×16&#x3D;21902400 个关键字，也就是两千多万条记录，其中的 16 为假定每一个叶子结点包含的关键字的个数（由于包含 Data 指针，所以叶子结点可以容纳的关键字的个数会少一些），就这样我想你也看到了 B+树的强大了。3层的 B+树就可以存储两千多万的数据，牛逼不？</p>
<p><a href="https://zhuanlan.zhihu.com/p/149287061">https://zhuanlan.zhihu.com/p/149287061</a></p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>其他</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>其他</tag>
      </tags>
  </entry>
  <entry>
    <title>B-树（B树）详解</title>
    <url>/posts/610f283b/</url>
    <content><![CDATA[<h1 id="B-树（B树）详解"><a href="#B-树（B树）详解" class="headerlink" title="B-树（B树）详解"></a>B-树（B树）详解</h1><p>具体讲解之前，有一点，再次强调下：B-树，即为B树。因为B树的原英文名称为B-tree，而国内很多人喜欢把B-tree译作B-树，其实，这是个非常不好的直译，很容易让人产生误解。如人们可能会以为B-树是一种树，而B树又是一种树。而事实上是，B-tree就是指的B树。特此说明。</p>
<h2 id="1、B-树-B树-的基本概念"><a href="#1、B-树-B树-的基本概念" class="headerlink" title="1、B-树(B树)的基本概念"></a>1、B-树(B树)的基本概念</h2><p>B-树中所有结点中孩子结点个数的最大值成为B-树的阶，通常用m表示，从查找效率考虑，一般要求m&gt;&#x3D;3。一棵m阶B-树或者是一棵空树，或者是满足以下条件的m叉树。<br> 1）每个结点最多有m个分支（子树）；而最少分支数要看是否为根结点，如果是根结点且不是叶子结点，则至少要有两个分支，非根非叶结点至少有ceil(m&#x2F;2)个分支，这里ceil代表向上取整。<br> 2）如果一个结点有n-1个关键字，那么该结点有n个分支。这n-1个关键字按照递增顺序排列。<br> 3）每个结点的结构为：</p>
<table>
<thead>
<tr>
<th align="center">n</th>
<th align="center">k1</th>
<th align="center">k2</th>
<th align="center">…</th>
<th align="center">kn</th>
</tr>
</thead>
<tbody><tr>
<td align="center">p0</td>
<td align="center">p1</td>
<td align="center">p2</td>
<td align="center">…</td>
<td align="center">pn</td>
</tr>
</tbody></table>
<p>其中，n为该结点中关键字的个数；ki为该结点的关键字且满足ki&lt;ki+1；pi为该结点的孩子结点指针且满足pi所指结点上的关键字大于ki且小于ki+1，p0所指结点上的关键字小于k1，pn所指结点上的关键字大于kn。</p>
<p>4）结点内各关键字互不相等且按从小到大排列。<br> 5）叶子结点处于同一层；可以用空指针表示，是查找失败到达的位置。</p>
<p><strong>注</strong>：平衡m叉查找树是指每个关键字的左侧子树与右侧子树的高度差的绝对值不超过1的查找树，其结点结构与上面提到的B-树结点结构相同，由此可见，B-树是平衡m叉查找树，但限制更强，要求所有叶结点都在同一层。</p>
<p>光看上面的解释可能大家对B-树理解的还不是那么透彻，下面我们用一个实例来进行讲解。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/4155986-f56390f6fdad36cd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/720/format/webp" alt="img"></p>
<p>上面的图片显示了一棵B-树，最底层的叶子结点没有显示。我们对上面提到的5条特点进行逐条解释：<br> 1）结点的分支数等于关键字数+1，最大的分支数就是B-树的阶数，因此m阶的B-树中结点最多有m个分支，所以可以看到，上面的一棵树是一个5-阶B-树。<br> 2）因为上面是一棵5阶B-树，所以非根非叶结点至少要有ceil(5&#x2F;2)&#x3D;3个分支。根结点可以不满足这个条件，图中的根结点有两个分支。<br> 3）如果根结点中没有关键字就没有分支，此时B-树是空树，如果根结点有关键字，则其分支数比大于或等于2，因为分支数等于关键字数+1.<br> 4）上图中除根结点外，结点中的关键字个数至少为2，因为分支数至少为3，分支数比关键字数多1，还可以看出结点内关键字都是有序的，并且在同一层中，左边结点内所有关键字均小于右边结点内的关键字，例如，第二层上的两个结点，左边结点内的关键字为15，26，他们均小于右边结点内的关键字39和45.<br> B-树一个很重要的特征是，下层结点内的关键字取值总是落在由上层结点关键字所划分的区间内，具体落在哪个区间内可以由指向它的指针看出。例如，第二层最左边的结点内的关键字划分了三个区间，小于15，15到26，大于26，可以看出其下层中最左边结点内的关键字都小于15，中间结点的关键字在15和26之间，右边结点的关键字大于26.<br> 5）上图中叶子结点都在第四层上，代表查找不成功的位置。</p>
<h2 id="2、B-树的查找操作"><a href="#2、B-树的查找操作" class="headerlink" title="2、B-树的查找操作"></a>2、B-树的查找操作</h2><p>B-树的查找很简单，是二叉排序树的扩展，二叉排序树是二路查找，B-树是多路查找，因为B-树结点内的关键字是有序的，在结点内进行查找时除了顺序查找外，还可以用折半查找来提升效率。B-树的具体查找步骤如下（假设查找的关键字为key）：<br> 1）先让key与根结点中的关键字比较，如果key等于k[i]（k[]为结点内的关键字数组），则查找成功<br> 2）若key&lt;k[1]，则到p[0]所指示的子树中进行继续查找（p[]为结点内的指针数组），这里要注意B-树中每个结点的内部结构。<br> 3）若key&gt;k[n]，则道p[n]所指示的子树中继续查找。<br> 4）若k[i]&lt;key&lt;k[i+1]，则沿着指针p[I]所指示的子树继续查找。<br> 5）如果最后遇到空指针，则证明查找不成功。</p>
<p>拿上面的二叉树进行举例，比如我们想要查找关键字42，下图加粗的部分显示了查找的路径：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/4155986-ff9b69085907aa81.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/730/format/webp" alt="img"></p>
<h2 id="3、B-树的插入"><a href="#3、B-树的插入" class="headerlink" title="3、B-树的插入"></a>3、B-树的插入</h2><p>与二叉排序树一样，B-树的创建过程也是将关键字逐个插入到树中的过程。<br> 在进行插入之前，要确定一下每个结点中关键字个数的范围，如果B-树的阶数为m，则结点中关键字个数的范围为ceil(m&#x2F;2)-1 ~ m-1个。<br> 对于关键字的插入，需要找到插入位置。在B-树的查找过程中，当遇到空指针时，则证明查找不成功，同时也找到了插入位置，即根据空指针可以确定在最底层非叶结点中的插入位置，为了方便，我们称最底层的非叶结点为<strong>终端结点</strong>，由此可见，B-树结点的插入总是落在终端结点上。在插入过程中有可能破坏B-树的特征，如新关键字的插入使得结点中关键字的个数超过规定个数，这是要进行<strong>结点的拆分</strong>。<br> 接下来，我们以关键字序列{1,2,6,7,11,4,8,13,10,5,17,9,16,20,3,12,14,18,19,15}创建一棵5阶B-树，我们将详细体会B-树的插入过程。<br> （1）确定结点中关键字个数范围<br> 由于题目要求建立5阶B-树，因此关键字的个数范围为2～4<br> （2）根结点最多可以容纳4个关键字，依次插入关键字1、2、6、7后的B-树如下图所示：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/4155986-480ae52e64570bb1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/314/format/webp" alt="img"></p>
<p>（3）当插入关键字11的时候，发现此时结点中关键字的个数变为5，超出范围，需要拆分，去关键字数组中的中间位置，也就是k[3]&#x3D;6，作为一个独立的结点，即新的根结点，将关键字6左、右关键字分别做成两个结点，作为新根结点的两个分支，此时树如下图所示：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/4155986-ed6e04f888690dde.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/360/format/webp" alt="img"></p>
<p>（4）新关键字总是插在叶子结点上，插入关键字4、8、13之后树为：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/4155986-276ef834e06bbc26.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/620/format/webp" alt="img"></p>
<p>（5）关键字10需要插入在关键字8和11之间，此时又会出现关键字个数超出范围的情况，因此需要拆分。拆分时需要将关键字10纳入根结点中，并将10左右的关键字做成两个新的结点连在根结点上。插入关键字10并经过拆分操作后的B-树如下图：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/4155986-c45170b8aee83e5b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/576/format/webp" alt="img"></p>
<p>（6）插入关键字5、17、9、16之后的B-树如图所示：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/4155986-266565ba8cd1375e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/684/format/webp" alt="img"></p>
<p>（7）关键字20插入在关键字17以后，此时会造成结点关键字个数超出范围，需要拆分，方法同上，树为：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/4155986-c8faeffe859d0041.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/686/format/webp" alt="img"></p>
<p>（8）按照上述步骤依次插入关键字3、12、14、18、19之后B-树如下图所示：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/4155986-2bc2ccf09ced3392.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/772/format/webp" alt="img"></p>
<p>（9）插入最后一个关键字15，15应该插入在14之后，此时会出现关键字个数超出范围的情况，则需要进行拆分，将13并入根结点，13并入根结点之后，又使得根结点的关键字个数超出范围，需要再次进行拆分，将10作为新的根结点，并将10左、右关键字做成两个新结点连接到新根结点的指针上，这种插入一个关键字之后出现多次拆分的情况称为<strong>连锁反应</strong>，最终形成的B-树如下图所示：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/4155986-185792894a3ea498.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/780/format/webp" alt="img"></p>
<h2 id="4、B-树的删除"><a href="#4、B-树的删除" class="headerlink" title="4、B-树的删除"></a>4、B-树的删除</h2><p>对于B-树关键字的删除，需要找到待删除的关键字，在结点中删除关键字的过程也有可能破坏B-树的特性，如旧关键字的删除可能使得结点中关键字的个数少于规定个数，这是可能需要向其兄弟结点<strong>借关键字</strong>或者和其孩子结点进行<strong>关键字的交换</strong>，也可能需要进行<strong>结点的合并</strong>，其中，和当前结点的孩子进行关键字交换的操作可以保证删除操作总是发生在终端结点上。</p>
<p>我们用刚刚生成的B-树作为例子，一次删除8、16、15、4这4个关键字。<br> （1）删除关键字8、16。关键字8在终端结点上，并且删除后其所在结点中关键字的个数不会少于2，因此可以直接删除。关键字16不在终端结点上，但是可以用17来覆盖16，然后将原来的17删除掉，这就是上面提到的和孩子结点进行关键字交换的操作。这里不能用15和16进行关键字交换，因为这样会导致15所在结点中关键字的个数小于2。因此，删除8和16之后B-树如下图所示：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/4155986-5c685c7a0629f5ef.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/810/format/webp" alt="img"></p>
<p>（2）删除关键字15，15虽然也在终端结点上，但是不能直接删除，因为删除后当前结点中关键字的个数小于2。这是需要向其兄弟结点借关键字，显然应该向其右兄弟来借关键字，因为左兄弟的关键字个数已经是下限2.借关键字不能直接将18移到15所在的结点上，因为这样会使得15所在的结点上出现比17大的关键字，所以正确的借法应该是先用17覆盖15，在用18覆盖原来的17，最后删除原来的18，删除关键字15后的B-树如下图所示：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/4155986-f2f4dd5acbe187ef.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/736/format/webp" alt="img"></p>
<p>（3）删除关键字4，4在终端结点上，但是此时4所在的结点的关键字个数已经到下限，需要借关键字，不过可以看到其左右兄弟结点已经没有多余的关键字可借。所以就需要进行关键字的合并。可以先将关键字4删除，然后将关键字5、6、7、9进行合并作为一个结点链接在关键字3右边的指针上，也可以将关键字1、2、3、5合并作为一个结点链接在关键字6左边的指针上，如下图所示：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/4155986-becfee0be9af3db8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/822/format/webp" alt="img"></p>
<p>显然上述两种情况下都不满足B-树的规定，即出现了非根的双分支结点，需要继续进行合并，合并后的B-树如下图所示：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/4155986-cf214149db0edf56.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/804/format/webp" alt="img"></p>
<p>有时候删除的结点不在终端结点上，我们首先需要将其转化到终端结点上，然后再按上面的各种情况进行删除。在讲述这种情况下的删除方法之前，要引入一个相邻关键字的概念，对于不在终端结点的关键字a，它的相邻关键字为其左子树中值最大的关键字或者其右子树中值最小的关键字。找a的相邻关键字的方法为：沿着a的左指针来到其子树根结点，然后沿着根结点中最右端的关键字的右指针往下走，用同样的方法一直走到叶结点上，叶结点上的最右端的关键字即为a的相邻关键字（这里找的是a左边的相邻关键字，我们可以用同样的思路找到a右边的相邻关键字）。可以看到下图中a的相邻关键字是d和e，要删除关键字a，可以用d来取代a，然后按照上面的情况删除叶子结点上的d即可。</p>
<h2 id="6、B-树的应用"><a href="#6、B-树的应用" class="headerlink" title="6、B-树的应用"></a>6、B-树的应用</h2><p>为了将大型数据库文件存储在硬盘上，以减少访问硬盘次数为目的，在此提出了一种平衡多路查找树——B-树结构。由其性能分析可知它的检索效率是相当高的 为了提高 B-树性能’还有很多种B-树的变型，力图对B-树进行改进，比如B+树。</p>
<h1 id="B树学习笔记之B树的删除"><a href="#B树学习笔记之B树的删除" class="headerlink" title="B树学习笔记之B树的删除"></a>B树学习笔记之B树的删除</h1><p><strong>B树的下溢发生于删除关键码后违反了B树的性质 。</strong></p>
<p>**<img src="/posts/610f283b/asset/20180427164813396.png" alt="img"><br>**</p>
<p><strong>一. 旋转</strong></p>
<ul>
<li><p><em><strong>*如果左右兄弟存在，则间接向左右兄弟借关键码*</strong></em></p>
<p><strong><img src="/posts/610f283b/asset/20180427171504639.png" alt="img"></strong></p>
</li>
</ul>
<p><strong>二. 合并</strong></p>
<p>**<img src="/posts/610f283b/asset/20180427172327947.png" alt="img"><br>**</p>
<p><strong>B树高度的减少只会发生于根节点的两个孩子合并 。</strong></p>
<p><strong>三. 实例</strong></p>
<p>**<img src="/posts/610f283b/asset/20180427172451550.png" alt="img"><br>**</p>
<p><strong>1. 删除249</strong></p>
<p>**<img src="/posts/610f283b/asset/2018042717283464.png" alt="img"><br>**</p>
<p><strong>不急于合并，先左顾右盼，向有兄弟接一个关键码。</strong></p>
<p>**<img src="/posts/610f283b/asset/20180427173012960.png" alt="img"><br>**</p>
<p><strong>删除操作顺利结束。</strong></p>
<p><em>*<em>*</em>*2. 删除****619****</em>*</p>
<p><em>*<em>*</em>*<img src="/posts/610f283b/asset/20180427173256549.png" alt="img"><br>****</em>*</p>
<p><em><strong>*664没有左兄弟，右兄弟处于即将下溢的边缘临界状态，旋转技巧已不适用，选择合并。*</strong></em></p>
<p><em>*<em>*</em>*<img src="/posts/610f283b/asset/20180427173529240.png" alt="img"><br>****</em>*</p>
<p><em><strong>*此时，父节点发生了下溢，继续合并。*</strong></em></p>
<p><em><strong>*<img src="/posts/610f283b/asset/20180427173725953.png" alt="img"><br>*</strong></em></p>
<p><strong>整棵B树的高度降低了一层，这时B树高度得以下降的唯一可能。</strong></p>
<p>四. 总结</p>
<p>B树被设计成相对矮宽，而对B树的访问是由一系列的外存操作和内存操作交替组成的。有多少外存操作，就有多少内存操作。但要使外存操作的代价与内存操作的代价大致相当。B树能做到，而AVL与BBST却做不到。</p>
<p>水平方向：对应与每个节点的内部搜索，在内存（RAM）中进行。<br>垂直方向：对应于磁盘（Disk）操作。树中每下降一层，就要付出一次IO操作的代价。</p>
<p> <img src="/posts/610f283b/asset/20180427174846284.png" alt="img"> </p>
<hr>
<p><a href="https://www.jianshu.com/p/7dedb7ebe033">https://www.jianshu.com/p/7dedb7ebe033</a></p>
<p><a href="https://blog.csdn.net/wydyd110/article/details/80097201">https://blog.csdn.net/wydyd110/article/details/80097201</a></p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>其他</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>其他</tag>
      </tags>
  </entry>
  <entry>
    <title>Skip List--跳表</title>
    <url>/posts/23aa0016/</url>
    <content><![CDATA[<h1 id="Skip-List–跳表"><a href="#Skip-List–跳表" class="headerlink" title="Skip List–跳表"></a>Skip List–跳表</h1><p><a href="https://www.jianshu.com/p/9d8296562806">https://www.jianshu.com/p/9d8296562806</a></p>
<p>跳表是一种神奇的数据结构，因为几乎所有版本的大学本科教材上都没有跳表这种数据结构，而且神书《算法导论》、《算法第四版》这两本书中也没有介绍跳表。但是跳表插入、删除、查找元素的时间复杂度跟红黑树都是一样量级的，时间复杂度都是O(logn)，而且跳表有一个特性是红黑树无法匹敌的（具体什么特性后面会提到）。所以在工业中，跳表也会经常被用到。废话不多说了，开始今天的跳表学习。</p>
<p>通过本文，你能 get 到以下知识：</p>
<ul>
<li>什么是跳表？</li>
<li>跳表的查找、插入、删除元素的流程</li>
<li>跳表查找、插入、删除元素的时间复杂度</li>
<li>跳表插入元素时，如何动态维护索引？</li>
<li>为什么Redis选择使用跳表而不是红黑树来实现有序集合？</li>
<li>工业上其他使用跳表的场景</li>
</ul>
<blockquote>
<p>友情提示：下文在跳表插入数据时，会讲述如何动态维护索引，实现比较简单，逻辑比较绕，不要放弃，加油！！！如果一遍看不懂没关系，可以选择暂时性的跳过，毕竟这块偏向于源码。但是读者必须知道跳表的查找、插入、删除的时间复杂度都是 O(logn)，而且可以按照范围区间查找元素，当工作中遇到某些场景时，需要想到可以使用跳表解决问题即可。毕竟平时的工作都是直接使用封装好的跳表，例如：java.util.concurrent 下的 ConcurrentSkipListMap()。</p>
</blockquote>
<h3 id="理解跳表，从单链表开始说起"><a href="#理解跳表，从单链表开始说起" class="headerlink" title="理解跳表，从单链表开始说起"></a>理解跳表，从单链表开始说起</h3><p>下图是一个简单的<strong>有序单链表</strong>，单链表的特性就是每个元素存放下一个元素的引用。即：通过第一个元素可以找到第二个元素，通过第二个元素可以找到第三个元素，依次类推，直到找到最后一个元素。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/19063731-70b00aafa9f5b793.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1142/format/webp" alt="img"></p>
<p>跳表-原始链表.jpeg</p>
<p>现在我们有个场景，想快速找到上图链表中的 10 这个元素，只能从头开始遍历链表，直到找到我们需要找的元素。查找路径：1、3、4、5、7、8、9、10。这样的查找效率很低，平均时间复杂度很高O(n)。那有没有办法提高链表的查找速度呢？如下图所示，我们从链表中每两个元素抽出来，加一级索引，一级索引指向了原始链表，即：通过一级索引 7 的down指针可以找到原始链表的 7 。那现在怎么查找 10 这个元素呢？</p>
<p><img src="https://upload-images.jianshu.io/upload_images/19063731-4f4535e6d0959c32.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1142/format/webp" alt="img"></p>
<p>跳表-一级索引.jpeg</p>
<p>先在索引找 1、4、7、9，遍历到一级索引的 9 时，发现 9 的后继节点是 13，比 10 大，于是不往后找了，而是通过 9 找到原始链表的 9，然后再往后遍历找到了我们要找的 10，遍历结束。有没有发现，加了一级索引后，查找路径：1、4、7、9、10，查找节点需要遍历的元素相对少了，我们不需要对 10 之前的所有数据都遍历，查找的效率提升了。</p>
<p>那如果加二级索引呢？如下图所示，查找路径：1、7、9、10。是不是找 10 的效率更高了？这就是跳表的思想，用“空间换时间”，通过给链表建立索引，提高了查找的效率。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/19063731-3852cc36af701f46.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1142/format/webp" alt="img"></p>
<p>跳表-二级索引.jpeg</p>
<p>可能同学们会想，从上面案例来看，提升的效率并不明显，本来需要遍历8个元素，优化了半天，还需要遍历 4 个元素，其实是因为我们的数据量太少了，当数据量足够大时，效率提升会很大。如下图所示，假如有序单链表现在有1万个元素，分别是 0~9999。现在我们建了很多级索引，最高级的索引，就两个元素 0、5000，次高级索引四个元素 0、2500、5000、7500，依次类推，当我们查找 7890 这个元素时，查找路径为 0、5000、7500 … 7890，通过最高级索引直接跳过了5000个元素，次高层索引直接跳过了2500个元素，<strong>从而使得链表能够实现二分查找</strong>。由此可以看出，当元素数量较多时，索引提高的效率比较大，近似于二分查找。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/19063731-d7bc5026051ea412.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1200/format/webp" alt="img"></p>
<p>数据量增多后，索引效果图.png</p>
<p>到这里大家应该已经明白了什么是跳表。跳表是<strong>可以实现二分查找的有序链表</strong>。</p>
<h3 id="查找的时间复杂度"><a href="#查找的时间复杂度" class="headerlink" title="查找的时间复杂度"></a>查找的时间复杂度</h3><p>既然跳表可以提升链表查找元素的效率，那查找一个元素的时间复杂度到底是多少呢？查找元素的过程是从最高级索引开始，一层一层遍历最后下沉到原始链表。所以，时间复杂度 &#x3D; 索引的高度 * 每层索引遍历元素的个数。</p>
<p>先来求跳表的索引高度。如下图所示，假设每两个结点会抽出一个结点作为上一级索引的结点，原始的链表有n个元素，则一级索引有n&#x2F;2 个元素、二级索引有 n&#x2F;4 个元素、k级索引就有 n&#x2F;2k个元素。最高级索引一般有2个元素，即：最高级索引 h 满足 2 &#x3D; n&#x2F;2h，即 h &#x3D; log2n - 1，最高级索引 h 为索引层的高度加上原始数据一层，跳表的总高度 h &#x3D; log2n。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/19063731-5ec10e6ae2c32587.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1142/format/webp" alt="img"></p>
<p>查找的时间复杂度证明.jpeg</p>
<p>我们看上图中加粗的箭头，表示查找元素 x 的路径，那查找过程中每一层索引最多遍历几个元素呢？</p>
<p>图中所示，现在到达第 k 级索引，我们发现要查找的元素 x 比 y 大比 z 小，所以，我们需要从 y 处下降到 k-1 级索引继续查找，k-1级索引中比 y 大比 z 小的只有一个 w，所以在 k-1 级索引中，我们遍历的元素最多就是 y、w、z，发现 x 比 w大比 z 小之后，再下降到 k-2 级索引。所以，k-2 级索引最多遍历的元素为 w、u、z。其实每级索引都是类似的道理，每级索引中都是两个结点抽出一个结点作为上一级索引的结点。 现在我们得出结论：当每级索引都是两个结点抽出一个结点作为上一级索引的结点时，每一层最多遍历3个结点。</p>
<p>跳表的索引高度 h &#x3D; log2n，且每层索引最多遍历 3 个元素。所以跳表中查找一个元素的时间复杂度为 O(3*logn)，省略常数即：O(logn)。</p>
<h3 id="空间复杂度"><a href="#空间复杂度" class="headerlink" title="空间复杂度"></a>空间复杂度</h3><p>跳表通过建立索引，来提高查找元素的效率，就是典型的“空间换时间”的思想，所以在空间上做了一些牺牲，那空间复杂度到底是多少呢？</p>
<p>假如原始链表包含 n 个元素，则一级索引元素个数为 n&#x2F;2、二级索引元素个数为 n&#x2F;4、三级索引元素个数为 n&#x2F;8 以此类推。所以，索引节点的总和是：n&#x2F;2 + n&#x2F;4 + n&#x2F;8 + … + 8 + 4 + 2 &#x3D; n-2，**空间复杂度是 O(n)**。</p>
<p>如下图所示：如果每三个结点抽一个结点做为索引，索引总和数就是 n&#x2F;3 + n&#x2F;9 + n&#x2F;27 + … + 9 + 3 + 1&#x3D; n&#x2F;2，减少了一半。所以我们可以通过较少索引数来减少空间复杂度，但是相应的肯定会造成查找效率有一定下降，我们可以根据我们的应用场景来控制这个阈值，看我们更注重时间还是空间。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/19063731-8899cf09c97fd229.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1142/format/webp" alt="img"></p>
<p>三个节点提取一个做索引.jpeg</p>
<p>But，索引结点往往只需要存储 key 和几个指针，并不需要存储完整的对象，所以当对象比索引结点大很多时，索引占用的额外空间就可以忽略了。举个例子：我们现在需要用跳表来给所有学生建索引，学生有很多属性：学号、姓名、性别、身份证号、年龄、家庭住址、身高、体重等。学生的各种属性只需要在原始链表中存储一份即可，我们只需要用学生的学号（int 类型的数据）建立索引，所以索引相对原始数据而言，占用的空间可以忽略。</p>
<h3 id="插入数据"><a href="#插入数据" class="headerlink" title="插入数据"></a>插入数据</h3><p>插入数据看起来也很简单，跳表的原始链表需要保持有序，所以我们会向查找元素一样，找到元素应该插入的位置。如下图所示，要插入数据6，整个过程类似于查找6，整个的查找路径为 1、1、1、4、4、5。查找到第底层原始链表的元素 5 时，发现 5 小于 6 但是后继节点 7 大于 6，所以应该把 6 插入到 5 之后 7 之前。整个时间复杂度为查找元素的时间复杂度 O(logn)。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/19063731-684743ff91121d5f.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1142/format/webp" alt="img"></p>
<p>插入数据图示.jpeg</p>
<p>如下图所示，假如一直往原始列表中添加数据，但是不更新索引，就可能出现两个索引节点之间数据非常多的情况，极端情况，跳表退化为单链表，从而使得查找效率从 O(logn) 退化为 O(n)。那这种问题该怎么解决呢？我们需要在插入数据的时候，索引节点也需要相应的增加、或者重建索引，来避免查找效率的退化。那我们该如何去维护这个索引呢？</p>
<p><img src="https://upload-images.jianshu.io/upload_images/19063731-83c166a281525a19.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1142/format/webp" alt="img"></p>
<p>插入数据，不更新索引图示.jpeg</p>
<p>比较容易理解的做法就是完全重建索引，我们每次插入数据后，都把这个跳表的索引删掉全部重建，重建索引的时间复杂度是多少呢？因为索引的空间复杂度是 O(n)，即：索引节点的个数是 O(n) 级别，每次完全重新建一个 O(n) 级别的索引，时间复杂度也是 O(n) 。造成的后果是：为了维护索引，导致每次插入数据的时间复杂度变成了 O(n)。</p>
<p>那有没有其他效率比较高的方式来维护索引呢？假如跳表每一层的晋升概率是 1&#x2F;2，最理想的索引就是在原始链表中每隔一个元素抽取一个元素做为一级索引。换种说法，<strong>我们在原始链表中随机的选 n&#x2F;2 个元素做为一级索引是不是也能通过索引提高查找的效率呢？</strong> 当然可以了，因为一般随机选的元素相对来说都是比较均匀的。如下图所示，随机选择了n&#x2F;2 个元素做为一级索引，虽然不是每隔一个元素抽取一个，但是对于查找效率来讲，影响不大，比如我们想找元素 16，仍然可以通过一级索引，使得遍历路径较少了将近一半。如果抽取的一级索引的元素恰好是前一半的元素 1、3、4、5、7、8，那么查找效率确实没有提升，但是这样的概率太小了。我们可以认为：当原始链表中<strong>元素数量足够大</strong>，且<strong>抽取足够随机</strong>的话，我们得到的索引是均匀的。我们要清楚设计良好的数据结构都是为了应对大数据量的场景，如果原始链表只有 5 个元素，那么依次遍历 5 个元素也没有关系，因为数据量太少了。所以，我们可以维护一个这样的索引：<strong>随机选 n&#x2F;2 个元素做为一级索引、随机选 n&#x2F;4 个元素做为二级索引、随机选 n&#x2F;8 个元素做为三级索引，依次类推，一直到最顶层索引</strong>。这里每层索引的元素个数已经确定，且每层索引元素选取的足够随机，所以可以通过索引来提升跳表的查找效率。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/19063731-af95a14df3637963.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1142/format/webp" alt="img"></p>
<p>跳表-一级索引随机分布.jpg</p>
<p>那代码该如何实现，才能使跳表满足上述这个样子呢？可以在每次新插入元素的时候，尽量让该元素有 1&#x2F;2 的几率建立一级索引、1&#x2F;4 的几率建立二级索引、1&#x2F;8 的几率建立三级索引，以此类推，就能满足我们上面的条件。现在我们就需要一个概率算法帮我们把控这个 1&#x2F;2、1&#x2F;4、1&#x2F;8 … ，<strong>当每次有数据要插入时，先通过概率算法告诉我们这个元素需要插入到几级索引中</strong>，然后开始维护索引并把数据插入到原始链表中。下面开始讲解这个概率算法代码如何实现。</p>
<p>我们可以实现一个 randomLevel() 方法，该方法会随机生成 1~MAX_LEVEL 之间的数（MAX_LEVEL表示索引的最高层数），且该方法<strong>有 1&#x2F;2 的概率返回 1、1&#x2F;4 的概率返回 2、1&#x2F;8的概率返回 3，以此类推</strong>。</p>
<ul>
<li>randomLevel() 方法返回 1 表示当前插入的该元素不需要建索引，只需要存储数据到原始链表即可（概率 1&#x2F;2）</li>
<li>randomLevel() 方法返回 2 表示当前插入的该元素需要建一级索引（概率 1&#x2F;4）</li>
<li>randomLevel() 方法返回 3 表示当前插入的该元素需要建二级索引（概率 1&#x2F;8）</li>
<li>randomLevel() 方法返回 4 表示当前插入的该元素需要建三级索引（概率 1&#x2F;16）</li>
<li>。。。以此类推</li>
</ul>
<p>所以，通过 randomLevel() 方法，我们可以控制整个跳表各级索引中元素的个数。<strong>重点来了</strong>：randomLevel() 方法返回 2 的时候会建立一级索引，我们想要一级索引中元素个数占原始数据的 1&#x2F;2，但是 randomLevel() 方法返回 2 的概率为 1&#x2F;4，那是不是有矛盾呢？明明说好的 1&#x2F;2，结果一级索引元素个数怎么变成了原始链表的 1&#x2F;4？我们先看下图，应该就明白了。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/19063731-684743ff91121d5f.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1142/format/webp" alt="img"></p>
<p>插入数据图示.jpeg</p>
<p>假设我们在插入元素 6 的时候，randomLevel() 方法返回 1，则我们不会为 6 建立索引。插入 7 的时候，randomLevel() 方法返回3 ，所以我们需要为元素 7 建立二级索引。这里我们发现了一个特点：当建立二级索引的时候，同时也会建立一级索引；当建立三级索引时，同时也会建立一级、二级索引。所以，一级索引中元素的个数等于 <em>[ 原始链表元素个数 ]</em> * *[ randomLevel() 方法返回值 &gt; 1 的概率 ]*。因为 randomLevel() 方法返回值 &gt; 1就会建索引，凡是建索引，无论几级索引必然有一级索引，<strong>所以一级索引中元素个数占原始数据个数的比率为 randomLevel() 方法返回值 &gt; 1 的概率</strong>。那 randomLevel() 方法返回值 &gt; 1 的概率是多少呢？因为 randomLevel() 方法随机生成 1~MAX_LEVEL 的数字，且 randomLevel() 方法返回值 1 的概率为 1&#x2F;2，则 randomLevel() 方法返回值 &gt; 1 的概率为 1 - 1&#x2F;2 &#x3D; 1&#x2F;2。即<strong>通过上述流程实现了一级索引中元素个数占原始数据个数的 1&#x2F;2</strong>。</p>
<p>同理，当 randomLevel() 方法返回值 &gt; 2 时，会建立二级或二级以上索引，都会在二级索引中增加元素，因此<strong>二级索引中元素个数占原始数据的比率为 randomLevel() 方法返回值 &gt; 2 的概率</strong>。 randomLevel() 方法返回值 &gt; 2 的概率为 1 减去 randomLevel() &#x3D; 1 或 &#x3D;2 的概率，即 1 - 1&#x2F;2 - 1&#x2F;4 &#x3D; 1&#x2F;4。OK，达到了我们设计的目标：<strong>二级索引中元素个数占原始数据的 1&#x2F;4</strong>。</p>
<p>以此类推，可以得出，遵守以下两个条件：</p>
<ul>
<li>randomLevel() 方法，随机生成 1~MAX_LEVEL 之间的数（MAX_LEVEL表示索引的最高层数），且<strong>有 1&#x2F;2的概率返回 1、1&#x2F;4的概率返回 2、1&#x2F;8的概率返回 3 …</strong> </li>
<li>randomLevel() 方法返回 1 不建索引、返回2建一级索引、返回 3 建二级索引、返回 4 建三级索引 …</li>
</ul>
<p>就可以满足我们想要的结果，即：一级索引中元素个数应该占原始数据的 1&#x2F;2，二级索引中元素个数占原始数据的 1&#x2F;4，三级索引中元素个数占原始数据的 1&#x2F;8 ，依次类推，一直到最顶层索引。</p>
<p>但是问题又来了，怎么设计这么一个 randomLevel() 方法呢？直接撸代码：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 该 randomLevel 方法会随机生成 1~MAX_LEVEL 之间的数，且 ：</span></span><br><span class="line"><span class="comment">//        1/2 的概率返回 1</span></span><br><span class="line"><span class="comment">//        1/4 的概率返回 2</span></span><br><span class="line"><span class="comment">//        1/8 的概率返回 3 以此类推</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="type">int</span> <span class="title">randomLevel</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> level = <span class="number">1</span>;</span><br><span class="line">  <span class="comment">// 当 level &lt; MAX_LEVEL，且随机数小于设定的晋升概率时，level + 1</span></span><br><span class="line">  <span class="keyword">while</span> (Math.<span class="built_in">random</span>() &lt; SKIPLIST_P &amp;&amp; level &lt; MAX_LEVEL)</span><br><span class="line">    level += <span class="number">1</span>;</span><br><span class="line">  <span class="keyword">return</span> level;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>上述代码可以实现我们的功能，而且，我们的案例中晋升概率 SKIPLIST_P 设置的 1&#x2F;2，即：每两个结点抽出一个结点作为上一级索引的结点。如果我们想节省空间利用率，可以适当的降低代码中的 SKIPLIST_P，从而减少索引元素个数，Redis 的 zset 中 SKIPLIST_P 设定的 0.25。下图所示，是Redis <a href="https://links.jianshu.com/go?to=https://github.com/antirez/redis/blob/unstable/src/t_zset.c">t_zset.c</a> 中 zslRandomLevel 函数的实现：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/19063731-174e6712e183eff7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1114/format/webp" alt="img"></p>
<p>Redis zslRandomLevel实现原理.png</p>
<p>Redis 源码中 <code>(random()&amp;0xFFFF) &lt; (ZSKIPLIST_P * 0xFFFF)</code>  在功能上等价于我代码中的 <code>Math.random() &lt; SKIPLIST_P</code> ，只不过 Redis 作者 <a href="https://links.jianshu.com/go?to=https://github.com/antirez">antirez</a> 使用位运算来提高浮点数比较的效率。</p>
<p>整体思路大家应该明白了，那插入数据时维护索引的时间复杂度是多少呢？**元素插入到单链表的时间复杂度为 O(1)**，我们索引的高度最多为 logn，当插入一个元素 x 时，最坏的情况就是元素 x 需要插入到每层索引中，所以插入数据到各层索引中，最坏时间复杂度是 O(logn)。</p>
<p>过程大概理解了，再通过一个例子描述一下跳表插入数据的全流程。现在我们要插入数据 6 到跳表中，首先 randomLevel() 返回 3，表示<strong>需要建二级索引</strong>，即：一级索引和二级索引需要增加元素 6。该跳表目前最高三级索引，首先找到三级索引的 1，发现 6 比 1大比 13小，所以，从 1 下沉到二级索引。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/19063731-d4fce992be91d0b3.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1142/format/webp" alt="img"></p>
<p>插入数据且维护跳表图示1.jpeg</p>
<p>下沉到二级索引后，发现 6 比 1 大比 7 小，此时需要在二级索引中 1 和 7 之间加一个元素6 ，并从元素 1 继续下沉到一级索引。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/19063731-4ef315fec46639ef.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1142/format/webp" alt="img"></p>
<p>插入数据且维护跳表图示2.jpeg</p>
<p>下沉到一级索引后，发现 6 比 1 大比 4 大，所以往后查找，发现 6 比 4 大比 7 小，此时需要在一级索引中 4 和 7 之间加一个元素 6 ，并把二级索引的 6 指向 一级索引的 6，最后，从元素 4 继续下沉到原始链表。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/19063731-dd671e793f1e3ffe.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1142/format/webp" alt="img"></p>
<p>插入数据且维护跳表图示3.jpeg</p>
<p>下沉到原始链表后，就比较简单了，发现 4、5 比 6小，7比6大，所以将6插入到 5 和 7 之间即可，整个插入过程结束。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/19063731-1a7f35e43819c9c4.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1142/format/webp" alt="img"></p>
<p>插入数据且维护跳表图示4.jpeg</p>
<p>整个插入过程的路径与查找元素路径类似， 每层索引中插入元素的时间复杂度 O(1)，所以整个插入的时间复杂度是 O(logn)。</p>
<h3 id="删除数据"><a href="#删除数据" class="headerlink" title="删除数据"></a>删除数据</h3><p>跳表删除数据时，要把索引中对应节点也要删掉。如下图所示，如果要删除元素 9，需要把原始链表中的 9 和第一级索引的 9 都删除掉。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/19063731-e95c396e6e62bc87.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1142/format/webp" alt="img"></p>
<p>删除数据.jpeg</p>
<p>跳表中，删除元素的时间复杂度是多少呢？</p>
<p>删除元素的过程跟查找元素的过程类似，只不过在查找的路径上如果发现了要删除的元素 x，则执行删除操作。跳表中，每一层索引其实都是一个有序的单链表，单链表删除元素的时间复杂度为 O(1)，索引层数为 logn 表示最多需要删除 logn 个元素，所以删除元素的总时间包含 <em>查找元素的时间</em> 加 <em>删除 logn个元素的时间</em> 为 O(logn) + O(logn) &#x3D; 2 O(logn)，忽略常数部分，删除元素的时间复杂度为 O(logn)。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ol>
<li>跳表是可以实现二分查找的有序链表；</li>
<li>每个元素插入时随机生成它的level；</li>
<li>最底层包含所有的元素；</li>
<li>如果一个元素出现在level(x)，那么它肯定出现在x以下的level中；</li>
<li>每个索引节点包含两个指针，一个向下，一个向右；（笔记目前看过的各种跳表源码实现包括Redis 的zset 都没有向下的指针，那怎么从二级索引跳到一级索引呢？留个悬念，看源码吧，文末有跳表实现源码）</li>
<li>跳表查询、插入、删除的时间复杂度为O(log n)，与平衡二叉树接近；</li>
</ol>
<h3 id="为什么Redis选择使用跳表而不是红黑树来实现有序集合？"><a href="#为什么Redis选择使用跳表而不是红黑树来实现有序集合？" class="headerlink" title="为什么Redis选择使用跳表而不是红黑树来实现有序集合？"></a>为什么Redis选择使用跳表而不是红黑树来实现有序集合？</h3><p>Redis 中的有序集合(zset) 支持的操作：</p>
<ol>
<li>插入一个元素</li>
<li>删除一个元素</li>
<li>查找一个元素</li>
<li>有序输出所有元素</li>
<li>按照范围区间查找元素（比如查找值在 [100, 356] 之间的数据）</li>
</ol>
<p>其中，前四个操作红黑树也可以完成，且时间复杂度跟跳表是一样的。但是，按照区间来查找数据这个操作，红黑树的效率没有跳表高。按照区间查找数据时，跳表可以做到 O(logn) 的时间复杂度定位区间的起点，然后在原始链表中顺序往后遍历就可以了，非常高效。</p>
<h3 id="工业上其他使用跳表的场景"><a href="#工业上其他使用跳表的场景" class="headerlink" title="工业上其他使用跳表的场景"></a>工业上其他使用跳表的场景</h3><p>在博客上从来没有见过有同学讲述 HBase MemStore 的数据结构，其实 HBase MemStore 内部存储数据就使用的跳表。为什么呢？HBase 属于 LSM Tree 结构的数据库，LSM Tree 结构的数据库有个特点，实时写入的数据先写入到内存，内存达到阈值往磁盘 flush 的时候，会生成类似于 StoreFile 的<strong>有序文件</strong>，而跳表恰好就是天然有序的，所以在 flush 的时候效率很高，而且跳表查找、插入、删除性能都很高，这应该是 HBase MemStore 内部存储数据使用跳表的原因之一。HBase 使用的是 java.util.concurrent 下的 ConcurrentSkipListMap()。</p>
<p>Google 开源的 key&#x2F;value 存储引擎 LevelDB 以及 Facebook 基于 LevelDB 优化的 RocksDB 都是 LSM Tree 结构的数据库，他们内部的 MemTable 都是使用了跳表这种数据结构。</p>
<p>后期笔者还会输出一篇深入剖析 LSM Tree 的博客，到时候再结合场景分析为什么使用跳表。</p>
<p>参考：</p>
<p><a href="https://links.jianshu.com/go?to=https://github.com/antirez/redis/blob/unstable/src/t_zset.c">Redis zset源码</a></p>
<p><a href="https://links.jianshu.com/go?to=https://time.geekbang.org/column/article/42896">极客时间-数据结构与算法之美课程</a></p>
<ul>
<li>王争老师的整套课程都很棒，对数据结构与算法想整体提高的同学可以订阅</li>
</ul>
<p><a href="https://links.jianshu.com/go?to=https://github.com/wangzheng0822/algo/blob/master/java/17_skiplist/SkipList.java">王争老师SkipList 实现</a></p>
<ul>
<li>这个跳表实现相对简单，建议初学者参考，整个项目是王争老师极客时间课程配套的代码，其他数据结构实现也可以参考</li>
<li>笔记在写本博客期间，向该项目提交了 pr，已被merge，模仿 redis 源码重新实现了 randomLevel() 方法，不过为了容易理解没有使用redis的位运算，之前的 randomLevel() 方法会导致索引冗余特别严重，5 级以下的索引中元素个数接近于所有元素的个数，有兴趣的同学可以继续深入研究</li>
</ul>
<p><a href="https://links.jianshu.com/go?to=https://juejin.im/book/5afc2e5f6fb9a07a9b362527/section/5b5ac63d5188256255299d9c">源码 5：凌波微步 —— 探索「跳跃列表」内部结构</a></p>
<ul>
<li>老钱的《Redis 深度历险》系列非常推荐</li>
</ul>
<p><a href="https://www.jianshu.com/p/dd01e8dc4d1f">拜托，面试别再问我跳表了！</a></p>
<ul>
<li>彤哥读源码系列，把 Java java.util.concurrent 包下的大多数集合类从源码层次深入分析了一遍，非常推荐</li>
</ul>
]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>其他</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>其他</tag>
      </tags>
  </entry>
  <entry>
    <title>位图原理及实现</title>
    <url>/posts/3a760810/</url>
    <content><![CDATA[<h1 id="位图原理及实现"><a href="#位图原理及实现" class="headerlink" title="位图原理及实现"></a>位图原理及实现</h1><p>位图<br>今天我们所介绍的数据结构叫做位图，在谈什么是位图之前我们先来看一道”非常简单的题”：有40亿个无符号的整型数据，现在给定一个目标数字，判断这个数字是否在这40亿数据中。题目看起来确实非常简单，有的同学说直接遍历一遍不就ok了吗？还有的同学给出了更高效的查找方式就是将这些数字排序然后进行二分查找。但是，这是有问题的，问题并不在于你搜索这个数字的效率问题，而是你在遍历也好排序也罢，这些数字在内存中放的下么？</p>
<p>一个整型int就是4个字节，10亿个int差不多已经需要4G的内存了，40亿个int就是16G。所以这里方法行不通的根本原因实际上是内存不够，但是我们今天的讲的位图却能很好的帮助我们处理这个问题。</p>
<p>位图模型<br>既然根本原因是这些数据用int放不下，那么是否有更小的东西标记这些数字呢？没错，有的同学想到了，char只占一个字节或许能表示一个数字，但是随着数字位数的增多，依旧不可能使用一个字符表示一个数字，这就意味着小于4G内存还是不能解决这个问题。<br>其实说到这里，我们的问题就转化为如何使用更小的内存单元来标记一个数字，而在程序中我们最小的访问单位的bit位，所以现在我们一起来看使用比特位如何标记(映射)这些数据。</p>
<p> <img src="/posts/3a760810/asset/20190513132653274.png" alt="在这里插入图片描述"> </p>
<p>现在我们发现，4个字节本来只能存储一个int，而现在使用位图我们就存了(映射)32个数字，意味着16G&#x2F;32约等于500m左右我们就能映射这些数据，那么这些数据是怎么映射到位图种的呢？接着看。</p>
<p>设计位图<br>为了方便，我们将位图用一个数组表示，让vector帮我们开辟一段连续的空间，我们只负责将数据设置或者移除就行。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">BitMap</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">	<span class="built_in">BitMap</span>(<span class="type">size_t</span> range)</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="comment">//右移5位相当于除以32，加1是因为小于32的数字如果与32相除则得到0</span></span><br><span class="line">		_bitTable.<span class="built_in">resize</span>((range &gt;&gt; <span class="number">5</span>) + <span class="number">1</span>);</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">	vector&lt;<span class="type">int</span>&gt; _bitTable;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>位图元素的设置</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">SetBit</span><span class="params">(<span class="type">size_t</span> x)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="type">size_t</span> index = x &gt;&gt; <span class="number">5</span>;</span><br><span class="line">	<span class="type">size_t</span> num = x % <span class="number">32</span>;</span><br><span class="line"></span><br><span class="line">	_bitTable[index] |= (<span class="number">1</span> &lt;&lt; num);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>来看看为什么需要size_t index &#x3D; x &gt;&gt; 5和size_t num &#x3D; x % 32两步操作：我们看看要映射5和32这俩个数</p>
<p> <img src="/posts/3a760810/asset/20190513134732215.png" alt="在这里插入图片描述"> </p>
<p>5表示防在第1个整型空间的第5位上，32则表示放在第2个整型空间第一位上。而**bitTable[index] |&#x3D; (1 &lt;&lt; num)**能保证把第num位上的数字设置为1，其余数字保持不变。</p>
<p>位图元素的移除</p>
<p>比较简单，需要知道的是**~(1 &lt;&lt; num)**表示出了num位为0，其余位都为1.</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">RemoveBit</span><span class="params">(<span class="type">size_t</span> x)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="type">size_t</span> index = x &gt;&gt; <span class="number">5</span>;</span><br><span class="line">	<span class="type">size_t</span> num = x % <span class="number">32</span>;</span><br><span class="line"></span><br><span class="line">	_bitTable[index] &amp;= ~(<span class="number">1</span> &lt;&lt; num);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>位图元素的查找</p>
<p>这个没啥好说的，很简单，说到这里，你的位图也就实现完了，非常简单把</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">bool</span> <span class="title">TestBit</span><span class="params">(<span class="type">size_t</span> x)</span></span></span><br><span class="line"><span class="function">	</span>&#123;</span><br><span class="line">		<span class="type">size_t</span> index = x &gt;&gt; <span class="number">5</span>;</span><br><span class="line">		<span class="type">size_t</span> num = x % <span class="number">32</span>;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">return</span> _bitTable[index] &amp; (<span class="number">1</span> &lt;&lt; num);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p>完整代码：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">BitMap</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">	<span class="built_in">BitMap</span>(<span class="type">size_t</span> range)</span><br><span class="line">	&#123;</span><br><span class="line">		_bitTable.<span class="built_in">resize</span>((range &gt;&gt; <span class="number">5</span>) + <span class="number">1</span>);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">//标识一个数字在位图中的位置</span></span><br><span class="line">	<span class="function"><span class="type">void</span> <span class="title">SetBit</span><span class="params">(<span class="type">size_t</span> x)</span></span></span><br><span class="line"><span class="function">	</span>&#123;</span><br><span class="line">		<span class="type">size_t</span> index = x &gt;&gt; <span class="number">5</span>;</span><br><span class="line">		<span class="type">size_t</span> num = x % <span class="number">32</span>;</span><br><span class="line"></span><br><span class="line">		_bitTable[index] |= (<span class="number">1</span> &lt;&lt; num);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">//取消数字在位图当中的标识.</span></span><br><span class="line">	<span class="function"><span class="type">void</span> <span class="title">RemoveBit</span><span class="params">(<span class="type">size_t</span> x)</span></span></span><br><span class="line"><span class="function">	</span>&#123;</span><br><span class="line">		<span class="type">size_t</span> index = x &gt;&gt; <span class="number">5</span>;</span><br><span class="line">		<span class="type">size_t</span> num = x % <span class="number">32</span>;</span><br><span class="line"></span><br><span class="line">		_bitTable[index] &amp;= ~(<span class="number">1</span> &lt;&lt; num);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="type">bool</span> <span class="title">TestBit</span><span class="params">(<span class="type">size_t</span> x)</span></span></span><br><span class="line"><span class="function">	</span>&#123;</span><br><span class="line">		<span class="type">size_t</span> index = x &gt;&gt; <span class="number">5</span>;</span><br><span class="line">		<span class="type">size_t</span> num = x % <span class="number">32</span>;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">return</span> _bitTable[index] &amp; (<span class="number">1</span> &lt;&lt; num);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">	vector&lt;<span class="type">int</span>&gt; _bitTable;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>拓展<br>现在将问题修改为让你寻找出40亿个数据中出现过两次的数据，此时我们就需要使用两位来标记同一个数据了。</p>
<p>N位位图的实现如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">NBitMap</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">	<span class="built_in">NBitMap</span>(<span class="type">size_t</span> range)</span><br><span class="line">	&#123;</span><br><span class="line">		_bitTable.<span class="built_in">resize</span>((range &gt;&gt; <span class="number">4</span>) + <span class="number">1</span>);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="type">void</span> <span class="title">SetBit</span><span class="params">(<span class="type">size_t</span> x)</span></span></span><br><span class="line"><span class="function">	</span>&#123;</span><br><span class="line">		<span class="type">size_t</span> index = x &gt;&gt; <span class="number">4</span>;</span><br><span class="line">		<span class="type">size_t</span> num = x % <span class="number">16</span>;</span><br><span class="line">		num *= <span class="number">2</span>;</span><br><span class="line"></span><br><span class="line">		<span class="type">bool</span> first = _bitTable[index] &amp; (<span class="number">1</span> &lt;&lt; num);</span><br><span class="line">		<span class="type">bool</span> second = _bitTable[index] &amp; (<span class="number">1</span> &lt;&lt; (num + <span class="number">1</span>));</span><br><span class="line"></span><br><span class="line">		<span class="keyword">if</span> (!(first &amp;&amp; second))</span><br><span class="line">		&#123;</span><br><span class="line">			_bitTable[index] += (<span class="number">1</span> &lt;&lt; num);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="type">bool</span> <span class="title">TestBit</span><span class="params">(<span class="type">size_t</span> x)</span></span></span><br><span class="line"><span class="function">	</span>&#123;</span><br><span class="line">		<span class="type">size_t</span> index = x &gt;&gt; <span class="number">4</span>;</span><br><span class="line">		<span class="type">size_t</span> num = x % <span class="number">16</span>;</span><br><span class="line">		num *= <span class="number">2</span>;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">return</span> (_bitTable[index] &gt;&gt; num) &amp; <span class="number">0x03</span>;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">	vector&lt;<span class="type">int</span>&gt; _bitTable;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>关于位图的讲解就到这里，现在我让你查找10亿个字符串中出现一次的那个字符串，有的同学丝毫不犹豫就要用我们使用的位图，但是仔细思考，我们这里的位图只是可以映射数字类型的数据，变成字符串以及其他文件好像就不再那么得心应手了，别急，聪明的大佬们又想到了一种骚东西叫做布隆过滤器，那么布隆过滤器是什么呢？请看下篇博客哦。</p>
<hr>
<p>版权声明：本文为CSDN博主「lucky52529」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。<br>原文链接：<a href="https://blog.csdn.net/lucky52529/article/details/90172264">https://blog.csdn.net/lucky52529/article/details/90172264</a></p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>其他</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>其他</tag>
      </tags>
  </entry>
  <entry>
    <title>双指针</title>
    <url>/posts/91a7e4d1/</url>
    <content><![CDATA[<h2 id="双指针"><a href="#双指针" class="headerlink" title="双指针"></a>双指针</h2><p>双指针，指的是在遍历对象的过程中，不是普通的使用单个指针进行访问，<br>而是使用两个相同方向（快慢指针）或者相反方向（对撞指针）的指针进行扫描，<br>从而达到相应的目的。<br>充分使用了数组有序的特征</p>
<h3 id="用法"><a href="#用法" class="headerlink" title="用法"></a>用法</h3><h4 id="对撞指针"><a href="#对撞指针" class="headerlink" title="对撞指针"></a>对撞指针</h4><p>对撞指针是指在有序数组中，将指向最左侧的索引定义为左指针(left)，<br>最右侧的定义为右指针(right)，然后从两头向中间进行数组遍历。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">function fn (list) &#123;</span><br><span class="line">  var left = 0;</span><br><span class="line">  var right = list.length - 1;</span><br><span class="line"></span><br><span class="line">  //遍历数组</span><br><span class="line">  while (left &lt;= right) &#123;</span><br><span class="line">    left++;</span><br><span class="line">    // 一些条件判断 和处理</span><br><span class="line">    ... ...</span><br><span class="line">    right--;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="快慢指针"><a href="#快慢指针" class="headerlink" title="快慢指针"></a>快慢指针</h4><p>快慢指针也是双指针，但是两个指针从同一侧开始遍历数组，<br>将这两个指针分别定义为快指针（fast）和慢指针（slow），<br>两个指针以不同的策略移动，直到两个指针的值相等（或其他特殊条件）为止，<br>如fast每次增长两个，slow每次增长一个。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">var hasCycle = function(head) &#123;</span><br><span class="line">  if (head === null || head.next === null) &#123;</span><br><span class="line">    return false</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  let slow = head</span><br><span class="line">  let fast = head.next</span><br><span class="line"></span><br><span class="line">  while (slow !== fast) &#123;</span><br><span class="line">    if (fast === null || fast.next === null) &#123;</span><br><span class="line">      return false</span><br><span class="line">    &#125;</span><br><span class="line">    slow = slow.next</span><br><span class="line">    fast = fast.next.next</span><br><span class="line">  &#125;</span><br><span class="line">  return true</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>当遇到有序数组时，应该优先想到双指针来解决问题，因两个指针的同时遍历会减少空间复杂度和时间复杂度。</p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>其他</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>其他</tag>
      </tags>
  </entry>
  <entry>
    <title>回溯法</title>
    <url>/posts/3635a217/</url>
    <content><![CDATA[<p>##回溯法</p>
<p>###基本原理：递归<br>###套路模板:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">res = []</span><br><span class="line">state = []</span><br><span class="line">p,q,r</span><br><span class="line">def back(状态，条件...)：</span><br><span class="line">    if 不满足条件</span><br><span class="line">        return</span><br><span class="line">    elif 状态满足要求</span><br><span class="line">        res.apend(state)</span><br><span class="line">        return</span><br><span class="line">    递归过程</span><br><span class="line">    back(状态，条件...)</span><br><span class="line">return res</span><br><span class="line">    </span><br></pre></td></tr></table></figure>
<p>###使用回溯法的明显标志<br>1.排列、组合（子集、幂集、字符全排列）<br>2.数值、字符串，给定一个特定规则，尝试搜索迭代找到这个解<br>3.二维数组下的DFS搜索（八皇后、黄金矿工、数独）<br>###加速方法<br>####传递数组下标而不是整个剩余数组<br>####剪枝<br>利用已知的先验条件，将后面不可能满足任务目标的搜索路径去掉<br>####构建图<br>将题目给出的数组数据建立联系，尝试构建一个图，回溯法转换为对图的DFS搜索，极大缩小了解空间</p>
<p>####回溯法转构造法</p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>其他</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>其他</tag>
      </tags>
  </entry>
  <entry>
    <title>生命游戏（数组，原地算法）</title>
    <url>/posts/804f5f57/</url>
    <content><![CDATA[<h1 id="生命游戏（数组，原地算法）"><a href="#生命游戏（数组，原地算法）" class="headerlink" title="生命游戏（数组，原地算法）"></a>生命游戏（数组，原地算法）</h1><p>题目链接：<a href="https://leetcode-cn.com/problems/game-of-life/">https://leetcode-cn.com/problems/game-of-life/</a></p>
<p>题目描述<br>根据百度百科，生命游戏，简称为生命，是英国数学家约翰·何顿·康威在1970年发明的细胞自动机。</p>
<p>给定一个包含 m × n 个格子的面板，每一个格子都可以看成是一个细胞。每个细胞具有一个初始状态 live（1）即为活细胞， 或 dead（0）即为死细胞。每个细胞与其八个相邻位置（水平，垂直，对角线）的细胞都遵循以下四条生存定律：</p>
<p>如果活细胞周围八个位置的活细胞数少于两个，则该位置活细胞死亡；<br>如果活细胞周围八个位置有两个或三个活细胞，则该位置活细胞仍然存活；<br>如果活细胞周围八个位置有超过三个活细胞，则该位置活细胞死亡；<br>如果死细胞周围正好有三个活细胞，则该位置死细胞复活；<br>根据当前状态，写一个函数来计算面板上细胞的下一个（一次更新后的）状态。下一个状态是通过将上述规则同时应用于当前状态下的每个细胞所形成的，其中细胞的出生和死亡是同时发生的。<br>示例:</p>
<p><strong>示例:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入: </span><br><span class="line">[</span><br><span class="line">  [0,1,0],</span><br><span class="line">  [0,0,1],</span><br><span class="line">  [1,1,1],</span><br><span class="line">  [0,0,0]</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<p><strong>输出:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[</span><br><span class="line">  [0,0,0],</span><br><span class="line">  [1,0,1],</span><br><span class="line">  [0,1,1],</span><br><span class="line">  [0,1,0]</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<p>进阶:</p>
<p>你可以使用原地算法解决本题吗？请注意，面板上所有格子需要同时被更新：你不能先更新某些格子，然后使用它们的更新后的值再更新其他格子。<br>本题中，我们使用二维数组来表示面板。原则上，面板是无限的，但当活细胞侵占了面板边界时会造成问题。你将如何解决这些问题？<br>思路<br>类似题73 矩阵置零，采用两次遍历数组的原地算法。<br>（1）第一次遍历时，标记需要更新的位；将活细胞-&gt;死细胞标记为-1，死细胞-&gt;活细胞标记为1；<br>（2）第二次遍历时，将标记为-1的置0，标记为2的置1</p>
<p>复杂度分析</p>
<p>时间复杂度：O（mn）<br>空间复杂度：O（1）<br>代码</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/*</span><br><span class="line"> * -1表示当前为1，下一次更新为0的细胞</span><br><span class="line"> * 2表示当前为0，下一次更新为1的细胞</span><br><span class="line"> */</span><br><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    void gameOfLife(vector&lt;vector&lt;int&gt;&gt;&amp; board) &#123;</span><br><span class="line">        if(board.empty() || board[0].empty()) return;</span><br><span class="line">        int rows = board.size(), cols = board[0].size();</span><br><span class="line">        </span><br><span class="line">        // 标记状态</span><br><span class="line">        for (int i = 0; i &lt; rows; ++i) &#123;</span><br><span class="line">            for (int j = 0; j &lt; cols; ++j) &#123;</span><br><span class="line">                int cnt = 0;</span><br><span class="line">                // 统计活细胞数量</span><br><span class="line">                for (int k = i-1; k &lt;= i+1 ; ++k) &#123;</span><br><span class="line">                    for (int l = j-1; l &lt;= j + 1 ; ++l) &#123;</span><br><span class="line">                        if(k&lt;0 || l &lt; 0|| k&gt;=rows || l&gt;=cols || (k==i &amp;&amp; l ==j))</span><br><span class="line">                            continue;</span><br><span class="line">                        if(board[k][l] == 1 ||board[k][l] == -1)</span><br><span class="line">                            cnt ++;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                if (board[i][j] == 1)&#123;</span><br><span class="line">                    if(cnt &lt; 2 || cnt &gt; 3)</span><br><span class="line">                        board[i][j] =  -1;</span><br><span class="line">                &#125;</span><br><span class="line">                else if(cnt == 3)</span><br><span class="line">                    board[i][j] = 2;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    </span><br><span class="line">        // 更新状态</span><br><span class="line">        for (int i = 0; i &lt; rows; ++i) &#123;</span><br><span class="line">            for (int j = 0; j &lt; cols; ++j) &#123;</span><br><span class="line">                if(board[i][j] == -1)</span><br><span class="line">                    board[i][j] = 0;</span><br><span class="line">                else if(board[i][j] ==2)</span><br><span class="line">                    board[i][j] = 1;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>


]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>其他</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>其他</tag>
      </tags>
  </entry>
  <entry>
    <title>红黑树</title>
    <url>/posts/f89cb603/</url>
    <content><![CDATA[<h1 id="红黑树详解"><a href="#红黑树详解" class="headerlink" title="红黑树详解"></a>红黑树详解</h1><p><a href="https://blog.csdn.net/u014454538/article/details/120120216">https://blog.csdn.net/u014454538/article/details/120120216</a></p>
<h1 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h1><h2 id="1-1-红黑树的引入"><a href="#1-1-红黑树的引入" class="headerlink" title="1.1 红黑树的引入"></a>1.1 红黑树的引入</h2><p><strong>有了二叉搜索树，为什么还需要平衡二叉树？</strong></p>
<ul>
<li>在学习二叉搜索树、平衡二叉树时，我们不止一次提到，二叉搜索树容易退化成一条链</li>
<li>这时，查找的时间复杂度从O(log2N))也将退化成 O(N)</li>
<li>引入对左右子树高度差有限制的平衡二叉树，保证查找操作的最坏时间复杂度也为O(log2N)</li>
</ul>
<p> <strong>有了平衡二叉树，为什么还需要红黑树？</strong> </p>
<ul>
<li><p>AVL的左右子树高度差不能超过1，每次进行插入&#x2F;删除操作时，几乎都需要通过旋转操作保持平衡</p>
</li>
<li><p>在频繁进行插入&#x2F;删除的场景中，频繁的旋转操作使得AVL的性能大打折扣</p>
</li>
<li><p>红黑树通过牺牲严格的平衡，换取插入&#x2F;删除时少量的旋转操作，整体性能优于AVL</p>
<ul>
<li>红黑树插入时的不平衡，不超过两次旋转就可以解决；删除时的不平衡，不超过三次旋转就能解决</li>
</ul>
</li>
<li><p>红黑树的红黑规则，保证最坏的情况下，也能在O(log 2N)时间内完成查找操作。</p>
</li>
</ul>
<h2 id="1-2-红黑规则"><a href="#1-2-红黑规则" class="headerlink" title="1.2 红黑规则"></a>1.2 红黑规则</h2><ul>
<li>一棵典型的红黑树，如图所示</li>
</ul>
<p> <img src="/posts/f89cb603/asset/20190409222157219.png" alt="在这里插入图片描述"> </p>
<ul>
<li>从图示，可以发现红黑树的一些规律：<ul>
<li>节点不是红色就是黑色，根节点是黑色</li>
<li>红黑树的叶子节点并非传统的叶子节点，红黑树的叶子节点是null节点（空节点）且为黑色</li>
<li>同一路径，不存在连续的红色节点</li>
</ul>
</li>
<li>以上是我们能发现的一些规律，这些规律其实是红黑规则的一部分</li>
</ul>
<p>红黑规则</p>
<ol>
<li>节点不是黑色，就是红色（非黑即红）</li>
<li>根节点为黑色</li>
<li>叶节点为黑色（叶节点是指末梢的空节点 <code>Nil</code>或<code>Null</code>）</li>
<li>一个节点为红色，则其两个子节点必须是黑色的（根到叶子的所有路径，不可能存在两个连续的红色节点）</li>
<li>每个节点到叶子节点的所有路径，都包含相同数目的黑色节点（相同的黑色高度）</li>
</ol>
<p>一些说明</p>
<ul>
<li><p>约束4和5，保证了红黑树的<strong>大致平衡</strong>：根到叶子的所有路径中，最长路径不会超过最短路径的2倍。</p>
</li>
<li><p>使得红黑树在最坏的情况下，也能有O(log2N)的查找效率</p>
<ul>
<li>黑色高度为3时，最短路径：黑色→ 黑色 →  黑色，最长路径：黑色→ 红色 → 黑色 →  红色 → 黑色</li>
<li>最短路径的长度为2（不算Nil的叶子节点），最长路径为4</li>
</ul>
</li>
<li><p>关于叶子节点：Java实现中，null代表空节点，无法看到黑色的空节点，反而能看到传统的红色叶子节点</p>
</li>
<li><p>默认新插入的节点为红色：因为父节点为黑色的概率较大，插入新节点为红色，可以避免颜色冲突</p>
</li>
</ul>
<h2 id="1-3-红黑树的应用"><a href="#1-3-红黑树的应用" class="headerlink" title="1.3 红黑树的应用"></a>1.3 红黑树的应用</h2><ul>
<li><p>Java中，TreeMap、TreeSet都使用红黑树作为底层数据结构</p>
</li>
<li><p>JDK 1.8开始，HashMap也引入了红黑树：当冲突的链表长度超过8时，自动转为红黑树</p>
</li>
<li><p>Linux底层的CFS进程调度算法中，vruntime使用红黑树进行存储。</p>
</li>
<li><p>多路复用技术的Epoll，其核心结构是红黑树 + 双向链表。</p>
</li>
</ul>
<p> 参考文档：<a href="https://www.zhihu.com/question/312327402">为什么这么多关于红黑树的面试题呢？</a> </p>
<h1 id="2-红黑树的左旋右旋"><a href="#2-红黑树的左旋右旋" class="headerlink" title="2. 红黑树的左旋右旋"></a>2. 红黑树的左旋右旋</h1><h2 id="2-1-红黑树的定义"><a href="#2-1-红黑树的定义" class="headerlink" title="2.1 红黑树的定义"></a>2.1 红黑树的定义</h2><ul>
<li>上一章节可知，红黑树要比<a href="https://so.csdn.net/so/search?q=%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91&spm=1001.2101.3001.7020">二叉搜索树</a>多一个颜色属性</li>
<li>同时，为了方便确认插入位置，还可以多一个parent属性，用于表示当前节点的父节点</li>
</ul>
<p> 因此，红黑树节点的定义如下： </p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">RedBlackTreeNode</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> val;</span><br><span class="line">    <span class="keyword">public</span> RedBlackTreeNode left;</span><br><span class="line">    <span class="keyword">public</span> RedBlackTreeNode right;</span><br><span class="line">    <span class="comment">// 记录节点颜色的color属性，暂定true表示红色</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> color;</span><br><span class="line">    <span class="comment">// 为了方便迭代插入，所需的parent属性</span></span><br><span class="line">    <span class="keyword">public</span> RedBlackTreeNode parent;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 一些构造函数，根据实际需求构建</span></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">RedBlackTreeNode</span><span class="params">()</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p> 红黑树中，有一个root属性，用于记录当前红黑树的根节点 </p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">RedBlackTree</span> &#123;</span><br><span class="line">    <span class="comment">// 当前红黑树的根节点，默认为null</span></span><br><span class="line">    <span class="keyword">private</span> RedBlackTreeNode root;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>当红黑规则不满足时，需要对节点进行<strong>变色或旋转</strong>操作</li>
</ul>
<h2 id="2-2-红黑树的左旋"><a href="#2-2-红黑树的左旋" class="headerlink" title="2.2 红黑树的左旋"></a>2.2 红黑树的左旋</h2><p>回忆二叉树的左旋：</p>
<ul>
<li>手工推演（先冲突，再移动）：<ul>
<li>根节点成为右儿子的左子树；</li>
<li>右儿子原有的左子树成为根节点的右子树</li>
</ul>
</li>
<li>代码实现（先空位，再补齐）：<ul>
<li>右儿子的左子树成为根节点的右子树</li>
<li>根节点成为右儿子的左子树</li>
</ul>
</li>
</ul>
<p>红黑树的左旋</p>
<ul>
<li>红黑树节点中，包含父节点的引用</li>
<li>进行左旋时，不仅需要更新左右子树的引用，还需要更新父节点的引用</li>
</ul>
<p>左旋需要三大步（被旋转的节点叫做节点P）：</p>
<ul>
<li><p><strong>空出右儿子的左子树：</strong> （对应下图步骤2）</p>
<ul>
<li>右儿子的左子树取代右儿子，成为节点P的右子树，从而空出右儿子的左子树</li>
<li>若右儿子的左子树不为空，需要更新左子树的父节点为节点P</li>
</ul>
</li>
<li><p><strong>空出节点P的父节点：</strong> （对应下图步骤3）</p>
</li>
<li><p>右儿子去取代节点P，成为其父节点的子树</p>
</li>
<li><p>父节点指向右儿子</p>
<ul>
<li>若父节点为null，root将指向右儿子，右儿子成为整棵树的根节点；</li>
<li>节点P是父节点的左子树，则右儿子成为父节点的左儿子；</li>
<li>节点P是父节点的右子树，则右儿子成为父节点的右儿子</li>
</ul>
</li>
</ul>
<p><strong>节点P和右儿子成功会师：</strong> （对应下图步骤4）</p>
<ul>
<li>上述两步，空出了节点P的父节点和右儿子的左子树。</li>
<li>这时直接更新，即可将节点P变成右儿子的左子树。</li>
</ul>
<p> 给出一个不是很正确的示意图 </p>
<p> <img src="/posts/f89cb603/asset/9c6af30b3ebd4d56ac813e234c279e9c.png" alt="在这里插入图片描述"> </p>
<p> 具体代码如下： </p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">leftRotate</span><span class="params">(RedBlackTreeNode p)</span> &#123;</span><br><span class="line">    <span class="comment">// 在当前节点不为null时，才进行左旋操作</span></span><br><span class="line">    <span class="keyword">if</span> (p != <span class="literal">null</span>) &#123;</span><br><span class="line">        <span class="comment">// 先记录p的右儿子</span></span><br><span class="line">        <span class="type">RedBlackTreeNode</span> <span class="variable">rightChild</span> <span class="operator">=</span> p.right;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1. 空出右儿子的左子树</span></span><br><span class="line">        p.right = rightChild.left;</span><br><span class="line">        <span class="comment">// 左子树不为空，需要更新父节点</span></span><br><span class="line">        <span class="keyword">if</span> (rightChild.left != <span class="literal">null</span>) &#123;</span><br><span class="line">            rightChild.left.parent = p;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 空出节点p的父节点</span></span><br><span class="line">        rightChild.parent = p.parent;</span><br><span class="line">        <span class="comment">// 父节点指向右儿子</span></span><br><span class="line">        <span class="keyword">if</span> (p.parent == <span class="literal">null</span>) &#123; <span class="comment">// 右儿子成为新的根节点</span></span><br><span class="line">            <span class="built_in">this</span>.root = rightChild;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (p == p.parent.left) &#123; <span class="comment">// 右儿子成为父节点的左儿子</span></span><br><span class="line">            p.parent.left = rightChild;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123; <span class="comment">// 右儿子成为父节点的右儿子</span></span><br><span class="line">            p.parent.right = rightChild;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 右儿子和节点p成功会师，节点p成为左子树</span></span><br><span class="line">        rightChild.left = p;</span><br><span class="line">        p.parent = rightChild;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="2-3-红黑树的右旋"><a href="#2-3-红黑树的右旋" class="headerlink" title="2.3 红黑树的右旋"></a>2.3 红黑树的右旋</h2><p>回忆二叉树的右旋：</p>
<ul>
<li>手工推演（先冲突，再移动）：<ul>
<li>根节点成为左儿子的右子树</li>
<li>左儿子原有的右子树成为根节点的左子树</li>
</ul>
</li>
<li>代码实现（先空位，再补齐）：<ul>
<li>左儿子的右子树成为根节点的左子树</li>
<li>根节点成为左儿子右子树</li>
</ul>
</li>
</ul>
<p>红黑树的右旋</p>
<ul>
<li>与红黑树的左旋一样，由于父节点引用的存在，不仅需要更新左右子树的引用，还需要更新父节点的引用</li>
</ul>
<p>右旋需要三大步（被旋转节点称为节点P）：</p>
<ul>
<li><p><strong>空出左儿子的右子树：</strong> （对应下图步骤2）</p>
<ul>
<li>左儿子的右子树取代左儿子，成为节点P的左子树，以空出左儿子的右子树</li>
<li>若左儿子的右子树不为空，需要更新右子树的父节点为节点P</li>
</ul>
</li>
<li><p><strong>空出节点P的父节点：</strong> （对应下图步骤3）</p>
<ul>
<li>左儿子取代节点P，成为其父节点的子树</li>
<li>父节点指向左儿子：<ul>
<li>父节点为空，root将指向左儿子，左儿子成为整棵树的根节点</li>
<li>节点P为父节点的左子树，左儿子成为父节点的左子树</li>
<li>节点P为父节点的右子树，左儿子成为节点P的右子树</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>节点P和左儿子成功会师：</strong> （对应下图步骤4）</p>
<ul>
<li>上述两步，空出了节点P的父节点和左儿子的右子树。</li>
<li>这时直接更新，即可将节点P成左儿子的右子树</li>
</ul>
</li>
</ul>
<p> 给出一个不是很正确的示意图 </p>
<p> <img src="/posts/f89cb603/asset/61c46ee09a534a889f4c125c79d690cb.png" alt="在这里插入图片描述"> </p>
<p> 具体代码如下： </p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">rightRotate</span><span class="params">(RedBlackTreeNode p)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (p != <span class="literal">null</span>) &#123;</span><br><span class="line">        <span class="comment">// 记录p的左儿子</span></span><br><span class="line">        <span class="type">RedBlackTreeNode</span> <span class="variable">leftChild</span> <span class="operator">=</span> p.left;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1. 空出左儿子的右子树</span></span><br><span class="line">        p.left = leftChild.right;</span><br><span class="line">        <span class="comment">// 右子树不为空，需要更新父节点</span></span><br><span class="line">        <span class="keyword">if</span> (leftChild.right != <span class="literal">null</span>) &#123;</span><br><span class="line">            leftChild.right.parent = p;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 空出节点p的父节点</span></span><br><span class="line">        leftChild.parent = p.parent;</span><br><span class="line">        <span class="comment">// 父节点指向左儿子</span></span><br><span class="line">        <span class="keyword">if</span> (p.parent == <span class="literal">null</span>) &#123; <span class="comment">// 左儿子成为整棵树根节点</span></span><br><span class="line">            <span class="built_in">this</span>.root = leftChild;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (p.parent.left == p) &#123; <span class="comment">// 左儿子成为父节点左儿子</span></span><br><span class="line">            p.parent.left = leftChild;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123; <span class="comment">// 左儿子成为父节点的右儿子</span></span><br><span class="line">            p.parent.right = leftChild;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 顺利会师</span></span><br><span class="line">        leftChild.right = p;</span><br><span class="line">        p.parent = leftChild;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="2-4-红黑树新增节点"><a href="#2-4-红黑树新增节点" class="headerlink" title="2.4 红黑树新增节点"></a>2.4 红黑树新增节点</h2><p>一些规则：</p>
<ul>
<li><p>新插入的节点默认为红色，原因：插入黑色节点会影响黑色高度，对红黑树的影响更大；</p>
</li>
<li><p>新增节点x时，循环的依据： <code>x != null &amp;&amp; x != root &amp;&amp; x.parent.color == RED</code>，即节点非空、不是整棵树的根节点（保证存在父节点）且父节点为红色（违反红黑规则4，需要调整）</p>
</li>
<li><p>完成循环调整后，需要将整棵树的根节点设为黑色，以满足红黑规则1；同时，根节点设为黑色，不会影响从根节点开始的所有路径的黑色高度</p>
</li>
</ul>
<h3 id="2-4-1-父亲为祖父的左儿子"><a href="#2-4-1-父亲为祖父的左儿子" class="headerlink" title="2.4.1 父亲为祖父的左儿子"></a>2.4.1 父亲为祖父的左儿子</h3><p>情况一：父亲和叔叔都是红色</p>
<ul>
<li>当父亲为祖父的左儿子，父亲和叔叔都是红色时：<br>（1）将父亲和叔叔改成黑色，以满足红黑规则4<br>（2）父亲和叔叔变成黑色了，黑色高度变化，需要将祖父变成红色，以满足红黑规则5<br>（3）从祖父开始，继续调整</li>
</ul>
<p> <img src="/posts/f89cb603/asset/e82f750093dd4b86a17ae568d3e8e528.jpg" alt="在这里插入图片描述"> </p>
<p> 情况二：叔叔为黑色，自己是父亲的左儿子 </p>
<ul>
<li><p>父亲为祖父的左儿子，叔叔为黑色，自己是父亲的左儿子<br>（1）父亲变成黑色，祖父变成红色（右子树的黑色高度变低）<br>（2）对祖父进行右旋，让父节点成为新的祖父，以恢复右子树的黑色高度<br>（3）不满足循环条件，退出循环</p>
<p> <img src="/posts/f89cb603/asset/cb8184f51240482ca3cc409b7e32db8d.jpg" alt="在这里插入图片描述"></p>
</li>
</ul>
<p>情况三：叔叔为黑色，自己是父亲的右儿子</p>
<ul>
<li>父亲为祖父的左儿子，叔叔为黑色，自己是父亲的右儿子<br>（1）父亲成为新的x，对父亲进行左旋操作，构造情况二的初始状态<br>（2）按照情况二，对新的x（原父亲）进行处理</li>
</ul>
<p> <img src="/posts/f89cb603/asset/ef43192623d2494f94680fd93b7764f9.jpg" alt="在这里插入图片描述"> </p>
<h3 id="2-4-2-父亲为祖父的右儿子"><a href="#2-4-2-父亲为祖父的右儿子" class="headerlink" title="2.4.2 父亲为祖父的右儿子"></a>2.4.2 父亲为祖父的右儿子</h3><p>情况一：父亲和叔叔都是红色</p>
<ul>
<li>父亲为祖父的右儿子，父亲和叔叔都是红色<br>（1）将父亲和叔叔都变成黑色，以保证红黑规则4<br>（2）将祖父变成红色，以保证红色规则5（相同的黑色高度）<br>（3）从祖父开始，继续调整</li>
</ul>
<p> <img src="/posts/f89cb603/asset/e767ff023a93414188be650a7cf537ef.jpg" alt="在这里插入图片描述"> </p>
<p>情况二：叔叔为黑色，自己是父亲的右儿子</p>
<ul>
<li>父亲为祖父的右儿子，叔叔为黑色，自己是父亲的右儿子<br>（1）父亲变成黑色，祖父变成红色（左子树的黑色高度降低）<br>（2）对祖父进行左旋操作，以恢复左子树的黑色高度<br>（3）不满足循环条件，退出循环</li>
</ul>
<p> <img src="/posts/f89cb603/asset/39ac0970c1f2411480c8b5890ba92fc4.jpg" alt="在这里插入图片描述"> </p>
<p>情况三：叔叔为黑色，自己是父亲的左儿子</p>
<ul>
<li>父亲是祖父的右儿子，叔叔为黑色，自己是父亲的左儿子<br>（1）父节点成为新的X，对父亲进行右旋操作，构造情况二的初始情况<br>（2）按照情况二，对新的x（原父节点）进行处理</li>
</ul>
<p> <img src="/posts/f89cb603/asset/0b7af295ce714f6c88ca90577b99bbb6.jpg" alt="在这里插入图片描述"> </p>
<h3 id="2-4-3-规律总结"><a href="#2-4-3-规律总结" class="headerlink" title="2.4.3 规律总结"></a>2.4.3 规律总结</h3><ul>
<li><p>循环条件： <code>x != null &amp;&amp; x != root &amp;&amp; x.parent.color == RED</code>，即节点非空、不是整棵树的根节点（保证存在父节点）且父节点为红色</p>
</li>
<li><p>最终处理：将整棵树的根节点变成黑色，以满足红黑规则1，又不会违反红黑规则5</p>
</li>
<li><p>对父亲是祖父的左儿子或右儿子的<strong>处理是对称的</strong>，只需要理解左儿子时的处理方法，就可以举一反三，知道对右儿子的处理方法</p>
</li>
</ul>
<p><strong>父亲为祖父的左儿子：</strong></p>
<ol>
<li>父亲和叔叔都是红色，将父亲和叔叔变成黑色，祖父变成红色，继续对祖父进行调整</li>
<li>叔叔是黑色，自己是父亲的左儿子：父亲变成黑色，祖父变成红色；对祖父进行右旋以满足红黑规则；此时节点不满足循环条件，可以退出循环。</li>
<li>叔叔是黑色，自己数父亲的右儿子：父亲成为新的X，对父亲执行左旋操作，构造情况2；按照情况2继续进行处理</li>
</ol>
<ul>
<li><strong>总结：</strong> 父叔同色，只进行变色操作；父叔异色，自己是右儿子，则进行LR操作；父叔异色，自己是左儿子，则进行R操作</li>
</ul>
<p><strong>父亲为祖父的右儿子</strong></p>
<ul>
<li>父叔同色，只进行变色操作</li>
<li>父叔异色，自己是左儿子，则进行RL操作</li>
<li>父叔异色，自己是右儿子，则进行L操作</li>
</ul>
<h3 id="2-4-4-代码实现"><a href="#2-4-4-代码实现" class="headerlink" title="2.4.4 代码实现"></a>2.4.4 代码实现</h3><ul>
<li>根据上面的分析，不难写出新增红黑节点后的代码</li>
<li>假设新增的节点为p，则代码如下</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">fixAfterInsert</span><span class="params">(RedBlackTreeNode x)</span> &#123;</span><br><span class="line">    <span class="comment">// 新插入的节点，默认为红色</span></span><br><span class="line">    x.color = RED;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// p不为null、不是整棵树的根节点、父亲为红色，需要调整</span></span><br><span class="line">    <span class="keyword">while</span> (x != <span class="literal">null</span> &amp;&amp; <span class="built_in">this</span>.root != x &amp;&amp; x.parent.color == RED) &#123;</span><br><span class="line">        <span class="comment">// 父亲是祖父的左儿子</span></span><br><span class="line">        <span class="keyword">if</span> (parentOf(x) == parentOf(parentOf(x)).left) &#123;</span><br><span class="line">            <span class="comment">// 父亲和叔叔都是红色</span></span><br><span class="line">            <span class="type">RedBlackTreeNode</span> <span class="variable">uncle</span> <span class="operator">=</span> parentOf(parentOf(x)).right;</span><br><span class="line">            <span class="keyword">if</span> (uncle.color == RED) &#123;</span><br><span class="line">                <span class="comment">// 父亲和叔叔都变成黑色</span></span><br><span class="line">                parentOf(x).color = BLACK;</span><br><span class="line">                uncle.color = BLACK;</span><br><span class="line">                <span class="comment">// 祖父变成红色，继续从祖父开始进行调整</span></span><br><span class="line">                parentOf(parentOf(x)).color = RED;</span><br><span class="line">                x = parentOf(parentOf(x));</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123; <span class="comment">// 叔叔为黑色</span></span><br><span class="line">                <span class="comment">// 自己是父亲的右儿子，需要对父亲左旋</span></span><br><span class="line">                <span class="keyword">if</span> (x == parentOf(x).right) &#123;</span><br><span class="line">                    x = parentOf(x);</span><br><span class="line">                    leftRotate(x);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">// 自己是父亲的左儿子，变色后右旋，保持黑色高度</span></span><br><span class="line">                parentOf(x).color = BLACK;</span><br><span class="line">                parentOf(parentOf(x)).color = RED;</span><br><span class="line">                rightRotate(parentOf(parentOf(x)));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123; <span class="comment">//父亲是祖父的右儿子</span></span><br><span class="line">            <span class="type">RedBlackTreeNode</span> <span class="variable">uncle</span> <span class="operator">=</span> parentOf(parentOf(x)).left;</span><br><span class="line">            <span class="comment">// 父亲和叔叔都是红色</span></span><br><span class="line">            <span class="keyword">if</span> (uncle.color == RED) &#123;</span><br><span class="line">                <span class="comment">// 叔叔和父亲变成黑色</span></span><br><span class="line">                parentOf(x).color = BLACK;</span><br><span class="line">                uncle.color = BLACK;</span><br><span class="line">                <span class="comment">// 祖父变为红色，从祖父开始继续调整</span></span><br><span class="line">                parentOf(parentOf(x)).color = RED;</span><br><span class="line">                x = parentOf(parentOf(x));</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="comment">// 自己是父亲的左儿子，以父亲为中心右旋</span></span><br><span class="line">                <span class="keyword">if</span> (parentOf(x).left == x) &#123;</span><br><span class="line">                    x = parentOf(x);</span><br><span class="line">                    rightRotate(x);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">// 自己是父亲的右儿子，变色后左旋，保持黑色高度</span></span><br><span class="line">                parentOf(x).color = BLACK;</span><br><span class="line">                parentOf(parentOf(x)).color = RED;</span><br><span class="line">                leftRotate(parentOf(parentOf(x)));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 最后将根节点置为黑色，以满足红黑规则1，又不会破坏规则5</span></span><br><span class="line">    <span class="built_in">this</span>.root.color = BLACK;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> RedBlackTreeNode <span class="title function_">parentOf</span><span class="params">(RedBlackTreeNode p)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> (p == <span class="literal">null</span> ? <span class="literal">null</span> : p.parent);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>参考文档</p>
<ul>
<li>操作过程与本文有差异，但调整后的结果具有参考意义：<a href="https://www.huaweicloud.com/articles/afb8a79bb7ee0b2e2152e4cbcd18f03c.html">java红黑树详解</a></li>
</ul>
<h2 id="2-5-删除节点"><a href="#2-5-删除节点" class="headerlink" title="2.5 删除节点"></a>2.5 删除节点</h2><p>一些规则：</p>
<ul>
<li><p>删除节点时，通过节点替换实现删除</p>
</li>
<li><p>假设替换节点为x，需要在x替换被删节点后，从x开始进行调整</p>
</li>
<li><p>调整操作，循环的依据： <code>x != root &amp;&amp; x.color == BLACK</code>，即替换节点不能为整棵树的根节点，替换节点的颜色为黑色（改变了红黑高度）</p>
</li>
<li><p>完成循环调整后，需要将x设为黑色，结束调整</p>
</li>
</ul>
<h3 id="2-5-1-自己是父亲的左儿子"><a href="#2-5-1-自己是父亲的左儿子" class="headerlink" title="2.5.1 自己是父亲的左儿子"></a>2.5.1 自己是父亲的左儿子</h3><p>情况一：兄弟为红色</p>
<ul>
<li>此时，自己为黑色、兄弟为红色、父节点为黑色（满足红黑规则4）<br>（1）将兄弟变成黑色，父节点变成红色；这时，以父节点为起点的左子树黑色高度降低<br>（2）对父节点进行左旋，以恢复左子树黑色高度；同时，兄弟的左孩子成为新的兄弟</li>
<li>此时，自己和兄弟都是黑色，可能满足满足情况2、3和4、4</li>
</ul>
<p><img src="/posts/f89cb603/asset/b23de477905244d09f1b57babafe4719.jpg" alt="在这里插入图片描述"> </p>
<p>情况二：兄弟为黑色，左右侄子也是黑色</p>
<ul>
<li>此时，自己和兄弟都是黑色，父节点为黑色或红色；兄弟的两个儿子，都是黑色<br>（1）将兄弟变成为红色，x指向父节点，继续进行调整</li>
</ul>
<p> <img src="/posts/f89cb603/asset/4c4e3659d8f7412cb83ffa5b67a60896.jpg" alt="在这里插入图片描述"> </p>
<p>情况三：兄弟为黑色，右侄子为黑色</p>
<ul>
<li><p>此时，自己和兄弟均为黑色，父节点为红色或黑色；右侄子为黑色、左侄子为红色；<br>（1）将左侄子变成黑色，兄弟变为红色；这时，以兄弟为起点的右子树黑色高度降低<br>（2）将兄弟节点右旋，以恢复右子树的黑色高度；这时，左侄子将成为新的右兄弟</p>
</li>
<li><p>此时，兄弟的右儿子为红色，满足情况4；继续按照情况4，对节点x进行调整</p>
</li>
</ul>
<p> <img src="/posts/f89cb603/asset/e868108a7d3143d29e0d21027739d19e.jpg" alt="在这里插入图片描述"> </p>
<p>情况四：兄弟为黑色，右侄子为红色</p>
<ul>
<li><p>此时，自己和兄弟都是黑色，父节点为红色或黑色；右侄子为红色，左侄子为黑色或红色</p>
<p>（1）兄弟颜色改成与父节点一致，右侄子和父节点都变成黑色<br>（2）为了保证父节点变为黑色后，不影响所有路径的黑色高度，需要将父节点左旋（兄弟节点上提）<br>（3）x指向根节点，结束循环</p>
</li>
</ul>
<p> <img src="/posts/f89cb603/asset/9637f30f666a441891cd70345794ef1f.jpg" alt="在这里插入图片描述"> </p>
<h3 id="2-5-2-自己是父亲的右儿子"><a href="#2-5-2-自己是父亲的右儿子" class="headerlink" title="2.5.2 自己是父亲的右儿子"></a>2.5.2 自己是父亲的右儿子</h3><p>情况一：兄弟是红色节点</p>
<ul>
<li><p>此时，兄弟是红色节点，父节点必为黑色；若兄弟有左右儿子，左右儿子必为黑色（满足红黑规则4）</p>
<p>（1）将兄弟变成黑色节点，父节点变成红色；这时，以父节点为起点的右子树黑色高度降低（2）将父节点右旋，以恢复右子树的黑色高度；这时，兄弟的右孩子成为新的兄弟 </p>
</li>
<li><p>此时，自己和兄弟都是黑色，将满足情况2、3和4、4</p>
</li>
</ul>
<p> <img src="/posts/f89cb603/asset/ea066490f84e4a6ea5ca6b171c933ade.jpg" alt="在这里插入图片描述"> </p>
<p>情况二：兄弟是黑色，左右侄子也是黑色</p>
<ul>
<li>此时，自己和兄弟是黑色，父节点可以为红色或黑色<br>（1）将兄弟变成红色，x指向父节点，继续对父节点进行调整</li>
</ul>
<p> <img src="/posts/f89cb603/asset/e98fcda94ba244feb95be3c1b5eebffb.jpg" alt="在这里插入图片描述"> </p>
<p>情况三：兄弟为黑色，左侄子为黑色</p>
<ul>
<li><p>此时，自己和兄弟均为黑色，父节点为黑色或红色；左侄子为黑色，右侄子为红色<br>（1）将右侄子变成黑色，兄弟变成红色；这是，以兄弟为起点的左子树黑色高度降低<br>（2）将兄弟左旋，以恢复左子树的黑色高度；这时，右侄子成为新的兄弟</p>
</li>
<li><p>此时，将满足情况4，可以按照情况4，继续进行调整</p>
</li>
</ul>
<p> <img src="/posts/f89cb603/asset/c9b4599bb5624635825478eff25de7ba.jpg" alt="在这里插入图片描述"> </p>
<p>情况四：兄弟为黑色，左侄子为红色</p>
<ul>
<li><p>此时，自己和兄弟均为黑色，父节点为红色或黑色；左侄子为红色，右侄子为红色或黑色<br>（1）将兄弟变成与父节点一样的颜色，左侄子和父节点变成黑色</p>
<p>（ 2）为了保证父节点变成黑色，不会影响所有路径的黑色高度，需要将父节点右旋（兄弟上提）<br>（3）x指向根节点，退出循环</p>
</li>
</ul>
<p> <img src="/posts/f89cb603/asset/5169996bac424dbe81a6ca32e9e219b5.jpg" alt="在这里插入图片描述"> </p>
<h3 id="2-5-3-规律总结"><a href="#2-5-3-规律总结" class="headerlink" title="2.5.3 规律总结"></a>2.5.3 规律总结</h3><ul>
<li>循环条件：<code>x != root &amp;&amp; x.color = BLACK</code>，x不是根节点且颜色为黑色</li>
<li>收尾操作：将x置为黑色</li>
<li>x为父亲的左儿子或右儿子，处理操作是对称的；同样只需要记住左儿子时的操作，即可举一反三</li>
</ul>
<p><strong>x为父亲的左儿子</strong></p>
<ol>
<li>兄弟为红色：将兄弟变成黑色，父节点变成红色；对父节点左旋，恢复左子树的黑色高度，左侄子成为新的兄弟</li>
<li>兄弟为黑色，左右侄子为黑色：兄弟变成红色，x指向父节点，继续进行调整</li>
<li>兄弟为黑色，右侄子为黑色（左侄子为红色）：左侄子变成黑色，兄弟变成红色；兄弟右旋，恢复右子树的黑色高度，左侄子成为新的兄弟</li>
<li>兄弟为黑色，右侄子为红色：兄弟变成父节点颜色，父节点和右侄子变成黑色；父节点左旋，x指向整棵树的根节点，结束循环</li>
</ol>
<h3 id="2-5-4-代码实现"><a href="#2-5-4-代码实现" class="headerlink" title="2.5.4 代码实现"></a>2.5.4 代码实现</h3><ul>
<li>删除节点后，调整红黑树的代码如下</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">fixAfterDeletion</span><span class="params">(RedBlackTreeNode x)</span> &#123;</span><br><span class="line">    <span class="comment">// x不是根节点且颜色为黑色，开始循环调整</span></span><br><span class="line">    <span class="keyword">while</span> (x != root &amp;&amp; x.color == BLACK) &#123;</span><br><span class="line">        <span class="comment">// x是父亲的左儿子</span></span><br><span class="line">        <span class="keyword">if</span> (x == parentOf(x).left) &#123;</span><br><span class="line">            <span class="type">RedBlackTreeNode</span> <span class="variable">brother</span> <span class="operator">=</span> parentOf(x).right;</span><br><span class="line">            <span class="comment">// 兄弟为红色</span></span><br><span class="line">            <span class="keyword">if</span> (brother.color == RED) &#123;</span><br><span class="line">                <span class="comment">// 兄弟变成黑色，父节点变成红色</span></span><br><span class="line">                brother.color = BLACK;</span><br><span class="line">                parentOf(x).color = RED;</span><br><span class="line">                <span class="comment">// 父节点左旋，恢复左子树的黑色高度</span></span><br><span class="line">                leftRotate(parentOf(x));</span><br><span class="line">                <span class="comment">// 更新兄弟</span></span><br><span class="line">                brother = parentOf(x).right;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 兄弟为黑色，左右侄子为黑色</span></span><br><span class="line">            <span class="keyword">if</span> (brother.left.color == BLACK &amp;&amp; brother.right.color == BLACK) &#123;</span><br><span class="line">                <span class="comment">// 兄弟变成红色</span></span><br><span class="line">                brother.color = RED;</span><br><span class="line">                <span class="comment">// 从父节点开始继续调整</span></span><br><span class="line">                x = parentOf(x);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="comment">// 右侄子为黑色（左侄子为红色）</span></span><br><span class="line">                <span class="keyword">if</span> (brother.right.color == BLACK) &#123;</span><br><span class="line">                    <span class="comment">// 左侄子变为黑色，兄弟变成红色</span></span><br><span class="line">                    brother.left.color = BLACK;</span><br><span class="line">                    brother.color = RED;</span><br><span class="line">                    <span class="comment">// 兄弟右旋，恢复右子树黑色高度</span></span><br><span class="line">                    rightRotate(brother);</span><br><span class="line">                    <span class="comment">// 左侄子成为新的兄弟</span></span><br><span class="line">                    brother = parentOf(x).right;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">// 右侄子为红色，兄弟变成父节点颜色</span></span><br><span class="line">                brother.color = parentOf(x).color;</span><br><span class="line">                <span class="comment">// 父节点和右侄子变成黑色</span></span><br><span class="line">                parentOf(x).color = BLACK;</span><br><span class="line">                brother.right.color = BLACK;</span><br><span class="line">                <span class="comment">// 父节点左旋</span></span><br><span class="line">                leftRotate(parentOf(x));</span><br><span class="line">                <span class="comment">// x指向根节点</span></span><br><span class="line">                x = root;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="type">RedBlackTreeNode</span> <span class="variable">brother</span> <span class="operator">=</span> parentOf(x).left;</span><br><span class="line">            <span class="comment">// 兄弟为红色</span></span><br><span class="line">            <span class="keyword">if</span> (brother.color == RED) &#123;</span><br><span class="line">                <span class="comment">// 兄弟变黑色，父亲变红色</span></span><br><span class="line">                brother.color = BLACK;</span><br><span class="line">                parentOf(x).color = RED;</span><br><span class="line">                <span class="comment">// 父亲右旋，恢复红黑色高度</span></span><br><span class="line">                rightRotate(parentOf(x));</span><br><span class="line">                <span class="comment">// 更新兄弟为右侄子</span></span><br><span class="line">                brother = parentOf(x).left;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 兄弟的左右儿子为黑色</span></span><br><span class="line">            <span class="keyword">if</span> (brother.left.color == BLACK &amp;&amp; brother.right.color == BLACK) &#123;</span><br><span class="line">                <span class="comment">// 兄弟变为红色</span></span><br><span class="line">                brother.color = RED;</span><br><span class="line">                <span class="comment">// x指向父节点，继续进行调整</span></span><br><span class="line">                x = parentOf(x);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="comment">// 左侄子为黑色(右侄子为红色)</span></span><br><span class="line">                <span class="keyword">if</span> (brother.left.color == BLACK) &#123;</span><br><span class="line">                    <span class="comment">// 右侄子变黑色，兄弟变红色</span></span><br><span class="line">                    brother.right.color = BLACK;</span><br><span class="line">                    brother.color = RED;</span><br><span class="line">                    <span class="comment">// 对兄弟左旋</span></span><br><span class="line">                    leftRotate(brother);</span><br><span class="line">                    <span class="comment">// 右侄子成为新的兄弟</span></span><br><span class="line">                    brother = parentOf(x).left;</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="comment">// 左侄子为红色，兄弟改为父节点颜色</span></span><br><span class="line">                brother.color = parentOf(x).color;</span><br><span class="line">                <span class="comment">// 父节点和左侄子变成黑色</span></span><br><span class="line">                brother.left.color = BLACK;</span><br><span class="line">                parentOf(x).color = BLACK;</span><br><span class="line">                <span class="comment">// 兄弟节点上提(右旋父节点)</span></span><br><span class="line">                rightRotate(parentOf(x));</span><br><span class="line">                <span class="comment">// x指向根节点</span></span><br><span class="line">                x = root;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 更新x为黑色</span></span><br><span class="line">    x.color = BLACK;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>参考文档</p>
<ul>
<li>删除节点后，如何调整红黑树，有清晰且与jdk源码一致的讲解：<a href="https://juejin.cn/post/6844903842513944583">自己手写HashMap——红黑树的Java实现</a></li>
<li>其他参考：<a href="https://tech.meituan.com/2016/12/02/redblack-tree.html">红黑树深入剖析及Java实现</a></li>
</ul>
<h1 id="3-絮絮叨叨"><a href="#3-絮絮叨叨" class="headerlink" title="3. 絮絮叨叨"></a>3. 絮絮叨叨</h1><ul>
<li>红黑树，自己差不多学了两周，菜鸟就是这么龟速</li>
<li>而且，关于删除或新增节点的调整，过一段时间就会忘记</li>
<li>这也是由于自己理解不到位，存在死记硬背的情况 😂</li>
<li>红黑树的删除或新增节点时的调整，应该属于高阶问题。面试被问到，能回答那就是加分项（毕竟我的追求不高）</li>
</ul>
<p> 红黑树的重要知识点 </p>
<ol>
<li>从二叉搜索树 → AVL，严格控制左右子树高度差，避免二叉搜索树退化成链表（时间复杂度从<br>O(log 2N) 退化成O(N)</li>
<li>从AVL →  红黑树，牺牲严格的平衡要求，以换取新增&#x2F;删除节点时少量的旋转操作，平均性能优于AVL；通过红黑规则，保证在最坏的情况下，也能拥有O(log2N)的时间复杂度</li>
<li>红黑树的应用：Java的TreeMap、TreeSet、HashMap(JDK1.8)；linux底层的CFS进程调度算法中，vruntime使用红黑树进行存储；多路复用技术的Epoll，其核心结构是红黑树 + 双向链表。</li>
<li>红黑规则</li>
<li>红黑树节点的定义、红黑树的定义、红黑树的左旋、右旋操作</li>
<li>红黑树新增节点后的调整，记住左儿子的情况，举一反三右儿子的情况</li>
<li>红黑树删除节点后的调整，记住左儿子的情况，举一反三右儿子的情况</li>
</ol>
<p>后来在学习的过程中，发现了一些还不错的博客</p>
<ul>
<li>对红黑树的增加、删除节点的调整讲得不错（虽然自己也没有仔细看）：<a href="https://mr-dai.github.io/java_collection_treemap/">Java TreeMap 源码解析</a></li>
<li><a href="https://www.jianshu.com/p/e136ec79235cl">30张图带你彻底理解红黑树</a></li>
<li><a href="https://www.cnblogs.com/skywang12345/p/3245399.html">红黑树(一)之 原理和算法详细介绍</a></li>
</ul>
]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>其他</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>其他</tag>
      </tags>
  </entry>
  <entry>
    <title>经典题思路</title>
    <url>/posts/3d5a66a4/</url>
    <content><![CDATA[<h1 id="递归"><a href="#递归" class="headerlink" title="递归"></a>递归</h1><h2 id="爬楼梯-斐波那契"><a href="#爬楼梯-斐波那契" class="headerlink" title="爬楼梯 斐波那契"></a>爬楼梯 斐波那契</h2><ul>
<li>直接递归</li>
<li>hash表</li>
<li>定义两个变量</li>
</ul>
<h2 id="两数之和（leetcode-1）"><a href="#两数之和（leetcode-1）" class="headerlink" title="两数之和（leetcode 1）"></a>两数之和（leetcode 1）</h2><ul>
<li>暴力求解</li>
<li>hashMap避免二次扫描</li>
</ul>
<h2 id="合并两个有序数组-leetcode-88"><a href="#合并两个有序数组-leetcode-88" class="headerlink" title="合并两个有序数组(leetcode 88)"></a>合并两个有序数组(leetcode 88)</h2><ul>
<li>利用Arrays的方法，合并后再排序</li>
<li>临时数组+双指针(取小)</li>
<li>双指针（倒序遍历，取大）</li>
</ul>
<h2 id="移动零-（leetcode283）"><a href="#移动零-（leetcode283）" class="headerlink" title="移动零 （leetcode283）"></a>移动零 （leetcode283）</h2><ul>
<li>双指针（一个指向非零，一个指向挪动的目标位置）</li>
</ul>
<h2 id="找到所有数组中消失的数字（leetcode-448）"><a href="#找到所有数组中消失的数字（leetcode-448）" class="headerlink" title="找到所有数组中消失的数字（leetcode 448）"></a>找到所有数组中消失的数字（leetcode 448）</h2><ul>
<li>标记下标法（负号或者加某个数）</li>
</ul>
<h1 id="链表-（递归理解为链表变短了）"><a href="#链表-（递归理解为链表变短了）" class="headerlink" title="链表 （递归理解为链表变短了）"></a>链表 （递归理解为链表变短了）</h1><h2 id="合并两个有序链表-（leetcode-21）"><a href="#合并两个有序链表-（leetcode-21）" class="headerlink" title="合并两个有序链表 （leetcode 21）"></a>合并两个有序链表 （leetcode 21）</h2><ul>
<li>双指针</li>
<li>递归</li>
</ul>
<h2 id="删除排序链表中的重复元素"><a href="#删除排序链表中的重复元素" class="headerlink" title="删除排序链表中的重复元素"></a>删除排序链表中的重复元素</h2><ul>
<li>双指针</li>
<li>递归</li>
</ul>
<h2 id="环形链表（leetcode-141）（判断是否有环）"><a href="#环形链表（leetcode-141）（判断是否有环）" class="headerlink" title="环形链表（leetcode 141）（判断是否有环）"></a>环形链表（leetcode 141）（判断是否有环）</h2><ul>
<li>hash表法</li>
<li>快慢指针（是否相遇）</li>
</ul>
<h2 id="环形链表（leetcode-142）（判环和入环第一个位置）"><a href="#环形链表（leetcode-142）（判环和入环第一个位置）" class="headerlink" title="环形链表（leetcode 142）（判环和入环第一个位置）"></a>环形链表（leetcode 142）（判环和入环第一个位置）</h2><ul>
<li>快慢指针（相遇后，都一步一步移动）</li>
</ul>
<h2 id="相交链表-（leetcode-160）"><a href="#相交链表-（leetcode-160）" class="headerlink" title="相交链表 （leetcode 160）"></a>相交链表 （leetcode 160）</h2><ul>
<li>穷举</li>
<li>hash表法</li>
<li>双指针（移动到尾时，指向另一个链表头）</li>
<li>双指针（计算长度差d，然后长的先移动d）</li>
</ul>
<h2 id="反转链表（leetcode-206）"><a href="#反转链表（leetcode-206）" class="headerlink" title="反转链表（leetcode 206）"></a>反转链表（leetcode 206）</h2><ul>
<li>preNode</li>
</ul>
<h2 id="回文链表（leetcode-234）"><a href="#回文链表（leetcode-234）" class="headerlink" title="回文链表（leetcode 234）"></a>回文链表（leetcode 234）</h2><ul>
<li>复制到数组中，然后双指针（相遇前值是否相同）</li>
<li>快慢指针找到中点，然后后半部分反转后，再逐一比较两部分（注意链表节点数目为奇数时）</li>
</ul>
<h2 id="链表的中间节点（leetcode-876）"><a href="#链表的中间节点（leetcode-876）" class="headerlink" title="链表的中间节点（leetcode 876）"></a>链表的中间节点（leetcode 876）</h2><ul>
<li>复制到数组中，找中间下标</li>
<li>快慢指针找中点</li>
</ul>
<h2 id="链表中倒数第k个节点-（leetcode-876）"><a href="#链表中倒数第k个节点-（leetcode-876）" class="headerlink" title="链表中倒数第k个节点 （leetcode 876）"></a>链表中倒数第k个节点 （leetcode 876）</h2><ul>
<li>hash表存正数位置</li>
<li>遍历得长度，再遍历</li>
<li>快慢指针（使得两个指针相距k-1,然后步长都为1，快指针到表尾时即可）</li>
</ul>
<h1 id="栈和队列"><a href="#栈和队列" class="headerlink" title="栈和队列"></a>栈和队列</h1><h2 id="用栈实现队列-（leetcode-232）"><a href="#用栈实现队列-（leetcode-232）" class="headerlink" title="用栈实现队列 （leetcode 232）"></a>用栈实现队列 （leetcode 232）</h2><ul>
<li>两个栈（输入栈和输出栈）</li>
</ul>
<h2 id="字符串解码（leetcode-394）"><a href="#字符串解码（leetcode-394）" class="headerlink" title="字符串解码（leetcode 394）"></a>字符串解码（leetcode 394）</h2><ul>
<li>栈，中括号配对后，弹栈，看左中括号右边的字符（注意数字可以是多位数）</li>
</ul>
<h1 id="树"><a href="#树" class="headerlink" title="树"></a>树</h1><h2 id="二叉树的中序遍历（leetcode-94）"><a href="#二叉树的中序遍历（leetcode-94）" class="headerlink" title="二叉树的中序遍历（leetcode 94）"></a>二叉树的中序遍历（leetcode 94）</h2><h2 id="二叉树的前序遍历（leetcode-144）"><a href="#二叉树的前序遍历（leetcode-144）" class="headerlink" title="二叉树的前序遍历（leetcode 144）"></a>二叉树的前序遍历（leetcode 144）</h2><h2 id="二叉树的后序遍历（leetcode-145）"><a href="#二叉树的后序遍历（leetcode-145）" class="headerlink" title="二叉树的后序遍历（leetcode 145）"></a>二叉树的后序遍历（leetcode 145）</h2><h2 id="对称二叉树（leetcode-101）"><a href="#对称二叉树（leetcode-101）" class="headerlink" title="对称二叉树（leetcode 101）"></a>对称二叉树（leetcode 101）</h2><ul>
<li>递归（只要不相等就退出）</li>
<li>队列</li>
</ul>
<h2 id="二叉树的最大深度-（leetcode-104）"><a href="#二叉树的最大深度-（leetcode-104）" class="headerlink" title="二叉树的最大深度 （leetcode 104）"></a>二叉树的最大深度 （leetcode 104）</h2><ul>
<li>递归遍历</li>
<li>队列</li>
</ul>
<h2 id="平衡二叉树（leetcode-）（判断是否为平衡二叉树）"><a href="#平衡二叉树（leetcode-）（判断是否为平衡二叉树）" class="headerlink" title="平衡二叉树（leetcode ）（判断是否为平衡二叉树）"></a>平衡二叉树（leetcode ）（判断是否为平衡二叉树）</h2><ul>
<li>递归（从上往下递归，从下往上回溯）</li>
</ul>
<h2 id="翻转二叉树-（leetcode-226）"><a href="#翻转二叉树-（leetcode-226）" class="headerlink" title="翻转二叉树 （leetcode 226）"></a>翻转二叉树 （leetcode 226）</h2><ul>
<li>递归</li>
</ul>
<p>查找算法：<br>二分<br>顺序<br>插值<br>斐波那契<br>树表<br>分块<br>哈希</p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>其他</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>其他</tag>
      </tags>
  </entry>
  <entry>
    <title>1.线性dp</title>
    <url>/posts/f6a5549/</url>
    <content><![CDATA[<h2 id="一、dp的引入"><a href="#一、dp的引入" class="headerlink" title="一、dp的引入"></a>一、dp的引入</h2><p>动态规划（简称dp）是指把一个问题分解为若干个子问题，通过局部最优解得到全局最优的一种算法策略或者说一种思想方法。简单来讲，就是说用一个数组表示我们要求的问题的答案：如果你知道前一个问题的答案，你就可以推出后一个问题的答案。dp有以下几个常见的概念： </p>
<p>1.状态：指当前所考虑的子问题的情况。例如背包的已用体积、区间的起止点，以及用状态压缩手段压缩后的状态。</p>
<p>2.状态转移：指由前一个子问题的答案推出当前问题的答案。一般来讲会由一个表示赋值的等式给出，称为状态转移方程。</p>
<p>3.无后效性：指当前子问题的处理策略与后边问题的解答无关。要记住我们是从子问题的答案推出新问题的答案，与这个子问题答案怎么来的无关。</p>
<p>总的来讲，dp一般有以下三个步骤：</p>
<p>1.设计状态：指设计出合适的dp数组以及规定dp数组的含义。设计出的dp数组要能够形容各种状态并且能无后效性地在状态之间进行转移。</p>
<p>2.推理状态转移方程：顾名思义，关键在于如何从已知问题的答案推出当前问题的答案，有的时候需要多个方程，有的时候一个方程要包含多个子状态。</p>
<p>3.确定边界条件：递推的初值或者说记忆化搜索的回溯条件，以及各个数组的初值。</p>
<p>举个例子，以在学习递推时就学过的台阶问题为例，如果把这个当成dp：</p>
<p>问题：一个人走楼梯，一次可以跨一阶，可以跨两阶，求到达第n阶有多少种办法。</p>
<p>设计状态：dp[i]表示到达第i阶的方法数</p>
<p> 状态转移：第i阶可以来自第(i−1)阶或第(i−2)阶，dp[i]&#x3D;dp[i−1]+dp[i−2]</p>
<p> 边界条件：到达第1阶只有一种办法，dp[0]&#x3D;dp[1]&#x3D;1</p>
<h2 id="二、线性结构上的dp"><a href="#二、线性结构上的dp" class="headerlink" title="二、线性结构上的dp"></a>二、线性结构上的dp</h2><p>线性dp往往指在一个序列上进行的dp，当然也可能有两个甚至多个序列。一般来讲，线性dp的三个步骤分别有以下特点：</p>
<p>设计状态：至少有一维表示当前考虑的对象在数列上的位置。</p>
<p>状态转移：必须找到这条线上前面的位置的dp值来推出当前位置的dp值。</p>
<p>边界条件：第一个位置单独讨论。</p>
<p><img src="/posts/f6a5549/asset/1688198173975.png" alt="1688198173975"></p>
<p><img src="/posts/f6a5549/asset/1688198475925.png" alt="1688198475925"></p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>动态规划</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>动态规划</tag>
      </tags>
  </entry>
  <entry>
    <title>2.背包</title>
    <url>/posts/335b2125/</url>
    <content><![CDATA[<h2 id="0-x2F-1背包"><a href="#0-x2F-1背包" class="headerlink" title="0&#x2F;1背包"></a>0&#x2F;1背包</h2><p><img src="/posts/335b2125/asset/1688200696018.png" alt="1688200696018"></p>
<p><img src="/posts/335b2125/asset/1688201101037.png" alt="1688201101037"></p>
<p><img src="/posts/335b2125/asset/1688201143398.png" alt="1688201143398"></p>
<p><img src="/posts/335b2125/asset/1688201592374.png" alt="1688201592374"></p>
<p><img src="/posts/335b2125/asset/1688201618504.png" alt="1688201618504"></p>
<p><img src="/posts/335b2125/asset/1688201851235.png" alt="1688201851235"></p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>动态规划</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>动态规划</tag>
      </tags>
  </entry>
  <entry>
    <title>线段树详解</title>
    <url>/posts/95304e2e/</url>
    <content><![CDATA[<h1 id="线段树详解-（原理，实现与应用）"><a href="#线段树详解-（原理，实现与应用）" class="headerlink" title="线段树详解 （原理，实现与应用）"></a>线段树详解 （原理，实现与应用）</h1><p><a href="https://www.cnblogs.com/AC-King/p/7789013.html">https://www.cnblogs.com/AC-King/p/7789013.html</a></p>
<p>目录：</p>
<p>一：综述</p>
<p>二：原理</p>
<p>三：递归实现</p>
<p>四：非递归原理</p>
<p>五：非递归实现</p>
<p>六：线段树解题模型</p>
<p>七：扫描线</p>
<p>八：可持久化 (主席树)</p>
<p>九：练习题</p>
<h1 id="一：综述"><a href="#一：综述" class="headerlink" title="一：综述"></a><strong>一：综述</strong></h1><p>假设有编号从1到n的n个点，每个点都存了一些信息，用[L,R]表示下标从L到R的这些点。</p>
<p>线段树的用处就是，对编号连续的一些点进行修改或者统计操作，修改和统计的复杂度都是O(log2(n)).</p>
<p>线段树的原理，就是，将[1,n]分解成若干特定的子区间(数量不超过4*n),然后，将每个区间[L,R]都分解为</p>
<p>少量特定的子区间，通过对这些少量子区间的修改或者统计，来实现快速对[L,R]的修改或者统计。</p>
<p>由此看出，用线段树统计的东西，必须符合<strong>区间加法</strong>，否则，不可能通过分成的子区间来得到[L,R]的统计结果。</p>
<p><strong>符合区间加法的例子：</strong></p>
<p>数字之和——总数字之和 &#x3D; 左区间数字之和 + 右区间数字之和</p>
<p>最大公因数(GCD)——总GCD &#x3D; gcd( 左区间GCD , 右区间GCD );</p>
<p>最大值——总最大值&#x3D;max(左区间最大值，右区间最大值)</p>
<p><strong>不符合区间加法的例子：</strong></p>
<p>众数——只知道左右区间的众数，没法求总区间的众数</p>
<p>01序列的最长连续零——只知道左右区间的最长连续零，没法知道总的最长连续零</p>
<p>一个问题，只要能化成对一些连续点的修改和统计问题，基本就可以用线段树来解决了，具体怎么转化在第六节会讲。</p>
<p>由于点的信息可以千变万化，所以线段树是一种非常灵活的数据结构，可以做的题的类型特别多，只要会转化。</p>
<p>线段树当然是可以维护线段信息的，因为线段信息也是可以转换成用点来表达的（每个点代表一条线段）。</p>
<p>所以在以下对结构的讨论中，都是对点的讨论，线段和点的对应关系在第七节扫描线中会讲。</p>
<p>本文二到五节是讲对线段树操作的原理和实现。</p>
<p>六到八节介绍了线段树解题模型，以及一些例题。</p>
<p>初学者可以先看这篇文章： <a href="http://blog.csdn.net/zearot/article/details/52280189">线段树从零开始</a></p>
<h1 id="二：原理"><a href="#二：原理" class="headerlink" title="二：原理"></a><strong>二：原理</strong></h1><p>**<em>*（注：由于线段树的每个节点代表一个区间，以下叙述中不区分节点和区间，只是根据语境需要，选择合适的词）*</em><br>**</p>
<p>线段树本质上是维护下标为1,2,..,n的n个按顺序排列的数的信息，所以，其实是“点树”，是维护n的点的信息，至于每个点的数据的含义可以有很多，</p>
<p>在对线段操作的线段树中，每个点代表一条线段，在用线段树维护数列信息的时候，每个点代表一个数，但本质上都是每个点代表一个数。以下，在讨论线段树的时候，区间[L,R]指的是下标从L到R的这(R-L+1)个数，而不是指一条连续的线段。只是有时候这些数代表实际上一条线段的统计结果而已。</p>
<p>线段树是将每个区间[L,R]分解成[L,M]和[M+1,R] (其中M&#x3D;(L+R)&#x2F;2 这里的除法是整数除法，即对结果下取整)直到 L&#x3D;&#x3D;R 为止。 </p>
<p>开始时是区间[1,n] ,通过递归来逐步分解，假设根的高度为1的话，树的最大高度为</p>
<p>线段树对于每个n的分解是唯一的，所以n相同的线段树结构相同，这也是实现可持久化线段树的基础。</p>
<p>下图展示了区间[1,13]的分解过程：</p>
<p><img src="/posts/95304e2e/asset/20150908231214395.bmp" alt="img"></p>
<p>上图中，每个区间都是一个节点，每个节点存自己对应的区间的统计信息。</p>
<h2 id="1-线段树的点修改："><a href="#1-线段树的点修改：" class="headerlink" title="(1)线段树的点修改："></a><strong>(1)线段树的点修改：</strong></h2><p>假设要修改[5]的值，可以发现，每层只有一个节点包含[5],所以修改了[5]之后，只需要每层更新一个节点就可以线段树每个节点的信息都是正确的，所以修改次数的最大值为层数<img src="https://img-blog.csdn.net/20150908232141714" alt="img">。</p>
<p>复杂度O(log2(n))</p>
<h2 id="2-线段树的区间查询："><a href="#2-线段树的区间查询：" class="headerlink" title="(2)线段树的区间查询："></a><strong>(2)线段树的区间查询：</strong></h2><p>线段树能快速进行区间查询的基础是下面的定理：</p>
<p><strong>定理：n&gt;&#x3D;3时，一个[1,n]的线段树可以将[1,n]的任意子区间[L,R]分解为不超过个子区间。</strong></p>
<p>这样，在查询[L,R]的统计值的时候，只需要访问不超过<img src="https://img-blog.csdn.net/20150908233339347" alt="img">个节点，就可以获得[L,R]的统计信息，实现了O(log2(n))的区间查询。</p>
<p>下面给出证明：</p>
<p>**(2.1)**先给出一个粗略的证明（结合下图）：</p>
<p>先考虑树的最下层，将所有在区间[L,R]内的点选中，然后，若相邻的点的直接父节点是同一个，那么就用这个父节点代替这两个节点（父节点在上一层）。这样操作之后，本层最多剩下两个节点。若最左侧被选中的节点是它父节点的右子树，那么这个节点会被剩下。若最右侧被选中的节点是它的父节点的左子树，那么这个节点会被剩下。中间的所有节点都被父节点取代。</p>
<p>对最下层处理完之后，考虑它的上一层，继续进行同样的处理，可以发现，每一层最多留下2个节点，其余的节点升往上一层，这样可以说明分割成的区间（节点）个数是大概是树高的两倍左右。</p>
<p>下图为n&#x3D;13的线段树，区间[2,12]，按照上面的叙述进行操作的过程图：</p>
<p><img src="/posts/95304e2e/asset/20150909172357585.png" alt="img"></p>
<p>由图可以看出：在n&#x3D;13的线段树中，[2,12]&#x3D;[2] + [3,4] + [5,7] + [8,10] + [11,12] 。</p>
<p>**(2.2)**然后给出正式一点的证明：</p>
<p><strong>定理：n&gt;&#x3D;3时，一个[1,n]的线段树可以将[1,n]的任意子区间[L,R]分解为不超过<img src="https://img-blog.csdn.net/20150908233339347" alt="img">个子区间。</strong></p>
<p>用数学归纳法，证明上面的定理：</p>
<p>首先,n&#x3D;3,4,5时，用穷举法不难证明定理成立。</p>
<p>假设对于n&#x3D; 3,4,5,…,k-1上式都成立，下面来证明对于n&#x3D;k ( k&gt;&#x3D;6 )成立：</p>
<p>分为4种情况来证明：</p>
<p><strong>情况一：</strong>[L,R]包含根节点(L&#x3D;1且R&#x3D;n)，此时，[L,R]被分解为了一个节点，定理成立。</p>
<p><strong>情况二：</strong>[L,R]包含根节点的左子节点，此时[L,R]一定不包含根的右子节点（因为如果包含，就可以合并左右子节点，</p>
<p>用根节点替代，此时就是情况一）。这时，以右子节点为根的这个树的元素个数为。</p>
<p>[L,R]分成的子区间由两部分组成：</p>
<p>一：根的左子结点，区间数为1 </p>
<p>二：以根的右子节点为根的树中，进行区间查询，这个可以递归使用本定理。</p>
<p>由归纳假设可得，[L,R]一共被分成了个区间。</p>
<p><strong>情况三</strong>：跟情况二对称，不一样的是，以根的左子节点为根的树的元素个数为。</p>
<p>[L,R]一共被分成了个区间。</p>
<p>从公式可以看出，情况二的区间数小于等于情况三的区间数，于是只需要证明情况三的区间数符合条件就行了。</p>
<p><img src="/posts/95304e2e/asset/20150909175521708.png" alt="img"></p>
<p>于是，情况二和情况三定理成立。</p>
<p><strong>情况四：</strong>[L,R]不包括根节点以及根节点的左右子节点。</p>
<p>于是，剩下的层，每层最多两个节点（参考粗略证明中的内容)。</p>
<p>于是[L,R]最多被分解成了个区间，定理成立。</p>
<p>上面只证明了<img src="https://img-blog.csdn.net/20150909175955762" alt="img">是上界，但是，其实它是最小上界。</p>
<p>n&#x3D;3,4时，有很多组区间的分解可以达到最小上界。</p>
<p>当n&gt;4时，当且仅当n&#x3D;2^t (t&gt;&#x3D;3),L&#x3D;2,R&#x3D;2^t -1 时，区间[L,R]的分解可以达到最小上界<img src="https://img-blog.csdn.net/20150909175955762" alt="img">。</p>
<p>就不证明了，有兴趣可以自己去证明。</p>
<p>下图是n&#x3D;16 , L&#x3D;2 , R&#x3D;15 时的操作图，此图展示了达到最小上界的树的结构。</p>
<p><img src="/posts/95304e2e/asset/20150909002033412.png" alt="img"></p>
<h2 id="3-线段树的区间修改："><a href="#3-线段树的区间修改：" class="headerlink" title="(3)线段树的区间修改："></a><strong>(3)线段树的区间修改：</strong></h2><p>线段树的区间修改也是将区间分成子区间，但是要加一个标记，称作懒惰标记。</p>
<p><strong>标记的含义：</strong></p>
<p><strong>本节点的统计信息已经根据标记更新过了，但是本节点的子节点仍需要进行更新。</strong></p>
<p>即，如果要给一个区间的所有值都加上1，那么，实际上并没有给这个区间的所有值都加上1，而是打个标记，记下来，这个节点所包含的区间需要加1.打上标记后，要根据标记更新本节点的统计信息，比如，如果本节点维护的是区间和，而本节点包含5个数，那么，打上+1的标记之后，要给本节点维护的和+5。这是向下延迟修改，但是向上显示的信息是修改以后的信息，所以查询的时候可以得到正确的结果。有的标记之间会相互影响，所以比较简单的做法是，每递归到一个区间，首先下推标记（若本节点有标记，就下推标记），然后再打上新的标记，这样仍然每个区间操作的复杂度是O(log2(n))。</p>
<p>标记有<strong>相对标记</strong>和<strong>绝对标记</strong>之分：</p>
<p><strong>相对标记</strong>是将区间的所有数+a之类的操作，标记之间可以共存，跟打标记的顺序无关（跟顺序无关才是重点）。</p>
<p>所以，可以在区间修改的时候不下推标记，留到查询的时候再下推。</p>
<p>   <strong>注意：</strong>如果区间修改时不下推标记，那么PushUp函数中，必须考虑本节点的标记。</p>
<p>​         而如果所有操作都下推标记，那么PushUp函数可以不考虑本节点的标记，因为本节点的标记一定已经被下推了（也就是对本节点无效了）</p>
<p><strong>绝对标记</strong>是将区间的所有数变成a之类的操作，打标记的顺序直接影响结果，</p>
<p>所以这种标记在区间修改的时候必须下推旧标记，不然会出错。</p>
<p>注意，有多个标记的时候，标记下推的顺序也很重要，错误的下推顺序可能会导致错误。</p>
<p>之所以要区分两种标记，是因为<strong>非递归线段树</strong>只能维护相对标记。</p>
<p>因为非递归线段树是自底向上直接修改分成的每个子区间，所以根本做不到在区间修改的时候下推标记。</p>
<p>非递归线段树一般不下推标记，而是自下而上求答案的过程中，根据标记更新答案。</p>
<h2 id="4-线段树的存储结构："><a href="#4-线段树的存储结构：" class="headerlink" title="(4)线段树的存储结构："></a><strong>(4)线段树的存储结构：</strong></h2><p>线段树是用数组来模拟树形结构，对于每一个节点R ,左子节点为 2<em>R (一般写作R&lt;&lt;1)右子节点为 2</em>R+1（一般写作R&lt;&lt;1|1）</p>
<p>然后以1为根节点，所以，整体的统计信息是存在节点1中的。</p>
<p>这么表示的原因看下图就很明白了，左子树的节点标号都是根节点的两倍，右子树的节点标号都是左子树+1：</p>
<p><img src="/posts/95304e2e/asset/20150909010827440.png" alt="img"></p>
<p>线段树需要的数组元素个数是：,一般都开4倍空间，比如： int A[n&lt;&lt;2];</p>
<h1 id="三：递归实现"><a href="#三：递归实现" class="headerlink" title="三：递归实现"></a><strong>三：递归实现</strong></h1><p>以下以维护数列区间和的线段树为例，演示最基本的线段树代码。</p>
<p><strong>(0)定义：</strong></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> maxn 100007  <span class="comment">//元素总个数  </span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ls l,m,rt&lt;&lt;1  </span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> rs m+1,r,rt&lt;&lt;1|1  </span></span><br><span class="line"><span class="type">int</span> Sum[maxn&lt;&lt;<span class="number">2</span>],Add[maxn&lt;&lt;<span class="number">2</span>];<span class="comment">//Sum求和，Add为懒惰标记   </span></span><br><span class="line"><span class="type">int</span> A[maxn],n;<span class="comment">//存原数组数据下标[1,n]   </span></span><br></pre></td></tr></table></figure>



<p><strong>(1)建树：</strong></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//PushUp函数更新节点信息 ，这里是求和  </span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">PushUp</span><span class="params">(<span class="type">int</span> rt)</span></span>&#123;Sum[rt]=Sum[rt&lt;&lt;<span class="number">1</span>]+Sum[rt&lt;&lt;<span class="number">1</span>|<span class="number">1</span>];&#125;  </span><br><span class="line"><span class="comment">//Build函数建树   </span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Build</span><span class="params">(<span class="type">int</span> l,<span class="type">int</span> r,<span class="type">int</span> rt)</span></span>&#123; <span class="comment">//l,r表示当前节点区间，rt表示当前节点编号  </span></span><br><span class="line">    <span class="keyword">if</span>(l==r) &#123;<span class="comment">//若到达叶节点   </span></span><br><span class="line">        Sum[rt]=A[l];<span class="comment">//储存数组值   </span></span><br><span class="line">        <span class="keyword">return</span>;  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="type">int</span> m=(l+r)&gt;&gt;<span class="number">1</span>;  </span><br><span class="line">    <span class="comment">//左右递归   </span></span><br><span class="line">    <span class="built_in">Build</span>(l,m,rt&lt;&lt;<span class="number">1</span>);  </span><br><span class="line">    <span class="built_in">Build</span>(m+<span class="number">1</span>,r,rt&lt;&lt;<span class="number">1</span>|<span class="number">1</span>);  </span><br><span class="line">    <span class="comment">//更新信息   </span></span><br><span class="line">    <span class="built_in">PushUp</span>(rt);  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>







<p><strong>(2)点修改：</strong></p>
<p>假设A[L]+&#x3D;C:</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">Update</span><span class="params">(<span class="type">int</span> L,<span class="type">int</span> C,<span class="type">int</span> l,<span class="type">int</span> r,<span class="type">int</span> rt)</span></span>&#123;<span class="comment">//l,r表示当前节点区间，rt表示当前节点编号  </span></span><br><span class="line">    <span class="keyword">if</span>(l==r)&#123;<span class="comment">//到叶节点，修改   </span></span><br><span class="line">        Sum[rt]+=C;  </span><br><span class="line">        <span class="keyword">return</span>;  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="type">int</span> m=(l+r)&gt;&gt;<span class="number">1</span>;  </span><br><span class="line">    <span class="comment">//根据条件判断往左子树调用还是往右   </span></span><br><span class="line">    <span class="keyword">if</span>(L &lt;= m) <span class="built_in">Update</span>(L,C,l,m,rt&lt;&lt;<span class="number">1</span>);  </span><br><span class="line">    <span class="keyword">else</span>       <span class="built_in">Update</span>(L,C,m+<span class="number">1</span>,r,rt&lt;&lt;<span class="number">1</span>|<span class="number">1</span>);  </span><br><span class="line">    <span class="built_in">PushUp</span>(rt);<span class="comment">//子节点更新了，所以本节点也需要更新信息   </span></span><br><span class="line">&#125;   </span><br></pre></td></tr></table></figure>





<p><strong>(3)区间修改：</strong></p>
<p>假设A[L,R]+&#x3D;C</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">Update</span><span class="params">(<span class="type">int</span> L,<span class="type">int</span> R,<span class="type">int</span> C,<span class="type">int</span> l,<span class="type">int</span> r,<span class="type">int</span> rt)</span></span>&#123;<span class="comment">//L,R表示操作区间，l,r表示当前节点区间，rt表示当前节点编号   </span></span><br><span class="line">    <span class="keyword">if</span>(L &lt;= l &amp;&amp; r &lt;= R)&#123;<span class="comment">//如果本区间完全在操作区间[L,R]以内   </span></span><br><span class="line">        Sum[rt]+=C*(r-l+<span class="number">1</span>);<span class="comment">//更新数字和，向上保持正确  </span></span><br><span class="line">        Add[rt]+=C;<span class="comment">//增加Add标记，表示本区间的Sum正确，子区间的Sum仍需要根据Add的值来调整  </span></span><br><span class="line">        <span class="keyword">return</span> ;   </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="type">int</span> m=(l+r)&gt;&gt;<span class="number">1</span>;  </span><br><span class="line">    <span class="built_in">PushDown</span>(rt,m-l+<span class="number">1</span>,r-m);<span class="comment">//下推标记  </span></span><br><span class="line">    <span class="comment">//这里判断左右子树跟[L,R]有无交集，有交集才递归   </span></span><br><span class="line">    <span class="keyword">if</span>(L &lt;= m) <span class="built_in">Update</span>(L,R,C,l,m,rt&lt;&lt;<span class="number">1</span>);  </span><br><span class="line">    <span class="keyword">if</span>(R &gt;  m) <span class="built_in">Update</span>(L,R,C,m+<span class="number">1</span>,r,rt&lt;&lt;<span class="number">1</span>|<span class="number">1</span>);   </span><br><span class="line">    <span class="built_in">PushUp</span>(rt);<span class="comment">//更新本节点信息   </span></span><br><span class="line">&#125;   </span><br></pre></td></tr></table></figure>



<p><strong>(4)区间查询：</strong></p>
<p>询问A[L,R]的和</p>
<p>首先是下推标记的函数：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">PushDown</span><span class="params">(<span class="type">int</span> rt,<span class="type">int</span> ln,<span class="type">int</span> rn)</span></span>&#123;  </span><br><span class="line">    <span class="comment">//ln,rn为左子树，右子树的数字数量。   </span></span><br><span class="line">    <span class="keyword">if</span>(Add[rt])&#123;  </span><br><span class="line">        <span class="comment">//下推标记   </span></span><br><span class="line">        Add[rt&lt;&lt;<span class="number">1</span>]+=Add[rt];  </span><br><span class="line">        Add[rt&lt;&lt;<span class="number">1</span>|<span class="number">1</span>]+=Add[rt];  </span><br><span class="line">        <span class="comment">//修改子节点的Sum使之与对应的Add相对应   </span></span><br><span class="line">        Sum[rt&lt;&lt;<span class="number">1</span>]+=Add[rt]*ln;  </span><br><span class="line">        Sum[rt&lt;&lt;<span class="number">1</span>|<span class="number">1</span>]+=Add[rt]*rn;  </span><br><span class="line">        <span class="comment">//清除本节点标记   </span></span><br><span class="line">        Add[rt]=<span class="number">0</span>;  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>




<p>然后是区间查询的函数：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">Query</span><span class="params">(<span class="type">int</span> L,<span class="type">int</span> R,<span class="type">int</span> l,<span class="type">int</span> r,<span class="type">int</span> rt)</span></span>&#123;<span class="comment">//L,R表示操作区间，l,r表示当前节点区间，rt表示当前节点编号  </span></span><br><span class="line">    <span class="keyword">if</span>(L &lt;= l &amp;&amp; r &lt;= R)&#123;  </span><br><span class="line">        <span class="comment">//在区间内，直接返回   </span></span><br><span class="line">        <span class="keyword">return</span> Sum[rt];  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="type">int</span> m=(l+r)&gt;&gt;<span class="number">1</span>;  </span><br><span class="line">    <span class="comment">//下推标记，否则Sum可能不正确  </span></span><br><span class="line">    <span class="built_in">PushDown</span>(rt,m-l+<span class="number">1</span>,r-m);   </span><br><span class="line">      </span><br><span class="line">    <span class="comment">//累计答案  </span></span><br><span class="line">    <span class="type">int</span> ANS=<span class="number">0</span>;  </span><br><span class="line">    <span class="keyword">if</span>(L &lt;= m) ANS+=<span class="built_in">Query</span>(L,R,l,m,rt&lt;&lt;<span class="number">1</span>);  </span><br><span class="line">    <span class="keyword">if</span>(R &gt;  m) ANS+=<span class="built_in">Query</span>(L,R,m+<span class="number">1</span>,r,rt&lt;&lt;<span class="number">1</span>|<span class="number">1</span>);  </span><br><span class="line">    <span class="keyword">return</span> ANS;  </span><br><span class="line">&#125;   </span><br></pre></td></tr></table></figure>





<p><strong>(5)函数调用:</strong></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//建树   </span></span><br><span class="line"><span class="built_in">Build</span>(<span class="number">1</span>,n,<span class="number">1</span>);   </span><br><span class="line"><span class="comment">//点修改  </span></span><br><span class="line"><span class="built_in">Update</span>(L,C,<span class="number">1</span>,n,<span class="number">1</span>);  </span><br><span class="line"><span class="comment">//区间修改   </span></span><br><span class="line"><span class="built_in">Update</span>(L,R,C,<span class="number">1</span>,n,<span class="number">1</span>);  </span><br><span class="line"><span class="comment">//区间查询   </span></span><br><span class="line"><span class="type">int</span> ANS=<span class="built_in">Query</span>(L,R,<span class="number">1</span>,n,<span class="number">1</span>);  </span><br></pre></td></tr></table></figure>



<p>感谢几位网友指出了我的错误。</p>
<p>我说相对标记在Update时可以不下推，这一点是对的，但是原来的代码是错误的。</p>
<p>因为原来的代码中，PushUP函数是没有考虑本节点的Add值的，如果Update时下推标记，那么PushUp的时候，节点的Add值一定为零，所以不需要考虑Add。</p>
<p>但是，如果Update时暂时不下推标记的话，那么PushUp函数就必须考虑本节点的Add值，否则会导致错误。</p>
<p>为了简便，上面函数中，PushUp函数没有考虑Add标记。所以无论是相对标记还是绝对标记，在更新信息的时候，</p>
<p>到达的每个节点都必须调用PushDown函数来下推标记，另外，代码中，点修改函数中没有PushDown函数，因为这里假设只有点修改一种操作，</p>
<p>如果题目中是点修改和区间修改混合的话，那么点修改中也需要PushDown。</p>
<h1 id="四：非递归原理"><a href="#四：非递归原理" class="headerlink" title="四：非递归原理"></a><strong>四：非递归原理</strong></h1><p>非递归的思路很巧妙，思路以及部分代码实现 来自  清华大学 张昆玮 《统计的力量》 ，有兴趣可以去找来看。</p>
<p>非递归的实现，代码简单（尤其是点修改和区间查询），速度快，建树简单，遍历元素简单。总之能非递归就非递归吧。</p>
<p>不过，要支持区间修改的话，代码会变得复杂，所以区间修改的时候还是要取舍。有个特例，如果区间修改，但是只需要</p>
<p>在所有操作结束之后，一次性下推所有标记，然后求结果，这样的话，非递归写起来也是很方便的。</p>
<p>下面先讲思路，再讲实现。</p>
<h2 id="点修改："><a href="#点修改：" class="headerlink" title="点修改："></a><strong>点修改：</strong></h2><p>非递归的思想总的来说就是自底向上进行各种操作。回忆递归线段树的点修改，首先由根节点1向下递归，找到对应的叶</p>
<p>节点，然后，修改叶节点的值，再向上返回，在函数返回的过程中，更新路径上的节点的统计信息。而非递归线段树的思路是，</p>
<p>如果可以直接找到叶节点，那么就可以直接从叶节点向上更新，而一个节点找父节点是很容易的，编号除以2再下取整就行了。</p>
<p>那么，如何可以直接找到叶节点呢？非递归线段树扩充了普通线段树(假设元素数量为n)，使得所有非叶结点都有两个子结点且叶子结点都在同一层。</p>
<p>来观察一下扩充后的性质：</p>
<p><img src="/posts/95304e2e/asset/20150909220210622.png" alt="img"></p>
<p>可以注意到红色和黑色数字的差是固定的，如果事先算出这个差值，就可以直接找到叶节点。</p>
<p><strong>注意：区分3个概念：原数组下标，线段树中的下标和存储下标。</strong></p>
<p><strong>原数组下标</strong>，是指，需要维护统计信息（比如区间求和）的数组的下标，这里都默认下标从1开始（一般用A数组表示）</p>
<p><strong>线段树下标</strong>，是指，加入线段树中某个位置的下标，比如，原数组中的第一个数，一般会加入到线段树中的第二个位置，</p>
<p>为什么要这么做，后面会讲。</p>
<p><strong>存储下标</strong>，是指该元素所在的叶节点的编号，即实际存储的位置。</p>
<p><strong>【在上面的图片中，红色为原数组下标，黑色为存储下标】</strong></p>
<p>有了这3个概念，下面开始讲区间查询。</p>
<h2 id="点修改下的区间查询："><a href="#点修改下的区间查询：" class="headerlink" title="点修改下的区间查询："></a><strong>点修改下的区间查询：</strong></h2><p>首先，区间的划分没有变，现在关键是如何直接找到被分成的区间。原来是递归查找，判断左右子区间跟[L,R]是否有交点，</p>
<p>若有交点则向下递归。现在要非递归实现，这就是巧妙之处，见下图，以查询[3,11]为例子。</p>
<p><img src="/posts/95304e2e/asset/20150909222744247.png" alt="img"></p>
<p>其实，容易发现，紫色部分的变化，跟原来分析线段树的区间分解的时候是一样的规则，图中多的蓝色是什么意思呢？</p>
<p>首先注意到，蓝色节点刚好在紫色节点的两端。</p>
<p>回忆一下，原来线段树在区间逐层被替代的过程中，哪些节点被留了下来？最左侧的节点，若为其父节点的右子节点，则留下。</p>
<p>最右侧的节点，若为其父节点的左子节点则留下。那么对于包裹着紫色的蓝色节点来看，刚好相反。</p>
<p>比如，以左侧的的蓝色为例，若该节点是其父节点的右子节点，就证明它右侧的那个紫色节点不会留下，会被其父替代，所以没必要在这一步计算，若该节点是其父节点的左子节点，就证明它右侧的那个紫色节点会留在这一层，所以必须在此刻计算，否则以后都不会再计算这个节点了。这样逐层上去，容易发现，对于左侧的蓝色节点来说，只要它是左子节点，那么就要计算对应的右子节点。同理，对于右侧的蓝色节点，只要它是右子节点，就需要计算它对应的左子节点。这个计算一直持续到左右蓝色节点的父亲为同一个的时候，才停止。于是，区间查询，其实就是两个蓝色节点一路向上走，在路径上更新答案。这样，区间修改就变成了两条同时向根走的链，明显复杂度O(log2(n))。并且可以非递归实现。</p>
<p>至此，区间查询也解决了，可以直接找到所有分解成的区间。</p>
<p>但是有一个问题，如果要查询[1,5]怎么办？[1]左边可是没地方可以放置蓝色节点了。</p>
<p>问题的解决办法简单粗暴，原数组的1到n就不存在线段树的1到n了，而是存在线段树的2到n+1,</p>
<p>而开始要建立一颗有n+2个元素的树，空出第一个和最后一个元素的空间。</p>
<p>现在来讲如何对线段树进行扩充。</p>
<p><img src="https://img-blog.csdn.net/20150909220210622?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="img"></p>
<p>再来看这个二叉树，令N&#x3D;8;注意到，该树可以存8个元素，并且[1..7]是非叶节点，[8..15]是叶节点。</p>
<p>也就是说，左下角为N的二叉树，可以存N个元素，并且[1..N-1]是非叶节点,[N..2N-1]是叶节点。</p>
<p>并且，<strong>线段树下标+N-1&#x3D;存储下标</strong> （还记不记得原来对三个下标的定义）</p>
<p>这时，这个线段树存在两段坐标映射：</p>
<p><strong>原数组下标+1&#x3D;线段树下标</strong></p>
<p><strong>线段树下标+N-1&#x3D;存储下标</strong> </p>
<p>联立方程得到：<strong>原数组下标+N&#x3D;存储下标</strong></p>
<p>于是从原数组下标到存储下标的转换及其简单。</p>
<p>下一个问题：N怎么确定？</p>
<p>上面提到了，N的含义之一是，这棵树可以存N个元素，也就是说N必须大于等于n+2</p>
<p>于是，N的定义，N是大于等于n+2的，某个2的次方。</p>
<h2 id="区间修改下的区间查询："><a href="#区间修改下的区间查询：" class="headerlink" title="区间修改下的区间查询："></a><strong>区间修改下的区间查询：</strong></h2><p>方法之一：如果题目许可，可以直接打上标记，最后一次下推所有标记，然后就可以遍历叶节点来获取信息。</p>
<p>方法之二：如果题目查询跟修改混在一起，那么，采用<strong>标记永久化</strong>思想。也就是，不下推标记。</p>
<p>递归线段树是在查询区间的时候下推标记，使得到达每个子区间的时候，Sum已经是正确值。</p>
<p>非递归没法这么做，非递归是从下往上，遇到标记就更新答案。</p>
<p>这题是Add标记，一个区间Add标记表示这个区间所有元素都需要增加Add</p>
<p>Add含义不变，Add仍然表示本节点的Sum已经更新完毕，但是子节点的Sum仍需要更新.</p>
<p>现在就是如何在<strong>查询</strong>的时候根据标记更新答案。</p>
<p>观察下图：</p>
<p><img src="https://img-blog.csdn.net/20150909222740550?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="img"></p>
<p>左边的蓝色节点从下往上走，在蓝色节点到达[1,4]时，注意到，左边蓝色节点之前计算过的所有节点（即[3,4]）都是目前蓝色节点的子节点也就是说，当前蓝色节点的Add是要影响这个节点已经计算过的所有数。多用一个变量来记录这个蓝色节点已经计算过多少个数，根据个数以及当前蓝色节点的Add，来更新最终答案。</p>
<p>更新完答案之后，再加上[5,8]的答案，同时当前蓝色节点计算过的个数要+4(因为[5,8]里有4个数)</p>
<p>然后当这个节点到达[1,8]节点时，可以更新[1,8]的Add.</p>
<p>这里，本来左右蓝色节点相遇之后就不再需要计算了，但是由于有了Add标记，左右蓝色节点的公共祖先上的Add标记会影响目前的所有数，所以还需要一路向上查询到根，沿路根据Add更新答案。</p>
<h2 id="区间修改："><a href="#区间修改：" class="headerlink" title="区间修改："></a><strong>区间修改：</strong></h2><p>这里讲完了查询，再来讲讲<strong>修改</strong>，</p>
<p>修改的时候，给某个区间的Add加上了C，这个区间的子区间向上查询时，会经过这个节点，也就是会计算这个Add,但是</p>
<p>如果路径经过这个区间的父节点，就不会计算这个节点的Add,也就会出错。这里其实跟递归线段树一样，改了某个区间的Add</p>
<p>仍需要向上更新所有包含这个区间的Sum，来保持上面所有节点的正确性。</p>
<h1 id="五：非递归实现"><a href="#五：非递归实现" class="headerlink" title="五：非递归实现"></a><strong>五：非递归实现</strong></h1><p>以下以维护数列区间和的线段树为例，演示最基本的非递归线段树代码。</p>
<p><strong>(0)定义</strong>：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//   </span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> maxn 100007  </span></span><br><span class="line"><span class="type">int</span> A[maxn],n,N;<span class="comment">//原数组,n为原数组元素个数 ,N为扩充元素个数   </span></span><br><span class="line"><span class="type">int</span> Sum[maxn&lt;&lt;<span class="number">2</span>];<span class="comment">//区间和   </span></span><br><span class="line"><span class="type">int</span> Add[maxn&lt;&lt;<span class="number">2</span>];<span class="comment">//懒惰标记   </span></span><br></pre></td></tr></table></figure>





<p><strong>(1)建树:</strong></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//  </span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Build</span><span class="params">(<span class="type">int</span> n)</span></span>&#123;  </span><br><span class="line">    <span class="comment">//计算N的值   </span></span><br><span class="line">    N=<span class="number">1</span>;<span class="keyword">while</span>(N &lt; n+<span class="number">2</span>) N &lt;&lt;= <span class="number">1</span>;  </span><br><span class="line">    <span class="comment">//更新叶节点   </span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=n;++i) Sum[N+i]=A[i];<span class="comment">//原数组下标+N=存储下标  </span></span><br><span class="line">    <span class="comment">//更新非叶节点   </span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=N<span class="number">-1</span>;i&gt;<span class="number">0</span>;--i)&#123;  </span><br><span class="line">        <span class="comment">//更新所有非叶节点的统计信息   </span></span><br><span class="line">        Sum[i]=Sum[i&lt;&lt;<span class="number">1</span>]+Sum[i&lt;&lt;<span class="number">1</span>|<span class="number">1</span>];  </span><br><span class="line">        <span class="comment">//清空所有非叶节点的Add标记   </span></span><br><span class="line">        Add[i]=<span class="number">0</span>;  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;   </span><br></pre></td></tr></table></figure>





<p><strong>(2)点修改：</strong></p>
<p>A[L]+&#x3D;C</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//  </span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Update</span><span class="params">(<span class="type">int</span> L,<span class="type">int</span> C)</span></span>&#123;  </span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> s=N+L;s;s&gt;&gt;=<span class="number">1</span>)&#123;  </span><br><span class="line">        Sum[s]+=C;  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;   </span><br></pre></td></tr></table></figure>





<p><strong>(3)点修改下的区间查询：</strong></p>
<p>求A[L..R]的和（点修改没有使用Add所以不需要考虑）</p>
<p>代码非常简洁，也不难理解,</p>
<p>s和t分别代表之前的论述中的左右蓝色节点，其余的代码根据之前的论述应该很容易看懂了。</p>
<p>s^t^1 在s和t的父亲相同时值为0，终止循环。</p>
<p>两个if是判断s和t分别是左子节点还是右子节点，根据需要来计算Sum</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//  </span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">Query</span><span class="params">(<span class="type">int</span> L,<span class="type">int</span> R)</span></span>&#123;  </span><br><span class="line">    <span class="type">int</span> ANS=<span class="number">0</span>;  </span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> s=N+L<span class="number">-1</span>,t=N+R+<span class="number">1</span>;s^t^<span class="number">1</span>;s&gt;&gt;=<span class="number">1</span>,t&gt;&gt;=<span class="number">1</span>)&#123;  </span><br><span class="line">        <span class="keyword">if</span>(~s&amp;<span class="number">1</span>) ANS+=Sum[s^<span class="number">1</span>];  </span><br><span class="line">        <span class="keyword">if</span>( t&amp;<span class="number">1</span>) ANS+=Sum[t^<span class="number">1</span>];  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="keyword">return</span> ANS;  </span><br><span class="line">&#125;   </span><br></pre></td></tr></table></figure>



<p><strong>(4)区间修改：</strong></p>
<p>A[L..R]+&#x3D;C</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">&lt;span style=<span class="string">&quot;font-size:14px;&quot;</span>&gt;<span class="comment">//  </span></span><br><span class="line"><span class="type">void</span> <span class="built_in">Update</span>(<span class="type">int</span> L,<span class="type">int</span> R,<span class="type">int</span> C)&#123;  </span><br><span class="line">    <span class="type">int</span> s,t,Ln=<span class="number">0</span>,Rn=<span class="number">0</span>,x=<span class="number">1</span>;  </span><br><span class="line">    <span class="comment">//Ln:  s一路走来已经包含了几个数  </span></span><br><span class="line">    <span class="comment">//Rn:  t一路走来已经包含了几个数  </span></span><br><span class="line">    <span class="comment">//x:   本层每个节点包含几个数  </span></span><br><span class="line">    <span class="keyword">for</span>(s=N+L<span class="number">-1</span>,t=N+R+<span class="number">1</span>;s^t^<span class="number">1</span>;s&gt;&gt;=<span class="number">1</span>,t&gt;&gt;=<span class="number">1</span>,x&lt;&lt;=<span class="number">1</span>)&#123;  </span><br><span class="line">        <span class="comment">//更新Sum  </span></span><br><span class="line">        Sum[s]+=C*Ln;  </span><br><span class="line">        Sum[t]+=C*Rn;  </span><br><span class="line">        <span class="comment">//处理Add  </span></span><br><span class="line">        <span class="keyword">if</span>(~s&amp;<span class="number">1</span>) Add[s^<span class="number">1</span>]+=C,Sum[s^<span class="number">1</span>]+=C*x,Ln+=x;  </span><br><span class="line">        <span class="keyword">if</span>( t&amp;<span class="number">1</span>) Add[t^<span class="number">1</span>]+=C,Sum[t^<span class="number">1</span>]+=C*x,Rn+=x;  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="comment">//更新上层Sum  </span></span><br><span class="line">    <span class="keyword">for</span>(;s;s&gt;&gt;=<span class="number">1</span>,t&gt;&gt;=<span class="number">1</span>)&#123;  </span><br><span class="line">        Sum[s]+=C*Ln;  </span><br><span class="line">        Sum[t]+=C*Rn;  </span><br><span class="line">    &#125;   </span><br><span class="line">&#125; &lt;/span&gt;  </span><br></pre></td></tr></table></figure>





<p><strong>(5)区间修改下的区间查询：</strong></p>
<p>求A[L..R]的和</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//  </span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">Query</span><span class="params">(<span class="type">int</span> L,<span class="type">int</span> R)</span></span>&#123;  </span><br><span class="line">    <span class="type">int</span> s,t,Ln=<span class="number">0</span>,Rn=<span class="number">0</span>,x=<span class="number">1</span>;  </span><br><span class="line">    <span class="type">int</span> ANS=<span class="number">0</span>;  </span><br><span class="line">    <span class="keyword">for</span>(s=N+L<span class="number">-1</span>,t=N+R+<span class="number">1</span>;s^t^<span class="number">1</span>;s&gt;&gt;=<span class="number">1</span>,t&gt;&gt;=<span class="number">1</span>,x&lt;&lt;=<span class="number">1</span>)&#123;  </span><br><span class="line">        <span class="comment">//根据标记更新   </span></span><br><span class="line">        <span class="keyword">if</span>(Add[s]) ANS+=Add[s]*Ln;  </span><br><span class="line">        <span class="keyword">if</span>(Add[t]) ANS+=Add[t]*Rn;  </span><br><span class="line">        <span class="comment">//常规求和   </span></span><br><span class="line">        <span class="keyword">if</span>(~s&amp;<span class="number">1</span>) ANS+=Sum[s^<span class="number">1</span>],Ln+=x;  </span><br><span class="line">        <span class="keyword">if</span>( t&amp;<span class="number">1</span>) ANS+=Sum[t^<span class="number">1</span>],Rn+=x;   </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="comment">//处理上层标记  </span></span><br><span class="line">    <span class="keyword">for</span>(;s;s&gt;&gt;=<span class="number">1</span>,t&gt;&gt;=<span class="number">1</span>)&#123;  </span><br><span class="line">        ANS+=Add[s]*Ln;  </span><br><span class="line">        ANS+=Add[t]*Rn;  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="keyword">return</span> ANS;  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>



<h1 id="六：线段树解题模型"><a href="#六：线段树解题模型" class="headerlink" title="六：线段树解题模型"></a>六：线段树解题模型</h1><p>给出线段树解题模型以及一些例题。</p>
<p><img src="/posts/95304e2e/asset/20150915173357612.png" alt="img"></p>
<p>先对图中各个名字给出定义：</p>
<p><strong>问题</strong>：可能可以用线段树解决的问题</p>
<p><strong>目标信息</strong>：由问题转换而成的，为了解决问题而需要统计的信息（可能不满足区间加法）。</p>
<p><strong>点信息</strong>：每个点储存的信息</p>
<p><strong>区间信息</strong>：每个区间维护的信息（线段树节点定义） （必须满足区间加法）</p>
<p>区间信息包括 <strong>统计信息</strong>和<strong>标记</strong></p>
<p><strong>——–统计信息：</strong>统计节点代表的区间的信息，一般自下而上更新</p>
<p><strong>——–标记：</strong>对操作进行标记（在区间修改时需要），一般自上而下传递，或者不传递</p>
<p><strong>区间加法</strong>：实现区间加法的代码</p>
<p><strong>查询</strong>：实现查询操作的代码</p>
<p><strong>修改</strong>：实现修改操作的代码</p>
<p>图中紫线右边是实际线段树的实现，左边是对问题的分析以及转换。</p>
<p>一个问题，若能转换成对一些连续点的修改或者统计，就可以考虑用线段树解决。</p>
<p>首先确定<strong>目标信息</strong>和<strong>点信息</strong>，然后将<strong>目标信息</strong>转换成<strong>区间信息</strong>（必要时，增加信息，使之符合区间加法）。</p>
<p>之后就是线段树的代码实现了，包括：</p>
<p>1.区间加法 </p>
<p>2.建树，点信息到区间信息的转换 </p>
<p>3.每种操作（包括查询，修改）对区间信息的调用，修改</p>
<p>这样，点的信息不同，区间信息不同，线段树可以维护很多种类的信息，所以是一种非常实用的数据结构。</p>
<p>可以解决很多问题，下面给出几个例子来说明。</p>
<h2 id="（1）：字符串哈希"><a href="#（1）：字符串哈希" class="headerlink" title="（1）：字符串哈希"></a><strong>（1）：字符串哈希</strong></h2><p>题目：URAL1989 Subpalindromes   <a href="http://blog.csdn.net/zearot/article/details/38921403">题解</a></p>
<p>给定一个字符串(长度&lt;&#x3D;100000)，有两个操作。  1：改变某个字符。 2：判断某个子串是否构成回文串。 </p>
<p>直接判断会超时。这个题目，是用线段树维护字符串哈希</p>
<p>对于一个字符串a[0],a[1],…,a[n-1] 它对应的哈希函数为a[0]+a[1]*K + a[2]*K^2 +…+a[n-1]*K^(n-1)</p>
<p>再维护一个从右往左的哈希值：a[0]*K^(n-1) + a[1]*K^(n-2) +…+a[n-1]</p>
<p>若是回文串，则左右的哈希值会相等。而左右哈希值相等，则很大可能这是回文串。</p>
<p>若出现误判，可以再用一个K2，进行二次哈希判断，可以减小误判概率。</p>
<p>实现上，哈希值最好对某个质数取余数，这样分布更均匀。</p>
<p>解题模型：</p>
<p>问题经过转换之后：</p>
<p><strong>目标信息：</strong>某个区间的左，右哈希值</p>
<p><strong>点信息：</strong>一个字符</p>
<p>目标信息已经符合区间加法，所以<strong>区间信息&#x3D;目标信息</strong>。</p>
<p>所以线段树的结构为：</p>
<p><strong>区间信息</strong>：区间哈希值</p>
<p><strong>点信息</strong>：一个字符</p>
<p>代码主要需要注意2个部分：</p>
<p>1.区间加法 ：（PushUp函数,Pow[a]&#x3D;K^a）</p>
<p>2.点信息-&gt;区间信息：(叶节点上，区间只包含一个点，所以需要将点信息转换成区间信息)</p>
<p>修改以及查询，在有了区间加法的情况下，没什么难度了。</p>
<p>可以看出，上述解题过程的核心，就是找到<strong>区间信息</strong>， 写好<strong>区间加法</strong>。</p>
<p>下面是维护区间和的部分，下面的代码没有取余，也就是实际上是对2^32取余数，这样其实分布不均匀，容易出现误判：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//   </span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> K 137  </span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> maxn 100001   </span></span><br><span class="line"><span class="type">char</span> str[maxn];  </span><br><span class="line"><span class="type">int</span> Pow[maxn];<span class="comment">//K的各个次方   </span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Node</span>&#123;  </span><br><span class="line">    <span class="type">int</span> KeyL,KeyR;  </span><br><span class="line">    <span class="built_in">Node</span>():<span class="built_in">KeyL</span>(<span class="number">0</span>),<span class="built_in">KeyR</span>(<span class="number">0</span>)&#123;&#125;  </span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">init</span><span class="params">()</span></span>&#123;KeyL=KeyR=<span class="number">0</span>;&#125;  </span><br><span class="line">&#125;node[maxn&lt;&lt;<span class="number">2</span>];  </span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">PushUp</span><span class="params">(<span class="type">int</span> L,<span class="type">int</span> R,<span class="type">int</span> rt)</span></span>&#123;  </span><br><span class="line">    node[rt].KeyL=node[rt&lt;&lt;<span class="number">1</span>].KeyL+node[rt&lt;&lt;<span class="number">1</span>|<span class="number">1</span>].KeyL*Pow[L];  </span><br><span class="line">    node[rt].KeyR=node[rt&lt;&lt;<span class="number">1</span>].KeyR*Pow[R]+node[rt&lt;&lt;<span class="number">1</span>|<span class="number">1</span>].KeyR;  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>





<h2 id="（2）：最长连续零"><a href="#（2）：最长连续零" class="headerlink" title="（2）：最长连续零"></a><strong>（2）：最长连续零</strong></h2><p>题目：Codeforces 527C Glass Carving  <a href="http://blog.csdn.net/zearot/article/details/44759437">题解</a></p>
<p>题意是给定一个矩形，不停地纵向或横向切割，问每次切割后，最大的矩形面积是多少。</p>
<p>最大矩形面积&#x3D;最长的长*最宽的宽</p>
<p>这题，长宽都是10^5，所以，用01序列表示每个点是否被切割，然后，</p>
<p>最长的长就是长的最长连续0的数量+1</p>
<p>最长的宽就是宽的最长连续0的数量+1</p>
<p>于是用线段树维护最长连续零</p>
<p>问题转换成：</p>
<p><strong>目标信息</strong>：区间最长连续零的个数</p>
<p><strong>点信息</strong>：0 或 1</p>
<p>由于目标信息不符合区间加法，所以要扩充目标信息。</p>
<p>转换后的<strong>线段树结构</strong>：</p>
<p><strong>区间信息</strong>：从左，右开始的最长连续零，本区间是否全零，本区间最长连续零。</p>
<p><strong>点信息</strong>：0 或 1</p>
<p>然后还是那2个问题：</p>
<p>1.区间加法：</p>
<p>这里，一个区间的最长连续零，需要考虑3部分：</p>
<p>-（1）：左子区间最长连续零</p>
<p>-（2）：右子区间最长连续零</p>
<p>-（3）：左右子区间拼起来，而在中间生成的连续零（可能长于两个子区间的最长连续零）</p>
<p>而中间拼起来的部分长度，其实是左区间从右开始的最长连续零+右区间从左开始的最长连续零。</p>
<p>所以每个节点需要多两个量，来存从左右开始的最长连续零。</p>
<p>然而，左开始的最长连续零分两种情况，</p>
<p>–（1）：左区间不是全零，那么等于左区间的左最长连续零</p>
<p>–（2）：左区间全零，那么等于左区间0的个数加上右区间的左最长连续零</p>
<p>于是，需要知道左区间是否全零，于是再多加一个变量。</p>
<p>最终，通过维护4个值，达到了维护区间最长连续零的效果。</p>
<p>2.点信息-&gt;区间信息 ： </p>
<p>如果是0，那么  最长连续零&#x3D;左最长连续零&#x3D;右最长连续零&#x3D;1 ，全零&#x3D;true。</p>
<p>如果是1，那么  最长连续零&#x3D;左最长连续零&#x3D;右最长连续零&#x3D;0， 全零&#x3D;false。</p>
<p>至于修改和查询，有了区间加法之后，机械地写一下就好了。</p>
<p>由于这里其实只有对整个区间的查询，所以查询函数是不用写的，直接找根的统计信息就行了。</p>
<p>代码如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//  </span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> maxn 200001  </span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;  </span><br><span class="line"><span class="type">int</span> L[maxn&lt;&lt;<span class="number">2</span>][<span class="number">2</span>];<span class="comment">//从左开始连续零个数   </span></span><br><span class="line"><span class="type">int</span> R[maxn&lt;&lt;<span class="number">2</span>][<span class="number">2</span>];<span class="comment">//从右   </span></span><br><span class="line"><span class="type">int</span> Max[maxn&lt;&lt;<span class="number">2</span>][<span class="number">2</span>];<span class="comment">//区间最大连续零   </span></span><br><span class="line"><span class="type">bool</span> Pure[maxn&lt;&lt;<span class="number">2</span>][<span class="number">2</span>];<span class="comment">//是否全零   </span></span><br><span class="line"><span class="type">int</span> M[<span class="number">2</span>];  </span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">PushUp</span><span class="params">(<span class="type">int</span> rt,<span class="type">int</span> k)</span></span>&#123;<span class="comment">//更新rt节点的四个数据  k来选择两棵线段树  </span></span><br><span class="line">    Pure[rt][k]=Pure[rt&lt;&lt;<span class="number">1</span>][k]&amp;&amp;Pure[rt&lt;&lt;<span class="number">1</span>|<span class="number">1</span>][k];   </span><br><span class="line">    Max[rt][k]=<span class="built_in">max</span>(R[rt&lt;&lt;<span class="number">1</span>][k]+L[rt&lt;&lt;<span class="number">1</span>|<span class="number">1</span>][k],<span class="built_in">max</span>(Max[rt&lt;&lt;<span class="number">1</span>][k],Max[rt&lt;&lt;<span class="number">1</span>|<span class="number">1</span>][k]));  </span><br><span class="line">    L[rt][k]=Pure[rt&lt;&lt;<span class="number">1</span>][k]?L[rt&lt;&lt;<span class="number">1</span>][k]+L[rt&lt;&lt;<span class="number">1</span>|<span class="number">1</span>][k]:L[rt&lt;&lt;<span class="number">1</span>][k];  </span><br><span class="line">    R[rt][k]=Pure[rt&lt;&lt;<span class="number">1</span>|<span class="number">1</span>][k]?R[rt&lt;&lt;<span class="number">1</span>|<span class="number">1</span>][k]+R[rt&lt;&lt;<span class="number">1</span>][k]:R[rt&lt;&lt;<span class="number">1</span>|<span class="number">1</span>][k];  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>





<h2 id="（3）：计数排序"><a href="#（3）：计数排序" class="headerlink" title="（3）：计数排序"></a><strong>（3）：计数排序</strong></h2><p>题目：Codeforces 558E A Simple Task  <a href="http://blog.csdn.net/zearot/article/details/48048559">题解</a></p>
<p>给定一个长度不超过10^5的字符串（小写英文字母），和不超过5000个操作。</p>
<p>每个操作 L R K 表示给区间[L,R]的字符串排序，K&#x3D;1为升序，K&#x3D;0为降序。</p>
<p>最后输出最终的字符串。</p>
<p>题目转换成：</p>
<p><strong>目标信息</strong>：区间的计数排序结果</p>
<p><strong>点信息</strong>：一个字符</p>
<p>这里，目标信息是符合区间加法的，但是为了支持区间操作，还是需要扩充信息。</p>
<p>转换后的<strong>线段树结构</strong>：</p>
<p><strong>区间信息</strong>：区间的计数排序结果，排序标记，排序种类（升，降）</p>
<p><strong>点信息</strong>：一个字符</p>
<p>代码中需要解决的四个问题（难点在于标记下推和区间修改）：</p>
<p>1.区间加法</p>
<p>对应的字符数量相加即可（注意标记是不上传的，所以区间加法不考虑标记）。</p>
<p>2.点信息-&gt;区间信息：把对应字符的数量设置成1，其余为0，排序标记为false。</p>
<p>3.<strong>标记下推</strong></p>
<p>明显，排序标记是<strong>绝对标记</strong>，也就是说，标记对子节点是覆盖式的效果，一旦被打上标记，下层节点的一切信息都无效。</p>
<p>下推标记时，根据自己的排序结果，将元素分成对应的部分，分别装入两个子树。</p>
<p>4.<strong>区间修改</strong></p>
<p>这个是难点，由于要对某个区间进行排序，首先对各个子区间求和（求和之前一定要下推标记，才能保证求的和是正确的）</p>
<p>由于使用的计数排序，所以求和之后，新顺序也就出来了。然后按照排序的顺序按照每个子区间的大小来分配字符。</p>
<p>操作后，每个子区间都被打上了标记。</p>
<p>最后，在所有操作结束之后，一次下推所有标记，就可以得到最终的字符序列。</p>
<p>这里只给出节点定义。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//   </span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Node</span>&#123;  </span><br><span class="line">    <span class="type">int</span> d[<span class="number">26</span>];<span class="comment">//计数排序   </span></span><br><span class="line">    <span class="type">int</span> D;<span class="comment">//总数  </span></span><br><span class="line">    <span class="type">bool</span> sorted;<span class="comment">//是否排好序   </span></span><br><span class="line">    <span class="type">bool</span> Inc;<span class="comment">//是否升序  </span></span><br><span class="line">&#125;;  </span><br><span class="line"></span><br></pre></td></tr></table></figure>





<h2 id="（4）总结："><a href="#（4）总结：" class="headerlink" title="（4）总结："></a><strong>（4）总结：</strong></h2><p>总结一下，线段树解题步骤。</p>
<p><strong>一</strong>：将问题转换成<strong>点信息</strong>和<strong>目标信息</strong>。</p>
<p>即，将问题转换成对一些点的信息的统计问题。</p>
<p><strong>二</strong>：将<strong>目标信息</strong>根据需要扩充成<strong>区间信息</strong></p>
<p>1.增加信息符合区间加法。</p>
<p>2.增加标记支持区间操作。</p>
<p><strong>三</strong>：代码中的主要模块：</p>
<p>1.区间加法 </p>
<p>2.标记下推 </p>
<p>3.点信息-&gt;区间信息 </p>
<p>4.操作（各种操作，包括修改和查询）</p>
<p>完成第一步之后，题目有了可以用线段树解决的可能。</p>
<p>完成第二步之后，题目可以由线段树解决。</p>
<p>第三步就是慢慢写代码了。</p>
<h1 id="七：扫描线"><a href="#七：扫描线" class="headerlink" title="七：扫描线"></a><strong>七：扫描线</strong></h1><p>线段树的一大应用是扫描线。</p>
<p>先把相关题目给出，有兴趣可以去找来练习：</p>
<p>POJ 1177 Picture:给定若干矩形求合并之后的图形周长   <a href="http://blog.csdn.net/zearot/article/details/47685361">题解</a></p>
<p>HDU 1255 覆盖的面积：给定平面上若干矩形,求出被这些矩形覆盖过至少两次的区域的面积.  <a href="http://blog.csdn.net/zearot/article/details/47762543"> 题解</a></p>
<p>HDU 3642 Get The Treasury：给定若干空间立方体，求重叠了3次或以上的体积（这个是扫描面，每个面再扫描线）<a href="http://blog.csdn.net/zearot/article/details/47763001">题解</a></p>
<p>再补充一道稍微需要一点模型转换的扫描线题：</p>
<p>POJ 2482 Stars in your window : 给定一些星星的位置和亮度，求用W*H的矩形能够框住的星星亮度之和最大为多少。</p>
<p>这题是把星星转换成了矩形，把矩形框转换成了点，然后再扫描线。  <a href="http://blog.csdn.net/zearot/article/details/47663851">题解</a></p>
<h2 id="扫描线求重叠矩形面积："><a href="#扫描线求重叠矩形面积：" class="headerlink" title="扫描线求重叠矩形面积："></a><strong>扫描线求重叠矩形面积：</strong></h2><p>考虑下图中的四个矩形：</p>
<p><img src="/posts/95304e2e/asset/20150910075556358.png" alt="img"></p>
<p><img src="/posts/95304e2e/asset/20150910075603559.png" alt="img"></p>
<p><img src="/posts/95304e2e/asset/20150910075607860.png" alt="img"></p>
<p>观察第三个图：</p>
<p>扫描线的思路：使用一条垂直于X轴的直线，从左到右来扫描这个图形，明显，只有在碰到矩形的左边界或者右边界的时候，</p>
<p>这个线段所扫描到的情况才会改变，所以把所有矩形的入边，出边按X值排序。然后根据X值从小到大去处理，就可以</p>
<p>用线段树来维护扫描到的情况。如上图，X1到X8是所有矩形的入边，出边的X坐标。</p>
<p>而红色部分的线段，是这样，如果碰到矩形的入边，就把这条边加入，如果碰到出边，就拿走。红色部分就是有线段覆盖的部分。</p>
<p>要求面积，只需要知道图中的L1到L8。而线段树就是用来维护这个L1到L8的。</p>
<p>扫描线算法流程：</p>
<p>**X1:**首先遇到X1,将第一条线段加入线段树，由线段树统计得到线段长度为L1.</p>
<p>**X2:**然后继续扫描到X2,此时要进行两个动作：</p>
<p>1.计算面积，目前扫过的面积&#x3D;L1*(X2-X1)</p>
<p>2.更新线段。由于X2处仍然是入边，所以往线段树中又加了一条线段，加的这条线段可以参考3幅图中的第一幅。</p>
<p>然后线段树自动得出此时覆盖的线段长度为L2 （注意两条线段有重叠部分，重叠部分的长度只能算一次）</p>
<p>**X3:**继续扫描到X3，步骤同X2</p>
<p>先计算 扫过的面积+&#x3D;L2*(X3-X2)</p>
<p>再加入线段，得到L3.</p>
<p>**X4:**扫描到X4有些不一样了。</p>
<p>首先还是计算  扫过的面积+&#x3D;L3*(X4-X3)</p>
<p>然后这时遇到了第一个矩形的出边，这时要从线段树中删除一条线段。</p>
<p>删除之后的结果是线段树中出现了2条线段，线段树自动维护这两条线段的长度之和L4</p>
<p>讲到这里算法流程应该很清晰了。</p>
<p>首先将所有矩形的入边，出边都存起来，然后根据X值排序。</p>
<p>这里用一个结构体，来存这些信息，然后排序。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//  </span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">LINE</span>&#123;  </span><br><span class="line">    <span class="type">int</span> x;<span class="comment">//横坐标   </span></span><br><span class="line">    <span class="type">int</span> y1,y2;<span class="comment">//矩形纵向线段的左右端点   </span></span><br><span class="line">    <span class="type">bool</span> In;<span class="comment">//标记是入边还是出边   </span></span><br><span class="line">    <span class="type">bool</span> <span class="keyword">operator</span> &lt; (<span class="type">const</span> Line &amp;B)<span class="type">const</span>&#123;<span class="keyword">return</span> x &lt; B.x;&#125;  </span><br><span class="line">&#125;Line[maxn];   </span><br></pre></td></tr></table></figure>




<p>然后扫描的时候，需要两个变量，一个叫PreL，存前一个x的操作结束之后的L值，和X，前一个横坐标。</p>
<p>假设一共有Ln条线段，线段下标从0开始，已经排好序。</p>
<p>那么算法大概是这样：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//  </span></span><br><span class="line"><span class="type">int</span> PreL=<span class="number">0</span>;<span class="comment">//前一个L值,刚开始是0，所以第一次计算时不会引入误差   </span></span><br><span class="line"><span class="type">int</span> X;<span class="comment">//X值   </span></span><br><span class="line"><span class="type">int</span> ANS=<span class="number">0</span>;<span class="comment">//存累计面积  </span></span><br><span class="line"><span class="type">int</span> I=<span class="number">0</span>;<span class="comment">//线段的下标   </span></span><br><span class="line">  </span><br><span class="line"><span class="keyword">while</span>(I &lt; Ln)&#123;  </span><br><span class="line">    <span class="comment">//先计算面积   </span></span><br><span class="line">    ANS+=PreL*(Line[I].x-X);  </span><br><span class="line">    X=Line[I].x;<span class="comment">//更新X值  </span></span><br><span class="line">    <span class="comment">//对所有X相同的线段进行操作   </span></span><br><span class="line">    <span class="keyword">while</span>(I &lt; Ln &amp;&amp; Line[I].x == X)&#123;  </span><br><span class="line">        <span class="comment">//根据入边还是出边来选择加入线段还是移除线段   </span></span><br><span class="line">        <span class="keyword">if</span>(Line[I].In) <span class="built_in">Cover</span>(Line[I].y1,Line[I].y2<span class="number">-1</span>,<span class="number">1</span>,n,<span class="number">1</span>);  </span><br><span class="line">        <span class="keyword">else</span>         <span class="built_in">Uncover</span>(Line[I].y1,Line[I].y2<span class="number">-1</span>,<span class="number">1</span>,n,<span class="number">1</span>);  </span><br><span class="line">        ++I;  </span><br><span class="line">    &#125;   </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>

<p>无论是求面积还是周长，扫描线的结构大概就是上面的样子。</p>
<h2 id="需要解决的几个问题："><a href="#需要解决的几个问题：" class="headerlink" title="需要解决的几个问题："></a><strong>需要解决的几个问题：</strong></h2><p>现在有两点需要说明一下。</p>
<p>（1）：线段树进行线段操作时，每个点的含义（比如为什么Cover函数中，y2后面要-1）。</p>
<p>（2）：线段树如何维护扫描线过程中的覆盖线段长度。</p>
<p>（3）：线段树如何维护扫描线过程中线段的数量。</p>
<h3 id="（1）：线段树中点的含义"><a href="#（1）：线段树中点的含义" class="headerlink" title="（1）：线段树中点的含义"></a><strong>（1）：线段树中点的含义</strong></h3><p>线段树如果没有离散化，那么线段树下标为1，就代表线段[1,2)</p>
<p>线段树下标为K的时候，代表的线段为[K,K+1) （长度为1）</p>
<p>所以，将上面的所有线段都化为[y1,y2)就可以理解了，线段[y1,y2)只包括线段树下标中的y1,y1+1,…,y2-1</p>
<p>当y值的范围是10^9时，就不能再按照上面的办法按值建树了，这时需要离散化。</p>
<p>下面是<strong>离散化</strong>的代码：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//  </span></span><br><span class="line"><span class="type">int</span> Rank[maxn],Rn;  </span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">SetRank</span><span class="params">()</span></span>&#123;<span class="comment">//调用前，所有y值被无序存入Rank数组，下标为[1..Rn]   </span></span><br><span class="line">    <span class="type">int</span> I=<span class="number">1</span>;  </span><br><span class="line">    <span class="comment">//第一步排序   </span></span><br><span class="line">    <span class="built_in">sort</span>(Rank+<span class="number">1</span>,Rank+<span class="number">1</span>+Rn);   </span><br><span class="line">    <span class="comment">//第二步去除重复值   </span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">2</span>;i&lt;=Rn;++i) <span class="keyword">if</span>(Rank[i]!=Rank[i<span class="number">-1</span>]) Rank[++I]=Rank[i];  </span><br><span class="line">    Rn=I;  </span><br><span class="line">    <span class="comment">//此时，所有y值被从小到大无重复地存入Rank数组，下标为[1..Rn]   </span></span><br><span class="line">&#125;   </span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">GetRank</span><span class="params">(<span class="type">int</span> x)</span></span>&#123;<span class="comment">//给定x，求x的下标   </span></span><br><span class="line">    <span class="comment">//二分法求下标   </span></span><br><span class="line">    <span class="type">int</span> L=<span class="number">1</span>,R=Rn,M;<span class="comment">//[L,R] first &gt;=x  </span></span><br><span class="line">    <span class="keyword">while</span>(L!=R)&#123;  </span><br><span class="line">        M=(L+R)&gt;&gt;<span class="number">1</span>;  </span><br><span class="line">        <span class="keyword">if</span>(Rank[M]&lt;x) L=M+<span class="number">1</span>;  </span><br><span class="line">        <span class="keyword">else</span> R=M;  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="keyword">return</span> L;  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>



<p>此时，线段树的下标的含义就变成：如果线段树下标为K,代表线段[ Rank[K] , Rank[K+1] )。</p>
<p>下标为K的线段长度为Rank[K+1]-Rank[K]</p>
<p>所以此时叶节点的线段长度不是1了。</p>
<p>这时，之前的扫描线算法的函数调用部分就稍微的改变了一点：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//   </span></span><br><span class="line"><span class="keyword">if</span>(Line[I].In) <span class="built_in">Cover</span>(<span class="built_in">GetRank</span>(Line[I].y1),<span class="built_in">GetRank</span>(Line[I].y2)<span class="number">-1</span>,<span class="number">1</span>,n,<span class="number">1</span>);  </span><br><span class="line"><span class="keyword">else</span>         <span class="built_in">Uncover</span>(<span class="built_in">GetRank</span>(Line[I].y1),<span class="built_in">GetRank</span>(Line[I].y2)<span class="number">-1</span>,<span class="number">1</span>,n,<span class="number">1</span>);  </span><br></pre></td></tr></table></figure>



<p>看着有点长，其实不难理解，只是多了一步从y值到离散之后的下标的转换。</p>
<p>注意一点，如果下标为K的线段长度为Rank[K+1]-Rank[K]，那么下标为Rn的线段树的长度呢？</p>
<p>其实这个不用担心，Rank[Rn]作为所有y值中的最大值，它肯定是一个线段的右端点，</p>
<p>而右端点求完离散之后的下标还要-1，所以上面的线段覆盖永远不会覆盖到Rn。</p>
<p>所以线段树其实只需要建立Rn-1个元素，因为下标为Rn的无法定义，也不会被访问。</p>
<p>不过有时候留着也有好处，这个看具体实现时自己取舍。</p>
<h3 id="（2）：如何维护覆盖线段长度"><a href="#（2）：如何维护覆盖线段长度" class="headerlink" title="（2）：如何维护覆盖线段长度"></a><strong>（2）：如何维护覆盖线段长度</strong></h3><p>先提一个小技巧，一般，利用两个子节点来更新本节点的函数写成PushUp();</p>
<p>但是，对于比较复杂的子区间合并问题，在区间查询的时候，需要合并若干个子区间。</p>
<p>而合并子区间是没办法用PushUp函数的。于是，对于比较复杂的问题，把单个节点的信息写成一个结构体。</p>
<p>在结构体内重载运算符”+”，来实现区间合并。这样，不仅在PushUp函数可以调用这个加法，区间询问时也可以</p>
<p>调用这个加法，这样更加方便。</p>
<p>下面给出维护线段覆盖长度的节点定义：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//  </span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Node</span>&#123;  </span><br><span class="line">    <span class="type">int</span> Cover;<span class="comment">//区间整体被覆盖的次数   </span></span><br><span class="line">    <span class="type">int</span> L;<span class="comment">//Length : 所代表的区间总长度  </span></span><br><span class="line">    <span class="type">int</span> CL;<span class="comment">//Cover Length :实际覆盖长度  </span></span><br><span class="line">    Node <span class="keyword">operator</span> +(<span class="type">const</span> Node &amp;B)<span class="type">const</span>&#123;  </span><br><span class="line">        Node X;  </span><br><span class="line">        X.Cover=<span class="number">0</span>;<span class="comment">//因为若上级的Cover不为0，不会调用子区间加法函数   </span></span><br><span class="line">        X.L=L+B.L;  </span><br><span class="line">        X.CL=CL+B.CL;  </span><br><span class="line">        <span class="keyword">return</span> X;  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;K[maxn&lt;&lt;<span class="number">2</span>];  </span><br></pre></td></tr></table></figure>



<p>若本区间的覆盖次数大于0，那么令CL&#x3D;L,直接为全覆盖，不管下层是怎么覆盖的，反正本区间已经全被覆盖。</p>
<p>若本区间的覆盖次数等于0，那么调用上面结构体中的加法函数，利用子区间的覆盖来计算。</p>
<p>加入一条线段就是给每一个分解的子区间的Cover+1,删除线段就-1，每次修改Cover之后，更新区间信息。</p>
<p>这里完全没有下推标记的过程。</p>
<p><strong>查询</strong>的代码如下：</p>
<p>如果不把区间加法定义成结构体内部的函数，而是定义在PushUp函数内，那么这里几乎就要重写一遍区间合并。</p>
<p>因为PushUp在这里用不上。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//  </span></span><br><span class="line"><span class="function">Node <span class="title">Query</span><span class="params">(<span class="type">int</span> L,<span class="type">int</span> R,<span class="type">int</span> l,<span class="type">int</span> r,<span class="type">int</span> rt)</span></span>&#123;  </span><br><span class="line">    <span class="keyword">if</span>(L &lt;= l &amp;&amp; r &lt;= R)&#123;  </span><br><span class="line">        <span class="keyword">return</span> K[rt];  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="type">int</span> m=(l+r)&gt;&gt;<span class="number">1</span>;  </span><br><span class="line">    Node LANS,RANS;  </span><br><span class="line">    <span class="type">int</span> X=<span class="number">0</span>;  </span><br><span class="line">    <span class="keyword">if</span>(L &lt;= m) LANS=<span class="built_in">Query</span>(L,R,ls),X+=<span class="number">1</span>;  </span><br><span class="line">    <span class="keyword">if</span>(R &gt;  m) RANS=<span class="built_in">Query</span>(L,R,rs),X+=<span class="number">2</span>;  </span><br><span class="line">    <span class="keyword">if</span>(X==<span class="number">1</span>) <span class="keyword">return</span> LANS;  </span><br><span class="line">    <span class="keyword">if</span>(X==<span class="number">2</span>) <span class="keyword">return</span> RANS;  </span><br><span class="line">    <span class="keyword">return</span> LANS+RANS;  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>




<p><strong>维护线段覆盖3次或以上的长度：</strong></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//  </span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Nodes</span>&#123;    </span><br><span class="line">    <span class="type">int</span> C;<span class="comment">//Cover    </span></span><br><span class="line">    <span class="type">int</span> CL[<span class="number">4</span>];<span class="comment">//CoverLength[0~3]    </span></span><br><span class="line">    <span class="comment">//CL[i]表示被覆盖了大于等于i次的线段长度，CL[0]其实就是线段总长   </span></span><br><span class="line">&#125;ST[maxn&lt;&lt;<span class="number">2</span>];    </span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">PushUp</span><span class="params">(<span class="type">int</span> rt)</span></span>&#123;    </span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=<span class="number">3</span>;++i)&#123;    </span><br><span class="line">        <span class="keyword">if</span>(ST[rt].C &lt; i) ST[rt].CL[i]=ST[rt&lt;&lt;<span class="number">1</span>].CL[i-ST[rt].C]+ST[rt&lt;&lt;<span class="number">1</span>|<span class="number">1</span>].CL[i-ST[rt].C];    </span><br><span class="line">        <span class="keyword">else</span> ST[rt].CL[i]=ST[rt].CL[<span class="number">0</span>];    </span><br><span class="line">    &#125;    </span><br><span class="line">&#125;    </span><br></pre></td></tr></table></figure>




<p>这里给出节点定义和PushUp().</p>
<p>更新节点信息的思路大概就是：</p>
<p>假设要更新CL[3],然后发现本节点被覆盖了2次，那么本节点被覆盖三次或以上的长度就等于子节点被覆盖了1次或以上的长度之和。</p>
<p>而CL[0]建树时就赋值，之后不需要修改。</p>
<h3 id="（3）：如何维护扫描线过程中线段的数量"><a href="#（3）：如何维护扫描线过程中线段的数量" class="headerlink" title="（3）：如何维护扫描线过程中线段的数量"></a><strong>（3）：如何维护扫描线过程中线段的数量</strong></h3><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//   </span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Node</span>&#123;    </span><br><span class="line">    <span class="type">int</span> cover;<span class="comment">//完全覆盖层数    </span></span><br><span class="line">    <span class="type">int</span> lines;<span class="comment">//分成多少个线段    </span></span><br><span class="line">    <span class="type">bool</span> L,R;<span class="comment">//左右端点是否被覆盖    </span></span><br><span class="line">    Node <span class="keyword">operator</span> +(<span class="type">const</span> Node &amp;B)&#123;<span class="comment">//连续区间的合并     </span></span><br><span class="line">        Node C;    </span><br><span class="line">        C.cover=<span class="number">0</span>;    </span><br><span class="line">        C.lines=lines+B.lines-(R&amp;&amp;B.L);    </span><br><span class="line">        C.L=L;C.R=B.R;    </span><br><span class="line">        <span class="keyword">return</span> C;    </span><br><span class="line">    &#125;    </span><br><span class="line">&#125;K[maxn&lt;&lt;<span class="number">2</span>];   </span><br></pre></td></tr></table></figure>




<p>要维护被分成多少个线段，就需要记录左右端点是否被覆盖，知道了这个，就可以合并区间了。</p>
<p>左右两个区间合并时，若左区间的最右侧有线段且右区间的最左侧也有线段，那么这两个线段会合二为一，于是总线段数量会少1.</p>
<h2 id="扫描线求重叠矩形周长："><a href="#扫描线求重叠矩形周长：" class="headerlink" title="扫描线求重叠矩形周长："></a><strong>扫描线求重叠矩形周长：</strong></h2><p><img src="/posts/95304e2e/asset/20150910134955319.png" alt="img"></p>
<p>这个图是在原来的基础上多画了一些东西，这次是要求周长。</p>
<p>所有的横向边都画了紫色，所有的纵向边画了绿色。</p>
<p>先考虑<strong>绿色的边</strong>，由图可以观察到，绿色边的长度其实就是L的变化值。</p>
<p>比如考虑X1,本来L是0,从0变到L1,所以绿色边长为L1.</p>
<p>再考虑X2,由L1变成了L2,所以绿色边长度为L2-L1,</p>
<p>于是，绿色边的长度就是L的变化值（注意上图中令L0&#x3D;0,L9&#x3D;0）。</p>
<p>因为长度是从0开始变化，最终归0.</p>
<p>再考虑<strong>紫色的边</strong>，要计算紫色边，其实就是计算L的线段是有几个线段组成的，每个线段会贡献两个端点（紫色圆圈）</p>
<p>而每个端点都会向右延伸出一条紫色边一直到下一个X值。</p>
<p>所以周长就是以上两部分的和。而两部分怎么维护，前面都讲过了，下面给出代码。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//   </span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Node</span>&#123;    </span><br><span class="line">    <span class="type">int</span> cover;<span class="comment">//完全覆盖层数    </span></span><br><span class="line">    <span class="type">int</span> lines;<span class="comment">//分成多少个线段    </span></span><br><span class="line">    <span class="type">bool</span> L,R;<span class="comment">//左右端点是否被覆盖    </span></span><br><span class="line">    <span class="type">int</span> CoverLength;<span class="comment">//覆盖长度     </span></span><br><span class="line">    <span class="type">int</span> Length;<span class="comment">//总长度     </span></span><br><span class="line">    <span class="built_in">Node</span>()&#123;&#125;    </span><br><span class="line">    <span class="built_in">Node</span>(<span class="type">int</span> cover,<span class="type">int</span> lines,<span class="type">bool</span> L,<span class="type">bool</span> R,<span class="type">int</span> CoverLength):<span class="built_in">cover</span>(cover),<span class="built_in">lines</span>(lines),<span class="built_in">L</span>(L),<span class="built_in">R</span>(R),<span class="built_in">CoverLength</span>(CoverLength)&#123;&#125;    </span><br><span class="line">    Node <span class="keyword">operator</span> +(<span class="type">const</span> Node &amp;B)&#123;<span class="comment">//连续区间的合并     </span></span><br><span class="line">        Node C;    </span><br><span class="line">        C.cover=<span class="number">0</span>;    </span><br><span class="line">        C.lines=lines+B.lines-(R&amp;&amp;B.L);    </span><br><span class="line">        C.CoverLength=CoverLength+B.CoverLength;    </span><br><span class="line">        C.L=L;C.R=B.R;    </span><br><span class="line">        C.Length=Length+B.Length;    </span><br><span class="line">        <span class="keyword">return</span> C;    </span><br><span class="line">    &#125;    </span><br><span class="line">&#125;K[maxn&lt;&lt;<span class="number">2</span>];    </span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">PushUp</span><span class="params">(<span class="type">int</span> rt)</span></span>&#123;<span class="comment">//更新非叶节点     </span></span><br><span class="line">    <span class="keyword">if</span>(K[rt].cover)&#123;    </span><br><span class="line">        K[rt].CoverLength=K[rt].Length;    </span><br><span class="line">        K[rt].L=K[rt].R=K[rt].lines=<span class="number">1</span>;    </span><br><span class="line">    &#125;    </span><br><span class="line">    <span class="keyword">else</span>&#123;    </span><br><span class="line">        K[rt]=K[rt&lt;&lt;<span class="number">1</span>]+K[rt&lt;&lt;<span class="number">1</span>|<span class="number">1</span>];    </span><br><span class="line">    &#125;    </span><br><span class="line">&#125;    </span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>扫描的代码：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> PreX=L[<span class="number">0</span>].x;<span class="comment">//前X坐标     </span></span><br><span class="line"><span class="type">int</span> ANS=<span class="number">0</span>;<span class="comment">//目前累计答案     </span></span><br><span class="line"><span class="type">int</span> PreLength=<span class="number">0</span>;<span class="comment">//前线段总长    </span></span><br><span class="line"><span class="type">int</span> PreLines=<span class="number">0</span>;<span class="comment">//前线段数量     </span></span><br><span class="line"><span class="built_in">Build</span>(<span class="number">1</span>,<span class="number">20001</span>,<span class="number">1</span>);    </span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;nL;++i)&#123;    </span><br><span class="line">    <span class="comment">//操作     </span></span><br><span class="line">    <span class="keyword">if</span>(L[i].c) <span class="built_in">Cover</span>(L[i].y1,L[i].y2<span class="number">-1</span>,<span class="number">1</span>,<span class="number">20001</span>,<span class="number">1</span>);    </span><br><span class="line">    <span class="keyword">else</span> <span class="built_in">Uncover</span>(L[i].y1,L[i].y2<span class="number">-1</span>,<span class="number">1</span>,<span class="number">20001</span>,<span class="number">1</span>);    </span><br><span class="line">    <span class="comment">//更新横向的边界     </span></span><br><span class="line">    ANS+=<span class="number">2</span>*PreLines*(L[i].x-PreX);    </span><br><span class="line">    PreLines=K[<span class="number">1</span>].lines;    </span><br><span class="line">    PreX=L[i].x;    </span><br><span class="line">    <span class="comment">//更新纵向边界     </span></span><br><span class="line">    ANS+=<span class="built_in">abs</span>(K[<span class="number">1</span>].CoverLength-PreLength);    </span><br><span class="line">    PreLength=K[<span class="number">1</span>].CoverLength;    </span><br><span class="line">&#125;    </span><br><span class="line"><span class="comment">//输出答案     </span></span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;%d\n&quot;</span>,ANS);  </span><br></pre></td></tr></table></figure>

<p>这个首先扫描面，每个面内求重叠了3次或以上的面积，然后乘以移动距离就是体积。</p>
<p>面内扫描线，用线段树维护重叠了3次或以上的线段长度，然后用长度乘移动距离就是重叠了3次或以上的面积。</p>
<p>扫描面基本原理都跟扫描线一样，就是嵌套了一层而已，写的时候细心一点就没问题了。</p>
<h1 id="八：可持久化-主席树"><a href="#八：可持久化-主席树" class="headerlink" title="八：可持久化 (主席树)"></a><strong>八：可持久化 (主席树)</strong></h1><p>可持久化线段树，也叫主席树。</p>
<p>可持久化数据结构思想，就是保留整个操作的历史，即，对一个线段树进行操作之后，保留访问操作前的线段树的能力。</p>
<p>最简单的方法，每操作一次，建立一颗新树。这样对空间的需求会很大。</p>
<p>而注意到，对于点修改，每次操作最多影响<img src="https://img-blog.csdn.net/20150908232141714" alt="img">个节点，于是，其实操作前后的两个线段树，结构一样，</p>
<p>而且只有<img src="https://img-blog.csdn.net/20150908232141714" alt="img">个节点不同，其余的节点都一样，于是可以重复利用其余的点。</p>
<p>这样，每次操作，会增加<img src="https://img-blog.csdn.net/20150908232141714" alt="img">个节点。</p>
<p>于是，这样的线段树，每次操作需要O(log2(n))的空间。</p>
<p><strong>题目：HDU 2665 Kth number</strong>    <a href="http://blog.csdn.net/zearot/article/details/44981711">题解</a></p>
<p>给定10万个数，10万个询问。</p>
<p>每个询问，问区间[L,R]中的数，从小到大排列的话，第k个数是什么。</p>
<p>这个题，首先对十万个数进行离散化，然后用线段树来维护数字出现的次数。</p>
<p>每个节点都存出现次数，那么查询时，若左节点的数的个数&gt;&#x3D;k，就往左子树递归，否则往右子树递归。</p>
<p>一直到叶节点，就找到了第k大的数。</p>
<p>这题的问题是，怎么得到一个区间的每个数出现次数。</p>
<p>注意到，数字的出现次数是满足区间减法的。</p>
<p>于是要求区间[L,R]的数，其实就是T[R]-T[L-1]  ，其中T[X]表示区间[1,X]的数形成的线段树。</p>
<p>现在的问题就是，如何建立这10万个线段树。</p>
<p>由之前的分析，需要O(n log2(n))的空间</p>
<p>下面是代码：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//主席树     </span></span><br><span class="line"><span class="type">int</span> L[maxnn],R[maxnn],Sum[maxnn],T[maxn],TP;<span class="comment">//左右子树，总和，树根，指针     </span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Add</span><span class="params">(<span class="type">int</span> &amp;rt,<span class="type">int</span> l,<span class="type">int</span> r,<span class="type">int</span> x)</span></span>&#123;<span class="comment">//建立新树，l,r是区间， x是新加入的数字的排名  </span></span><br><span class="line">    ++TP;L[TP]=L[rt];R[TP]=R[rt];Sum[TP]=Sum[rt]+<span class="number">1</span>;rt=TP;<span class="comment">//复制&amp;新建    </span></span><br><span class="line">    <span class="keyword">if</span>(l==r) <span class="keyword">return</span>;    </span><br><span class="line">    <span class="type">int</span> m=(l+r)&gt;&gt;<span class="number">1</span>;    </span><br><span class="line">    <span class="keyword">if</span>(x &lt;= m) <span class="built_in">Add</span>(L[rt],l,m,x);    </span><br><span class="line">    <span class="keyword">else</span>       <span class="built_in">Add</span>(R[rt],m+<span class="number">1</span>,r,x);    </span><br><span class="line">&#125;    </span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">Search</span><span class="params">(<span class="type">int</span> TL,<span class="type">int</span> TR,<span class="type">int</span> l,<span class="type">int</span> r,<span class="type">int</span> k)</span></span>&#123;<span class="comment">//区间查询第k大    </span></span><br><span class="line">    <span class="keyword">if</span>(l==r) <span class="keyword">return</span> l;<span class="comment">//返回第k大的下标    </span></span><br><span class="line">    <span class="type">int</span> m=(l+r)&gt;&gt;<span class="number">1</span>;    </span><br><span class="line">    <span class="keyword">if</span>(Sum[L[TR]]-Sum[L[TL]]&gt;=k) <span class="keyword">return</span> <span class="built_in">Search</span>(L[TL],L[TR],l,m,k);    </span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">return</span> <span class="built_in">Search</span>(R[TL],R[TR],m+<span class="number">1</span>,r,k-Sum[L[TR]]+Sum[L[TL]]);    </span><br><span class="line">&#125;    </span><br></pre></td></tr></table></figure>


<p>以上就是主席树部分的代码。</p>
<p>熟悉SBT的，应该都很熟悉这种表示方法。</p>
<p>L,R是伪指针，指向左右子节点。</p>
<p>特殊之处是，0 表示空树，并且 L[0]&#x3D;R[0]&#x3D;0.</p>
<p>也就是说，空树的左右子树都是空树。</p>
<p>而本题中，每一颗树其实都是完整的，刚开始有一颗空树。</p>
<p>但是刚开始的空树，真的需要用空间去存吗？</p>
<p>其实不需要，刚开始的空树有这些性质：</p>
<p>1.每个节点的Sum值为0</p>
<p>2.每个非叶节点的左右子节点的Sum值也是0</p>
<p>而SBT的空树刚好满足这个性质。而线段树不依赖L,R指针来结束递归。</p>
<p>线段树是根据区间l,r来结束的，所以不会出现死循环。</p>
<p>所以只需要把Sum[0]&#x3D;0;那么刚开始就不需要建树了，只有每个操作的<img src="https://img-blog.csdn.net/20150908232141714" alt="img">个节点。</p>
<p>这个线段树少了表示父节点的int rt，因为不需要（也不能够）通过rt来找子节点了，而是直接根据L,R来找。</p>
<p>—————————–   补充   ————————————-</p>
<p>终于又找到一道可以用主席树的题目了：<strong>Codeforces 650D.Zip-line</strong> <a href="http://blog.csdn.net/zearot/article/details/50857353">题解</a></p>
<p>做这题之前需要会求普通的LIS问题（最长上升子序列问题）。</p>
<h1 id="九：练习题"><a href="#九：练习题" class="headerlink" title="九：练习题"></a>九：练习题</h1><h2 id="适合非递归线段树的题目："><a href="#适合非递归线段树的题目：" class="headerlink" title="适合非递归线段树的题目："></a>适合非递归线段树的题目：</h2><p><strong>Codeforces 612D</strong> <strong>The Union of k-Segments :</strong>  <a href="http://blog.csdn.net/zearot/article/details/50422199">题解</a></p>
<p>题意：线段求交，给定一堆线段，按序输出被覆盖k次或以上的线段和点。</p>
<p>基础题，先操作，最后一次下推标记，然后输出，</p>
<p>维护两个线段树，一个线段覆盖，一个点覆盖。</p>
<p><strong>Codeforces 35E Parade</strong> : <a href="http://blog.csdn.net/zearot/article/details/48247929">题解</a></p>
<p>题意：给定若干矩形，下端挨着地面，求最后的轮廓形成的折线，要求输出每一点的坐标。</p>
<p>思路：虽然是区间修改的线段树，但只需要在操作结束后一次下推标记，然后输出，所以适合非递归线段树。</p>
<p><strong>URAL 1846 GCD2010 ：</strong> <a href="http://blog.csdn.net/zearot/article/details/38941525"> 题解</a></p>
<p>题意：总共10万个操作，每次向集合中加入或删除一个数，求集合的最大公因数。（规定空集的最大公因数为1）</p>
<p><strong>Codeforces 12D Ball :</strong>  <a href="http://blog.csdn.net/zearot/article/details/48193087">题解</a></p>
<p>题意：</p>
<p>给N (N&lt;&#x3D;500000)个点，每个点有x,y,z ( 0&lt;&#x3D; x,y,z &lt;&#x3D;10^9 )</p>
<p>对于某点(x,y,z)，若存在一点(x1,y1,z1)使得x1 &gt; x &amp;&amp; y1 &gt; y &amp;&amp; z1 &gt; z 则点(x,y,z)是特殊点。</p>
<p>问N个点中，有多少个特殊点。</p>
<p>提示：排序+线段树</p>
<p><strong>Codeforces 19D Points</strong> : <a href="http://blog.csdn.net/zearot/article/details/48153507">题解</a></p>
<p>题意：</p>
<p>给定最多20万个操作，共3种：</p>
<p>1.add x y     ：加入(x,y)这个点</p>
<p>2.remove x y  ：删除(x,y)这个点</p>
<p>3.find x y     ：找到在(x,y)这点右上方的x最小的点，若x相同找y最小的点，输出这点坐标，若没有，则输出-1.</p>
<p>提示：排序，线段树套平衡树</p>
<p><strong>Codeforces 633E Startup Funding :</strong> <a href="http://blog.csdn.net/zearot/article/details/50825559">题解</a></p>
<p>这题需要用到一点概率论，组合数学知识，和二分法。</p>
<p>非递归线段树在这题中主要解决RMQ问题（区间最大最小值问题），由于不带修改，这题用Sparse Table求解RMQ是标答。</p>
<p>因为RMQ询问是在二分法之内求的，而Sparse Table可以做到O(1)查询，所以用Sparse Table比较好，总复杂度O(n*log(n))。</p>
<p>不过非递归线段树也算比较快的了，虽然复杂度是O(n*log(n)*log(n))，还是勉强过了这题。</p>
<h2 id="扫描线题目："><a href="#扫描线题目：" class="headerlink" title="扫描线题目："></a>扫描线题目：</h2><p><strong>POJ 1177 Picture</strong>:给定若干矩形求合并之后的图形周长   <a href="http://blog.csdn.net/zearot/article/details/47685361">题解</a></p>
<p><strong>HDU 1255 覆盖的面积：</strong>给定平面上若干矩形,求出被这些矩形覆盖过至少两次的区域的面积.  <a href="http://blog.csdn.net/zearot/article/details/47762543"> 题解</a></p>
<p><strong>HDU 3642 Get The Treasury：</strong>给定若干空间立方体，求重叠了3次或以上的体积（这个是扫描面，每个面再扫描线）<a href="http://blog.csdn.net/zearot/article/details/47763001">题解</a></p>
<p><strong>POJ 2482 Stars in your window :</strong> 给定一些星星的位置和亮度，求用W*H的矩形能够框住的星星亮度之和最大为多少。 <a href="http://blog.csdn.net/zearot/article/details/47663851">题解</a></p>
<h2 id="递归线段树题目："><a href="#递归线段树题目：" class="headerlink" title="递归线段树题目："></a>递归线段树题目：</h2><p><strong>Codeforces 558E A Simple Task</strong> <a href="http://blog.csdn.net/zearot/article/details/48048559">题解</a></p>
<p>给定一个长度不超过10^5的字符串（小写英文字母），和不超过5000个操作。</p>
<p>每个操作 L R K 表示给区间[L,R]的字符串排序，K&#x3D;1为升序，K&#x3D;0为降序。</p>
<p>最后输出最终的字符串。</p>
<p><strong>Codeforces 527C Glass Carving</strong> :  <a href="http://blog.csdn.net/zearot/article/details/44759437">题解</a></p>
<p>给定一个矩形，不停地纵向或横向切割，问每次切割后，最大的矩形面积是多少。</p>
<p><strong>URAL1989 Subpalindromes</strong>   <a href="http://blog.csdn.net/zearot/article/details/38921403">题解</a></p>
<p>给定一个字符串(长度&lt;&#x3D;100000)，有10万个操作。</p>
<p>操作有两种：  </p>
<p>1：改变某个字符。 </p>
<p>2：判断某个子串是否构成回文串。 </p>
<p><strong>HDU 4288 Coder</strong> :  <a href="http://blog.csdn.net/zearot/article/details/40538467">题解</a></p>
<p> 题意：对一个集合进行插入与删除操作。要求询问某个时刻，集合中的元素从小到大排序之后，序号%5 &#x3D;&#x3D;3 的元素值之和。</p>
<p>这题其实不一定要用线段树去做的，不过线段树还是可以做的。</p>
<p><strong>HDU 2795 BillBoard</strong> : <a href="http://blog.csdn.net/zearot/article/details/40538377">题解</a></p>
<p>题意：有一个板，h行，每行w长度的位置。每次往上面贴一张海报，长度为1*wi .</p>
<p>每次贴的时候，需要找到最上面的，可以容纳的空间，并且靠边贴。</p>
<p><strong>Codeforces 374D Inna and Sequence</strong> ：<a href="http://blog.csdn.net/zearot/article/details/40515997">题解</a></p>
<p>题意：给定百万个数a[m]，然后有百万个操作，每次给现有序列加一个字符（0或1），或者删掉已有序列中，第 a[0] 个，第a[1]个,…，第a[m]个。</p>
<p><strong>Codeforces 482B Interesting Array</strong>:  <a href="http://blog.csdn.net/zearot/article/details/40449455">题解</a></p>
<p>题意就是，给定n,m.</p>
<p>满足m个条件的n个数，或说明不存在。</p>
<p>每个条件的形式是，给定 Li,Ri,Qi ，要求  a[Li]&amp;a[Li+1]&amp;…&amp;a[Ri] &#x3D; Qi ;</p>
<p><strong>Codeforces 474E Pillar （线段树+动态规划）：</strong> <a href="http://blog.csdn.net/zearot/article/details/40383479">题解</a></p>
<p>题意就是，给定10^5 个数（范围10^15）,求最长子序列使得相邻两个数的差大于等于 d。</p>
<p><strong>POJ 2777  Count Color :</strong>  <a href="http://blog.csdn.net/zearot/article/details/38908579">题解</a></p>
<p>给线段涂颜色，最多30种颜色，10万个操作。</p>
<p>每个操作给线段涂色，或问某一段线段有多少种颜色。</p>
<p>30种颜色用int的最低30位来存，然后线段树解决。</p>
<p><strong>URAL 1019 Line Painting:</strong> 线段树的区间合并  <a href="http://blog.csdn.net/zearot/article/details/38902843">题解</a></p>
<p>给一段线段进行黑白涂色，最后问最长的一段白色线段的长度。</p>
<p><strong>Codeforces 633H Fibonacci-ish II</strong> ：<a href="http://blog.csdn.net/zearot/article/details/50850792">题解</a></p>
<p>这题需要用到莫队算法（Mo’s Algorithm）+线段树区间修改，不过是单边界的区间，写起来挺有趣。</p>
<p>另一种解法就是暴力，很巧妙的方法，高复杂度+低常数居然就这么给过了。</p>
<h2 id="树套树题目："><a href="#树套树题目：" class="headerlink" title="树套树题目："></a>树套树题目：</h2><p><strong>ZOJ 2112 Dynamic Rankings</strong> 动态区间第k大  <a href="http://blog.csdn.net/zearot/article/details/44998563">题解</a></p>
<p>做法：树状数组套主席树 或者 线段树套平衡树</p>
<p><strong>Codeforces 605D</strong> <strong>Board Game :</strong>  <a href="http://blog.csdn.net/zearot/article/details/50371308">题解</a></p>
<p>做法：广度优先搜索(BFS)  +  线段树套平衡树</p>
<p><strong>Codeforces 19D Points</strong> : <a href="http://blog.csdn.net/zearot/article/details/48153507">题解</a></p>
<p>题意：</p>
<p>给定最多20万个操作，共3种：</p>
<p>1.add x y     ：加入(x,y)这个点</p>
<p>2.remove x y  ：删除(x,y)这个点</p>
<p>3.find x y     ：找到在(x,y)这点右上方的x最小的点，若x相同找y最小的点，输出这点坐标，若没有，则输出-1.</p>
<p>提示：排序，线段树套平衡树</p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>其他</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>其他</tag>
      </tags>
  </entry>
  <entry>
    <title>3.区间dp</title>
    <url>/posts/833a660c/</url>
    <content><![CDATA[<p> 所谓<strong>区间dp</strong>，指在一段区间上进行动态规划，一般做法是由长度较小的区间往长度较大的区间进行递推，最终得到整个区间的答案，而边界就是长度为1以及2的区间。 </p>
<h2 id="转移方程"><a href="#转移方程" class="headerlink" title="转移方程"></a>转移方程</h2><p>区间dp常见的转移方程如下：</p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">dp(i,j) = min&#123;dp(i,k-1) + dp(k,j)&#125; + w(i,j)   (i &lt; k &lt;= j)</span><br></pre></td></tr></table></figure>

<p>其中<code>dp(i,j)</code>表示在区间<code>[i,j]</code>上的最优值，<code>w(i,j)</code>表示在转移时需要额外付出的代价，min也可以是max。</p>
<h2 id="四边形不等式"><a href="#四边形不等式" class="headerlink" title="四边形不等式"></a>四边形不等式</h2><p>按上述转移方程递推的时间复杂度为O(n3)，如果w函数满足区间单调性和四边形不等式，可通过四边形不等式将时间优化到O(n2)。</p>
<ul>
<li>区间单调性：对于<code>a&lt;=b&lt;=c&lt;=d</code>，有<code>w(b,c) &lt;= w(a,d)</code>。</li>
<li>四边形不等式：对于<code>a&lt;=b&lt;=c&lt;=d</code>，有<code>f[a][c]+f[b][d]&lt;=f[a][d]+f[b][c]</code></li>
</ul>
<p> 当<code>w</code>满足以上两点时，dp也满足四边形不等式，定义<code>s(i,j)</code>表示<code>dp(i,j)</code>取得最优值时对应的下标，那么有<code>s(i,j)</code>单调，即<code>s(i,j)&lt;=s(i,j+1)&lt;=s(i+1,j)</code>。 </p>
<p>将该单调性应用到转移方程中，可大大缩小k的枚举范围。</p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">dp(i,j) = min&#123;dp(i,k-1) + dp(k,j)&#125; + w(i,j)    (s(i,j-1) &lt;= k &lt;= s(i+1,j))</span><br></pre></td></tr></table></figure>

<h2 id="石头合并"><a href="#石头合并" class="headerlink" title="石头合并"></a>石头合并</h2><p>我们常见的石子合并问题一般就三种</p>
<p>第一种</p>
<p>n堆石子，每次合并的花费为两堆石子数目之和，求怎样合并可以使得合并为一整堆石子的总花费最少</p>
<p>实际上这就是HUfffman编码的变形，运用贪心策略，每次找出最小的两堆合并即可。</p>
<p>第二种</p>
<p>描述与第一种很相似，只不过每次合并只能合并相邻的两堆石子</p>
<p>那么贪心策略就不一定有用，局部最优的结果不一定是全局最优</p>
<p>那么我们就要考虑了，全局最优的子结构也应当是最优的。那么，我们就要考虑动态规划了，</p>
<p>状态转移方程：</p>
<p>dp[i][j] &#x3D; min(dp[i][j],d[i][k]+dp[k+1][j]+sum[j]-sim[i])</p>
<p>解释一下，dp[i][j]表示合并第i堆到第j堆石子的最小花费，k的取值范围为i到j之间，表示分割点，例如1-3就可以分为1-2与3-3，sum【i】表示前i堆石子的总重量</p>
<p>初始化dp[i][i]为0，其他为无穷大</p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">#include&lt;bits/stdc++.h&gt;</span><br><span class="line">using namespace std;</span><br><span class="line">const int imax =0x7F7F7F7F;//极大值 </span><br><span class="line">int n;</span><br><span class="line">int dp[2000][2000];//答案数组 </span><br><span class="line">int sum[2000];//花费数组 </span><br><span class="line">int data[2000];//数据数组 </span><br><span class="line">void init()//初始化</span><br><span class="line">&#123;</span><br><span class="line">	memset(sum,0,sizeof(sum));</span><br><span class="line">	memset(dp,imax,sizeof(dp));</span><br><span class="line">	cin&gt;&gt;n;</span><br><span class="line">	for(int i=1;i&lt;=n;i++)</span><br><span class="line">	&#123;</span><br><span class="line">		cin&gt;&gt;data[i];</span><br><span class="line">		sum[i]+=sum[i-1];</span><br><span class="line">		sum[i]+=data[i];</span><br><span class="line">		dp[i][i] = 0;</span><br><span class="line">	&#125;</span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line">int solve()</span><br><span class="line">&#123;</span><br><span class="line">	init();</span><br><span class="line">	for(int v=1;v&lt;n;v++)//v控制离中心线距离 </span><br><span class="line">	&#123;</span><br><span class="line">		for(int i=1;i&lt;=n-v;i++)//i控制行 </span><br><span class="line">		&#123;</span><br><span class="line">			int j = i+v;//j控制列 </span><br><span class="line">			int s = sum[j]-sum[i-1];//合并花费 </span><br><span class="line">			for(int k=i;k&lt;j;k++)</span><br><span class="line">			dp[i][j] = min(dp[i][j],dp[i][k]+dp[k+1][j]+s); </span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	return dp[1][n];</span><br><span class="line">&#125;</span><br><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">	cout&lt;&lt;solve();</span><br><span class="line">	return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>上述代码的时间复杂度为O^3,那么我们有没有优化的方法呢？</p>
<p>平行四边形优化，我们用一个二维数组记录合并该堆石子的最佳决策点，也就是上述的K</p>
<p>有dp[i][j]的K值一定大于等于dp[i][j-1]的K,一定小于等于dp[i+1][j]的K</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include&lt;bits/stdc++.h&gt;</span><br><span class="line">using namespace std;</span><br><span class="line">const int imax =0x7F7F7F7F;//极大值 </span><br><span class="line">int n;</span><br><span class="line">int dp[2000][2000];//答案数组 </span><br><span class="line">int sum[2000];//花费数组 </span><br><span class="line">int data[2000];//数据数组 </span><br><span class="line">int p[2000][2000];//优化数组 </span><br><span class="line">void init()//初始化</span><br><span class="line">&#123;</span><br><span class="line">	memset(sum,0,sizeof(sum));</span><br><span class="line">	memset(dp,imax,sizeof(dp));</span><br><span class="line">	cin&gt;&gt;n;</span><br><span class="line">	for(int i=1;i&lt;=n;i++)</span><br><span class="line">	&#123;</span><br><span class="line">		cin&gt;&gt;data[i];</span><br><span class="line">		sum[i]+=sum[i-1];</span><br><span class="line">		sum[i]+=data[i];</span><br><span class="line">		dp[i][i] = 0;</span><br><span class="line">		p[i][i] = i; </span><br><span class="line">	&#125;</span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line">int solve()</span><br><span class="line">&#123;</span><br><span class="line">	init();</span><br><span class="line">	for(int v=1;v&lt;n;v++)//v控制离中心线距离 </span><br><span class="line">	&#123;</span><br><span class="line">		for(int i=1;i&lt;=n-v;i++)//i控制行 </span><br><span class="line">		&#123;</span><br><span class="line">			int j = i+v;//j控制列 </span><br><span class="line">			for(int k=p[i][j-1];k&lt;=p[i+1][j];k++)&#123;</span><br><span class="line">			int s = dp[i][k]+dp[k+1][j]+sum[j]-sum[i-1];//合并花费 </span><br><span class="line">			if(dp[i][j]&gt;s)</span><br><span class="line">			&#123;</span><br><span class="line">				dp[i][j] = s;</span><br><span class="line">				p[i][j] = k;</span><br><span class="line">			&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	return dp[1][n];</span><br><span class="line">&#125;</span><br><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">	cout&lt;&lt;solve();</span><br><span class="line">//	for(int i=1;i&lt;=n;i++)</span><br><span class="line">//	&#123;</span><br><span class="line">//		for(int j=1;j&lt;=n;j++)</span><br><span class="line">//		cout&lt;&lt;dp[i][j]&lt;&lt;&quot; &quot;;</span><br><span class="line">//		cout&lt;&lt;endl;</span><br><span class="line">//	&#125;</span><br><span class="line">	return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>第三种：</p>
<p>环形</p>
<p>n堆石子围成环状，求解</p>
<p>那么我们的dp数组的含义就要进行改变了，dp[i][j]的意义以第i堆石子为起点，合并j堆石子的最小（大）花费</p>
<p>sum的含义为第i堆为起点，后j堆的总和</p>
<p>最终遍历dp[i][n]（1&lt;&#x3D;i&lt;&#x3D;n）</p>
<p>找到最小（大）的值</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include&lt;bits/stdc++.h&gt;</span><br><span class="line">#define maxn 1&lt;&lt;27</span><br><span class="line">#define N  101</span><br><span class="line">using namespace std;</span><br><span class="line">int n,ansmin = 1&lt;&lt;27,ansmax = -1;</span><br><span class="line">int dp_max[N][N],dp_min[N][N];</span><br><span class="line">int date[N];</span><br><span class="line">void init()</span><br><span class="line">&#123;</span><br><span class="line">	cin&gt;&gt;n;</span><br><span class="line">	date[0] = 0;</span><br><span class="line">	for(int i=1;i&lt;=n;i++)</span><br><span class="line">	&#123;</span><br><span class="line">		cin&gt;&gt;date[i];</span><br><span class="line">		dp_min[i][1] = 0;//还没合并，没有花费 </span><br><span class="line">		dp_max[i][1] = 0;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">&#125;</span><br><span class="line">int sum(int i,int v)</span><br><span class="line">&#123;</span><br><span class="line">	int ans = 0;</span><br><span class="line">	for(;v&gt;0;v--,i++)</span><br><span class="line">	&#123;</span><br><span class="line">		if(i&gt;n)</span><br><span class="line">		i%=n;</span><br><span class="line">		ans+=date[i];</span><br><span class="line">	&#125;</span><br><span class="line">	return ans;</span><br><span class="line">&#125;</span><br><span class="line">void AC()</span><br><span class="line">&#123;</span><br><span class="line">	init();</span><br><span class="line">	for(int v=2;v&lt;=n;v++)//合并的个数 </span><br><span class="line">	&#123;</span><br><span class="line">		for(int i=1;i&lt;=n;i++)//起始位置 </span><br><span class="line">		&#123;</span><br><span class="line">			dp_min[i][v] = maxn;</span><br><span class="line">			dp_max[i][v] = -1;</span><br><span class="line">			for(int k =1;k&lt;v;k++)</span><br><span class="line">			&#123;</span><br><span class="line">				dp_min[i][v] = min(dp_min[i][v],dp_min[i][k]+dp_min[(i+k-1)%n+1][v-k]+sum(i,v));</span><br><span class="line">				dp_max[i][v] = max(dp_max[i][v],dp_max[i][k]+dp_max[(i+k-1)%n+1][v-k]+sum(i,v));</span><br><span class="line">			 &#125; </span><br><span class="line">		 &#125; </span><br><span class="line">	&#125;</span><br><span class="line">	for(int i=1;i&lt;=n;i++)</span><br><span class="line">	&#123;</span><br><span class="line">		if(dp_min[i][n]&lt;ansmin)</span><br><span class="line">		ansmin = dp_min[i][n];</span><br><span class="line">		if(dp_max[i][n]&gt;ansmax)</span><br><span class="line">		ansmax = dp_max[i][n];</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">	AC();</span><br><span class="line">	cout&lt;&lt;ansmin&lt;&lt;endl&lt;&lt;ansmax;</span><br><span class="line">	return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>动态规划</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>动态规划</tag>
      </tags>
  </entry>
  <entry>
    <title>4.树形dp</title>
    <url>/posts/98cba112/</url>
    <content><![CDATA[<p>这个问题题意很简单，给定一棵树，并不一定是二叉树，树上的树枝带有权重，可以看成是长度。要求树上最长的链路的长度是多少？</p>
<p> 比如我们随手画一棵树，可能丑了点，勿怪： <img src="/posts/98cba112/asset/v2-b8b2b698382daee440168234cb59c0f6_1440w.webp" alt="img"></p>
<p> 如果让我们用肉眼来看，稍微尝试一下就能找到答案，最长的路径应该是下图当中红色的这条： </p>
<p><img src="/posts/98cba112/asset/v2-9829a07678c3c9bc2456962adb877953_1440w.webp" alt="img"></p>
<p>但是如果让我们用算法来算，应该怎么办呢？</p>
<p>这道题其实有一个非常巧妙的办法，我们先不讲，先来看看动态规划怎么解决这个问题</p>
<h2 id="树形DP"><a href="#树形DP" class="headerlink" title="树形DP"></a><strong>树形DP</strong></h2><p>动态规划并不只是可以在数组当中运行，实际上只要满足动态规划的<strong>状态转移的条件和无后效性</strong>就可以使用动态规划，无论在什么数据结构当中。树上也是一样的，明白了这点之后，就只剩下了两个问题，第一个是状态是什么，第二个问题是状态之间怎么转移？</p>
<p> 在之前的背包问题当中，状态就是背包当前用的体积，转移呢就是我们新拿一个物品的决策。但是这一次我们要在树上进行动态规划，相对来说状态和对应的转移会隐蔽一些。没有关系，我会从头开始整理思路，一点一点将推导和思考的过程讲解清楚。 </p>
<p>首先，我们都知道，状态之间转移其实<strong>本质上是一个由局部计算整体的过程</strong>。我们通过相对容易的子状态进行转移，得到整体的结果。这个是动态规划的精髓，某种程度上来说它和分治法也比较接近，都存在大问题和小问题之间逻辑上的关系。所以当我们面临一个大问题一筹莫展的时候，可以借鉴一下分治法，思考一下从小问题入手。</p>
<p>所以，我们从小到大，由微观到宏观，来看看最简单的情况：</p>
<p><img src="/posts/98cba112/asset/v2-d70dbc834050ba333b2bdca7cf6809c1_1440w.webp" alt="img"></p>
<p> 这种情况很明显，链路只有一条，所以长度自然是5 + 6 &#x3D; 11，这显然也是最长的长度。这种情况都没有问题，下面我们来把情况稍微再变得复杂一些，我们在树上多加入一层： <img src="/posts/98cba112/asset/v2-7c2149458b7bddbbdb880d4acfe82cb6_1440w.webp" alt="img"></p>
<p> 这张图稍微复杂了一些，但是路径也不难找到，应该是<strong>E-B-F-H</strong>。路径的总长度为12： </p>
<p> 但是如果我们变更一下路径长度呢，比如我们把FG和FH的路径加长，会得到什么结果呢？ </p>
<p> 举这个例子只为了说明一个很简单的问题，即<strong>对于一棵树而言它上面的最长路径并不一定经过根节点</strong>。比如刚才的例子当中，如果路径必须要经过B的话，最长只能构造出4+2+16&#x3D;22的长度，但是如果可以不用经过B的话，可以得到最长的长度是31。 </p>
<p>得出这个结论看似好像没有用，但其实对于我们理清思路很有帮助。既然我们不能保证最长路径一定会经过树根，所以我们就不能直接转移答案。那我们应该怎么办呢？</p>
<p>回答这个问题光想是不够的，依然需要我们来观察问题和深入思考。</p>
<h2 id="转移过程"><a href="#转移过程" class="headerlink" title="转移过程"></a><strong>转移过程</strong></h2><p>我们再观察一下下面这两张图：</p>
<p><img src="/posts/98cba112/asset/v2-9829a07678c3c9bc2456962adb877953_1440w-1688205596574.webp" alt="img"></p>
<p>有没有发现什么规律？</p>
<p>由于我们的数据结构就是树形的，所以这个最长路径不管它连通的哪两个节点，<strong>一定可以保证，它会经过某一棵子树的根节点</strong>。不要小看这个不起眼的结论，实际上它非常重要。有了这个结论之后，我们将整条路径在根节点处切开。</p>
<p><img src="/posts/98cba112/asset/v2-b920fb2891f5549b4f25609329079f37_1440w.webp" alt="img"></p>
<p> 切开之后我们<strong>得到了两条通往叶子节点的链路</strong>，问题来了，根节点通往叶子节点的链路有很多条，为什么是这两条呢？ </p>
<p> 很简单，因为这两条链路最长。所以这样<strong>加起来之后就可以保证得到的链路最长</strong>。这两条链路都是从叶子节点通往A的，所以我们得到的最长链路就是以A为根节点的子树的最长路径。 </p>
<p> 我们前面的分析说了，最长路径是不能转移的，但是<strong>到叶子的最长距离是可以转移的</strong>。我们举个例子：  F到叶子的最长距离显然就是5和6中较大的那个，B稍微复杂一些，D和E都是叶子节点，这个容易理解。它还有一个子节点F，对于F来说它并不是叶子节点，但是我们前面算到了F到叶子节点的最长距离是6，所以B通过F到叶子节点的最长距离就是2 + 6 &#x3D; 8。这样我们就得到了状态转移方程，不过我们转移的不是要求的答案而是<strong>从当前节点到叶子节点的最长距离和次长距离</strong>。 </p>
<p> 因为只有最长距离是不够的，因为我们要将根节点的最长距离加上次长距离得到经过根节点的最长路径，由于我们之前说过，所有的路径必然经过某棵子树的根节点。这个想明白了是废话，但是这个条件的确很重要。既然所有的链路都至少经过某一个子树的根节点，那么我们<strong>算出所有子树经过根节点的最长路径</strong>，其中最长的那个不就是答案么？ </p>
<p><img src="/posts/98cba112/asset/v2-29a1499d40198eef38300cccd2500403_1440w.webp" alt="img"></p>
<p> 上图当中用<strong>粉色笔标出的就是转移的过程</strong>，对于叶子节点来说最长距离和次长距离都是0，主要的转移过程发生在中间节点上。 </p>
<p>转移的过程也很容易想通，对于中间节点i，我们遍历它所有的子节点j，然后维护最大值和次大值，我们写下状态转移方程：</p>
<p><img src="/posts/98cba112/asset/1688206027548.png" alt="1688206027548"></p>
<p> 状态转移想明白了，剩下的就是编码的问题了。可能在树上尤其是递归的时候做状态转移有些违反我们的直觉，但实际上并不难，我们写出代码来看下，我们首先来看建树的这个部分。为了简化操作，我们可以<strong>把树上所有的节点序号看成是int</strong>，对于每一个节点，都会有一个数组存储所有与这个节点连接的边，包括父亲节点。 </p>
<p> 由于我们只关注树上的链路的长度，并不关心树的结构，树建好了之后，<strong>不管以哪一个点为整体的树根结果都是一样的</strong>。所以我们随便找一个节点作为整棵树的根节点进行递归即可。强调一下，这个是一个很重要的性质，因为本质上来说，树是一个无向无环全连通图。所以不管以哪个节点为根节点都可以连通整棵子树。 </p>
<h2 id="没有上司的舞会"><a href="#没有上司的舞会" class="headerlink" title="没有上司的舞会"></a>没有上司的舞会</h2><p><img src="/posts/98cba112/asset/1688211975350.png" alt="1688211975350"></p>
<p> f(x,0&#x2F;1) 代表以 x为根的子树的最优解（第二维的值为 0 代表 x 不参加舞会的情况，1 代表 ix参加舞会的情况） </p>
<p>状态转移方程:</p>
<p>$$<br>\begin{cases}<br>f(x,0) &#x3D; \sum\max{f(i,1),f(i,0)} \text{   上司没来，直接下属可能回来} \<br>f(x,1) &#x3D; \sum f(i,0)  \text{   上司来，直接下属一定不来}<br>\end{cases}<br>$$</p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>动态规划</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>动态规划</tag>
      </tags>
  </entry>
  <entry>
    <title>5.环形结构dp</title>
    <url>/posts/a2cf036c/</url>
    <content><![CDATA[<p> 环形DP，顾名思义就是在环上做DP，一般这类问题都会与环有关 </p>
<p> 解法大体分下列几种 </p>
<p>###先断环为链，然后强制连接首尾的普通DP</p>
<p><img src="/posts/a2cf036c/asset/1688216605832.png" alt="1688216605832"></p>
<p><img src="/posts/a2cf036c/asset/1688216752154.png" alt="1688216752154"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include &lt;cstdio&gt;</span><br><span class="line">#include &lt;iostream&gt;</span><br><span class="line">#include &lt;algorithm&gt;</span><br><span class="line">#include &lt;cstring&gt;</span><br><span class="line">using namespace std;</span><br><span class="line">typedef long long LL;</span><br><span class="line"></span><br><span class="line">int n, m;</span><br><span class="line">LL a[100010];</span><br><span class="line">LL dp[2][4010][2];</span><br><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">    scanf(&quot;%d%d&quot;, &amp;n, &amp;m);</span><br><span class="line">    LL ans = 0;</span><br><span class="line">    for (register int i = 1;i &lt;= n;i ++)scanf(&quot;%lld&quot;, &amp;a[i]);</span><br><span class="line">    for (register int i = 2;i &lt;= n;i ++)//第一次DP，假装这道题是一道在链上DP的水题</span><br><span class="line">    &#123;</span><br><span class="line">        dp[i &amp; 1][1][1] = dp[(i &amp; 1) ^ 1][0][0];</span><br><span class="line">        dp[i &amp; 1][1][0] = max(dp[(i &amp; 1) ^ 1][1][0], dp[(i &amp; 1) ^ 1][1][1]);</span><br><span class="line">        for (register int j = 2;j &lt;= m &amp;&amp; j &lt;= i;j ++)</span><br><span class="line">        &#123;</span><br><span class="line">            dp[i &amp; 1][j][1] = max(dp[(i &amp; 1) ^ 1][j - 1][0], dp[(i &amp; 1) ^ 1][j - 1][1] + a[i]);</span><br><span class="line">            dp[i &amp; 1][j][0] = max(dp[(i &amp; 1) ^ 1][j][1], dp[(i &amp; 1) ^ 1][j][0]);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    ans = max(dp[n &amp; 1][m][1], dp[n &amp; 1][m][0]);</span><br><span class="line">    memset(dp, 0, sizeof(dp));</span><br><span class="line">    dp[1 &amp; 1][1][1] = a[1];//第二次DP，强制连接首尾</span><br><span class="line">    for (register int i = 2;i &lt;= n;i ++)</span><br><span class="line">    &#123;</span><br><span class="line">        dp[i &amp; 1][1][1] = dp[(i &amp; 1) ^ 1][0][0];</span><br><span class="line">        dp[i &amp; 1][1][0] = max(dp[(i &amp; 1) ^ 1][1][0], dp[(i &amp; 1) ^ 1][1][1]);</span><br><span class="line">        for (register int j = 2;j &lt;= m &amp;&amp; j &lt;= i;j ++)</span><br><span class="line">        &#123;</span><br><span class="line">            dp[i &amp; 1][j][1] = max(dp[(i &amp; 1) ^ 1][j - 1][0], dp[(i &amp; 1) ^ 1][j - 1][1] + a[i]);</span><br><span class="line">            dp[i &amp; 1][j][0] = max(dp[(i &amp; 1) ^ 1][j][1], dp[(i &amp; 1) ^ 1][j][0]);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    ans = max(ans, dp[n &amp; 1][m][1]);//强制选择最后一项</span><br><span class="line">    printf(&quot;%lld\n&quot;, ans);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p> 由此得出结论，环形DP的一类解法就是先跑一遍假的普通DP，再跑一遍强制首尾相接的DP，最后两部分合并得出答案。 </p>
<p>###直接破环为链，倍长区间的DP</p>
<p><img src="/posts/a2cf036c/asset/1688217029284.png" alt="1688217029284"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include &lt;bits/stdc++.h&gt;</span><br><span class="line">using namespace std;</span><br><span class="line">#define MAXN 110</span><br><span class="line">#define INF 0x3f3f3f3f</span><br><span class="line">int n;</span><br><span class="line">int a[MAXN &lt;&lt; 1], dp1[MAXN &lt;&lt; 1][MAXN &lt;&lt; 1], b[MAXN &lt;&lt; 1], dp2[MAXN &lt;&lt; 1][MAXN &lt;&lt; 1];//开两倍大小的数组，因为我们把区间扩大到了原来的两倍</span><br><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">    scanf(&quot;%d&quot;, &amp;n);</span><br><span class="line">    for (register int i = 1;i &lt;= n;i ++) scanf(&quot;%d&quot;, &amp;a[i]), a[n + i] = a[i];//a[n + i] = a[i]使得区间被复制一边</span><br><span class="line">    for (register int i = 1;i &lt;= (n &lt;&lt; 1);i ++) b[i] = b[i - 1] + a[i];//前缀和维护区间和</span><br><span class="line">    for (register int len = 2;len &lt;= n;len ++)&#123;</span><br><span class="line">        for (register int i = 1;i + len - 1 &lt;= (n &lt;&lt; 1);i ++)&#123;</span><br><span class="line">            int j = i + len - 1;</span><br><span class="line">            dp1[i][j] = INF;</span><br><span class="line">            dp2[i][j] = -INF;</span><br><span class="line">            for (register int k = i;k &lt; j;k ++)&#123;</span><br><span class="line">                dp1[i][j] = min(dp1[i][j], dp1[i][k] + dp1[k + 1][j] + b[j] - b[i - 1]);</span><br><span class="line">                dp2[i][j] = max(dp2[i][j], dp2[i][k] + dp2[k + 1][j] + b[j] - b[i - 1]);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    int ans1 = INF, ans2 = -INF;</span><br><span class="line">    for (register int i = 1;i &lt;= n;i ++)&#123;//扫描每一段环上长度为n的区间</span><br><span class="line">        ans1 = min(ans1, dp1[i][i + n - 1]);</span><br><span class="line">        ans2 = max(ans2, dp2[i][i + n - 1]);</span><br><span class="line">    &#125;</span><br><span class="line">    printf(&quot;%d\n%d\n&quot;, ans1, ans2);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="使用循环数组"><a href="#使用循环数组" class="headerlink" title="使用循环数组"></a>使用循环数组</h3><p>越界的数组元素，下表模数组长度取余</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p> 说到底，环形DP不过是DP的一种，其核心思维主要在于如何把一个环破成一条或多条链，并且要在保证时间复杂度正确的情况下保证正确性，即每一种状态都应该被考虑到，大概就是这样子。 </p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>动态规划</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>动态规划</tag>
      </tags>
  </entry>
  <entry>
    <title>6.状态压缩dp</title>
    <url>/posts/35a94d42/</url>
    <content><![CDATA[<blockquote>
<p>动态规划算法的过程是随着阶段的增长，在每个状态维度上的分界点组成了DP拓展的轮廓。对于某些问题，我们需要在动态规划的状态中记录一个集合，保存这个轮廓的详细信息，以便于进行状态转移。若集合大小不超过 N NN ，集合中每个元素都是小于 k kk 的自然数，则我们可以把这个集合看做一个 N NN 位 k kk 进制数，以一个 [ 0 , k N − 1 ] [0,k^N-1][0,k N −1] 之间的十进制整数的形式作为DP状态的一维。这种把集合转化为整数记录在DP状态中的一类算法被称之为状态压缩动态规划算法。</p>
</blockquote>
<p>在讲状压dp之前，我们应该清楚dp是<strong>解决多阶段决策最优化问题</strong>的一种思想方法，即利用各个阶段之间的关系，逐个求解，最终求得全局最优解。</p>
<p>我们通常需要确认原问题与子问题、动态规划状态、边界状态、状态转移方程。</p>
<p>动态规划多阶段一个重要的特性就是无后效性，即“未来与过去无关”。无后效性就是对于某个给定的阶段状态，它以前各阶段的状态无法直接影响它未来的发展。换句话说，当前的状态是此前历史的一个完整总结，此前的历史只能通过当前的状态去影响过程未来的演变。<img src="/posts/35a94d42/asset/v2-3a97e87651f11c2a4e7d6d0341fcdc35_1440w.webp" alt="img"></p>
<p> 对于动态规划，如何定义状态是至关重要的，因为状态决定了阶段的划分，阶段的划分保证了无后效性。 </p>
<p><img src="/posts/35a94d42/asset/v2-652bfcc2863ca973d2541dfa6e3f720a_1440w.webp" alt="img"></p>
<h3 id="状态压缩DP介绍"><a href="#状态压缩DP介绍" class="headerlink" title="状态压缩DP介绍"></a><strong>状态压缩DP介绍</strong></h3><p>状态压缩DP其实是一种<strong>暴力的算法</strong>，因为它需要遍历每个状态，而每个状态是多个事件的集合，也就是<strong>以集合为状态，一个集合就是一个状态</strong>。集合问题一般是指数复杂度的NP问题，所以状态压缩DP的复杂度仍然是指数的，只能用于小规模问题的求解。</p>
<p>为了方便地<strong>同时表示一个状态的多个事件</strong>，状态一般用二进制数来表示。<strong>一个数就能表示一个状态</strong>，通常一个状态数据就是一个一串0和1组成的二进制数，每一位二进制数只有两种状态，比如说硬币的正反两面，10枚硬币的结果就可以用10位二进制数完全表示出来，每一个10位二进制数就表示了其中一种结果。 <img src="/posts/35a94d42/asset/v2-0af09891a956d1bc9ffe6aa112dbd1a5_1440w.webp" alt="img"></p>
<p>使用二进制数表示状态不仅<strong>缩小了数据存储空间</strong>，还能利用二进制数的位运算很方便地<strong>进行状态转移</strong>。</p>
<p><strong>下面列举了一些常见的二进制位的变换操作。</strong></p>
<table>
<thead>
<tr>
<th>技巧</th>
<th>示例</th>
<th>代码实现</th>
</tr>
</thead>
<tbody><tr>
<td>去掉最后一位</td>
<td>(101101-&gt;10110)</td>
<td>x &gt;&gt; 1</td>
</tr>
<tr>
<td>在最后加一个0</td>
<td>(101101-&gt;1011010)</td>
<td>x &lt;&lt; 1</td>
</tr>
<tr>
<td>在最后加一个1</td>
<td>(101101-&gt;1011011)</td>
<td>x &lt;&lt; 1 + 1</td>
</tr>
<tr>
<td>把最后一位变成1</td>
<td>(101100-&gt;101101)</td>
<td>x | 1</td>
</tr>
<tr>
<td>把最后一位变成0</td>
<td>(101101-&gt;101100)</td>
<td>x | 1 - 1</td>
</tr>
<tr>
<td>最后一位取反</td>
<td>(101101-&gt;101100)</td>
<td>x ^ 1</td>
</tr>
<tr>
<td>把右数第k位变成1</td>
<td>(101001-&gt;101101,k&#x3D;3)</td>
<td>x | (1 &lt;&lt; (k - 1))</td>
</tr>
<tr>
<td>把右数第k位变成0</td>
<td>(101101-&gt;101001,k&#x3D;3)</td>
<td>x &amp; ~(1 &lt;&lt; (k - 1))</td>
</tr>
<tr>
<td>右数第k位取反</td>
<td>(101001-&gt;101101,k&#x3D;3)</td>
<td>x ^ (1 &lt;&lt; (k - 1))</td>
</tr>
<tr>
<td>取末k位</td>
<td>(1101101-&gt;1101,k&#x3D;5)</td>
<td>x &amp; (1 &lt;&lt; k - 1)</td>
</tr>
<tr>
<td>取右数第k位</td>
<td>(1101101-&gt;1,k&#x3D;4)</td>
<td>x &gt;&gt; (k - 1) &amp; 1</td>
</tr>
<tr>
<td>把末k位变成1</td>
<td>(101001-&gt;101111,k&#x3D;4)</td>
<td>x | (1 &lt;&lt; k - 1)</td>
</tr>
<tr>
<td>末k位取反</td>
<td>(101001-&gt;100110,k&#x3D;4)</td>
<td>x ^ (1 &lt;&lt; k - 1)</td>
</tr>
<tr>
<td>把右起第一个0变成1</td>
<td>(100101111-&gt;100111111)</td>
<td>x | (x + 1)</td>
</tr>
<tr>
<td>把右起第一个1变成0</td>
<td>(11011000-&gt;11010000)</td>
<td>x &amp; (x − 1)</td>
</tr>
<tr>
<td>把右边连续的0变成1</td>
<td>(11011000-&gt;11011111)</td>
<td>x | (x - 1)</td>
</tr>
<tr>
<td>把右边连续的1变成0</td>
<td>(100101111-&gt;100100000)</td>
<td>x &amp; (x + 1)</td>
</tr>
<tr>
<td>取右边连续的1</td>
<td>(100101111-&gt;1111)</td>
<td>(x ^ (x + 1)) &gt;&gt; 1</td>
</tr>
</tbody></table>
<h3 id="例题讲解"><a href="#例题讲解" class="headerlink" title="例题讲解"></a><strong>例题讲解</strong></h3><p>给你一个整数数组 <code>cookies</code> ，其中 <code>cookies[i]</code> 表示在第 <code>i</code> 个零食包中的饼干数量。另给你一个整数 <code>k</code> 表示等待分发零食包的孩子数量，<strong>所有</strong> 零食包都需要分发。在同一个零食包中的所有饼干都必须分发给同一个孩子，不能分开。</p>
<p>分发的 <strong>不公平程度</strong> 定义为单个孩子在分发过程中能够获得饼干的最大总数。</p>
<p>返回所有分发的最小不公平程度。</p>
<p><strong>提示：</strong></p>
<ul>
<li><code>2 &lt;= cookies.length &lt;= 8</code></li>
<li><code>1 &lt;= cookies[i] &lt;= 105</code></li>
<li><code>2 &lt;= k &lt;= cookies.length</code></li>
</ul>
<h3 id="题意理解"><a href="#题意理解" class="headerlink" title="题意理解"></a><strong>题意理解</strong></h3><p>将<code>n</code>包具有一定饼干数量的零食分给<code>k</code>位小朋友，为了让能拿到最多饼干的小朋友拿到尽可能少的饼干，可理解为缩小贫富差距，求所有可行的零食分发方案中最多饼干那位小朋友最少的一种，为多少。</p>
<h3 id="算法分析"><a href="#算法分析" class="headerlink" title="算法分析"></a><strong>算法分析</strong></h3><p>如果你想先想出一套可行的零食分发算法再按部就班计算出答案，比如说使用贪心算法等，可能一辈子都解不出这道题来，因为这是一个NP类问题，即是一个<strong>可以在多项式时间内验证解的问题而目前无法在多项式时间内求出解的问题</strong>。</p>
<p>既然我们无法给出快速求取精确解的算法，但是可以穷举所有可行解，根据题目需要选取最优解。</p>
<p>由于问题规模较小，我们使用穷举法枚举每一种可能结果。</p>
<p>对于每一种可能结果，n 包零食的分发状态需要明确，这里使用n位二进制数<code>j</code>来表示，共有<code>（1 &lt;&lt; n）</code>种可能。</p>
<p>对于已经分好零食的当前 k 位小朋友，设此时 n 包零食状态为<code>j</code>，比方说第 k 位小朋友拿到了其中的 2 包零食，设零食状态为<code>c</code>，那么对于当前 k 位朋友分好零食得到的结果，等价于，已经将前 k 位小朋友分好零食，再将那 2 包零食分给第 k 位小朋友后得到的结果。也就是说，分好 k 位朋友可由分好前 k 位朋友经过决策转移而来。</p>
<p>对于最优的决策，我们需要比较所有可能的决策来确定，设第 k 位朋友得到的零食状态<code>c</code>，这里使用技巧<code>for(int c=j;c;c=(c-1)&amp;j)</code>枚举所有可能决策。</p>
<p>对于分好前 k 位朋友的零食状态，我们可以使用位运算轻松表示为<code>j ^ c</code>。</p>
<h3 id="算法实现"><a href="#算法实现" class="headerlink" title="算法实现"></a><strong>算法实现</strong></h3><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">distributeCookies</span><span class="params">(vector&lt;<span class="type">int</span>&gt;&amp; cookies, <span class="type">int</span> k)</span> </span>&#123;</span><br><span class="line">        <span class="type">int</span> n=cookies.<span class="built_in">size</span>();</span><br><span class="line">        vector&lt;<span class="type">int</span>&gt;<span class="built_in">s</span>(<span class="number">1</span>&lt;&lt;n); <span class="comment">// 表示所有的零食包分发状态的不公平程度</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;n;i++)&#123; </span><br><span class="line">            <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">0</span>,c=(<span class="number">1</span>&lt;&lt;i);j&lt;c;j++)&#123; <span class="comment">// 将第i个零食包分发到所有子集</span></span><br><span class="line">                s[j|c]=s[j]+cookies[i];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        vector&lt;vector&lt;<span class="type">int</span>&gt;&gt;<span class="built_in">f</span>(k,<span class="built_in">vector</span>&lt;<span class="type">int</span>&gt;(<span class="number">1</span>&lt;&lt;n,INT_MAX)); <span class="comment">// f[i][j]表示以零食包分发状态j时分给i个小朋友的最优解</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;(<span class="number">1</span>&lt;&lt;n);i++)&#123; <span class="comment">// 分给一个小朋友时就是零食包分发状态的不公平程度</span></span><br><span class="line">            f[<span class="number">0</span>][i]=s[i];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;k;i++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">1</span>;j&lt;(<span class="number">1</span>&lt;&lt;n);j++)&#123;</span><br><span class="line">                <span class="keyword">for</span>(<span class="type">int</span> c=j;c;c=(c<span class="number">-1</span>)&amp;j)&#123; <span class="comment">// 将零食包分发状态j分给第i位小朋友</span></span><br><span class="line">                    f[i][j]=<span class="built_in">min</span>(f[i][j],<span class="built_in">max</span>(f[i<span class="number">-1</span>][j^c],s[c]));</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> f[k<span class="number">-1</span>][(<span class="number">1</span>&lt;&lt;n)<span class="number">-1</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p><img src="/posts/35a94d42/asset/1688221546201.png" alt="1688221546201"></p>
<p><img src="/posts/35a94d42/asset/1688221568068.png" alt="1688221568068"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include &lt;bits/stdc++.h&gt;</span><br><span class="line">using namespace std;</span><br><span class="line">const int maxn = 21;</span><br><span class="line">int f[1 &lt;&lt; maxn][maxn];</span><br><span class="line">int n, m, s, t, k, ans;</span><br><span class="line">int w[maxn &lt;&lt; 1][maxn &lt;&lt; 1];</span><br><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">    cin &gt;&gt; n;</span><br><span class="line">    for (int i = 0; i &lt; n; ++ i) </span><br><span class="line">        for (int j = 0; j &lt; n; ++ j) </span><br><span class="line">            scanf(&quot;%d&quot;, &amp;w[i][j]);</span><br><span class="line">    memset(f, 0x3f, sizeof f);</span><br><span class="line">    f[1][0] = 0;</span><br><span class="line">    for (int i = 0; i &lt;= (1 &lt;&lt; n) - 1; ++ i) &#123;</span><br><span class="line">        for (int j = 0; j &lt; n; ++ j) &#123;</span><br><span class="line">            if ((i &gt;&gt; j) &amp; 1) &#123;</span><br><span class="line">                for (int k = 0; k &lt; n; ++ k) &#123;</span><br><span class="line">                    int now = i ^ (1 &lt;&lt; j);</span><br><span class="line">                    if ((now &gt;&gt; k) &amp; 1)</span><br><span class="line">                        f[i][j] = min(f[i][j], f[now][k] + w[k][j]);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    cout &lt;&lt; f[(1 &lt;&lt; n) - 1][n - 1] &lt;&lt; &#x27;\n&#x27;;</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>动态规划</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>动态规划</tag>
      </tags>
  </entry>
  <entry>
    <title>7.倍增优化dp</title>
    <url>/posts/57b019a2/</url>
    <content><![CDATA[<p>倍增优化DP通常会将<code>2^k</code> 中的k压入状态方程之中，以表示状态方程其他状态满足某种倍增性质时的结果，例如下面的两个例子，跑路中的<code>dp[i][j][k]</code>可以表示i，j两点之间是否存在一条路径长度为<code>2^k</code> 的路径，开车旅行中的<code>Fun[who][city][k]</code>可以表示who先开，从city出发，开<code>2^k</code>天可以到达的城市。</p>
<p> 而转移方程，毫无疑问也与倍增相关，转移方程中，最外层的循环几乎都是循环与倍增有关的变量——k，这一点上可以类比<a href="https://www.cnblogs.com/TanJI-life/p/15008861.html">区间动态规划的</a>思想，都是从短(小)的循环到长(大)的。</p>
<p><img src="/posts/57b019a2/asset/2308687-20210716230614132-1881461767.png" alt="img"></p>
<p>求家到公司的最短时间，稍微思考一下，发现是求图上两点最短路的变种板，即从原来的最短路，变成了求最短时间，而两者之间的联系——速度（广义），并不是一个恒定值，而是满足于一个规律，即跑<code>2^k</code> m只要一秒，其他距离通过<code>2^k</code>的模式进行合并。</p>
<p> 转换转换思维，求两点之间的最短路，需要一个单位进行度量，在这道题中是秒，因此我们要把所有可以在一个单位时间内跑完的路径求出作为求最短路之前的准备工作，进而求出其他需要大于一个单位时间内跑完的路径。</p>
<p> 发现数据量并不大，所以可以使用Floyd算法。</p>
<p> 于是我们得到状态方程<code>dp[i][j]</code>，表示从i跑到j所需要的最少时间。</p>
<p> 那首先是初始化，即上面所说的将所有可以在一个单位时间内跑完的路求出。由于题目给出的都是距离为1(2^0)的点，所以所有可以一个单位时间内跑完的路径<code>2^k</code>一定都可以由两个<code>2^(k - 1)</code>的路径组成，这里就用到了倍增优化的思想（虽然感觉关系不大），于是我们可以类比<a href="https://www.cnblogs.com/TanJI-life/p/15008861.html">区间动态规划的</a>思想，从最短的“一单位”路径枚举到最长的“一单位”路径，所以我们可以得到以下方程</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">for(int k = 0; k &lt; 节点数量; k++)</span><br><span class="line">for(int t = 0; t &lt; 节点数量; t++)</span><br><span class="line">for(int i = 0; i &lt; 节点数量; i++) </span><br><span class="line">for(int j = 0; j &lt; 节点数量; j++) </span><br><span class="line">	if (G[i][t][k - 1] &amp;&amp; G[k][j][k - 1]) &#123;</span><br><span class="line">		G[i][j][k] = true;</span><br><span class="line">		dp[i][j] = 1;</span><br><span class="line">	&#125;</span><br><span class="line">//G[i][j][k]表示i到j有2^k的路径吗</span><br></pre></td></tr></table></figure>

<p>也可以得到转移方程（Floyd的算法）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">for(int k = 0; k &lt; 节点数量; k++) for(int i = 0; i &lt; 节点数量; i++)  for(int j = 0; j &lt; 节点数量; j++)  dp[i][j] = min(dp[i][j], dp[i][k] + dp[k][j]);</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>动态规划</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>动态规划</tag>
      </tags>
  </entry>
  <entry>
    <title>8.数据结构优化dp</title>
    <url>/posts/2a37d8a5/</url>
    <content><![CDATA[<p> 在DP的转移中需要用到某一个阶段的最值的时候可以用线段树和树状数组等数据结构进行维护，在O(1)或O(log N) 的时间复杂度内完成转移 </p>
<p><a href="https://www.luogu.com.cn/problem/P4644">https://www.luogu.com.cn/problem/P4644</a></p>
<h1 id="USACO05DEC-Cleaning-Shifts-S"><a href="#USACO05DEC-Cleaning-Shifts-S" class="headerlink" title="[USACO05DEC] Cleaning Shifts S"></a>[USACO05DEC] Cleaning Shifts S</h1><h2 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h2><p>约翰的奶牛们从小娇生惯养，她们无法容忍牛棚里的任何脏东西。约翰发现，如果要使这群有洁癖的奶牛满意，他不得不雇佣她们中的一些来清扫牛棚，约翰的奶牛中有 $ N(1 \leq N \leq 10000) $ 头愿意通过清扫牛棚来挣一些零花钱。</p>
<p>由于在某个时段中奶牛们会在牛棚里随时随地地乱扔垃圾，自然地，她们要求在这段时间里，无论什么时候至少要有一头奶牛正在打扫。需要打扫的时段从某一天的第 $ M $ 秒开始，到第 $ E $ 秒结束 $ (0 \leq M \leq E \leq 86399) $。注意这里的秒是指时间段而不是时间点，也就是说，每天需要打扫的总时间是 $ E-M+1 $ 秒。</p>
<p>约翰已经从每头牛那里得到了她们愿意接受的工作计划：对于某一头牛，她每天都愿意在笫 $ T_1 \ldots T_2 $ 秒的时间段内工作 $ (M \leq T_1 \leq T_2 \leq E) $ ，所要求的报酬是 $ S $ 美元 $ (0 \leq S \leq 500000) $。与需打扫时段的描述一样，如果一头奶牛愿意工作的时段是每天的第 $ 10 \ldots 20 $ 秒，那她总共工作的时间是 $ 11 $ 秒，而不是 $ 10 $ 秒。</p>
<p>约翰一旦决定雇佣某一头奶牛，就必须付给她全额的工资，而不能只让她工作一段时间，然后再按这段时间在她愿意工作的总时间中所占的百分比来决定她的工资。现在请你帮约翰决定该雇佣哪些奶牛以保持牛棚的清洁，当然，在能让奶牛们满意的前提下，约翰希望使总花费尽量小。</p>
<h2 id="输入格式"><a href="#输入格式" class="headerlink" title="输入格式"></a>输入格式</h2><p>第 $ 1 $ 行： $ 3 $ 个正整数 $ N,M,E $ 。</p>
<p>第 $ 2 $ 到 $ N+1 $ 行：第 $ i+1 $ 行给出了编号为 $ i $ 的奶牛的工作计划，即 $ 3 $ 个正整数 $ T_1,T_2,S $ 。</p>
<h2 id="输出格式"><a href="#输出格式" class="headerlink" title="输出格式"></a>输出格式</h2><p>输出一个整数，表示约翰需要为牛棚清理工作支付的最少费用。如果清理工作不可能完成，那么输出 $ -1 $ 。</p>
<h2 id="样例-1"><a href="#样例-1" class="headerlink" title="样例 #1"></a>样例 #1</h2><h3 id="样例输入-1"><a href="#样例输入-1" class="headerlink" title="样例输入 #1"></a>样例输入 #1</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">3 0 4</span><br><span class="line">0 2 3</span><br><span class="line">3 4 2</span><br><span class="line">0 0 1</span><br></pre></td></tr></table></figure>

<h3 id="样例输出-1"><a href="#样例输出-1" class="headerlink" title="样例输出 #1"></a>样例输出 #1</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">5</span><br></pre></td></tr></table></figure>

<h2 id="提示"><a href="#提示" class="headerlink" title="提示"></a>提示</h2><p>约翰有 $ 3 $ 头牛，牛棚在第 $ 0 $ 秒到第 $ 4 $ 秒之间需要打扫。 约翰雇佣前两头牛清扫牛棚，可以只花 $ 5 $ 美元就完成一整天的清扫。</p>
<p>首先设计出状态，dp[x]表示从m清理到x所付出的最小代价<br>很显然，状态转移方程为<br><img src="/posts/2a37d8a5/asset/sd1kqdun.png" alt="img"><br>很显然，我们的每一次的转移都会用到一个区间的最小值，所以考虑运用线段树进行优化</p>
<h5 id="build"><a href="#build" class="headerlink" title="build"></a>build</h5><p>我们在[m,e]上建立一颗线段树，存储DP的最小值</p>
<h5 id="change"><a href="#change" class="headerlink" title="change"></a>change</h5><p>当我们更新完一个DP的值的时候，就在线段树中插入这个值</p>
<h5 id="ask"><a href="#ask" class="headerlink" title="ask"></a>ask</h5><p>每一次状态转移我们都需要在区间<img src="/posts/2a37d8a5/asset/9ms74x2e.png" alt="img">查找最小值</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include&lt;bits/stdc++.h&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">const int MAXN=1e5+5,MAXM=9e5+5;</span><br><span class="line">struct Node</span><br><span class="line">&#123;</span><br><span class="line">	int t1,t2,s;</span><br><span class="line">&#125;cow[MAXN];</span><br><span class="line">struct node</span><br><span class="line">&#123;</span><br><span class="line">	int l,r,val;</span><br><span class="line">&#125;lst[MAXM];</span><br><span class="line">int n,s,e,dp[MAXM],ans;</span><br><span class="line"></span><br><span class="line">void build_tree(int id,int l,int r)</span><br><span class="line">&#123;</span><br><span class="line">	lst[id].l=l; lst[id].r=r;</span><br><span class="line">	if( l==r )</span><br><span class="line">	&#123;</span><br><span class="line">		lst[id].val=dp[l];</span><br><span class="line">		return;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	int mid=(l+r)/2;</span><br><span class="line">	build_tree(id*2,l,mid);</span><br><span class="line">	build_tree(id*2+1,mid+1,r);</span><br><span class="line">	lst[id].val=min(lst[id*2].val,lst[id*2+1].val);</span><br><span class="line">	return;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void change_tree(int id,int ver,int val)</span><br><span class="line">&#123;</span><br><span class="line">	if( lst[id].l==lst[id].r )</span><br><span class="line">	&#123;</span><br><span class="line">		lst[id].val=dp[ver];</span><br><span class="line">		return;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	int mid=(lst[id].l+lst[id].r)/2;</span><br><span class="line">	if( mid &gt;= ver ) change_tree(id*2,ver,val);</span><br><span class="line">	else change_tree(id*2+1,ver,val);</span><br><span class="line">	lst[id].val=min(lst[id*2].val,lst[id*2+1].val);</span><br><span class="line">	return;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int ask_tree(int id,int l,int r)</span><br><span class="line">&#123;</span><br><span class="line">	if( lst[id].l==lst[id].r ) return lst[id].val;</span><br><span class="line">	</span><br><span class="line">	int mid=(lst[id].l+lst[id].r)/2,tem=0x7f7f7f7f;</span><br><span class="line">	if( mid &gt;= l ) tem=min(tem,ask_tree(id*2,l,r));</span><br><span class="line">	if( mid &lt;= r ) tem=min(tem,ask_tree(id*2+1,l,r));</span><br><span class="line">	return tem;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">bool cmp(Node x,Node y)</span><br><span class="line">&#123;</span><br><span class="line">	return x.t2 &lt; y.t2;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">	scanf(&quot;%d%d%d&quot;,&amp;n,&amp;s,&amp;e);</span><br><span class="line">	for(int i=1;i&lt;=n;i++) scanf(&quot;%d%d%d&quot;,&amp;cow[i].t1,&amp;cow[i].t2,&amp;cow[i].s);</span><br><span class="line">	sort(cow+1,cow+n+1,cmp);</span><br><span class="line">	memset(dp,0x7f7f7f7f,sizeof(dp));</span><br><span class="line">	dp[s]=0;</span><br><span class="line">	build_tree(1,s,e);</span><br><span class="line">	for(int i=1;i&lt;=n;i++)</span><br><span class="line">	&#123;</span><br><span class="line">		int tem=ask_tree(1,cow[i].t1-1,cow[i].t2);</span><br><span class="line">		dp[cow[i].t2]=tem+cow[i].s;</span><br><span class="line">		if( cow[i].t2 &gt;= e ) &#123;ans=dp[cow[i].t2]; break;&#125;</span><br><span class="line">		change_tree(1,cow[i].t2,dp[i]);</span><br><span class="line">	&#125;</span><br><span class="line">	if( ans==2139075787 ) printf(&quot;-1&quot;);</span><br><span class="line">	else printf(&quot;%d&quot;,ans);</span><br><span class="line">	return 0;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="The-Battle-of-Chibi"><a href="#The-Battle-of-Chibi" class="headerlink" title="The Battle of Chibi"></a>The Battle of Chibi</h1><h2 id="题面翻译"><a href="#题面翻译" class="headerlink" title="题面翻译"></a>题面翻译</h2><p>$T$ 组数据，在长度为 $n$ 的数列 $a$ 中，求出长度为 $m$ 的<strong>严格上升子序列</strong>的个数。答案对 $10^9 + 7$ 取模。</p>
<p>举个例子：</p>
<p>$n &#x3D; 5$，$m &#x3D; 3$，$a$ 为 1 3 2 4 5。</p>
<p>那么符合条件的序列就有：1 3 4，1 2 5，1 3 5，1 4 5，3 4 5。最终答案就是 $5$。</p>
<p>数据范围：</p>
<p>$1 \le m \le n \le 1000$，$1 \le a_i \le 10^9$，$1 \le T \le 100$。</p>
<h2 id="题目描述-1"><a href="#题目描述-1" class="headerlink" title="题目描述"></a>题目描述</h2><p><a href="https://uva.onlinejudge.org/external/129/p12983.pdf">PDF</a></p>
<p><img src="/posts/2a37d8a5/asset/2c81a6fe1132b701952f63c78a9a7d2e6b9e5ec1.png"></p>
<h2 id="输入格式-1"><a href="#输入格式-1" class="headerlink" title="输入格式"></a>输入格式</h2><p><img src="/posts/2a37d8a5/asset/52880c5074f5f4a6fdfae251027312d6918f944a.png"></p>
<h2 id="输出格式-1"><a href="#输出格式-1" class="headerlink" title="输出格式"></a>输出格式</h2><p><img src="/posts/2a37d8a5/asset/7c1e7c5f4a868fbee2074a74bbef857cb077861d.png"></p>
<h2 id="样例-1-1"><a href="#样例-1-1" class="headerlink" title="样例 #1"></a>样例 #1</h2><h3 id="样例输入-1-1"><a href="#样例输入-1-1" class="headerlink" title="样例输入 #1"></a>样例输入 #1</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">2</span><br><span class="line">3 2</span><br><span class="line">1 2 3</span><br><span class="line">3 2</span><br><span class="line">3 2 1</span><br></pre></td></tr></table></figure>

<h3 id="样例输出-1-1"><a href="#样例输出-1-1" class="headerlink" title="样例输出 #1"></a>样例输出 #1</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Case #1: 3</span><br><span class="line">Case #2: 0</span><br></pre></td></tr></table></figure>

<h5 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h5><p>实际上是给定一个长度为N的数列，求数列中有多少个长度为M的严格递增子序列<br>首先设计状态 dp[i] [j] 表示前j个数中以第j个数为结尾的长度为i 的严格递增序列有多少个</p>
<p>状态转移方程为：</p>
<p><img src="/posts/2a37d8a5/asset/asasumou.png" alt="img"></p>
<h5 id="add"><a href="#add" class="headerlink" title="add"></a>add</h5><p>将c[disc[j]]增加dp[i-1] [j]</p>
<h5 id="ask-1"><a href="#ask-1" class="headerlink" title="ask"></a>ask</h5><p>查询disc[j]的前缀和</p>
<h5 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h5><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;bits/stdc++.h&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> MAXN=<span class="number">1e3</span>+<span class="number">5</span>,mod=<span class="number">1e9</span>+<span class="number">7</span>;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Node</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="type">int</span> id,val;</span><br><span class="line">&#125;a[MAXN],b[MAXN];</span><br><span class="line"><span class="type">int</span> c[MAXN],disc[MAXN],n,m,t,dp[MAXN][MAXN];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">lowbit</span><span class="params">(<span class="type">int</span> x)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="keyword">return</span> x &amp; -x;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">cmp</span><span class="params">(Node x,Node y)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="keyword">return</span> x.val == y.val ? x.id &gt; y.id : x.val &lt; y.val;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">ask</span><span class="params">(<span class="type">int</span> x)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="type">int</span> tem=<span class="number">0</span>;</span><br><span class="line">	<span class="keyword">while</span>( x )</span><br><span class="line">	&#123;</span><br><span class="line">		tem+=c[x]; tem%=mod;</span><br><span class="line">		x-=<span class="built_in">lowbit</span>(x);</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> tem;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">add</span><span class="params">(<span class="type">int</span> x,<span class="type">int</span> y)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="keyword">while</span>( x &lt;= n+<span class="number">1</span> )</span><br><span class="line">	&#123;</span><br><span class="line">		c[x]+=y; c[x]%=mod;</span><br><span class="line">		x+=<span class="built_in">lowbit</span>(x);</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">work</span><span class="params">(<span class="type">int</span> k)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="built_in">memset</span>(a,<span class="number">0</span>,<span class="built_in">sizeof</span>(a)); <span class="built_in">memset</span>(dp,<span class="number">0</span>,<span class="built_in">sizeof</span>(dp));</span><br><span class="line">	<span class="built_in">memset</span>(disc,<span class="number">0</span>,<span class="built_in">sizeof</span>(disc));</span><br><span class="line">	dp[<span class="number">0</span>][<span class="number">0</span>]=<span class="number">1</span>;</span><br><span class="line">	<span class="built_in">scanf</span>(<span class="string">&quot;%d%d&quot;</span>,&amp;n,&amp;m);</span><br><span class="line">	<span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=n;i++) <span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>,&amp;a[i].val),a[i].id=i,b[i]=a[i];</span><br><span class="line">	<span class="built_in">sort</span>(b+<span class="number">1</span>,b+n+<span class="number">1</span>,cmp);</span><br><span class="line">	<span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=n;i++) disc[b[i].id]=i+<span class="number">1</span>;</span><br><span class="line">	<span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=m;i++)</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="built_in">memset</span>(c,<span class="number">0</span>,<span class="built_in">sizeof</span>(c));</span><br><span class="line">		<span class="built_in">add</span>(<span class="number">1</span>,dp[i<span class="number">-1</span>][<span class="number">0</span>]);</span><br><span class="line">		<span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">1</span>;j&lt;=n;j++)</span><br><span class="line">		&#123;</span><br><span class="line">			dp[i][j]=<span class="built_in">ask</span>(disc[j]<span class="number">-1</span>);</span><br><span class="line">			<span class="built_in">add</span>(disc[j],dp[i<span class="number">-1</span>][j]);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="type">int</span> ans=<span class="number">0</span>;</span><br><span class="line">	<span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=n;i++) ans+=dp[m][i],ans%=mod;</span><br><span class="line">	<span class="built_in">printf</span>(<span class="string">&quot;Case #%d: %d\n&quot;</span>,k,ans%mod);</span><br><span class="line">	<span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>,&amp;t);</span><br><span class="line">	<span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=t;i++) <span class="built_in">work</span>(i);</span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>动态规划</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>动态规划</tag>
      </tags>
  </entry>
  <entry>
    <title>1.位运算</title>
    <url>/posts/379d38db/</url>
    <content><![CDATA[<h2 id="位运算"><a href="#位运算" class="headerlink" title="位运算"></a>位运算</h2><ul>
<li>按位与 : &amp; ,and （有0为0，无0为1）</li>
<li>按位或：|，or  （有1为1，无1为0）</li>
<li>异或：^,xor      （相同为0，不同为1）</li>
<li>非：~，not       （取反）</li>
</ul>
<p>m位二进制，通常最低位为第0位</p>
<h2 id="移位运算"><a href="#移位运算" class="headerlink" title="移位运算"></a>移位运算</h2><p>1&lt;&lt; n&#x3D;2^n^</p>
<p>n&lt;&lt;1 &#x3D; 2n</p>
<p>n&gt;&gt;1 &#x3D; floor(n&#x2F;2.0)  除以2向下取整</p>
<h2 id="二进制状态压缩"><a href="#二进制状态压缩" class="headerlink" title="二进制状态压缩"></a>二进制状态压缩</h2><p> <strong>注意下表的第k位都是从第0位开始的</strong> </p>
<p><img src="/posts/379d38db/asset/1688096756442.png" alt="1688096756442"></p>
<p> 更多状压DP请点击下方链接：<br><a href="https://blog.csdn.net/weixin_45697774/article/details/104874248">https://blog.csdn.net/weixin_45697774/article/details/104874248</a> </p>
<h2 id="成对变换"><a href="#成对变换" class="headerlink" title="成对变换"></a>成对变换</h2><p> <img src="/posts/379d38db/asset/20200418214802598.png" alt="在这里插入图片描述"> </p>
<h2 id="lowbit"><a href="#lowbit" class="headerlink" title="lowbit"></a>lowbit</h2><p> lowbit定义为非负整数n在二进制表示下“最低位的1及其后边的所有0”构成的数值， 例如n&#x3D;10&#x3D;(1010)<del>2</del>,则lowbit(n) &#x3D; 2 &#x3D;(10)<del>2</del> ,</p>
<p> <code>-x</code> 的值， 其实就是在x的值的基础上进行按位<a href="https://so.csdn.net/so/search?q=%E5%8F%96%E5%8F%8D&spm=1001.2101.3001.7020">取反</a>(<del>x)之后在增加1所得, x &amp; -x &#x3D;&#x3D; x &amp; (</del>x + 1) </p>
<p>x&amp;(-x)  ,  <strong>如果是x是奇数， 那x &amp; -x 的结果一定是1</strong> ; <strong>当一个偶数与它的负值相与时， 结果是能整除这个偶数的最大的2的幂, 即： m &#x3D; n &amp; -n , 则 n % m &#x3D; 0, 且 m &#x3D; 2 ^ k</strong> </p>
<p> <strong>lowbit配合hash可以找出整数二进制表示下的所有的是1 的位数。</strong> </p>
<h2 id="位图"><a href="#位图" class="headerlink" title="位图"></a>位图</h2><p><code>vector of bits</code>也就是位图，由于可以用<strong>非常紧凑的格式</strong>来表示给定范围的连续数据而经常出现在各种算法设计中，这里<strong>非常紧凑的格式</strong>指的就是数组。</p>
<p>基本原理是，在一个特定的位置上(往往是数组下标的位置上)的值(开关)，0为没有出现过，1表示出现过，也就是说使用的时候可根据某一个位置是否为0表示此数(这个位置代表的数，往往是下标)是否出现过。</p>
<p><img src="/posts/379d38db/asset/fa9cf2f23f0048538d9d24f34e08551c_tplv-k3u1fbpfcp-zoom-in-crop-mark_4536_0_0_0.awebp" alt="image-20210119092558445"></p>
<p>为了方便大家理解，我么可以对上图的数据解释一下，上图是我截取了一个位向量的一部分，也就是下标为1000-1009 的位置。这里开关为1(值为1)代表着此处的数据出现过，也就是说值为数组下标的数据，也就是1000出现过，同理1003 也出现过，然后就是1008 也出现过，其他的都没有出现过。</p>
<p>其实到这里我们就可以对位图有了一个基本的认识，说白了它就是用数组表示特定位置上的数据出现过没有，因为出现还是没有出现只会有两种结果，也就是true 和 false ，所以我们可以使用0 1 来表示，这里的0 1 指的是二进制中的0 1 ，这样我们用bit 来表示，而不是使用其他数据类型，例如Int 类型或者是String ,因为这种数据类型是比较耗空间的，这就是为什么我们使用这种数据结构的原因</p>
<h2 id="BitSet类"><a href="#BitSet类" class="headerlink" title="BitSet类"></a>BitSet类</h2><p> BitSet类实现了一个按需增长的位向量,实际是由“二进制位”构成的一个Vector。每一位都是一个表示true或者false 的boolean 值。如果我们希望高效地存储这样只有两种类型的数据，就可以使用BitSet。 </p>
<p>首先需要说明的是，BitSet并不属于集合框架，没有实现List或Map或者Set接口，BitSet更多的表示一种开关信息，对于海量不重复数据，利用索引表示数据的方式，将会大大节省空间使用。</p>
<p><img src="/posts/379d38db/asset/37738dfaef7e4e789f4dfde20c727c5c_tplv-k3u1fbpfcp-zoom-in-crop-mark_4536_0_0_0.awebp" alt="image-20210124105544952"></p>
<h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><p> <strong>面试题</strong>中也常出现，比如：统计40亿个数据中没有出现的数据，将40亿个不同数据进行排序等。</p>
<p>又如：现在有1千万个随机数，随机数的范围在1到1亿之间。现在要求写出一种算法，将1到1亿之间没有在随机数中的数求出来(百度)。</p>
<p>programming pearls上也有一个关于使用bitset来查找电话号码的题目。</p>
<p>Bitmap的常见扩展，是用2位或者更多为来表示此数字的更多信息，比如出现了多少次等。</p>
<h2 id="相关习题"><a href="#相关习题" class="headerlink" title="相关习题"></a>相关习题</h2><p><a href="https://fanfansann.blog.csdn.net/article/details/105595549">https://fanfansann.blog.csdn.net/article/details/105595549</a></p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>基本算法</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>基本算法</tag>
      </tags>
  </entry>
  <entry>
    <title>10.hash表</title>
    <url>/posts/55878d22/</url>
    <content><![CDATA[<h2 id="hash-表"><a href="#hash-表" class="headerlink" title="hash 表"></a>hash 表</h2><p>Hash 表又称散列表，一般由 Hash 函数与链表结构共同实现。</p>
<p>有一种称为开散列的解决方案是，建立一个邻接表结构，以Hash 函数的值域作为表头数组，映射后的值相同的原始信息被分到同一类。</p>
<p><img src="/posts/55878d22/asset/1688119985448.png" alt="1688119985448"></p>
<p><img src="/posts/55878d22/asset/20200506223525792.png" alt="在这里插入图片描述"></p>
<p>###采用hash表+链表</p>
<p><img src="/posts/55878d22/asset/1688120447339.png" alt="1688120447339"></p>
<h3 id="字符串的最小表示法"><a href="#字符串的最小表示法" class="headerlink" title="字符串的最小表示法"></a>字符串的最小表示法</h3><p> 判断是否有相同雪花的方式就是直接暴力枚举就好<br>        若只有旋转操作，可以用字符串的最小表示:<br>        字符串长度为n，旋转n次，取字典序最小的那一种，即为字符串的最小表示。<br>        现在有翻转操作，所以我们对原序列求最小表示，再对翻转后的序列求一个最小表示 </p>
<p>再排序</p>
<h2 id="字符串hash"><a href="#字符串hash" class="headerlink" title="字符串hash"></a>字符串hash</h2><p> 将一个任意长度的字符串映射为一个非负整数，并且其冲突概率几乎为零。 </p>
<p><img src="/posts/55878d22/asset/1688121042532.png" alt="1688121042532"></p>
<p><img src="/posts/55878d22/asset/20200507115803778.png" alt="在这里插入图片描述"></p>
<p> 这道其实就是上面思路的一个模板题。 </p>
<h2 id="回文子串的最大长度"><a href="#回文子串的最大长度" class="headerlink" title="回文子串的最大长度"></a>回文子串的最大长度</h2><p><img src="/posts/55878d22/asset/20200507164346161.png" alt="在这里插入图片描述"></p>
<p>我们可以算出一个前缀和,再算出一个后缀和,然后就可以知道,正字符串和一个反字符串.字符串的哈希值就是这个区间的哈希值和.算完之后,我们当前就只需要枚举一个mid中间点,因为所有回文串都是有一个中间点(奇),或者中间区间(偶),然后二分分别寻找这个字符串长度即可,记住不是回文串,回文串的长度,是 字符串长度×2 + 1(奇) 或者是 字符串长度×2(偶数).</p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>基本算法</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>基本算法</tag>
      </tags>
  </entry>
  <entry>
    <title>11.字符串</title>
    <url>/posts/56a1f4e8/</url>
    <content><![CDATA[<h2 id="KMP模式匹配"><a href="#KMP模式匹配" class="headerlink" title="KMP模式匹配"></a>KMP模式匹配</h2><p> <strong>KMP算法</strong>，又称模式匹配算法，能够在<strong>线性</strong>时间内判断一个字符串是否为另一个字符串的子串，并以此求出子串的出现位置。 </p>
<p><img src="/posts/56a1f4e8/asset/1688128499849.png" alt="1688128499849"></p>
<p><img src="/posts/56a1f4e8/asset/1688128695536.png" alt="1688128695536"></p>
<p><img src="/posts/56a1f4e8/asset/1688128731324.png" alt="1688128731324"></p>
<p>求next数组:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">next[1] = 0;</span><br><span class="line"></span><br><span class="line">for (int i = 2, j = 0; i &lt;= n; ++i)</span><br><span class="line">&#123;</span><br><span class="line">    while (j &gt; 0 &amp;&amp; a[i] != a[j + 1]) j = next[j];//匹配j的下一个字符</span><br><span class="line">    if (a[i] == a[j + 1]) ++j;</span><br><span class="line">    next[i] = j;//有可能是 0</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p> 两者的定义相似，求法也相似。<br><strong>求 f数组</strong>： </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">//n指的是A串的长度</span><br><span class="line">for (int i = 1, j = 0; i &lt;= m; ++i)</span><br><span class="line">&#123;</span><br><span class="line">    while (j &gt; 0 &amp;&amp; (j == n || b[i] != a[j + 1])) j = next[j];</span><br><span class="line">    if (b[i] == a[j + 1]) ++j;</span><br><span class="line">    f[i] == j;</span><br><span class="line"></span><br><span class="line">    if (f[i] == n)</span><br><span class="line">    &#123;</span><br><span class="line">        // do something（表明 a 在 b 中出现一次）</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>整个算法的时间复杂度为Θ ( N + M ) </p>
<p><img src="/posts/56a1f4e8/asset/20200511232033531.png" alt="在这里插入图片描述"></p>
<p><img src="https://img-blog.csdnimg.cn/20200511232228803.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTY5Nzc3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h2 id="字符串的最小表示"><a href="#字符串的最小表示" class="headerlink" title="字符串的最小表示"></a>字符串的最小表示</h2><p> 字符串长度为n，旋转n次，取字典序最小的那一种，即为字符串的最小表示。 </p>
<p>例如：</p>
<p>s&#x3D;”00ab”</p>
<p>变形有（省略引号）b00a ab00 0ab0</p>
<p>一共4种</p>
<p>那么找到其中字典序最小的一个，用的算法便是这个。</p>
<p>定义三个指针，i,j,k</p>
<p>初始i&#x3D;0;j&#x3D;1;k&#x3D;0</p>
<p>首先，如果s[i]&lt;s[j]那么很明显j++</p>
<p>如果s[i]&gt;s[j]那么也很明显i&#x3D;j++</p>
<p>省下的就是如果s[i]&#x3D;&#x3D;s[j]的时候。</p>
<p>这时候有一个性质就是在i和j之间的所有的字符一定是大于等于s[i]的</p>
<p>另k&#x3D;0，循环寻找第一个s[i+k]!&#x3D;s[j+k]的位置</p>
<p>如果s[i+k]&lt;s[j+k]那么j+&#x3D;k+1</p>
<p>为什么呢？</p>
<p>首先s[i]到s[i+k-1]一定是大于等于s[i]，因为如果其中有一个数小于s[i]，那么这个数一定在s[j]到s[j+k-1]中存在，又因为必定有一个会在后面，所以如果s[j]先碰到了，那么一定不会继续到k的位置的，所以一定不存在比s[i]小的字符。</p>
<p>所以从其中的任意一个字符开始当作起始点，都不会比现在更小，所以只有从选出来的序列的后面那一个字符开始才有可能会是最小。</p>
<p>所以j+&#x3D;k+1</p>
<p>如果序列中某个数和s[i]相等的话，那么一定会有之前或者以后再这个位置起始过，所以不需要再从这个位置进行起始。</p>
<p>因为在这里i和j是等价的，i在前和j在前的结果是一样的，所以i和j的处理是相同的，下面就不仔细的进行讲解了，直接贴代码：</p>
<p>还有就是如果i&#x3D;&#x3D;j那么让j++就可以回到原先的状态了</p>
<p>最后的时候，肯定是小的不会动，而大的会不停的向后移动，所以最后只需要输出i和j最小的一个即可</p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>基本算法</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>基本算法</tag>
      </tags>
  </entry>
  <entry>
    <title>12.trie树</title>
    <url>/posts/caf7e096/</url>
    <content><![CDATA[<h2 id="trie树（字典树）"><a href="#trie树（字典树）" class="headerlink" title="trie树（字典树）"></a>trie树（字典树）</h2><p><img src="/posts/caf7e096/asset/1688131850547.png" alt="1688131850547"></p>
<p> 字典树，顾名思义，干嘛的？首先字典是干嘛的？查找字的。字典树自然也是起查找作用的，只不过是在树上找字的。为啥要在树上找字呢？因为我们都知道树上的操作更加高效。一般查找和更新操作的时间复杂度只与树的高度成正相关（貌似我们所有高效的数据结构都要往树上靠）。 </p>
<p>我们先看一下几个问题：</p>
<p>1.我们输入n个单词，然后给出m个查询，每次查询一个单词，需要回答出这个单词是否在之前输入的n单词中出现过。</p>
<p> 答：map计数（是STL中一种映射容器map&lt;key,value&gt;，这里key为单词，value为判断是否出现过的bool型标记），短小精悍。 </p>
<p> 2.我们输入n个单词，然后给出m个查询，每次查询一个单词的前缀，需要回答出 这个前缀 是之前输入的n单词中 多少个单词的前缀？ </p>
<p> 答：我们好像还是可以用map做，把输入n个单词中的每一个单词的前缀分别存入map中，然后计数，那这样真的很麻烦而且时间、空间复杂度会非常的高。若有n个单词，平均每个单词的长度为c，那么时间复杂度就会达到nc，很容易TLE。 </p>
<p>在实际的搜索引擎中，当我们在数据库中搜索一个关键字的时候，如何快速准确的进行定位是一个关键的问题，在面临大规模数据的时候，使用暴力的手段往往会造成检索和查找性能的低下，因此我们需要更加高效的数据结构。</p>
<p>这时候我们引入一种新的数据结构：Trie树（字典树）。</p>
<h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p> 接下来我通过举个具体的例子让大家对字典树的原理有一个清晰的认识，我对cat、cash、apple、aply、ok建立一颗字典树，如下图所示： <img src="asset/v2-5e40295bfa6c4a1688b6b5888aef583d_1440w.webp" alt="img" style="zoom:25%;" /></p>
<p>从图中可以看出：</p>
<p>1.每一个节点代表一个字符</p>
<p>2.有相同前缀的单词在树中就有公共的前缀节点，由于一共有26个小写英文字母（在这篇文章中，我们主要讨论小写的英文字母查询），因此每个节点最多有26个子节点。</p>
<p>3.整棵树的根节点是空的（这里我们设置根节点为root&#x3D;0），这便于查找和插入，可以通过根节点快速的进入树结构，稍后就会明白。</p>
<p>4.每个节点结束的时候用一个特殊的标记来表示，这里我们用-1来表示结束，从根节点到-1所经过的所有的节点对应一个英文单词。</p>
<h2 id="基本操作"><a href="#基本操作" class="headerlink" title="基本操作"></a>基本操作</h2><p><strong>A. Insert</strong>，插入一个单词</p>
<p>如何插入？怎么用树结构去储存每一个单词呢，一个节点有26个子节点，每一个节点对应26字母中的一个字符，我们可以这样描述：编号为i的节点的第j个子节点是编号为k的节点。我们用数组tree[i][j]&#x3D;k来表示。但是这里的i，k和j代表的意义是不一样的。i和k的编号是针对于整个树来说的，表示的位置编号，这个编号在树中可以唯一确定一个节点（位置+字符）。也就是说一个节点的字符和这个节点所在位置共同影响了这个点的编号，这个编号我们后续称之为绝对编号，相同的字符可能也会有不同的编号，因为位置可能不一样，如下面这种情况：</p>
<img src="asset/v2-ae133892ea2221fea230ccf406fede2f_1440w.webp" alt="img" style="zoom: 25%;" />

<p> 绝对编号，这个绝对编号字符按照插入的顺序编号，可以理解为一种dfs序 </p>
<p> 同一个字符a由于位置不同编号也不同。而j编号是相对于其父节点来说的，我们称之为相对编号，这个字符可能是父节点的第1个儿子a，可能是第2个儿子b，或者第26个儿子z，相当于有26个位置，针对不同的位置来对此字符施加编号，也就是如下图所示： </p>
<img src="asset/v2-5357204a844a22d0bfbcc1558e8fcc46_1440w.webp" alt="img" style="zoom:25%;" />

<p> 这个编号只取决于字符而与此字符所在位置无关。接下来我们用代码来实现一下这个插入字符的过程，比较简单，大家可以先自己写一下。 </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">void Insert(char s[])</span><br><span class="line">&#123;</span><br><span class="line">    int root=0;</span><br><span class="line">    for(int i=0;s[i];i++)</span><br><span class="line">    &#123;</span><br><span class="line">        int id=s[i]-&#x27;a&#x27;;//相对编号</span><br><span class="line">        if(tree[root][id]==-1) tree[root][id]=++cnt;//绝对编号</span><br><span class="line">        root=tree[root][id];</span><br><span class="line">    &#125;</span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure>

<p> 我们一开始把tree数组都初始化为-1，往树中插入单词的时候，有单词的节点被非负数字覆盖，而-1则可以作为字符缺失的标志，也可以理解为此节点还没有被插入字符。 </p>
<p> <strong>B. Search，</strong>查找 </p>
<p> 查找有很多种，可以查找一个前缀，也可以查找整个单词，也可以统计一个前缀在单词表中出现的次数。 </p>
<p> 我们这里以查找一个前缀是否出现过为例子进行讲解。 </p>
<p> <strong>从左往右扫描前缀单词中的每一个字母，然后从字典树的第一层开始找，能找到第一个字母就顺着字典树往下走，否则结束查找，即没有此前缀；若前缀单词扫完了，表示有这个前缀。</strong> </p>
<p> 代码如下 ： </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">int Search(char s[])</span><br><span class="line">&#123;</span><br><span class="line">    int root=0;</span><br><span class="line">    for(int i=0;s[i];i++)</span><br><span class="line">    &#123;</span><br><span class="line">        int id=s[i]-&#x27;a&#x27;;</span><br><span class="line">        if(tree[root][id]==-1) return -1;</span><br><span class="line">        root=tree[root][id];;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;   </span><br></pre></td></tr></table></figure>

<p> 代码比较简单，但是我们进一步想统计前缀出现的次数怎么办？那就开一个sum[]数组，表示某节点被访问过的次数。我们知道对于每一个前缀单词的插入，只要出现过这个前缀，那么总是要遍历一次从根节点到这个前缀单词的终节点路径中所有的节点，在遍历每一个节点的时候，我们都让此节点的sum计数数组加一即可。而对于某个前缀出现的次数，我们最后只需要返回此前缀单词最后一个字符对应的sum值即可。代码如下： </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">void Insert(char s[])</span><br><span class="line">&#123;</span><br><span class="line">    int root=0;</span><br><span class="line">    for(int i=0;s[i];i++)</span><br><span class="line">    &#123;</span><br><span class="line">        int id=s[i]-&#x27;a&#x27;;</span><br><span class="line">        if(tree[root][id]==0) tree[root][id]=++cnt;</span><br><span class="line">        sum[tree[root][id]]++;</span><br><span class="line">        root=tree[root][id];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">int Search(char s[])</span><br><span class="line">&#123;</span><br><span class="line">    int root=0;</span><br><span class="line">    for(int i=0;s[i];i++)</span><br><span class="line">    &#123;</span><br><span class="line">        int id=s[i]-&#x27;a&#x27;;</span><br><span class="line">        if(tree[root][id]==0) return 0;</span><br><span class="line">        root=tree[root][id];;</span><br><span class="line">    &#125;</span><br><span class="line">    return sum[root];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p> 只是 在之前的代码上增加了几行代码而已。好了整体来说，字典树就讲完了，更加复杂的操作在后续的专栏里会讲到。我们要掌握树的这种思想，如何高效地的储存数据，就比如这串代码里很关键的一个数组tree数组就可以很好的描述节点和节点之间的关系。在掌握思想之后，我们才能以不变应万变，用基本的思想去解决更加复杂的实际问题，事后呢我突然想写一个大规模数据的查询模块，觉得这个在实际中还是比较常用的，也可以去找一些更加高效算法来学习。 </p>
<h3 id="AcWing-143-最大异或对"><a href="#AcWing-143-最大异或对" class="headerlink" title="AcWing 143. 最大异或对"></a>AcWing 143. 最大异或对</h3><p><img src="/posts/caf7e096/asset/20200513212137582.png" alt="在这里插入图片描述"></p>
<p><img src="/posts/caf7e096/asset/1688134285386.png" alt="1688134285386"></p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>基本算法</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>基本算法</tag>
      </tags>
  </entry>
  <entry>
    <title>13.ac自动机</title>
    <url>/posts/52bfa0e7/</url>
    <content><![CDATA[<p> AC自动机就是KMP算法拓展到多模式匹配之后的结果，是一<img src="https://pic4.zhimg.com/80/v2-94518a2b306d9b8f1d10e4b49911e567_1440w.webp" alt="img">棵带有“失配指针”的字典树。 </p>
<p> AC自动机是一种典型的前缀搜索算法： </p>
<p><img src="/posts/52bfa0e7/asset/v2-6fc59897b84332efb8f05997ca41cb5e_1440w.webp" alt="img"></p>
<p><strong>什么是有限自动机 (Deterministic Finite Automaton, DFA)呢？</strong></p>
<p>**自动机(Automaton)**：就是一个代码块,只做一件事——接收输入值，和状态值，输出同为状态值的结果。</p>
<p>**有限(Finite)**：是指自动机接收、输入的状态种类是有限的。不然就是英菲尼迪了。</p>
<p>**确定(Deterministic )**：是指自动机的输出状态是单一的一个状态，不然就是NFA了。</p>
<p><img src="/posts/52bfa0e7/asset/v2-af615557d3e105387ee55c6bc02eb457_1440w.webp" alt="img"></p>
<pre><code>                                                                 典型的DFA 
</code></pre>
<p><img src="https://pic2.zhimg.com/80/v2-e27cfbbbeb5387c2c8a8088d23a1ccf1_1440w.webp" alt="img"></p>
<pre><code>                                                                 典型的NFA 
</code></pre>
<p> AC自动机(Aho-Corasick automaton)算法于1975年产生于贝尔实验室，是一种用于解决<strong>多模式匹配</strong>问题的经典算法。常被用来做敏感词检测，后处理的替换模块也是基于此。 </p>
<p> 值得注意的是，AC自动机应当属于基于<strong>前缀搜索</strong>的<strong>非压缩字典树</strong>。 </p>
<p><img src="/posts/52bfa0e7/asset/v2-4662e74f81c5c39547e6f4b689efca0d_1440w.webp" alt="img"></p>
<p> UNIX之中的grep就是用的这玩意实现的。 </p>
<h2 id="AC自动机的原理如下："><a href="#AC自动机的原理如下：" class="headerlink" title="AC自动机的原理如下："></a>AC自动机的原理如下：</h2><p> 以模式串(替换列表)为his、hers、she为例，首先构建一个trie： </p>
<p><img src="/posts/52bfa0e7/asset/v2-decc0b1650618f5822c0b0a32c6702e4_1440w.webp" alt="img"></p>
<p> 这时，我们就需要“失配指针”来帮忙了，为了节省匹配次数，不放弃已匹配过的部分，AC自动机之中加入了fail路径，又叫失配路径(指针)。失配指针能够在节点无法匹配下个字符的时候，转向其他节点。 </p>
<p><img src="/posts/52bfa0e7/asset/v2-48bfb675523a5252021ba12b64c8df38_1440w.webp" alt="img"></p>
<p> 那失配指针是如何构建的呢？ </p>
<p><img src="/posts/52bfa0e7/asset/v2-5cc8931c5a0caca1c41e79ed5a33046b_1440w.webp" alt="img"></p>
<p>结果如下：</p>
<p><img src="/posts/52bfa0e7/asset/v2-c84ed892d56eb833a52ac615d76dbf49_1440w.webp" alt="img"></p>
<p>继续构建第二类：</p>
<p><img src="/posts/52bfa0e7/asset/v2-1085e55eb2eb9410212b561e199dd851_1440w.webp" alt="img"></p>
<p>继续构建第三</p>
<p><img src="/posts/52bfa0e7/asset/v2-231927a50eb2d26e3754df0283ae9c3b_1440w.webp" alt="img"></p>
<p>最终的结果如下：</p>
<p><img src="/posts/52bfa0e7/asset/v2-4a555093e97f93434b320b7d1de2c4a3_1440w.webp" alt="img"></p>
<p>那么构建完毕之后，如何搜索字符串呢？为了更好的说明匹配规则，我们往原来的trie之中多</p>
<p>插入一个”<strong>he</strong>”，则4号节点变为terminal。</p>
<p><img src="/posts/52bfa0e7/asset/v2-b77cbdff0d4fb111e39a9dda76176d07_1440w.webp" alt="img"></p>
<p> 当然了，实际上字符串匹配的传统算法还有很多： </p>
<p><img src="/posts/52bfa0e7/asset/v2-c3c06dce0d59607ea861fa23588fdeab_1440w.webp" alt="img"></p>
<p><img src="/posts/52bfa0e7/asset/v2-aad6983d88da23f5e266dde7eeea15fd_1440w.webp" alt="img"></p>
<p>能看到，该算法在搜索的时候，突出一个稳定，尤其是在于WM算法进行比较的时候，优势明显</p>
<p> <img src="/posts/52bfa0e7/asset/v2-1167696649ed0a082c0a93737ae2522b_1440w.webp" alt="img"></p>
<p><img src="/posts/52bfa0e7/asset/v2-271a6126786a33582b71434063a6c33f_1440w.webp" alt="img"></p>
<p><img src="/posts/52bfa0e7/asset/v2-3174b5312c7052d657a6fbf55db4ef8d_1440w.webp" alt="img"></p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>基本算法</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>基本算法</tag>
      </tags>
  </entry>
  <entry>
    <title>14.二叉堆</title>
    <url>/posts/b2bff183/</url>
    <content><![CDATA[<h2 id="二叉堆"><a href="#二叉堆" class="headerlink" title="二叉堆"></a>二叉堆</h2><p> <strong>堆</strong>（Heap）是一类数据结构，它们拥有树状结构，且能够保证父节点比子节点大（或小）。当根节点保存堆中最大值时，称为<strong>大根堆</strong>；反之，则称为<strong>小根堆</strong>。 </p>
<p> <strong>二叉堆</strong>（Binary Heap）是最简单、常用的堆，是一棵符合堆的性质的<strong>完全二叉树</strong>。它可以实现 O(log⁡n) 地插入或删除某个值，并且 O(1) 地查询最大（或最小）值。 </p>
<img src="asset/v2-139c2e7f40642f428aeb3b69857b12bd_1440w.webp" alt="img" style="zoom:25%;" />

<p> 作为一棵完全二叉树，二叉堆完全可以用一个1-index的<strong>数组</strong>来存储，对于节点<code>p</code>，<code>p*2</code>即为左儿子，<code>p*2+1</code>即为右节点。同时，用<code>size</code>记录当前二叉堆中节点的个数。 </p>
<p><img src="/posts/b2bff183/asset/v2-9d9b386e079f892da8213024878c7767_1440w.webp" alt="img"></p>
<p> 现在我们考虑如何保证二叉堆的性质不被破坏。实际上，对于一个破坏堆性质的节点，我们可以使其<strong>上浮</strong>或<strong>下沉</strong>，因为最差也不过是上浮到顶或是下沉到底，所以只需要 O(log⁡n) 的时间就可以使其不再破坏性质。稍后我们会看到，插入和删除都只需要上浮&#x2F;下沉一个节点。 </p>
<h2 id="上浮"><a href="#上浮" class="headerlink" title="上浮"></a>上浮</h2><p>很简单，不断与父节点比较，如果比父节点大（以大根堆为例，下同）就与之交换，直到不大于父节点或成为根节点为止。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">swim</span><span class="params">(<span class="type">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = n; i &gt; <span class="number">1</span> &amp;&amp; heap[i] &gt; heap[i / <span class="number">2</span>]; i /= <span class="number">2</span>)</span><br><span class="line">        <span class="built_in">swap</span>(heap[i], heap[i / <span class="number">2</span>]);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="下沉"><a href="#下沉" class="headerlink" title="下沉"></a>下沉</h2><p>类似地，不断与较大的子节点比较，如果比它小就与之交换，直到不小于任何子节点或成为叶子节点为止。之所以要与较大的子节点比较，是为了保证交换上来的节点比两个子节点都大。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">son</span><span class="params">(<span class="type">int</span> n)</span> <span class="comment">// 找到需要交换的那个子节点</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> n * <span class="number">2</span> + (n * <span class="number">2</span> + <span class="number">1</span> &lt;= size &amp;&amp; heap[n * <span class="number">2</span> + <span class="number">1</span>] &gt; heap[n * <span class="number">2</span>]);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">sink</span><span class="params">(<span class="type">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = n, t = <span class="built_in">son</span>(i); t &lt;= size &amp;&amp; heap[t] &gt; heap[i]; i = t, t = <span class="built_in">son</span>(i))</span><br><span class="line">        <span class="built_in">swap</span>(heap[i], heap[t]);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="插入"><a href="#插入" class="headerlink" title="插入"></a>插入</h2><p>直接在尾部插入值，然后上浮即可。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">insert</span><span class="params">(<span class="type">int</span> x)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    heap[++size] = x;</span><br><span class="line">    <span class="built_in">swim</span>(size);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h2><p> 可以将根节点与最后一个节点交换，使<code>size</code>减1，然后再下沉。 </p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">pop</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">swap</span>(heap[<span class="number">1</span>], heap[size--]);</span><br><span class="line">    <span class="built_in">sink</span>(<span class="number">1</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h2><p>直接返回根节点即可。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">top</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> heap[<span class="number">1</span>];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="建立"><a href="#建立" class="headerlink" title="建立"></a>建立</h2><p>可以从一个数组 O(n)地建立堆，只需复制过来然后从底部到顶部依次下沉即可。实际上因为叶子节点不需要下沉，所以可以从 n&#x2F;2 处开始遍历。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">build</span><span class="params">(<span class="type">int</span> A[], <span class="type">int</span> n)</span> <span class="comment">// 从一个（这里是0-index的）数组O(n)地建立二叉堆</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">memcpy</span>(heap + <span class="number">1</span>, A, <span class="built_in">sizeof</span>(<span class="type">int</span>) * n);</span><br><span class="line">    size = n;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = n / <span class="number">2</span>; i &gt; <span class="number">0</span>; --i)</span><br><span class="line">        <span class="built_in">sink</span>(i);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><img src="/posts/b2bff183/asset/1688136953436.png" alt="1688136953436"></p>
<p> 使用手写的二叉堆，会比<code>STL</code>提供的<code>priority_queue</code>快一些。此外，了解其原理也有助于理解一些更高级的数据结构。接下来提供一个可以方便地在小根堆和大根堆间切换的模板（利用了宏定义）： </p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">namespace</span> heap</span><br><span class="line">&#123;</span><br><span class="line"><span class="meta">#<span class="keyword">define</span> maxheap <span class="comment">// 如果需要小根堆，把这行注释掉即可</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> maxheap</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> op &gt;</span></span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> op &lt;</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> MAXN = <span class="number">1000005</span>;</span><br><span class="line"><span class="type">int</span> heap[MAXN], size;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">swim</span><span class="params">(<span class="type">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = n; i &gt; <span class="number">1</span> &amp;&amp; heap[i] op heap[i / <span class="number">2</span>]; i /= <span class="number">2</span>)</span><br><span class="line">        <span class="built_in">swap</span>(heap[i], heap[i / <span class="number">2</span>]);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">son</span><span class="params">(<span class="type">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> n * <span class="number">2</span> + (n * <span class="number">2</span> + <span class="number">1</span> &lt;= size &amp;&amp; heap[n * <span class="number">2</span> + <span class="number">1</span>] op heap[n * <span class="number">2</span>]);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">sink</span><span class="params">(<span class="type">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = n, t = <span class="built_in">son</span>(i); t &lt;= size &amp;&amp; heap[t] op heap[i]; i = t, t = <span class="built_in">son</span>(i))</span><br><span class="line">        <span class="built_in">swap</span>(heap[i], heap[t]);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">push</span><span class="params">(<span class="type">int</span> x)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    heap[++size] = x;</span><br><span class="line">    <span class="built_in">swim</span>(size);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">pop</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">swap</span>(heap[<span class="number">1</span>], heap[size--]);</span><br><span class="line">    <span class="built_in">sink</span>(<span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">top</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> heap[<span class="number">1</span>];</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">build</span><span class="params">(<span class="type">int</span> A[], <span class="type">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">memcpy</span>(heap + <span class="number">1</span>, A, <span class="built_in">sizeof</span>(<span class="type">int</span>) * n);</span><br><span class="line">    size = n;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = n / <span class="number">2</span>; i &gt; <span class="number">0</span>; --i)</span><br><span class="line">        <span class="built_in">sink</span>(i);</span><br><span class="line">&#125;</span><br><span class="line">&#125; <span class="comment">// namespace heap</span></span><br></pre></td></tr></table></figure>

<h2 id="0-AcWing-145-超市"><a href="#0-AcWing-145-超市" class="headerlink" title="0.AcWing 145. 超市"></a>0.AcWing 145. 超市</h2><p><img src="/posts/b2bff183/asset/2020051710102666.png" alt="在这里插入图片描述"></p>
<p>贪心策略：对于 t tt 天,我们需要在保证不卖出过期商品的前提下,卖出利润前 t tt 大的商品。</p>
<p>因此我们可以把商品按照过期时间排序,然后建立一个小根堆,对于每一个数而言,如果说它的过期时间大于当前小根堆的个数,那么我们可以直接将这个货物的价值加入进来,如果说当前过期时间等于这个小根堆堆内的个数,那么我们就需要对比一下,如果说这个货物的价值,是高于小根堆的堆顶的话,那么我们就将小根堆堆顶弹出,然后push我们这个新货物,因为新货物明显是更加优于堆顶的老货物的，因为每次都选择最优的选项，保证了算法的正确性。</p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>基本算法</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>基本算法</tag>
      </tags>
  </entry>
  <entry>
    <title>15.霍夫曼树</title>
    <url>/posts/7fadcaca/</url>
    <content><![CDATA[<h2 id="霍夫曼树"><a href="#霍夫曼树" class="headerlink" title="霍夫曼树"></a>霍夫曼树</h2><p> 给定N个权值作为N个叶子结点，构造一棵二叉树，若该树的带权路径长度达到最小，称这样的二叉树为最优二叉树，也称为哈夫曼树(Huffman Tree)。哈夫曼树是带权路径长度最短的树，权值较大的结点离根较近。 </p>
<h3 id="路径和路径长度"><a href="#路径和路径长度" class="headerlink" title="路径和路径长度"></a>路径和路径长度</h3><p>在一棵树中，从一个结点往下可以达到的孩子或孙子结点之间的通路，称为路径。</p>
<p>通路中分支的数目称为路径长度。若规定根结点的层数为1，则从根结点到第L层结点的路径长度为L-1。</p>
<p><img src="/posts/7fadcaca/asset/v2-f07e3b68c7798559e664eeb6cf20ba3c_1440w.webp" alt="img"></p>
<h3 id="节点的权和带权路径长度"><a href="#节点的权和带权路径长度" class="headerlink" title="节点的权和带权路径长度"></a>节点的权和带权路径长度</h3><p> 若将树中结点赋给一个有着某种含义的数值，则这个数值称为该结点的权。结点的带权路径长度为：从根结点到该结点之间的路径长度与该结点的权的乘积。 </p>
<p><img src="/posts/7fadcaca/asset/v2-561bb507a8adcbbed29281abac1d3485_1440w.webp" alt="img"></p>
<h3 id="树的带权路径长度"><a href="#树的带权路径长度" class="headerlink" title="树的带权路径长度"></a>树的带权路径长度</h3><p> 树的带权路径长度规定为所有叶子结点的带权路径长度之和，记为WPL。 </p>
<p>如上图：数的带权路径长度为：</p>
<p>WPL &#x3D; (2+3) * 3 + 4 * 2 + 6 * 1 &#x3D; 29</p>
<p>假设有n个权值，则构造出的哈夫曼树有n个叶子结点。 n个权值分别设为 w1、w2、…、wn，则哈夫曼树的构造规则为：</p>
<p>(1) 将w1、w2、…，wn看成是有n 棵树的森林(每棵树仅有一个结点)；</p>
<p>(2) 在森林中选出两个根结点的权值最小的树合并，作为一棵新树的左、右子树，且新树的根结点权值为其左、右子树根结点权值之和；</p>
<p>(3)从森林中删除选取的两棵树，并将新树加入森林；</p>
<p>(4)重复(2)、(3)步，直到森林中只剩一棵树为止，该树即为所求得的哈夫曼树。</p>
<p> 例如：对 2，3，4，6 这四个数进行构造 </p>
<p><img src="https://pic3.zhimg.com/80/v2-5c5bdbcdbfbacf4565bb5e99445b964a_1440w.webp" alt="img"></p>
<h2 id="哈夫曼树的应用：哈夫曼编码"><a href="#哈夫曼树的应用：哈夫曼编码" class="headerlink" title="哈夫曼树的应用：哈夫曼编码"></a>哈夫曼树的应用：哈夫曼编码</h2><p>哈夫曼编码是一种压缩编码的编码算法，是基于哈夫曼树的一种编码方式。哈夫曼树又称为带权路径长度最短的二叉树。</p>
<p>哈夫曼编码跟 ASCII 编码有什么区别？ASCII 编码是对照ASCII 表进行的编码，每一个字符符号都有对应的编码，其编码长度是固定的。而哈夫曼编码对于不同字符的出现频率其使用的编码是不一样的。其会对频率较高的字符使用较短的编码，频率低的字符使用较高的编码。这样保证总体使用的编码长度会更少，从而实现到了数据压缩的目的。</p>
<p> 举一个例子：对字符串“aaa bb cccc dd e”使用 ASCII 进行编码得到的结果为：97 97 97 32 98 98 32 99 99 99 99 32 100 100 32 101 （十进制）需要 16 个字节，如果使用二进制表示的话需要 128位的内存空间去存储。 </p>
<p>而如果使用 Unicode 的话会更多，因为 Unicode 又称为万国码，内容更多，因此使用的空间也需要更大。</p>
<p>接下来使用哈夫曼编码对上面的字符串进行编码。看看需要多大的空间</p>
<h3 id="统计频率"><a href="#统计频率" class="headerlink" title="统计频率"></a>统计频率</h3><p>上面的介绍已经说明了哈夫曼编码会根据字符出现的频率从而条件字符使用的编码长度。因此要先求出这个字符串中每个字符出现的频率</p>
<table>
<thead>
<tr>
<th>字符</th>
<th>c</th>
<th>‘ ‘ 空</th>
<th>a</th>
<th>b</th>
<th>d</th>
<th>e</th>
</tr>
</thead>
<tbody><tr>
<td>频率</td>
<td>4</td>
<td>4</td>
<td>3</td>
<td>2</td>
<td>2</td>
<td>1</td>
</tr>
</tbody></table>
<h3 id="构建哈夫曼树"><a href="#构建哈夫曼树" class="headerlink" title="构建哈夫曼树"></a>构建哈夫曼树</h3><blockquote>
<p>排序</p>
</blockquote>
<p>哈夫曼树是一个带权的二叉树，而在哈夫曼编码中，字符的出现频率就是字符的权重。因此要根据字符的频率放入优先队列中进行排序。然后根据这些字符构建一棵哈夫曼树</p>
<table>
<thead>
<tr>
<th>字符</th>
<th>e</th>
<th>d</th>
<th>b</th>
<th>a</th>
<th>‘ ‘ 空</th>
<th>c</th>
</tr>
</thead>
<tbody><tr>
<td>频率</td>
<td>1</td>
<td>2</td>
<td>2</td>
<td>3</td>
<td>4</td>
<td>4</td>
</tr>
</tbody></table>
<p>将队列中的每一个元素（字符）都看成一棵树。</p>
<blockquote>
<p>合并</p>
</blockquote>
<p>进行迭代，每次都去除队列中的前面两个元素，也就是权值最小的两棵子树进行合并成一棵子树。直到最终所有的元素合并成一棵树。这棵树就是哈夫曼树。</p>
<p>合并步骤</p>
<p>合并 1、2 权值为 3：</p>
<p><img src="/posts/7fadcaca/asset/v2-6d884a6ee86b5ab861826a07779cb5fc_1440w.webp" alt="img"></p>
<p>将 3这棵树重新插入队列：</p>
<p><img src="https://pic2.zhimg.com/80/v2-94b73b86126b3331c789df2298557169_1440w.webp" alt="img"></p>
<p>合并 2、3 生成 5 的树，并插入队列：</p>
<p><img src="/posts/7fadcaca/asset/v2-36e021cba0c7adbd190bd1346d833ac1_1440w.webp" alt="img"></p>
<p>合并 3、4 生成 7 的树，并插入队列：</p>
<p><img src="/posts/7fadcaca/asset/v2-eeacd39cfb0ad14dea90967a6d998210_1440w.webp" alt="img"></p>
<p>合并 4、5 生成 9 的数，并插入队列：</p>
<p><img src="https://pic3.zhimg.com/80/v2-0184f2ac6280fdbb8297a9e91abc54b6_1440w.webp" alt="img"></p>
<p>合并 7、9 生成 16 的树，最终只有一棵树，该树便是这个字符串所生成的哈夫曼树：</p>
<p><img src="https://pic3.zhimg.com/80/v2-48e3cdd3fbd1e25ce40a4205a753e24e_1440w.webp" alt="img"></p>
<p> 为哈夫曼树进行编码</p>
<p>将二叉树分支中的左分支编为 0，右分支编为 1：</p>
<p><img src="https://pic4.zhimg.com/80/v2-82b9db088f6babb04754a98f22978433_1440w.webp" alt="img"></p>
<p>可以发现每个字符都在树的叶子节点上，因此要获取每个字符的哈夫曼编码，就通过根节点遍历到对应的子节点所经历的路径就是这个字符的编码：</p>
<table>
<thead>
<tr>
<th>字符</th>
<th>e</th>
<th>d</th>
<th>b</th>
<th>a</th>
<th>‘ ‘</th>
<th>c</th>
</tr>
</thead>
<tbody><tr>
<td>编码</td>
<td>1110</td>
<td>1111</td>
<td>110</td>
<td>00</td>
<td>01</td>
<td>10</td>
</tr>
</tbody></table>
<p> 可以发现使用频率高的字符<code>e</code> 其编码长度是比出现频率低的字符<code>c</code> 编码长度要少。最后计算使用哈夫曼编码的字符串“aaa bb cccc dd e”要使用多少位的内存空间进行存储：出现次数 * 编码长度。结果为 4 * 3 + 3 * 2 + 11 * 2 &#x3D; 40位，与 ASCII 对应的 128位，少了2&#x2F;3的存储空间。 </p>
<h2 id="用小顶堆构建"><a href="#用小顶堆构建" class="headerlink" title="用小顶堆构建"></a>用小顶堆构建</h2><p><img src="/posts/7fadcaca/asset/1688140692331.png" alt="1688140692331"></p>
<p><img src="/posts/7fadcaca/asset/20200519152808107.png" alt="在这里插入图片描述"></p>
<p><img src="/posts/7fadcaca/asset/20200519152817958.png" alt="1688140732234"></p>
<p><img src="/posts/7fadcaca/asset/20200519154053906.png" alt="在这里插入图片描述"></p>
<p>题目很长，但其实就是一个求k叉的Huffman字典树，让出现次数多的最短，最短，也就意味着离根节点最近，看上去就是一颗trie树（字典树）<img src="/posts/7fadcaca/asset/20200519162728184.png" alt="在这里插入图片描述"></p>
<p><img src="/posts/7fadcaca/asset/20200519162735557.png" alt="在这里插入图片描述"></p>
<p><img src="/posts/7fadcaca/asset/1688141574030.png" alt="1688141574030"></p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>基本算法</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>基本算法</tag>
      </tags>
  </entry>
  <entry>
    <title>16.树与图的遍历</title>
    <url>/posts/449b1d94/</url>
    <content><![CDATA[<h2 id="深度优先遍历"><a href="#深度优先遍历" class="headerlink" title="深度优先遍历"></a>深度优先遍历</h2><p> 深度优先遍历，就是在每个点x上面的的多条分支时，任意选择一条边走下去，执行递归，直到回溯到点x后再走其他的边 </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">int vis[N];//标记每一个点的状态</span><br><span class="line"></span><br><span class="line">void dfs(int u)&#123;</span><br><span class="line">    vis[u] = 1;</span><br><span class="line">    for(int i = head[u];i;i = nex[i])&#123;</span><br><span class="line">        int v = ver[i];</span><br><span class="line">        if(vis[v])</span><br><span class="line">            continue;</span><br><span class="line">        dfs(v);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="时间戳"><a href="#时间戳" class="headerlink" title="时间戳"></a>时间戳</h3><p> 按照上述的深度优先遍历的过程，以每一个结点第一次被访问的顺序，依次赋值1~N的整数标记，该标记就被称为时间戳。<br>标记了每一个结点的访问顺序。 </p>
<h3 id="树的DFS序-树链剖分前驱知识"><a href="#树的DFS序-树链剖分前驱知识" class="headerlink" title="树的DFS序(树链剖分前驱知识)"></a>树的DFS序(树链剖分前驱知识)</h3><p>一般来说，我们在对树的进行深度优先时，对于每个节点，在刚进入递归时和回溯前各记录一次该点的编号，最后会产生一个长度为2N的序列，就成为该树的DFS序。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">int a[N],cnt;</span><br><span class="line">int dfs(int u)&#123;</span><br><span class="line">     a[++cnt] = u;//用a数组存DFS序</span><br><span class="line">     vis[u] = 1;</span><br><span class="line">     for(int i = head[u]; i;i = nex[i])&#123;</span><br><span class="line">        int v = ver[i];</span><br><span class="line">        if(vis[v])</span><br><span class="line">            continue;</span><br><span class="line">        dfs(v);</span><br><span class="line">     &#125;</span><br><span class="line">     a[++cnt] = u;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><img src="/posts/449b1d94/asset/1688142098509.png" alt="1688142098509"></p>
<p><img src="/posts/449b1d94/asset/20200522162933487.png" alt="在这里插入图片描述"></p>
<p><img src="/posts/449b1d94/asset/20200522162939859.png" alt="在这里插入图片描述"></p>
<p><img src="/posts/449b1d94/asset/20171103194643948.png" alt="这里写图片描述"></p>
<p> 如下图，DFS之后，那么树的每个节点就具有了区间的性质。  </p>
<p><img src="/posts/449b1d94/asset/20171103194706310.png" alt="这里写图片描述"></p>
<h3 id="dfs序的七个基本问题："><a href="#dfs序的七个基本问题：" class="headerlink" title="dfs序的七个基本问题："></a>dfs序的七个基本问题：</h3><p>ps:deep[x]为x的深度，l[x]为dfs序中x的位置，r[x]为dfs序中x子树的结束位置</p>
<p><strong>1.点修改，子树和查询</strong></p>
<p>　　在dfs序中，子树处于一个连续区间中。所以这题可以转化为：点修改，区间查询。用树状数组或线段树即可。</p>
<p>2.树链修改，单点查询</p>
<p>　　将一条树链x,y上的所有点的权值加v。这个问题可以等价为：</p>
<p>　　1）.x到根节点的链上所有节点权值加v。</p>
<p>　　2）.y到根节点的链上所有节点权值加v。</p>
<p>　　3）.lca（x,y）到根节点的链上所有节点权值和减v。</p>
<p>　　4）.fa(lca(x,y))到根节点的链上所有节点权值和减v。　　</p>
<p>　　上面四个操作可以归结为：节点x到根节点链上所有节点的权值加减v。修改节点x权值，当且仅当y是x的祖先节点时，x对y的值有贡献。</p>
<p>　　所以节点y的权值可以转化为节点y的子树节点贡献和。从贡献和的角度想：这就是点修改，区间和查询问题。</p>
<p>　　修改树链x,y等价于add(l[x],v),add(l[y],v),add(l[lca(x,y)],-v),add(l[fa(lca(x,y))],-v)。</p>
<p>　　查询：get_sum(r[x])-get_sum(l[x]-1)</p>
<p>　　用树状数组或线段树即可。</p>
<p>3.树链修改，子树和查询</p>
<p>　　树链修改部分同上一问题。下面考虑子树和查询问题：前一问是从贡献的角度想，子树和同理。</p>
<p>　　对于节点y其到根节点的权值和，考虑其子节点x的贡献：w[x]<em>(deep[x]-deep[y]+1) &#x3D; w[x]</em>(deep[x]+1)-w[x]*deep[y] </p>
<p>　　所以节点y的子树和为：</p>
<p>　　</p>
<p>　　ps:公式中的v[i]为手误，应为w[i]。</p>
<p>　　所以用两个树状数组或线段树即可：</p>
<p>　　　　第一个维护∑w[i]*(deep[i]+1):支持操作单点修改，区间和查询。（这也就是问题2）</p>
<p>　　　　第二个维护∑ w[i]：支持操作单点修改，区间查询。（这其实也是问题2）</p>
<p>4.单点更新，树链和查询</p>
<p>　　树链和查询与树链修改类似，树链和(x,y)等于下面四个部分和相加：</p>
<p>　　1）.x到根节点的链上所有节点权值加。</p>
<p>　　2）.y到根节点的链上所有节点权值加。</p>
<p>　　3）.lca（x,y）到根节点的链上所有节点权值和的-1倍。</p>
<p>　　4）.fa(lca(x,y))到根节点的链上所有节点权值和的-1倍。</p>
<p>　　所以问题转化为：查询点x到根节点的链上的所有节点权值和。</p>
<p>　　修改节点x权值，当且仅当y是x的子孙节点时，x对y的值有贡献。</p>
<p>　　差分前缀和，y的权值等于dfs中[1,l[y]]的区间和。</p>
<p>　　单点修改：add(l[x],v),add(r[x]+1,-v);</p>
<p><strong>5.子树修改，单点查询</strong></p>
<p>　　修改节点x的子树权值，在dfs序上就是区间修改，单点权值查询就是单点查询。</p>
<p>　　区间修改，单点查询问题：树状数组或线段树即可;</p>
<p><strong>6.子树修改，子树和查询</strong></p>
<p>　　题目等价与区间修改，区间查询问题。用树状数组或线段树即可。</p>
<p>7.子树修改，树链查询</p>
<p>　　树链查询同上，等价为根节点到y节点的链上所有节点和问题。</p>
<p>　　修改节点x的子树权值，当且仅当y是x的子孙节点时（或y等于x），x对y的值有贡献。</p>
<p>　　x对根节点到y节点的链上所有节点和的贡献为：w[x]*(deep[y]-deep[x]+1)&#x3D;w[x]<em>deep[y]-w[x]</em>(1-deep[x])</p>
<p>　　同问题三，用两个树状数组或线段树即可。</p>
<h3 id="树的深度"><a href="#树的深度" class="headerlink" title="树的深度"></a>树的深度</h3><p>树中各个节点的深度是一种自顶向下的统计信息</p>
<p>起初，我们已知根节点深度是0.若节点x的深度为d[x],则它的子结点 y yy 的深度就是d[y]&#x3D;d[x]+1</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">int dep[N];</span><br><span class="line">void dfs(int u)&#123;</span><br><span class="line">	vis[u] = 1;</span><br><span class="line">	for(int i = head[u];i;i = nex[i])&#123;</span><br><span class="line">		int v = ver[i];</span><br><span class="line">		if(vis[v])</span><br><span class="line">			continue;</span><br><span class="line">		dep[v] = dep[u]+1;//父结点 u 到子结点 v  递推 </span><br><span class="line">		dfs(v);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="树的重心与size"><a href="#树的重心与size" class="headerlink" title="树的重心与size"></a>树的重心与size</h3><p> 树的重心是自底向上统计的<br>树的重心也叫树的质心。对于一棵树n个节点的无根树，找到一个点，使得把树变成以该点为根的有根树时，最大子树的结点数最小。 </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">int vis[N];</span><br><span class="line">int Size[N];</span><br><span class="line">int ans = INF;</span><br><span class="line">int id;</span><br><span class="line">void dfs(int u)&#123;</span><br><span class="line">    vis[u] = 1;</span><br><span class="line">    Size[u] = 1;//子树的大小</span><br><span class="line">    int max_part = 0;</span><br><span class="line">    for(int i = head[u];i;i = nex[i])&#123;</span><br><span class="line">        int v = ver[i];</span><br><span class="line">        if(vis[v])</span><br><span class="line">            continue;</span><br><span class="line">        dfs(v);</span><br><span class="line">        Size[u] += Size[v];</span><br><span class="line">        max_part = max(max_part,Size[v]);//比较儿子的size因为这里是假设以u为重心</span><br><span class="line">    &#125;</span><br><span class="line">    max_part = max(max_part,n-Size[u]);//n为整棵树的结点数</span><br><span class="line">    if(max_part&lt;ans)&#123;//更新</span><br><span class="line">        ans = max_part;//记录重心对应的max_part的值</span><br><span class="line">        id = u;//记录重心位置</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="图的连通块划分"><a href="#图的连通块划分" class="headerlink" title="图的连通块划分"></a>图的连通块划分</h3><p>若在一个无向图中的一个子图中任意两个点之间都存在一条路径（可以相互到达），并且这个子图是“极大的”（不能在扩展），则称该子图是原图的一个联通块</p>
<p>如下代码所示，cnt是联通块的个数，v记录的是每一个点属于哪一个联通块<br>经过连通块划分，可以将森林划分出每一颗树，或者将图划分为各个连通块。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">int cnt;</span><br><span class="line">void dfs(int u)&#123;</span><br><span class="line">    vis[u] = cnt;//这里存的是第几颗树或者是第几块连通图</span><br><span class="line">    for(int i = head[u];i;i = nex[i])&#123;</span><br><span class="line">        int v = ver[i];</span><br><span class="line">        if(vis[v])</span><br><span class="line">            continue;</span><br><span class="line">        dfs(v);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">    for(int i = 1;i&lt;=n;++i)&#123;</span><br><span class="line">        if(!vis[i])//如果是颗新树就往里面搜</span><br><span class="line">            ++cnt,dfs(i);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="广度优先搜索"><a href="#广度优先搜索" class="headerlink" title="广度优先搜索"></a>广度优先搜索</h2><p> 树与图的广度优先遍历，顺便求d数组（树结点的深度&#x2F;图结点的层次）。 </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">void bfs()&#123;</span><br><span class="line">    memset(d,0,sizeof d);</span><br><span class="line">    queue&lt;int&gt;q;</span><br><span class="line">    q.push(1);</span><br><span class="line">    d[1] = 1;</span><br><span class="line">    while(q.size())&#123;</span><br><span class="line">        int u = q.front();</span><br><span class="line">        q.pop();</span><br><span class="line">        for(int i = head[u];i;i = nex[i])&#123;</span><br><span class="line">            int v = ver[i];</span><br><span class="line">            if(d[v])continue;</span><br><span class="line">            d[v] = d[u]+1;</span><br><span class="line">            q.push(v);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>广度优先遍历是一种按照层次顺序访问的方法。<br>它具有两个重要的性质：</p>
<ol>
<li>在访问完所有的第i层结点后，才会访问第i+1层结点。</li>
<li>任意时刻，队列中只会有两个层次的结点，满足“两段性”和“单调性”。</li>
</ol>
<h2 id="拓扑排序"><a href="#拓扑排序" class="headerlink" title="拓扑排序"></a>拓扑排序</h2><p>给定一张有向无环图，若一个序列A满足图中的任意一条边(x,y)x都在y的前面呢么序列A就是图的拓扑排序</p>
<p>求拓扑序的过程非常简单我们只需要不断将入度为0的点加入序列中即可<br>    （入度：有向图中以结点x为终点的有向边的条数）<br>    （出度：有向图中以结点x为起点的有向边的条数）<br>    （无向图中的度：以x为端点的无向边的条数）</p>
<p>1.建立空拓扑序列A<br>        2.预处理出所有入度为deg[i],起初把入度为0的点入队<br>        3.取出队列头节点x,并把x放入队列A中<br>        4.对于从x出发的每条边(x,y)，把deg[y]减1，若deg[y] &#x3D; 0 ,把y加入队列中<br>        5.重复3，4直到队列为空，此时A即为所求</p>
<p> 拓扑排序可以判定有向图中是否存在环。若拓扑排序以后的A序列的长度小于图中点的长度，说明有的点没有被遍历，进而说明存在环。 </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">int head[N],ver[N],nex[N],edge[N],tot;</span><br><span class="line">int n,m;</span><br><span class="line">int deg[N];</span><br><span class="line">int A[N];</span><br><span class="line">void add(int u,int v)&#123;</span><br><span class="line">    ver[++tot] = v;</span><br><span class="line">    nex[tot] = head[u];</span><br><span class="line">    head[u] = tot;</span><br><span class="line">    deg[v]++;//入度加1</span><br><span class="line">&#125;</span><br><span class="line">int cnt;</span><br><span class="line">void toposort()&#123;//拓扑排序</span><br><span class="line">    queue&lt;int&gt;q;</span><br><span class="line">    for(int i = 1;i&lt;=n;++i)</span><br><span class="line">        if(deg[i] == 0)q.push(i);//步骤2，先找所有度为0的点</span><br><span class="line">    while(q.size())&#123;</span><br><span class="line">        int u = q.front();</span><br><span class="line">        q.pop();</span><br><span class="line">        A[++cnt] = u;</span><br><span class="line">        for(int i = head[u];i;i = nex[i])&#123;</span><br><span class="line">            int v = ver[i];</span><br><span class="line">            if(--deg[v] == 0)</span><br><span class="line">                q.push(v);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">    cin&gt;&gt;n&gt;&gt;m;</span><br><span class="line">    for(int i = 1;i &lt;=m;++i)&#123;</span><br><span class="line">        int x,y;</span><br><span class="line">        scanf(&quot;%d%d&quot;,&amp;x,&amp;y);</span><br><span class="line">        add(x,y);</span><br><span class="line">    &#125;</span><br><span class="line">    toposort();</span><br><span class="line">    for(int i = 1;i &lt;=cnt;++i)&#123;</span><br><span class="line">        printf(&quot;%d &quot;,A[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    puts(&quot;&quot;);</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>基本算法</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>基本算法</tag>
      </tags>
  </entry>
  <entry>
    <title>17.拓扑排序</title>
    <url>/posts/a599f945/</url>
    <content><![CDATA[<p>Topological sort 又称 Topological order，这个名字有点迷惑性，因为拓扑排序并不是一个纯粹的排序算法，它只是针对<strong>某一类图</strong>，找到一个可以执行的线性顺序。 </p>
<h2 id="有向无环图"><a href="#有向无环图" class="headerlink" title="有向无环图"></a>有向无环图</h2><p>刚刚我们提到，拓扑排序只是针对特定的一类图，那么是针对哪类图的呢？</p>
<p>答：Directed acyclic graph (DAG)，有向无环图。即：</p>
<ol>
<li>这个图的边必须是有方向的；</li>
<li>图内无环。</li>
</ol>
<p>那么什么是方向呢？</p>
<p>比如微信好友就是有向的，你加了他好友他可能把你删了你却不知道。。。那这个朋友关系就是单向的。。</p>
<p>什么是环？环是和方向有关的，从一个点出发能回到自己，这是环。</p>
<p>所以下图左边不是环，右边是。</p>
<p><img src="https://pic3.zhimg.com/80/v2-1e72742f8cc825e716ab74f68a3d38f6_1440w.webp" alt="img"></p>
<p> 那么如果一个图里有环，比如右图，想执行1就要先执行3，想执行3就要先执行2，想执行2就要先执行1，这成了个死循环，无法找到正确的打开方式，所以找不到它的一个拓扑序。 </p>
<h3 id="总结："><a href="#总结：" class="headerlink" title="总结："></a><strong>总结：</strong></h3><ul>
<li>如果这个图不是 DAG，那么它是没有拓扑序的；</li>
<li>如果是 DAG，那么它至少有一个拓扑序；</li>
<li>反之，如果它存在一个拓扑序，那么这个图必定是 DGA.</li>
</ul>
<p> 所以这是一个<strong>充分必要条件</strong>。 <img src="/posts/a599f945/asset/v2-f09acb4f50bb4ecd4cefd635172cc8d9_1440w.webp" alt="img"></p>
<h2 id="拓扑排序"><a href="#拓扑排序" class="headerlink" title="拓扑排序"></a><strong>拓扑排序</strong></h2><p> 那么这么一个图的<code>「拓扑序」</code>是什么意思呢？ </p>
<p> 9 门课程，有些课程是有先修课程的要求的，就是你要先学了「最右侧这一栏要求的这个课」才能再去选「高阶」的课程。 </p>
<p> 那么这个例子中拓扑排序的意思就是：<br><strong>就是求解一种可行的顺序，能够让我把所有课都学了。</strong> </p>
<p>那怎么做呢？</p>
<p>首先我们可以用<code>图</code>来描述它，<br>图的两个要素是<code>顶点和边</code>，<br>那么在这里：</p>
<ul>
<li>顶点：每门课</li>
<li>边：起点的课程是终点的课程的先修课</li>
</ul>
<p>画出来长这个样：</p>
<p><img src="https://pic4.zhimg.com/80/v2-49a86090444ba413a1d11e09715d1283_1440w.webp" alt="img"></p>
<p>这种图叫 <strong>AOV</strong> (Activity On Vertex) 网络，在这种图里：</p>
<ul>
<li>顶点：表示活动；</li>
<li>边：表示活动间的先后关系</li>
</ul>
<p><strong>所以一个 AOV 网应该是一个 DAG，即有向无环图，否则某些活动会无法进行。</strong><br><strong>那么所有活动可以排成一个可行线性序列，这个序列就是<code>拓扑序列</code>。</strong></p>
<p> 那么这个序列的<code>实际意义</code>是：<br><strong>按照这个顺序，在每个项目开始时，能够保证它的前驱活动都已完成，从而使整个工程顺利进行。</strong> </p>
<p>回到我们这个例子中：</p>
<ol>
<li>我们一眼可以看出来要先学 C1, C2，因为这两门课没有任何要求嘛，大一的时候就学呗；</li>
<li>大二就可以学第二行的 C3, C5, C8 了，因为这三门课的先修课程就是 C1, C2，我们都学完了；</li>
<li>大三可以学第三行的 C4, C9；</li>
<li>最后一年选剩下的 C6, C7。</li>
</ol>
<p>这样，我们就把所有课程学完了，也就得到了这个图的<strong>一个</strong><code>拓扑排序</code>。</p>
<p> <strong>注意，有时候拓扑序并不是唯一的，比如在这个例子中，先学 C1 再学 C2，和先 C2 后 C1 都行，都是这个图的正确的拓扑序，但这是两个顺序了。</strong> </p>
<p>我们总结一下，</p>
<p>**在这个图里的<code>边</code>表示的是一种<code>依赖关系</code>**，如果要修下一门课，就要先把前一门课修了。</p>
<p>这和打游戏里一样一样的嘛，要拿到一个道具，就要先做 A 任务，再完成 B 任务，最终终于能到达目的地了。</p>
<h2 id="算法详解"><a href="#算法详解" class="headerlink" title="算法详解"></a><strong>算法详解</strong></h2><p>在上面的图里，大家很容易就看出来了它的拓扑序，但当工程越来越庞大时，依赖关系也会变得错综复杂，那就需要用一种系统性的方式方法来求解了。</p>
<p> 那么我们回想一下刚刚自己找拓扑序的过程，为什么我们先看上了 C1, C2? </p>
<p>*<strong>因为它们没有依赖别人啊，也就是它的<code>入度为 0</code>.</strong> </p>
<p> 所以我们先执行入度为 0 的那些点，那也就是要记录每个顶点的入度。因为<strong>只有当它的 <code>入度 = 0</code> 的时候，我们才能执行它。</strong> </p>
<p> 那在这个算法里第一步就是得到每个顶点的入度。 </p>
<h3 id="Step0-预处理得到每个点的入度"><a href="#Step0-预处理得到每个点的入度" class="headerlink" title="Step0: 预处理得到每个点的入度"></a><strong>Step0: 预处理得到每个点的入度</strong></h3><p>我们可以用一个 HashMap 来存放这个信息，或者用一个<code>数组</code>会更精巧。</p>
<h3 id="Step1"><a href="#Step1" class="headerlink" title="Step1"></a><strong>Step1</strong></h3><p>拿到了这个之后，就可以执行入度为 0 的这些点了，也就是 C1, C2.</p>
<p> 那我们把可以被执行的这些点，放入一个<code>待执行的容器</code>里，这样之后我们一个个的从这个容器里取顶点就好了。 </p>
<p> 至于这个<code>容器</code>究竟选哪种<code>数据结构</code>，这取决于我们需要做哪些<code>操作</code>，再看哪种数据结构可以为之服务。 </p>
<p> 那么首先可以把<code>[C1, C2]</code>放入<code>容器</code>中， </p>
<p>然后想想我们需要哪些操作吧！</p>
<p>我们最常做的操作无非就是<code>把点放进来</code>，<code>把点拿出去</code>执行了，也就是需要一个 <code>offer</code> 和 <code>poll</code> 操作比较高效的数据结构，那么 <code>queue</code> 就够用了。</p>
<p> （其他的也行，放进来这个容器里的顶点的地位都是一样的，都是可以执行的，和进来的顺序无关，但何必非得给自己找麻烦呢？一个常规顺序的简简单单的 queue 就够用了。） </p>
<p>然后就需要把某些点拿出去执行了。</p>
<blockquote>
<p>【划重点】当我们把 C1 拿出来执行，那这意味这什么？</p>
</blockquote>
<p>答：意味着「以 C1 为顶点」的「指向其他点」的「边」都消失了，也就是 C1 的出度变成了 0.</p>
<p> 如下图，也就是这两条边可以消失了。 </p>
<p><img src="/posts/a599f945/asset/v2-82ac3e9c57fcab366d635bc65b9b43d4_b.webp" alt="动图"></p>
<p> 那么此时我们就可以更新 <code>C1 所指向的那些点</code>也就是 <code>C3 和 C8</code> 的 <code>入度</code> 了，</p>
<p><strong>那我们这里看到很关键的一步，C8 的入度变成了 0！</strong></p>
<p><strong>也就意味着 C8 此时没有了任何依赖，可以放到我们的 queue 里等待执行了。</strong></p>
<h3 id="Step2"><a href="#Step2" class="headerlink" title="Step2"></a><strong>Step2</strong></h3><p>下一个我们再执行 C2，</p>
<p> <img src="/posts/a599f945/asset/v2-f0129fff3bb7e3d5ec6b2828ce53c761_b.webp" alt="动图"> </p>
<p> 那么 <code>C2 所指向的</code> <code>C3, C5</code> 的 <code>入度-1</code>， </p>
<p>。。。以此类推直到。。。</p>
<p><strong>C6C7</strong>入度<strong>00</strong></p>
<p>C6 和 C7 的入度都变成 0 啦！！把它们放入 queue，继续执行到直到 queue 为空即可。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h3><p>好了，那我们梳理一下这个算法：</p>
<p><strong>数据结构</strong></p>
<p> 这里我们的入度表格可以用 map 来存放， </p>
<p> Map: &lt;key &#x3D; Vertex, value &#x3D; 入度&gt; </p>
<p> 但实际代码中，我们用一个 <strong>int array</strong> 来存储也就够了，graph node 可以用数组的 index 来表示，value 就用数组里的数值来表示，这样比 Map 更精巧。 </p>
<p> 然后用了一个普通的 queue，用来存放可以被执行的那些 node. </p>
<p><strong>过程</strong></p>
<p>我们把入度为 0 的那些顶点放入 queue 中，然后通过每次执行 queue 中的顶点，就可以让依赖这个被执行的顶点的那些点的 <code>入度-1</code>，如果有顶点的入度变成了 0，就可以放入 queue 了，直到 queue 为空。</p>
<p><strong>细节</strong></p>
<p>这里有几点实现上的细节：</p>
<p><strong>当我们 check 是否有新的顶点的 入度 &#x3D;&#x3D; 0 时，没必要过一遍整个 map 或者数组，只需要 check 刚刚改动过的就好了。</strong></p>
<p> 另一个是如果题目没有给这个图是 DAG 的条件的话，那么有可能是不存在可行解的，那怎么判断呢？很简单的一个方法就是比较一下最后结果中的顶点的个数和图中所有顶点的个数是否相等，或者加个计数器，如果不相等，说明就不存在有效解。所以这个算法也可以用来<strong>判断一个图是不是有向无环图</strong>。 </p>
<p> 很多题目给的条件可能是给这个图的 <code>edge list</code>，也是表示图的一种常用的方式。那么给的这个 <code>list</code> 就是表示图中的<code>边</code>。这里要注意审题哦，看清楚是谁 depends on 谁。其实图的题一般都不会直接给你这个图，而是给一个场景，需要你把它变回一个图。 </p>
<p><strong>时间复杂度</strong></p>
<p>注意⚠️：对于图的时间复杂度分析一定是两个参数，面试的时候很多同学张口就是 O(n)…</p>
<p>对于有 v 个顶点和 e 条边的图来说，</p>
<p>第一步，预处理得到 map 或者 array，需要过一遍所有的边才行，所以是 O(e)；</p>
<p>第二步，把 入度 &#x3D;&#x3D; 0 的点入队出队的操作是 O(v)，如果是一个 DAG，那所有的点都需要入队出队一次；</p>
<p>第三步，每次执行一个顶点的时候，要把它指向的那条边消除了，这个总共执行 e 次；</p>
<p><strong>总：O(v + e)</strong></p>
<p><strong>空间复杂度</strong></p>
<p>用了一个数组来存所有点的 indegree，之后的 queue 也是最多把所有的点放进去，所以是 O(v).</p>
<p>###输出所有拓扑排序</p>
<p> <a href="https://blog.csdn.net/u013480600/article/details/30315289/">POJ 1270 Following Orders(拓扑排序:输出所有可能</a> </p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>基本算法</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>基本算法</tag>
      </tags>
  </entry>
  <entry>
    <title>18.深度优先遍历</title>
    <url>/posts/f6fb8bbc/</url>
    <content><![CDATA[<p>深度优先搜索算法是一种用于遍历或搜索树或图的算法</p>
<p>建立一颗搜索树，沿着树的深度遍历树的节点，尽可能深的搜索树的分支。当节点v的所在边都己被探寻过，搜索将回溯到发现节点v的那条边的起始节点。这一过程一直进行到已发现从源节点可达的所有节点为止。如果还存在未被发现的节点，则选择其中一个作为源节点并重复以上过程，整个进程反复进行直到所有节点都被访问为止。</p>
<h2 id="子集和问题"><a href="#子集和问题" class="headerlink" title="子集和问题"></a>子集和问题</h2><blockquote>
<p> 子集和问题的一个实例为&lt;S,c&gt;。其中S&#x3D;{x1,x2,…,xn}是一个正整数的集合，c是一个正整数。子集和问题判定是否存在S的一个子集S1，使得S1中所有元素的和为c。 </p>
</blockquote>
<h2 id="全排列问题"><a href="#全排列问题" class="headerlink" title="全排列问题"></a>全排列问题</h2><blockquote>
<p> 给定一个由不同的小写字母组成的字符串，输出这个字符串的所有全排列。 </p>
</blockquote>
<h2 id="N皇后问题"><a href="#N皇后问题" class="headerlink" title="N皇后问题"></a>N皇后问题</h2><p><img src="/posts/f6fb8bbc/asset/20200524120657135.png" alt="在这里插入图片描述"></p>
<p>##N皇后（状态压缩）</p>
<p><img src="/posts/f6fb8bbc/asset/20200524122524602.png" alt="在这里插入图片描述"></p>
<p> 这里我所习惯的二进制还是右边是第0位开始，这样正好与实际情况相反，所以都要反着来。 </p>
<p>逐行放置皇后,首先排除每行有多个皇后互相排斥的情况</p>
<p>用二进制表示状态.1表示该点不能放(与其他位置的皇后排斥或初始状态就不能放).0表示该点可以放皇后</p>
<p>用sta[]来存储初始状态,将’.’位 置为1</p>
<p>dfs保存四个参数:当前行的状态,从左上到右下对角线的状态,从右上到左下对角线的状态,当前为第几行</p>
<p>获取当前哪一位可以放置皇后:将四者取并集(即将四者进行或运算).得到的状态中为0的就可以放置皇后.</p>
<p>为了快速得到可以放置皇后的位置,对上一步得到的状态进行取反.转换成快速得到1的位置.</p>
<p>用树状数组中的lowbit()就可以得到从右向左的第一个1</p>
<p>将状态中的1减掉,继续找下一个1</p>
<p>更新”将是下一行的状态”,由于对角线是斜着影响的,所以左上到右下对角线的状态需要右移一位,右上到左下对角线的状态需要左移一位.</p>
<p>知道当前行的状态全为1时,即每一行都有一个皇后时,ans++;</p>
<h2 id="数独"><a href="#数独" class="headerlink" title="数独"></a>数独</h2><p><img src="/posts/f6fb8bbc/asset/20200524212354855.png" alt="在这里插入图片描述"></p>
<p>首先需要从当前能填合法数字最小的位置开始填数字<br>排除等效冗余:任意一个状态下,我们只需要找一个位置填数即可,而不是找所有的位置和可填的数字.<br>位运算:很明显这里面check判定很多,我们必须优化这个check,所以我们可以对于,每一行,每一列,每一个九宫格,都利用一个九位二进制数保存,当前还有哪些数字可以填写.<br>lowbit:我们这道题目当前得需要用lowbit运算取出当前可以能填的数字.</p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>基本算法</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>基本算法</tag>
      </tags>
  </entry>
  <entry>
    <title>19.质数</title>
    <url>/posts/27f4adb8/</url>
    <content><![CDATA[<h2 id="质数"><a href="#质数" class="headerlink" title="质数"></a>质数</h2><p>若一个数，只有一和它本身两个因子，那么这个数就是一个质数</p>
<p>在自然数集中，小于n的质数约有ln(n)个</p>
<h2 id="质数的判定"><a href="#质数的判定" class="headerlink" title="质数的判定"></a>质数的判定</h2><p>###试除法</p>
<p>试除法是常用的判断素数的方法<br>时间复杂度O ( n^1&#x2F;2^ ) </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">inline bool is_prime(int x)&#123;</span><br><span class="line">    if(x &lt; 2)</span><br><span class="line">        return false;</span><br><span class="line">    for(register int i = 2;i*i &lt;= x ++i)</span><br><span class="line">        if(x % i == 0)</span><br><span class="line">            return false;</span><br><span class="line">    return true;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Miller-Robbin算法"><a href="#Miller-Robbin算法" class="headerlink" title="Miller-Robbin算法"></a>Miller-Robbin算法</h3><p> 根据人品判断质数（雾 </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">int modexp(int a,int b,int m)</span><br><span class="line">&#123;</span><br><span class="line">    __int64 ans=1;__int64 t=a%m;</span><br><span class="line">    while(b)</span><br><span class="line">    &#123;</span><br><span class="line">        if(b&amp;1)</span><br><span class="line">        &#123;</span><br><span class="line">            ans=(ans*t)%m;</span><br><span class="line">            b--;</span><br><span class="line">        &#125;</span><br><span class="line">        t=(t*t)%m;</span><br><span class="line">        b&gt;&gt;=1;</span><br><span class="line">    &#125;</span><br><span class="line">    return ans;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">bool MillerRobbin(int n)</span><br><span class="line">&#123;</span><br><span class="line">    if(n==2) return 1;</span><br><span class="line">    else if((n&amp;1)==0) return 0;</span><br><span class="line">    int a,d;</span><br><span class="line">    long long t;</span><br><span class="line">    for(int i=0;i&lt;s;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        a=rand()%(n-1)+1;</span><br><span class="line">        d=n-1;</span><br><span class="line">        while((d&amp;1)==0) d&gt;&gt;=1;</span><br><span class="line">        t=modexp(a,d,n);</span><br><span class="line">        while(d!=n-1&amp;&amp;t!=1&amp;&amp;t!=n-1)</span><br><span class="line">        &#123;</span><br><span class="line">            t=(t*t)% n;</span><br><span class="line">            d&lt;&lt;=1;</span><br><span class="line">        &#125;</span><br><span class="line">        if(t==n-1||(d&amp;1)==1) continue;</span><br><span class="line">        else return 0;</span><br><span class="line">    &#125;</span><br><span class="line">    return 1;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p> <a href="https://www.cnblogs.com/p-z-y/p/10603061.html">浅谈 Miller-Robbin 与 Pollard Rho</a> </p>
<h2 id="质数的筛选"><a href="#质数的筛选" class="headerlink" title="质数的筛选"></a>质数的筛选</h2><h3 id="Eratosthenes筛选（埃拉托色尼筛法）"><a href="#Eratosthenes筛选（埃拉托色尼筛法）" class="headerlink" title="Eratosthenes筛选（埃拉托色尼筛法）"></a>Eratosthenes筛选（埃拉托色尼筛法）</h3><p>每次只用素数去筛复杂度O(nloglogn)</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">int v[N];</span><br><span class="line">void primes(int n&#123;</span><br><span class="line">    memset(v,0,sizeof v);</span><br><span class="line">    for(int i = 2;i &lt;= n; ++i)&#123;</span><br><span class="line">        if( v[i] )continue;</span><br><span class="line">        cout&lt;&lt;i&lt;&lt;endl;</span><br><span class="line">        for(int j = i;j &lt;= n/i;++j)</span><br><span class="line">            v[i*j] = 1;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="线型筛（欧拉筛）"><a href="#线型筛（欧拉筛）" class="headerlink" title="线型筛（欧拉筛）"></a>线型筛（欧拉筛）</h3><p>每次只用一个数用小于当前这个数最小质因子的质数去筛其他数，即保证每个数都被自己的最小质因子筛掉。O(n)</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">const int N = 10005;</span><br><span class="line">int n,prime[N],cnt;</span><br><span class="line">bool vis[N];</span><br><span class="line"></span><br><span class="line">inline void primes()</span><br><span class="line">&#123;</span><br><span class="line">	for(register int i = 2;i &lt;= n;i ++)</span><br><span class="line">    &#123;</span><br><span class="line">    	if(!vis[i]) prime[++cnt] = i;</span><br><span class="line">    	for(register int j = 1;j &lt;= cnt &amp;&amp; i * prime[j] &lt;= n; j ++)</span><br><span class="line">        &#123;</span><br><span class="line">        	vis[i * prime[j]] = 1;</span><br><span class="line">            if(i % prime[j] == 0) break;</span><br><span class="line">    	&#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;	</span><br></pre></td></tr></table></figure>

<h2 id="质因数分解"><a href="#质因数分解" class="headerlink" title="质因数分解"></a>质因数分解</h2><p> 任何一个大于1的数都可以被分解成有限个质数乘积的形式 </p>
<h3 id="试除法"><a href="#试除法" class="headerlink" title="试除法"></a>试除法</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">const int N = 1005;</span><br><span class="line">int p[N];</span><br><span class="line">inline int factorize(int x)</span><br><span class="line">&#123;</span><br><span class="line">	register int cnt = 0;</span><br><span class="line">	for(register int i = 2;i * i &lt;= x;i ++)</span><br><span class="line">		while(x % i == 0)</span><br><span class="line">			p[++cnt] = i, x /= i;	</span><br><span class="line">	if(x &gt; 1) p[++cnt] = x;</span><br><span class="line">	return cnt;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>更优的写法</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/* 有点二进制拆分的意思 */</span><br><span class="line">vector&lt;int&gt;p;//存质数</span><br><span class="line">vector&lt;int&gt;factor(int n)&#123;</span><br><span class="line">    vector&lt;int&gt;f;</span><br><span class="line">    for(int i = 0;i &lt; p.size();++i)&#123;</span><br><span class="line">        if(p[i]*p[i] &gt; n)</span><br><span class="line">            break;</span><br><span class="line">        while(n % p[i] == 0)//直接从质数里挑</span><br><span class="line">            f.push_back(p[i]),n /= p[i]; </span><br><span class="line">    &#125;</span><br><span class="line">    if(n&gt;1)//如果还有</span><br><span class="line">        f.push_back(n);</span><br><span class="line">    return f;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="/posts/27f4adb8/asset/20200528171044232.png" alt="在这里插入图片描述"></p>
<p>样例解释<br>5 ! &#x3D; 120 &#x3D; 2^3^<em>3</em>5<br>N!中质数因子p的个数,就是1~N中每个数中含有的质因数p的个数.既然如此的话,那么我们发现,1～N中，p的倍数，至少有一个质因子p的显然有 n&#x2F;p</p>
<p>  个,而至少有两个质因子p数的显然是有 n&#x2F;p^2^ ，以此类推。</p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>基本算法</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>基本算法</tag>
      </tags>
  </entry>
  <entry>
    <title>2.递归与递推</title>
    <url>/posts/e2044e70/</url>
    <content><![CDATA[<h2 id="递推与递归"><a href="#递推与递归" class="headerlink" title="递推与递归"></a>递推与递归</h2><p> 对于一个待求解的问题，当它局限于某处边界，某个小范围或者某种特殊情况下时，其答案往往是已知的。如果能够将该解答的应用场景扩大到原问题的状态空间，并且扩展过程的每个步骤都具有相似性，就可以考虑使用递推或者递归求解。 </p>
<p>递归问题的核心思想：</p>
<p>在每次递归的时候都<strong>分别尝试所有可能的情况</strong>，选择分支，将问题数量减少一，从而转化为<strong>一个规模更小的同类问题</strong></p>
<p><img src="/posts/e2044e70/asset/20200419112738114.png" alt="在这里插入图片描述"></p>
<h2 id="分治"><a href="#分治" class="headerlink" title="分治"></a>分治</h2><p> 分治法把一个问题划分位&#x3D;为若干个规模更小的同类子问题，对这些子问题递归求解，然后在回溯时通过它们推导出原问题的解。 </p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>基本算法</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>基本算法</tag>
      </tags>
  </entry>
  <entry>
    <title>20.并查集</title>
    <url>/posts/d9275abb/</url>
    <content><![CDATA[<p>并查集被很多OIer认为是最简洁而优雅的数据结构之一，主要用于解决一些<strong>元素分组</strong>的问题。它管理一系列<strong>不相交的集合</strong>，并支持两种操作：</p>
<ul>
<li><strong>合并</strong>（Union）：把两个不相交的集合合并为一个集合。</li>
<li><strong>查询</strong>（Find）：查询两个元素是否在同一个集合中。</li>
</ul>
<p> 当然，这样的定义未免太过学术化，看完后恐怕不太能理解它具体有什么用。所以我们先来看看并查集最直接的一个应用场景：<strong>亲戚问题</strong>。 </p>
<p><strong>洛谷P1551）亲戚</strong></p>
<blockquote>
<p><strong>题目背景</strong><br>若某个家族人员过于庞大，要判断两个是否是亲戚，确实还很不容易，现在给出某个亲戚关系图，求任意给出的两个人是否具有亲戚关系。<br><strong>题目描述</strong><br>规定：x和y是亲戚，y和z是亲戚，那么x和z也是亲戚。如果x,y是亲戚，那么x的亲戚都是y的亲戚，y的亲戚也都是x的亲戚。<br><strong>输入格式</strong><br>第一行：三个整数n,m,p，（n&lt;&#x3D;5000,m&lt;&#x3D;5000,p&lt;&#x3D;5000），分别表示有n个人，m个亲戚关系，询问p对亲戚关系。<br>以下m行：每行两个数Mi，Mj，1&lt;&#x3D;Mi，Mj&lt;&#x3D;N，表示Mi和Mj具有亲戚关系。<br>接下来p行：每行两个数Pi，Pj，询问Pi和Pj是否具有亲戚关系。<br><strong>输出格式</strong><br>P行，每行一个’Yes’或’No’。表示第i个询问的答案为“具有”或“不具有”亲戚关系。</p>
</blockquote>
<p> 这其实是一个很有现实意义的问题。我们可以建立模型，把所有人划分到若干个不相交的集合中，每个集合里的人彼此是亲戚。为了判断两个人是否为亲戚，只需看它们是否属于同一个集合即可。因此，这里就可以考虑用并查集进行维护了。 </p>
<h2 id="并查集的引入"><a href="#并查集的引入" class="headerlink" title="并查集的引入"></a>并查集的引入</h2><p>并查集的重要思想在于，<strong>用集合中的一个元素代表集合</strong>。我曾看过一个有趣的比喻，把集合比喻成<strong>帮派</strong>，而代表元素则是<strong>帮主</strong>。接下来我们利用这个比喻，看看并查集是如何运作的。</p>
<p><img src="/posts/d9275abb/asset/v2-09fa3fa35e5411444b327d9cb9a31057_1440w.webp" alt="img"></p>
<p> 最开始，所有大侠各自为战。他们各自的帮主自然就是自己。<em>（对于只有一个元素的集合，代表元素自然是唯一的那个元素）</em> </p>
<p> 现在1号和3号比武，假设1号赢了（这里具体谁赢暂时不重要），那么3号就认1号作帮主<em>（合并1号和3号所在的集合，1号为代表元素）</em>。 </p>
<p><img src="/posts/d9275abb/asset/v2-3bf6c1a6ecf87fa93f4dbab2012446c7_1440w.webp" alt="img"></p>
<p> 现在2号想和3号比武<em>（合并3号和2号所在的集合）</em>，但3号表示，别跟我打，让我帮主来收拾你<em>（合并代表元素）</em>。不妨设这次又是1号赢了，那么2号也认1号做帮主。 </p>
<p><img src="/posts/d9275abb/asset/v2-be12a6c795572d2acd77dcd49de35127_1440w.webp" alt="img"></p>
<p> 现在我们假设4、5、6号也进行了一番帮派合并，江湖局势变成下面这样： </p>
<p><img src="/posts/d9275abb/asset/v2-3c353bc781c7f3553079d541a9cfdc28_1440w.webp" alt="img"></p>
<p> 现在假设2号想与6号比，跟刚刚说的一样，喊帮主1号和4号出来打一架（帮主真辛苦啊）。1号胜利后，4号认1号为帮主，当然他的手下也都是跟着投降了。 </p>
<p><img src="/posts/d9275abb/asset/v2-6362d8b13705d5ba17b19cdeee453022_1440w.webp" alt="img"></p>
<p> 好了，比喻结束了。如果你有一点图论基础，相信你已经觉察到，这是一个<strong>树</strong>状的结构，要寻找集合的代表元素，只需要一层一层往上访问<strong>父节点</strong>（图中箭头所指的圆），直达树的<strong>根节点</strong>（图中橙色的圆）即可。根节点的父节点是它自己。我们可以直接把它画<img src="/posts/d9275abb/asset/v2-cca3ddf5806a221201ed78caf1d27041_1440w.webp" alt="img">成一棵树： </p>
<p> 用这种方法，我们可以写出最简单版本的并查集代码。 </p>
<h3 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h3><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> fa[MAXN];</span><br><span class="line"><span class="keyword">inline</span> <span class="type">void</span> <span class="title function_">init</span><span class="params">(<span class="type">int</span> n)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= n; ++i)</span><br><span class="line">        fa[i] = i;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p> 假如有编号为1, 2, 3, …, n的n个元素，我们用一个数组fa[]来存储每个元素的父节点（因为每个元素有且只有一个父节点，所以这是可行的）。一开始，我们先将它们的父节点设为自己。 </p>
<h3 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h3><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">find</span><span class="params">(<span class="type">int</span> x)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">if</span>(fa[x] == x)</span><br><span class="line">        <span class="keyword">return</span> x;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="keyword">return</span> find(fa[x]);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p> 我们用递归的写法实现对代表元素的查询：一层一层访问父节点，直至根节点（根节点的标志就是父节点是本身）。要判断两个元素是否属于同一个集合，只需要看它们的根节点是否相同即可。 </p>
<h3 id="合并"><a href="#合并" class="headerlink" title="合并"></a>合并</h3><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">inline</span> <span class="type">void</span> <span class="title function_">merge</span><span class="params">(<span class="type">int</span> i, <span class="type">int</span> j)</span></span><br><span class="line">&#123;</span><br><span class="line">    fa[find(i)] = find(j);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p> 合并操作也是很简单的，先找到两个集合的代表元素，然后将前者的父节点设为后者即可。当然也可以将后者的父节点设为前者，这里暂时不重要。本文末尾会给出一个更合理的比较方法。 </p>
<h2 id="路径压缩"><a href="#路径压缩" class="headerlink" title="路径压缩"></a>路径压缩</h2><p>最简单的并查集效率是比较低的。例如，来看下面这个场景：</p>
<p><img src="/posts/d9275abb/asset/v2-49b5dd7af650192373e96d29f9c4b8cf_1440w.webp" alt="img"></p>
<p>现在我们要merge(2,3)，于是从2找到1，fa[1]&#x3D;3，于是变成了这样：</p>
<p> <img src="/posts/d9275abb/asset/v2-6f85fc7c5578aa20400ac56f0da31e37_1440w.webp" alt="img"></p>
<p>然后我们又找来一个元素4，并需要执行merge(2,4)：</p>
<p><img src="/posts/d9275abb/asset/v2-1d3ef8a42d424cbec76135ce8a494ff7_1440w.webp" alt="img"></p>
<p>从2找到1，再找到3，然后fa[3]&#x3D;4，于是变成了这样：</p>
<p><img src="/posts/d9275abb/asset/v2-23c367515ace6fc0603692dfd865849f_1440w.webp" alt="img"></p>
<p>大家应该有感觉了，这样可能会形成一条长长的<strong>链</strong>，随着链越来越长，我们想要从底部找到根节点会变得越来越难。</p>
<p>怎么解决呢？我们可以使用<strong>路径压缩</strong>的方法。既然我们只关心一个元素对应的<strong>根节点</strong>，那我们希望每个元素到根节点的路径尽可能短，最好只需要一步<img src="/posts/d9275abb/asset/v2-c2f835398a3e54d8209bf5e034ac6820_1440w.webp" alt="img">，像这样：</p>
<p> 其实这说来也很好实现。只要我们在查询的过程中，<strong>把沿途的每个节点的父节点都设为根节点</strong>即可。下一次再查询时，我们就可以省很多事。这用递归的写法很容易实现： </p>
<h3 id="合并（路径压缩）"><a href="#合并（路径压缩）" class="headerlink" title="合并（路径压缩）"></a>合并（路径压缩）</h3><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">find</span><span class="params">(<span class="type">int</span> x)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">if</span>(x == fa[x])</span><br><span class="line">        <span class="keyword">return</span> x;</span><br><span class="line">    <span class="keyword">else</span>&#123;</span><br><span class="line">        fa[x] = find(fa[x]);  <span class="comment">//父节点设为根节点</span></span><br><span class="line">        <span class="keyword">return</span> fa[x];         <span class="comment">//返回父节点</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p> 路径压缩优化后，并查集的时间复杂度已经比较低了，绝大多数不相交集合的合并查询问题都能够解决。然而，对于某些时间卡得很紧的题目，我们还可以进一步优化。</p>
<h2 id="按秩合并"><a href="#按秩合并" class="headerlink" title="按秩合并"></a>按秩合并</h2><p>有些人可能有一个误解，以为路径压缩优化后，并查集始终都是一个<strong>菊花图</strong>（只有两层的树的俗称）。但其实，由于路径压缩只在查询时进行，也只压缩一条路径，所以并查集最终的结构仍然可能是比较复杂的。例如，现在我们有一棵较复杂的树需要与一个单元素的集合合并：</p>
<p><img src="/posts/d9275abb/asset/v2-d3ff42bb79a6bc751f47daf3fc70e0d9_1440w.webp" alt="img"></p>
<p>假如这时我们要merge(7,8)，如果我们可以选择的话，是把7的父节点设为8好，还是把8的父节点设为7好呢？</p>
<p>当然是后者。因为如果把7的父节点设为8，会使树的<strong>深度</strong>（树中最长链的长度）加深，原来的树中每个元素到根节点的距离都变长了，之后我们寻找根节点的路径也就会相应变长。虽然我们有路径压缩，但路径压缩也是会消耗时间的。而把8的父节点设为7，则不会有这个问题，因为它没有影响到不相关的节点。<img src="/posts/d9275abb/asset/v2-96fbb25365b43f0a109bec6d55b3b899_1440w.webp" alt="img"></p>
<p>这启发我们：我们应该把简单的树往复杂的树上合并，而不是相反。因为这样合并后，到根节点距离变长的节点个数比较少。</p>
<p>我们用一个数组rank[]记录每个根节点对应的树的深度（如果不是根节点，其rank相当于以它作为根节点的<strong>子树</strong>的深度）。一开始，把所有元素的rank（<strong>秩</strong>）设为1。合并时比较两个根节点，把rank较小者往较大者上合并。</p>
<p>路径压缩和按秩合并如果一起使用，时间复杂度接近 O(n) ，但是很可能会破坏rank的准确性。</p>
<h3 id="初始化（按秩合并）"><a href="#初始化（按秩合并）" class="headerlink" title="初始化（按秩合并）"></a>初始化（按秩合并）</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">inline void init(int n)</span><br><span class="line">&#123;</span><br><span class="line">    for (int i = 1; i &lt;= n; ++i)</span><br><span class="line">    &#123;</span><br><span class="line">        fa[i] = i;</span><br><span class="line">        rank[i] = 1;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="合并（按秩合并）"><a href="#合并（按秩合并）" class="headerlink" title="合并（按秩合并）"></a>合并（按秩合并）</h3><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">inline</span> <span class="type">void</span> <span class="title function_">merge</span><span class="params">(<span class="type">int</span> i, <span class="type">int</span> j)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> x = find(i), y = find(j);    <span class="comment">//先找到两个根节点</span></span><br><span class="line">    <span class="keyword">if</span> (rank[x] &lt;= rank[y])</span><br><span class="line">        fa[x] = y;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        fa[y] = x;</span><br><span class="line">    <span class="keyword">if</span> (rank[x] == rank[y] &amp;&amp; x != y)</span><br><span class="line">        rank[y]++;                   <span class="comment">//如果深度相同且根节点不同，则新的根节点的深度+1</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p> 为什么深度相同，新的根节点深度要+1？如下图，我们有两个深度均为2的树，现在要merge(2,5)： </p>
<p><img src="/posts/d9275abb/asset/v2-de356190829600f438058e8615c7a5ac_1440w.webp" alt="img"></p>
<p> 这里把2的父节点设为5，或者把5的父节点设为2，其实没有太大区别。我们选择前者，于是变成这样： </p>
<p><img src="/posts/d9275abb/asset/v2-a829932f008f000440942cb8df393662_1440w.webp" alt="img"></p>
<p> 显然树的深度增加了1。另一种合并方式同样会让树的深度+1。</p>
<h2 id="并查集的应用"><a href="#并查集的应用" class="headerlink" title="并查集的应用"></a>并查集的应用</h2><p>我们先给出亲戚问题的AC代码：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> MAXN 5005</span></span><br><span class="line"><span class="type">int</span> fa[MAXN], rank[MAXN];</span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">void</span> <span class="title">init</span><span class="params">(<span class="type">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= n; ++i)</span><br><span class="line">    &#123;</span><br><span class="line">        fa[i] = i;</span><br><span class="line">        rank[i] = <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">find</span><span class="params">(<span class="type">int</span> x)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> x == fa[x] ? x : (fa[x] = <span class="built_in">find</span>(fa[x]));</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">void</span> <span class="title">merge</span><span class="params">(<span class="type">int</span> i, <span class="type">int</span> j)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> x = <span class="built_in">find</span>(i), y = <span class="built_in">find</span>(j);</span><br><span class="line">    <span class="keyword">if</span> (rank[x] &lt;= rank[y])</span><br><span class="line">        fa[x] = y;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        fa[y] = x;</span><br><span class="line">    <span class="keyword">if</span> (rank[x] == rank[y] &amp;&amp; x != y)</span><br><span class="line">        rank[y]++;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> n, m, p, x, y;</span><br><span class="line">    <span class="built_in">scanf</span>(<span class="string">&quot;%d%d%d&quot;</span>, &amp;n, &amp;m, &amp;p);</span><br><span class="line">    <span class="built_in">init</span>(n);</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; m; ++i)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">&quot;%d%d&quot;</span>, &amp;x, &amp;y);</span><br><span class="line">        <span class="built_in">merge</span>(x, y);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; p; ++i)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">&quot;%d%d&quot;</span>, &amp;x, &amp;y);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%s\n&quot;</span>, <span class="built_in">find</span>(x) == <span class="built_in">find</span>(y) ? <span class="string">&quot;Yes&quot;</span> : <span class="string">&quot;No&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p> <strong>并查集能在一张无向图中维护结点之间的连通性，实际上，并查集擅长动态维护许多具有传递性的关系。</strong> </p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>基本算法</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>基本算法</tag>
      </tags>
  </entry>
  <entry>
    <title>21.树状数组</title>
    <url>/posts/eec6e917/</url>
    <content><![CDATA[<p> <strong>树状数组可以解决大部分基于区间上的更新以及求和问题。</strong> </p>
<p> 树状数组（<strong>B</strong>inary <strong>I</strong>ndex <strong>T</strong>ree, <strong>BIT</strong>）也是很多OIer心中最简洁优美的数据结构之一。最简单的树状数组支持两种操作，时间复杂度均为 哦O(log⁡n) ： </p>
<ul>
<li><strong>单点修改</strong>：更改数组中一个元素的值</li>
<li><strong>区间查询</strong>：查询一个区间内所有元素的和</li>
</ul>
<p> 当然，树状数组能维护的不局限于加法，支持的操作也不止这两种，甚至有大佬能用树状数组实现平衡树，但这篇笔记不会深入讨论（因为我也还不是很懂hh）。 </p>
<p> 我们还是先来看一道模板题，来看看树状数组最基本的应用场景： </p>
<blockquote>
<p> <strong>Problem Description</strong><br>C国的死对头A国这段时间正在进行军事演习，所以C国间谍头子Derek和他手下Tidy又开始忙乎了。A国在海岸线沿直线布置了N个工兵营地,Derek和Tidy的任务就是要监视这些工兵营地的活动情况。由于采取了某种先进的监测手段，所以每个工兵营地的人数C国都掌握的一清二楚,每个工兵营地的人数都有可能发生变动，可能增加或减少若干人手,但这些都逃不过C国的监视。<br>中央情报局要研究敌人究竟演习什么战术,所以Tidy要随时向Derek汇报某一段连续的工兵营地一共有多少人,例如Derek问:“Tidy,马上汇报第3个营地到第10个营地共有多少人!”Tidy就要马上开始计算这一段的总人数并汇报。但敌兵营地的人数经常变动，而Derek每次询问的段都不一样，所以Tidy不得不每次都一个一个营地的去数，很快就精疲力尽了，Derek对Tidy的计算速度越来越不满:”你个死肥仔，算得这么慢，我炒你鱿鱼!”Tidy想：“你自己来算算看，这可真是一项累人的工作!我恨不得你炒我鱿鱼呢!”无奈之下，Tidy只好打电话向计算机专家Windbreaker求救,Windbreaker说：“死肥仔，叫你平时做多点acm题和看多点算法书，现在尝到苦果了吧!”Tidy说：”我知错了。。。”但Windbreaker已经挂掉电话了。Tidy很苦恼，这么算他真的会崩溃的，聪明的读者，你能写个程序帮他完成这项工作吗？不过如果你的程序效率不够高的话，Tidy还是会受到Derek的责骂的.<br><strong>Input</strong><br>第一行一个整数T，表示有T组数据。<br>每组数据第一行一个正整数N（N&lt;&#x3D;50000）,表示敌人有N个工兵营地，接下来有N个正整数,第i个正整数ai代表第i个工兵营地里开始时有ai个人（1&lt;&#x3D;ai&lt;&#x3D;50）。<br>接下来每行有一条命令，命令有4种形式：<br>(1) Add i j,i和j为正整数,表示第i个营地增加j个人（j不超过30）<br>(2)Sub i j ,i和j为正整数,表示第i个营地减少j个人（j不超过30）;<br>(3)Query i j ,i和j为正整数,i&lt;&#x3D;j，表示询问第i到第j个营地的总人数;<br>(4)End 表示结束，这条命令在每组数据最后出现;<br>每组数据最多有40000条命令<br><strong>Output</strong><br>对第i组数据,首先输出“Case i:”和回车,<br>对于每个Query询问，输出一个整数并回车,表示询问的段中的总人数,这个数保持在int以内。 </p>
</blockquote>
<p> 这个数据范围，直接模拟肯定会T，所以我们要使用数据结构来维护数组，树状数组可以说是其中最简洁的一种。我们来看看树状数组是怎么实现的。 </p>
<h2 id="树状数组的引入"><a href="#树状数组的引入" class="headerlink" title="树状数组的引入"></a>树状数组的引入</h2><p>回顾一下，我们说，我们要实现两种操作：<strong>单点修改</strong>和<strong>区间求和</strong>。对于普通数组而言，<strong>单点修改</strong>的时间复杂度是 O(1) ，但<strong>区间求和</strong>的时间复杂度是 O(n) 。<img src="/posts/eec6e917/asset/v2-5652a46124eaa79fafae0558253e6a80_1440w.webp" alt="img"></p>
<pre><code>                                                                                                     普通数组 
</code></pre>
<p> 当然，我们也可以用<strong>前缀和</strong>的方法维护这个数组，这样的话<strong>区间求和</strong>的时间复杂度就降到了O(1)，但是<strong>单点修改</strong>会影响后面所有的元素，时间复杂度是O(n)。 </p>
<p><img src="/posts/eec6e917/asset/v2-83809502459ae695ec219d6974315292_1440w.webp" alt="img"></p>
<p> 程序最后跑多长时间，是由最慢的一环决定的，因此现在我们希望找到这样一种折中的方法：无论单点修改还是区间查询，它都能不那么慢地完成。 </p>
<p> 注意到对 [a,b] 进行区间查询只需查询 [1,a] 和 [1,b) 然后相减即可（前缀和就是这样进行区间查询的），所以我们可以把区间查询问题转化为求前n项和的问题。 </p>
<p> 关于数组的维护，有个很自然的想法：可以用一个数组 C维护若干个小区间，单点修改时，<strong>只更新包含这一元素的区间</strong>；求前n项和时，<strong>通过将区间进行组合，得到从1到n的区间，然后对所有用到的区间求和</strong>。实际上，设原数组是 A ，如果 C<del>i</del> 维护的区间是 [A<del>i</del>,A<del>i</del>] ，此结构就相当于普通数组（还浪费了一倍内存）；如果 C<del>i</del> 维护的区间就是 [1,A<del>i</del>] ，此结构就相当于前缀和。 </p>
<p> 现在我们试图寻找一种结构，一方面，单点修改时需要更新的区间不会太多；另一方面，区间查询时需要用来组合的区间也不会太多。 </p>
<p> 树状数组就是这样一种结构，它巧妙地利用了<strong>二进制</strong>（实际上，树状数组的英文名BIT，直译过来就是<strong>二进制下标树</strong>）。例如11，转化为二进制数就是 (1011)2 ，如果我们要求前11项和，可以分别查询 ((0000)2,(1000)2] 、((1000)2,(1010)2]以及((1010)2,(1011)2]的和再相加。这三个区间怎么来的呢？其实就是<strong>不断地去掉二进制数最右边的一个1</strong>的过程（如下图）。 </p>
<p><img src="/posts/eec6e917/asset/v2-a53a897f22763ef04a728f8263f06547_1440w.webp" alt="img"></p>
<p> 我们定义，二进制数最右边的一个1，连带着它之后的0为 lowbit(x) （稍后再来看如何实现）。那么我们用C<del>i</del> 维护区间 (A<del>i</del>−lowbit(A<del>i</del>),A<del>i</del>]，这样显然查询前n项和时需要合并的区间数是少于 log<del>2</del>n 的。树状数组的结构大概像下面这样： </p>
<p><img src="/posts/eec6e917/asset/v2-fbaeb49fdbad31a211fe37f068ca8bb0_1440w.webp" alt="img"></p>
<p> 那么如何更新呢，大家会发现更新就是一个“<strong>爬树</strong>”的过程。一路往上更新，直到MAXN（树状数组的容量）。 </p>
<p><img src="/posts/eec6e917/asset/v2-df001651925903a86ab640482b78c2d6_1440w.webp" alt="img"></p>
<p> 我们举个例子来看看这树是怎么爬的。 现有二进制数(100110)2 ，包含它的最小区间当然是((100100)2,(100110)2]。然后，它也肯定位于区间((100000)2,(101000)2]内。然后是((100000)2,(110000)2]，再然后是 (0,(1000000)2] …… </p>
<p><img src="/posts/eec6e917/asset/v2-8ce9df6ada69084d3ccd0df5ecc45b5e_1440w.webp" alt="img"></p>
<p> 如上图，每一步都把<strong>从右边起一系列连续的1变为0，再把这一系列1的前一位0变为1</strong>。这看起来像是一个<strong>进位</strong>的过程对吧？实际上，每一次加的正是 lowbit(x) 。（神奇吧？）这样，我们更新的区间数不会超过 log2⁡MAXN 。一个能以 O(log⁡n) 时间复杂度进行单点修改和区间查询的数据结构就诞生了。 </p>
<h2 id="树状数组的实现"><a href="#树状数组的实现" class="headerlink" title="树状数组的实现"></a>树状数组的实现</h2><p>前面已经讲得很详细了，代码实现倒是一件简单的事了。不过我们需要先解决一个问题：lowbit怎么算？如果一位一位验证的话，会形成额外的时间开销。然而，我们有这样神奇的一个公式：</p>
<p>lowbit(x)&#x3D;x&amp;-x</p>
<p> 为什么可以这样？我们需要知道，计算机里有符号数一般是以<strong>补码</strong>的形式存储的。-x相当于x<strong>按位取反再加1</strong>，会把结尾处原来1000…的形式，变成0111…，再变成1000…；而前面每一位都与原来相反。这时我们再把它和x按位与，得到的结果便是lowbit(x)。下面的图中举了两个例子： </p>
<p><img src="/posts/eec6e917/asset/v2-fd4b485006b55bfd45c13f4348e1e1ee_1440w.webp" alt="img"></p>
<p>现在我们可以愉快地实现树状数组了：</p>
<h3 id="单点修改"><a href="#单点修改" class="headerlink" title="单点修改"></a>单点修改</h3><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> tree[MAXN];</span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">void</span> <span class="title">update</span><span class="params">(<span class="type">int</span> i, <span class="type">int</span> x)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> pos = i; pos &lt; MAXN; pos += <span class="built_in">lowbit</span>(pos))</span><br><span class="line">        tree[pos] += x;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="求前n项和"><a href="#求前n项和" class="headerlink" title="求前n项和"></a>求前n项和</h3><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">int</span> <span class="title">query</span><span class="params">(<span class="type">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> ans = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> pos = n; pos; pos -= <span class="built_in">lowbit</span>(pos))</span><br><span class="line">        ans += tree[pos];</span><br><span class="line">    <span class="keyword">return</span> ans;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="区间查询"><a href="#区间查询" class="headerlink" title="区间查询"></a>区间查询</h3><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">int</span> <span class="title">query</span><span class="params">(<span class="type">int</span> a, <span class="type">int</span> b)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">query</span>(b) - <span class="built_in">query</span>(a - <span class="number">1</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p> 初始化的时候，我们只需要update每个点的初始值即可。 </p>
<h2 id="树状数组的拓展应用"><a href="#树状数组的拓展应用" class="headerlink" title="树状数组的拓展应用"></a>树状数组的拓展应用</h2><h2 id="1-区间加，求单点值"><a href="#1-区间加，求单点值" class="headerlink" title="1.区间加，求单点值"></a>1.区间加，求单点值</h2><p><img src="/posts/eec6e917/asset/20200720204402471.png" alt="在这里插入图片描述"></p>
<p>把整数拆分成前n项和，那么区间加，就变成左边端点加，右边端点减</p>
<h2 id="2-区间加，区间求和"><a href="#2-区间加，区间求和" class="headerlink" title="2.区间加，区间求和"></a>2.区间加，区间求和</h2><p><img src="/posts/eec6e917/asset/20200720220916901.png" alt="在这里插入图片描述"></p>
<p><img src="/posts/eec6e917/asset/20200720220905947.png" alt="在这里插入图片描述"></p>
<p><img src="/posts/eec6e917/asset/20200720220545651.png" alt="在这里插入图片描述"></p>
<p><img src="/posts/eec6e917/asset/1688194742126.png" alt="1688194742126"></p>
<p>方法：树状数组+二分，从后往前枚举时，有两个操作：</p>
<p>​           从剩余的数中找第k小的数</p>
<p>​           删除某个数</p>
<p>如何理解用树状数组来维护序列exist数组呢？</p>
<p>我们知道树状数组由两个经典函数，一个是单点修改update函数，另一个是区间查询getSum函数。</p>
<p>对于单点修改update(int x,int v)函数，表示在x位置+v，那么如何知道这个x值和v值呢？其实这个x值也就是exist中的i，这个v值也就是exist序列中的某个数exist[i]，因此，树状数组的update函数中的x值和v值来源于exist序列，作用于exist序列上，所以称用树状数组来维护序列exist数组。<br>        对于区间查询getSum(int x)函数，如何知道这个x值呢？其实这个x值也就是exist中的i，因此，树状数组的getSum函数中的x值来源于exist序列，作用于exist序列上，所以称用树状数组来维护序列exist数组。</p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>基本算法</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>基本算法</tag>
      </tags>
  </entry>
  <entry>
    <title>22.线段树</title>
    <url>/posts/cccf62a7/</url>
    <content><![CDATA[<p> <strong>线段树</strong>（Segment Tree）几乎是算法竞赛最常用的数据结构了，它主要用于维护<strong>区间信息</strong>（要求满足结合律）。与树状数组相比，它可以实现 O(log⁡n) 的<strong>区间修改</strong>，还可以同时支持<strong>多种操作</strong>（加、乘），更具通用性。 </p>
<p> 接下来我们用这道模板题为例，看看线段树是怎么维护<strong>区间和</strong>这一信息的。 </p>
<blockquote>
<p> <strong>题目描述</strong><br>如题，已知一个数列，你需要进行下面两种操作：<br>1.将某区间每一个数加上x<br>2.求出某区间每一个数的和<br><strong>输入格式</strong><br>第一行包含两个整数N、M，分别表示该数列数字的个数和操作的总个数。<br>第二行包含N个用空格分隔的整数，其中第i个数字表示数列第i项的初始值。<br>接下来M行每行包含3或4个整数，表示一个操作，具体如下：<br>操作1： 格式：1 x y k 含义：将区间[x,y]内每个数加上k<br>操作2： 格式：2 x y 含义：输出区间[x,y]内每个数的和<br><strong>输出格式</strong><br>输出包含若干行整数，即为所有操作2的结果。 </p>
</blockquote>
<h2 id="线段树的建立"><a href="#线段树的建立" class="headerlink" title="线段树的建立"></a>线段树的建立</h2><p>线段树是一棵<strong>平衡二叉树</strong>。母结点代表整个区间的和，越往下区间越小。注意，线段树的每个<strong>节点</strong>都对应一条<strong>线段（区间）</strong>，但并不保证所有的线段（区间）都是线段树的节点，这两者应当区分开。</p>
<p> 如果有一个数组[1,2,3,4,5]，那么它对应的线段树大概长这个样子： </p>
<p><img src="/posts/cccf62a7/asset/v2-5e9124a6147143e51cea46755e9a0398_1440w.webp" alt="img"></p>
<p> 每个节点 p 的左右子节点的编号分别为 2p 和 2p+1 ，假如节点 p 储存区间 [l,r] 的和，设 mid&#x3D;⌊(1+r)&#x2F;2⌋ ，那么两个子节点分别储存 [l, mid] 和 [mid+1,r] 的和。可以发现，左节点对应的区间长度，与右节点相同或者比之恰好多1。 </p>
<p> 如何从数组建立一棵线段树？我们可以考虑<strong>递归</strong>地进行。 <strong>分治</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">void build(ll l = 1, ll r = n, ll p = 1)</span><br><span class="line">&#123;</span><br><span class="line">    if (l == r) // 到达叶子节点</span><br><span class="line">        tree[p] = A[l]; // 用数组中的数据赋值</span><br><span class="line">    else</span><br><span class="line">    &#123;</span><br><span class="line">        ll mid = (l + r) / 2;</span><br><span class="line">        build(l, mid, p * 2); // 先建立左右子节点</span><br><span class="line">        build(mid + 1, r, p * 2 + 1);</span><br><span class="line">        tree[p] = tree[p * 2] + tree[p * 2 + 1]; // 该节点的值等于左右子节点之和</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p> 我这里用一张gif展现上述的过程： </p>
<p><img src="/posts/cccf62a7/asset/v2-c2d11b12c87b6a7076e3df0bb3585423_b.webp" alt="动图"></p>
<h2 id="区间修改"><a href="#区间修改" class="headerlink" title="区间修改"></a>区间修改</h2><p>在讲区间修改前，要先引入一个“<strong>懒标记</strong>”（或延迟标记）的概念。懒标记是线段树的精髓所在。对于区间修改，朴素的想法是用<strong>递归</strong>的方式一层层修改（类似于线段树的建立），但这样的时间复杂度比较高。使用懒标记后，对于那些正好是线段树节点的区间，我们不继续递归下去，而是打上一个<strong>标记</strong>，将来要用到它的<strong>子区间</strong>的时候，再向下<strong>传递</strong>。</p>
<p> 代码比较复杂，我慢慢解释： </p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">update</span><span class="params">(ll l, ll r, ll d, ll p = <span class="number">1</span>, ll cl = <span class="number">1</span>, ll cr = n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (cl &gt; r || cr &lt; l) <span class="comment">// 区间无交集</span></span><br><span class="line">        <span class="keyword">return</span>; <span class="comment">// 剪枝</span></span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (cl &gt;= l &amp;&amp; cr &lt;= r) <span class="comment">// 当前节点对应的区间包含在目标区间中</span></span><br><span class="line">    &#123;</span><br><span class="line">        tree[p] += (cr - cl + <span class="number">1</span>) * d; <span class="comment">// 更新当前区间的值</span></span><br><span class="line">        <span class="keyword">if</span> (cr &gt; cl) <span class="comment">// 如果不是叶子节点</span></span><br><span class="line">            mark[p] += d; <span class="comment">// 给当前区间打上标记</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> <span class="comment">// 与目标区间有交集，但不包含于其中</span></span><br><span class="line">    &#123;</span><br><span class="line">        ll mid = (cl + cr) / <span class="number">2</span>;</span><br><span class="line">        mark[p * <span class="number">2</span>] += mark[p]; <span class="comment">// 标记向下传递</span></span><br><span class="line">        mark[p * <span class="number">2</span> + <span class="number">1</span>] += mark[p];</span><br><span class="line">        tree[p * <span class="number">2</span>] += mark[p] * (mid - cl + <span class="number">1</span>); <span class="comment">// 往下更新一层</span></span><br><span class="line">        tree[p * <span class="number">2</span> + <span class="number">1</span>] += mark[p] * (cr - mid);</span><br><span class="line">        mark[p] = <span class="number">0</span>; <span class="comment">// 清除标记</span></span><br><span class="line">        <span class="built_in">update</span>(l, r, d, p * <span class="number">2</span>, cl, mid); <span class="comment">// 递归地往下寻找</span></span><br><span class="line">        <span class="built_in">update</span>(l, r, d, p * <span class="number">2</span> + <span class="number">1</span>, mid + <span class="number">1</span>, cr);</span><br><span class="line">        tree[p] = tree[p * <span class="number">2</span>] + tree[p * <span class="number">2</span> + <span class="number">1</span>]; <span class="comment">// 根据子节点更新当前节点的值</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p> 更新时，我们是从最大的区间开始，递归向下处理。注意到，<strong>任何区间都是线段树上某些节点的并集</strong>。于是我们记目标区间为 [l,r] ，当前区间为 [cl,cr] ， 当前节点为 p ，我们会遇到三种情况： </p>
<p>\1. 当前区间与目标区间没有交集：</p>
<p><img src="/posts/cccf62a7/asset/v2-794f7124f288eeae7661200d948f43a4_1440w.webp" alt="img"></p>
<p>这时直接结束递归。</p>
<p>2.当前区间被包括在目标区间里：</p>
<p><img src="/posts/cccf62a7/asset/v2-abebb05b5e4c44821e7325c6e6b623fe_1440w.webp" alt="img"></p>
<p>这时可以更新当前区间，别忘了乘上区间长度：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">tree[p] += (cr - cl + <span class="number">1</span>) * d;</span><br></pre></td></tr></table></figure>

<p>然后打上懒标记（叶子节点可以不打标记，因为不会再向下传递了）：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">mark[p] += d;</span><br></pre></td></tr></table></figure>

<p>这个标记表示“该区间上每一个点都要加上d”。因为原来可能存在标记，所以是+&#x3D;而不是&#x3D;。</p>
<p>3.当前区间与目标区间相交，但不包含于其中：</p>
<p><img src="/posts/cccf62a7/asset/v2-10c7ce5904b8300109f51e290ff2c14a_1440w.webp" alt="img"></p>
<p>这时把当前区间一分为二，分别进行处理。如果存在懒标记，要先把懒标记传递给子节点（注意也是+&#x3D;，因为原来可能存在懒标记）：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">ll mid = (cl + cr) / <span class="number">2</span>;</span><br><span class="line">mark[p * <span class="number">2</span>] += mark[p];</span><br><span class="line">mark[p * <span class="number">2</span> + <span class="number">1</span>] += mark[p];</span><br></pre></td></tr></table></figure>

<p>两个子节点的值也就需要相应的更新（后面乘的是区间长度）：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">tree[p * <span class="number">2</span>] += mark[p] * (mid - cl + <span class="number">1</span>);</span><br><span class="line">tree[p * <span class="number">2</span> + <span class="number">1</span>] += mark[p] * (cr - mid);</span><br></pre></td></tr></table></figure>

<p>不要忘记清除该节点的懒标记：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">mark[p] = <span class="number">0</span>;</span><br></pre></td></tr></table></figure>

<p>这个过程并不是递归的，我们只往下传递一层（所以叫“懒”标记啊！），以后要用再才继续传递。其实我们常常把这个传递过程封装成一个函数：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">void</span> <span class="title">push_down</span><span class="params">(ll p, ll len)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    mark[p * <span class="number">2</span>] += mark[p];</span><br><span class="line">    mark[p * <span class="number">2</span> + <span class="number">1</span>] += mark[p];</span><br><span class="line">    tree[p * <span class="number">2</span>] += mark[p] * (len - len / <span class="number">2</span>);</span><br><span class="line">    tree[p * <span class="number">2</span> + <span class="number">1</span>] += mark[p] * (len / <span class="number">2</span>); <span class="comment">// 右边的区间可能要短一点</span></span><br><span class="line">    mark[p] = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>然后在update函数中这样调用：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">push_down</span>(p, cr - cl + <span class="number">1</span>);</span><br></pre></td></tr></table></figure>

<p>传递完标记后，再递归地去处理左右两个子节点。</p>
<p><img src="/posts/cccf62a7/asset/v2-77ed3d65f505555fe291c12322550157_1440w.webp" alt="img"></p>
<p> 至于单点修改，只需要令左右端点相等即可。 </p>
<h2 id="区间查询"><a href="#区间查询" class="headerlink" title="区间查询"></a>区间查询</h2><p>有了区间修改的经验，区间查询的方法完全类似，直接上代码了：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ll query(ll l, ll r, ll p = 1, ll cl = 1, ll cr = n)</span><br><span class="line">&#123;</span><br><span class="line">    if (cl &gt; r || cr &lt; l)</span><br><span class="line">        return 0;</span><br><span class="line">    else if (cl &gt;= l &amp;&amp; cr &lt;= r)</span><br><span class="line">        return tree[p];</span><br><span class="line">    else</span><br><span class="line">    &#123;</span><br><span class="line">        ll mid = (cl + cr) / 2;</span><br><span class="line">        push_down(p, cr - cl + 1);</span><br><span class="line">        return query(l, r, p * 2, cl, mid) + query(l, r, p * 2 + 1, mid + 1, cr); </span><br><span class="line">        // 上一行拆成三行写就和区间修改格式一致了</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p> 一样的递归，一样自顶至底地寻找，一样的合并信息 </p>
<p> 本文只介绍了最基本的线段树用法，其实线段树的题目千奇百怪，有很多技巧。在维护不同的信息时，需要注意是否需要乘区间长度、不同的标记之间是否相互影响等。 </p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>基本算法</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>基本算法</tag>
      </tags>
  </entry>
  <entry>
    <title>23.图最短路</title>
    <url>/posts/83fd62ff/</url>
    <content><![CDATA[<h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><p>所谓最短路径问题是指：如果从图中某一顶点（源点）到达另一顶点（终点）的路径可能不止一条，如何找到一条路径使得沿此路径上各边的权值总和（称为路径长度）达到最小。</p>
<p>下面我们介绍两种比较常用的求最短路径算法：</p>
<h2 id="Dijkstra（迪杰斯特拉）算法"><a href="#Dijkstra（迪杰斯特拉）算法" class="headerlink" title="Dijkstra（迪杰斯特拉）算法"></a>Dijkstra（迪杰斯特拉）算法</h2><p>他的算法思想是按路径长度递增的次序一步一步并入来求取，是贪心算法的一个应用，用来解决单源点到其余顶点的最短路径问题。</p>
<h4 id="算法思想"><a href="#算法思想" class="headerlink" title="算法思想"></a>算法思想</h4><p>首先，我们引入一个辅助向量D，它的每个分量D[i]表示当前找到的从起始节点v到终点节点vi的最短路径的长度。它的初始态为：若从节点v到节点vi有弧，则D[i]为弧上的权值，否则D[i]为∞，显然，长度为**D[j] &#x3D; Min{D[i] | vi ∈V}**的路径就是从v出发最短的一条路径，路径为(v, vi)。<br> 那么，下一条长度次短的最短路径是哪一条呢？假设次短路径的终点是vk，则可想而知，这条路径或者是(v, vk)或者是(v, vj, vk)。它的长度或者是从v到vk的弧上的权值，或者是D[j]和从vj到vk的权值之和。</p>
<p>一般情况下，假设S为已知求得的最短路径的终点集合，则可证明：一下条最短路径（设其终点为x）或者是弧(v, x)或者是中间只经过S中的顶点而最后到达顶点x的路径。这可用反证法来证明，假设此路径上有一个顶点不在S中，则说明存在一条终点不在S中而长度比此路径短的路径。但是这是不可能的。因为，我们是按路径常度的递增次序来产生个最短路径的，故长度比此路径端的所有路径均已产生，他们的终点必定在S集合中，即假设不成立。</p>
<p>因此下一条次短的最短路径的长度是：**D[j] &#x3D; Min{D[i] | vi ∈ V - S}**，其中，D[i]或者是弧(v, vi)的权值，或者是D[k](vk ∈ S)和弧(vk, vi)上权值之和。</p>
<h4 id="算法描述"><a href="#算法描述" class="headerlink" title="算法描述"></a>算法描述</h4><p>假设现要求取如下示例图所示的顶点V0与其余各顶点的最短路径：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/2295192-b54b0c630ff6dada.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/621/format/webp" alt="img"></p>
<p>Dijkstra算法示例图</p>
<p>我们使用Guava的ValueGraph作为该图的数据结构，每个顶点对应一个visited变量来表示节点是在V中还是在S中，初始时S中只有顶点V0。然后从nodes集合中遍历找出从V0出发到各节点路径最短的节点，并将该节点并入S中（即修改该节点的visited属性为true），此时就找到了一个顶点的最短路径。然后，<strong>我们看看新加入的顶点是否可以到达其他顶点，并且看看通过该顶点到达其他点的路径长度是否比从V0直接到达更短,如果是，则修改这些顶点的权值</strong>(即<code>if (D[j] + arcs[j][k] &lt; D[k]) then D[k] = D[j] + arcs[j][k]</code>)。然后又从{V - S}中找最小值，重复上述动作，直到所有顶点都并入S中。</p>
<p>第一步，我们通过<code>ValueGraphBuilder</code>构造图的实例，并输入边集：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">MutableValueGraph&lt;String, Integer&gt; graph = ValueGraphBuilder.directed()</span><br><span class="line">        .nodeOrder(ElementOrder.insertion())</span><br><span class="line">        .expectedNodeCount(<span class="number">10</span>)</span><br><span class="line">        .build();</span><br><span class="line">graph.putEdgeValue(V0, V2, <span class="number">10</span>);</span><br><span class="line">graph.putEdgeValue(V0, V4, <span class="number">30</span>);</span><br><span class="line">graph.putEdgeValue(V0, V5, <span class="number">100</span>);</span><br><span class="line">graph.putEdgeValue(V1, V2, <span class="number">5</span>);</span><br><span class="line">graph.putEdgeValue(V2, V3, <span class="number">50</span>);</span><br><span class="line">graph.putEdgeValue(V3, V5, <span class="number">10</span>);</span><br><span class="line">graph.putEdgeValue(V4, V3, <span class="number">20</span>);</span><br><span class="line">graph.putEdgeValue(V4, V5, <span class="number">60</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> graph;</span><br></pre></td></tr></table></figure>

<p>初始输出结果如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">nodes: [v0, v2, v4, v5, v1, v3], </span><br><span class="line">edges: &#123;&lt;v0 -&gt; v5&gt;=<span class="number">100</span>, &lt;v0 -&gt; v4&gt;=<span class="number">30</span>, &lt;v0 -&gt; v2&gt;=<span class="number">10</span>, </span><br><span class="line">&lt;v2 -&gt; v3&gt;=<span class="number">50</span>, &lt;v4 -&gt; v5&gt;=<span class="number">60</span>, &lt;v4 -&gt; v3&gt;=<span class="number">20</span>, &lt;v1 -&gt; v2&gt;=<span class="number">5</span>, </span><br><span class="line">&lt;v3 -&gt; v5&gt;=<span class="number">10</span>&#125;</span><br></pre></td></tr></table></figure>

<p>为了不破坏<code>graph</code>的状态，我们引入一个临时结构来记录每个节点运算的中间结果：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">NodeExtra</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> String nodeName; <span class="comment">//当前的节点名称</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> distance; <span class="comment">//开始点到当前节点的最短路径</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> visited; <span class="comment">//当前节点是否已经求的最短路径（S集合）</span></span><br><span class="line">    <span class="keyword">public</span> String preNode; <span class="comment">//前一个节点名称</span></span><br><span class="line">    <span class="keyword">public</span> String path; <span class="comment">//路径的所有途径点</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>第二步，我们首先将起始点V0并入集合S中，因为他的最短路径已知为0：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">startNode = V0;</span><br><span class="line"><span class="type">NodeExtra</span> <span class="variable">current</span> <span class="operator">=</span> nodeExtras.get(startNode);</span><br><span class="line">current.distance = <span class="number">0</span>; <span class="comment">//一开始可设置开始节点的最短路径为0</span></span><br><span class="line">current.visited = <span class="literal">true</span>; <span class="comment">//并入S集合</span></span><br><span class="line">current.path = startNode;</span><br><span class="line">current.preNode = startNode;</span><br></pre></td></tr></table></figure>

<p>第三步，在当前状态下找出起始点V0开始到其他节点路径最短的节点：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">NodeExtra</span> <span class="variable">minExtra</span> <span class="operator">=</span> <span class="literal">null</span>; <span class="comment">//路径最短的节点信息</span></span><br><span class="line"><span class="type">int</span> <span class="variable">min</span> <span class="operator">=</span> Integer.MAX_VALUE;</span><br><span class="line"><span class="keyword">for</span> (String notVisitedNode : nodes) &#123;</span><br><span class="line">    <span class="comment">//获取节点的辅助信息</span></span><br><span class="line">    <span class="type">NodeExtra</span> <span class="variable">extra</span> <span class="operator">=</span> nodeExtras.get(notVisitedNode); </span><br><span class="line">    </span><br><span class="line">    <span class="comment">//不在S集合中，且路径较短</span></span><br><span class="line">    <span class="keyword">if</span> (!extra.visited &amp;&amp; extra.distance &lt; min) &#123;</span><br><span class="line">        min = extra.distance;</span><br><span class="line">        minExtra = extra;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>第四步，将最短路径的节点并入集合S中：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (minExtra != <span class="literal">null</span>) &#123; <span class="comment">//找到了路径最短的节点</span></span><br><span class="line">    minExtra.visited = <span class="literal">true</span>; <span class="comment">//并入集合S中</span></span><br><span class="line">    <span class="comment">//更新其中转节点路径</span></span><br><span class="line">    minExtra.path = nodeExtras.get(minExtra.preNode).path + <span class="string">&quot; -&gt; &quot;</span> + minExtra.nodeName; </span><br><span class="line">    current = minExtra; <span class="comment">//标识当前并入的最短路径节点</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>第五步，更新与其相关节点的最短路径中间结果：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 并入新查找到的节点后，更新与其相关节点的最短路径中间结果</span></span><br><span class="line"><span class="comment"> * if (D[j] + arcs[j][k] &lt; D[k]) D[k] = D[j] + arcs[j][k]</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="comment">//只需循环当前节点的后继列表即可(优化)</span></span><br><span class="line">Set&lt;String&gt; successors = graph.successors(current.nodeName); </span><br><span class="line"><span class="keyword">for</span> (String notVisitedNode : successors) &#123;</span><br><span class="line">    <span class="type">NodeExtra</span> <span class="variable">extra</span> <span class="operator">=</span> nodeExtras.get(notVisitedNode);</span><br><span class="line">    <span class="keyword">if</span> (!extra.visited) &#123;</span><br><span class="line">        <span class="keyword">final</span> <span class="type">int</span> <span class="variable">value</span> <span class="operator">=</span> current.distance </span><br><span class="line">            + graph.edgeValueOrDefault(current.nodeName,</span><br><span class="line">                notVisitedNode, <span class="number">0</span>); <span class="comment">//D[j] + arcs[j][k]</span></span><br><span class="line">        <span class="keyword">if</span> (value &lt; extra.distance) &#123; <span class="comment">//D[j] + arcs[j][k] &lt; D[k]</span></span><br><span class="line">            extra.distance = value;</span><br><span class="line">            extra.preNode = current.nodeName;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>第六步，输出起始节点V0到每个节点的最短路径以及路径的途径点信息</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Set&lt;String&gt; keys = nodeExtras.keySet();</span><br><span class="line"><span class="keyword">for</span> (String node : keys) &#123;</span><br><span class="line">    <span class="type">NodeExtra</span> <span class="variable">extra</span> <span class="operator">=</span> nodeExtras.get(node);</span><br><span class="line">    <span class="keyword">if</span> (extra.distance &lt; Integer.MAX_VALUE) &#123;</span><br><span class="line">        Log.i(TAG, startNode + <span class="string">&quot; -&gt; &quot;</span> + node + <span class="string">&quot;: min: &quot;</span> + extra.distance</span><br><span class="line">                + <span class="string">&quot;, path: &quot;</span> + extra.path); <span class="comment">//path在运算过程中更新</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>实例图的输出结果为：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">v0 -&gt; v0: min: <span class="number">0</span>, path: v0</span><br><span class="line">v0 -&gt; v2: min: <span class="number">10</span>, path: v0 -&gt; v2</span><br><span class="line">v0 -&gt; v3: min: <span class="number">50</span>, path: v0 -&gt; v4 -&gt; v3</span><br><span class="line">v0 -&gt; v4: min: <span class="number">30</span>, path: v0 -&gt; v4</span><br><span class="line">v0 -&gt; v5: min: <span class="number">60</span>, path: v0 -&gt; v4 -&gt; v3 -&gt; v5</span><br></pre></td></tr></table></figure>

<p>具体Dijkstra算法的示例demo实现，请参考：<a href="https://github.com/Jarrywell/GH-Demo/blob/master/app/src/main/java/com/android/test/demo/graph/Dijkstra.java">https://github.com/Jarrywell/GH-Demo/blob/master/app/src/main/java/com/android/test/demo/graph/Dijkstra.java</a></p>
<h2 id="Floyd（弗洛伊德）算法"><a href="#Floyd（弗洛伊德）算法" class="headerlink" title="Floyd（弗洛伊德）算法"></a>Floyd（弗洛伊德）算法</h2><p>Floyd算法是一个经典的<strong>动态规划</strong>算法。是解决<strong>任意两点间的最短路径</strong>(称为多源最短路径问题)的一种算法，可以正确处理有向图或负权的最短路径问题。（动态规划算法是通过拆分问题规模，并定义问题状态与状态的关系，使得问题能够以递推（分治）的方式去解决，最终合并各个拆分的小问题的解为整个问题的解。）</p>
<h4 id="算法思想-1"><a href="#算法思想-1" class="headerlink" title="算法思想"></a>算法思想</h4><p>从任意节点i到任意节点j的最短路径不外乎2种可能：<strong>1)直接从节点i到节点j，2)从节点i经过若干个节点k到节点j</strong>。所以，我们假设arcs(i,j)为节点i到节点j的最短路径的距离，对于每一个节点k，我们检查arcs(i,k) + arcs(k,j) &lt; arcs(i,j)是否成立，如果成立，证明从节点i到节点k再到节点j的路径比节点i直接到节点j的路径短，我们便设置arcs(i,j) &#x3D; arcs(i,k) + arcs(k,j)，这样一来，当我们遍历完所有节点k，arcs(i,j)中记录的便是节点i到节点j的最短路径的距离。（由于动态规划算法在执行过程中，需要保存大量的临时状态（即小问题的解），因此它天生适用于用矩阵来作为其数据结构，因此在本算法中，我们将不使用Guava-Graph结构，而采用邻接矩阵来作为本例的数据结构）</p>
<h4 id="算法分析及描述"><a href="#算法分析及描述" class="headerlink" title="算法分析及描述"></a>算法分析及描述</h4><p>假设现要求取如下示例图所示任意两点之间的最短路径：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/2295192-c10b4a16958cd4e4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/479/format/webp" alt="img"></p>
<p>最短路径示例图</p>
<p>我们以一个4x4的邻接矩阵（二维数组arcs[ ][ ]）作为图的数据结构。比如1号节点到2号节点的路径的权值为2，则arcs[1][2] &#x3D; 2，2号节点无法直接到达4号节点，则arcs[2][4] &#x3D; ∞(Integer.MAX_VALUE)，则可构造如下矩阵：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/2295192-c1d3d0588d4f05fe.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/290/format/webp" alt="img"></p>
<p>有向图的初始邻接矩阵</p>
<p>根据以往的经验，如果要让任意两个顶点（假设从顶点a到顶点b）之间的距离变得更短，唯一的选择就是引入第三个顶点（顶点k），并通过顶点k中转（a -&gt; k -&gt;b）才可能缩短顶点a到顶点b之间的距离。于是，现在的问题便分解为：求取某一个点k，使得经过中转节点k后，使得两点之间的距离可能变短，且还可能需要中转两个或者多个节点才能使两点之间的距离变短。比如图中的4号节点到3号节点（4 -&gt; 3）的距离原本是12（arcs[4][3] &#x3D; 12），如果在只通过1号节点时中转时（4 -&gt; 1 -&gt;3），距离将缩短为11（arcs[4][1] + arcs[1][3] &#x3D; 5 + 6 &#x3D; 11）。其实1号节点到3号节点也可以通过2号节点中转，使得1号到3号节点的路程缩短为5（arcs[1][2] + arcs[2][3] &#x3D; 2 + 3 &#x3D; 5），所以如果同时经过1号和2号两个节点中转的话，从4号节点到3号节点的距离会进一步缩短为10。于是，延伸到一般问题：<br> 1、当不经过任意第三节点时，其最短路径为初始路径，即上图中的邻接矩阵所示。<br> 2、当只允许经过1号节点时，求两点之间的最短路径该如何求呢？<strong>只需判断arcs[i][1]+arcs[1][j]是否比arcs[i][j]要小即可。</strong>arcs[i][j]表示的是从i号顶点到j号顶点之间的距离，arcs[i][1] + arcs[1][j]表示的是从i号顶点先到1号顶点，再从1号顶点到j号顶点的路程之和。循环遍历一遍二维数组，便可以获取在仅仅经过1号节点时的最短距离，实现如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">1</span>; i &lt;= vexCount; i++) &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">j</span> <span class="operator">=</span> <span class="number">1</span>; j &lt; vexCount; j++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (arcs[i][<span class="number">1</span>] + arcs[<span class="number">1</span>][j] &lt; arcs[i][j]) &#123;</span><br><span class="line">            arcs[i][j] = arcs[i][<span class="number">1</span>] + arcs[<span class="number">1</span>][j]; </span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>由于上述代码更新了两点之间经过1号节点的最短距离arcs[i][j]，因此，数组中每两个节点之间对应距离都是最短的。由于此时arcs[i][j]的结果已经保存了中转1号节点的最短路径，此时如果继续并入2号节点为中转节点，则是任意两个节点都经过中转节点1号节点和2号节点的最短路径，因为运算完中转1号节点时，arcs[i][j]的结果已经更新为中转1号节点的最短路径了。更一般的，继续并入下一个中转节点一直到vexCount个时，arcs[i][j]的结果保存的就是整个图中两点之间的最短路径了。这就是Floyd算法的描述，变成代码就是下面几行行：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="type">int</span> <span class="variable">k</span> <span class="operator">=</span> <span class="number">1</span>; k &lt;= vexCount; k++) &#123; <span class="comment">//并入中转节点1,2,...vexCount</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">1</span>; i &lt;= vexCount; i++) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">j</span> <span class="operator">=</span> <span class="number">1</span>; j &lt; vexCount; j++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (arcs[i][k] + arcs[k][j] &lt; arcs[i][j]) &#123;</span><br><span class="line">                arcs[i][j] = arcs[i][k] + arcs[k][j];</span><br><span class="line">                path[i][j] = path[i][k]; <span class="comment">//这里保存当前是中转的是哪个节点的信息</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure>

<p>对应到示例图的中间运算结果如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">print array step of <span class="number">1</span>: <span class="comment">//并入1号节点的结果</span></span><br><span class="line">    <span class="number">0</span>     <span class="number">2</span>     <span class="number">6</span>     <span class="number">4</span> </span><br><span class="line">    ∞     <span class="number">0</span>     <span class="number">3</span>     ∞ </span><br><span class="line">    <span class="number">7</span>     <span class="number">9</span>     <span class="number">0</span>     <span class="number">1</span> </span><br><span class="line">    <span class="number">5</span>     <span class="number">7</span>    <span class="number">11</span>     <span class="number">0</span> </span><br><span class="line"></span><br><span class="line">print array step of <span class="number">2</span>: <span class="comment">//并入2号节点的结果</span></span><br><span class="line">    <span class="number">0</span>     <span class="number">2</span>     <span class="number">5</span>     <span class="number">4</span> </span><br><span class="line">    ∞     <span class="number">0</span>     <span class="number">3</span>     ∞ </span><br><span class="line">    <span class="number">7</span>     <span class="number">9</span>     <span class="number">0</span>     <span class="number">1</span> </span><br><span class="line">    <span class="number">5</span>     <span class="number">7</span>    <span class="number">10</span>     <span class="number">0</span> </span><br><span class="line"></span><br><span class="line">print array step of <span class="number">3</span>: <span class="comment">//并入3号节点的结果</span></span><br><span class="line">    <span class="number">0</span>     <span class="number">2</span>     <span class="number">5</span>     <span class="number">4</span> </span><br><span class="line">   <span class="number">10</span>     <span class="number">0</span>     <span class="number">3</span>     <span class="number">4</span> </span><br><span class="line">    <span class="number">7</span>     <span class="number">9</span>     <span class="number">0</span>     <span class="number">1</span> </span><br><span class="line">    <span class="number">5</span>     <span class="number">7</span>    <span class="number">10</span>     <span class="number">0</span> </span><br><span class="line"></span><br><span class="line">print array step of <span class="number">4</span>: <span class="comment">//并入4号节点（图最终两两节点之间的最短路径值）</span></span><br><span class="line">    <span class="number">0</span>     <span class="number">2</span>     <span class="number">5</span>     <span class="number">4</span> </span><br><span class="line">    <span class="number">9</span>     <span class="number">0</span>     <span class="number">3</span>     <span class="number">4</span> </span><br><span class="line">    <span class="number">6</span>     <span class="number">8</span>     <span class="number">0</span>     <span class="number">1</span> </span><br><span class="line">    <span class="number">5</span>     <span class="number">7</span>    <span class="number">10</span>     <span class="number">0</span> </span><br></pre></td></tr></table></figure>

<p>虽然此时已求得了节点的最短路径，但结果却不能明显的表达最终最短路径是中转了哪些节点，因此这里对应到动态规划算法中的强项——算法过程中可以完全记录所有的中间结果。我们再定义一个二位数组path[][]，其大小规模对应arcs[][]，初始结果path[i][j] &#x3D; j，表示节点i到节点j最后的中转节点是j。在运算中是在判断arcs[i][k]+arcs[k][j]比arcs[i][j]要小时，我们进一步更新为：path[i][j] &#x3D; path[i][k]，即当前最短路径的最后中转节点是path[i][k]对应的节点（如果只允许中专一个节点时即为k，但中转多个节点时，需要对应上一步的中转节点，因此这里要指明是path[i][k]而不是k）。<br> 于是我们通过向前递推path[][]数组，直到path[i][j]是目标节点。则可输出其中转节点，输出函数实现如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">printPath</span><span class="params">(<span class="type">int</span> arcs[][], <span class="type">int</span> path[][], <span class="type">int</span> vexCount)</span> &#123;</span><br><span class="line">    <span class="type">int</span> temp;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">1</span>; i &lt;= vexCount; i++) &#123;</span><br><span class="line">        <span class="type">StringBuilder</span> <span class="variable">builder</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StringBuilder</span>();</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">j</span> <span class="operator">=</span> <span class="number">1</span>; j &lt;= vexCount; j++) &#123; <span class="comment">//遍历打印任意亮点的路径</span></span><br><span class="line">            builder.append(i).append(<span class="string">&quot;-&gt;&quot;</span>).append(j)</span><br><span class="line">                .append(<span class="string">&quot;, weight: &quot;</span>). append(arcs[i][j])</span><br><span class="line">                    .append(<span class="string">&quot;:&quot;</span>).append(i);</span><br><span class="line">            temp = path[i][j];</span><br><span class="line">            <span class="keyword">while</span>(temp != j) &#123;</span><br><span class="line">                builder.append(<span class="string">&quot;-&gt;&quot;</span>).append(temp);</span><br><span class="line">                temp = path[temp][j];</span><br><span class="line">            &#125;</span><br><span class="line">            builder.append(<span class="string">&quot;-&gt;&quot;</span>).append(j).append(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        Log.i(TAG, builder.toString());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>对应示例图的最短路径的中转节点结果输出如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="number">1</span>-&gt;<span class="number">1</span>, weight: <span class="number">0</span>, path: <span class="number">1</span>-&gt;<span class="number">1</span></span><br><span class="line"><span class="number">1</span>-&gt;<span class="number">2</span>, weight: <span class="number">2</span>, path: <span class="number">1</span>-&gt;<span class="number">2</span></span><br><span class="line"><span class="number">1</span>-&gt;<span class="number">3</span>, weight: <span class="number">5</span>, path: <span class="number">1</span>-&gt;<span class="number">2</span>-&gt;<span class="number">3</span></span><br><span class="line"><span class="number">1</span>-&gt;<span class="number">4</span>, weight: <span class="number">4</span>, path: <span class="number">1</span>-&gt;<span class="number">4</span></span><br><span class="line"><span class="number">2</span>-&gt;<span class="number">1</span>, weight: <span class="number">9</span>, path: <span class="number">2</span>-&gt;<span class="number">3</span>-&gt;<span class="number">4</span>-&gt;<span class="number">1</span></span><br><span class="line"><span class="number">2</span>-&gt;<span class="number">2</span>, weight: <span class="number">0</span>, path: <span class="number">2</span>-&gt;<span class="number">2</span></span><br><span class="line"><span class="number">2</span>-&gt;<span class="number">3</span>, weight: <span class="number">3</span>, path: <span class="number">2</span>-&gt;<span class="number">3</span></span><br><span class="line"><span class="number">2</span>-&gt;<span class="number">4</span>, weight: <span class="number">4</span>, path: <span class="number">2</span>-&gt;<span class="number">3</span>-&gt;<span class="number">4</span></span><br><span class="line"><span class="number">3</span>-&gt;<span class="number">1</span>, weight: <span class="number">6</span>, path: <span class="number">3</span>-&gt;<span class="number">4</span>-&gt;<span class="number">1</span></span><br><span class="line"><span class="number">3</span>-&gt;<span class="number">2</span>, weight: <span class="number">8</span>, path: <span class="number">3</span>-&gt;<span class="number">4</span>-&gt;<span class="number">1</span>-&gt;<span class="number">2</span></span><br><span class="line"><span class="number">3</span>-&gt;<span class="number">3</span>, weight: <span class="number">0</span>, path: <span class="number">3</span>-&gt;<span class="number">3</span></span><br><span class="line"><span class="number">3</span>-&gt;<span class="number">4</span>, weight: <span class="number">1</span>, path: <span class="number">3</span>-&gt;<span class="number">4</span></span><br><span class="line"><span class="number">4</span>-&gt;<span class="number">1</span>, weight: <span class="number">5</span>, path: <span class="number">4</span>-&gt;<span class="number">1</span></span><br><span class="line"><span class="number">4</span>-&gt;<span class="number">2</span>, weight: <span class="number">7</span>, path: <span class="number">4</span>-&gt;<span class="number">1</span>-&gt;<span class="number">2</span></span><br><span class="line"><span class="number">4</span>-&gt;<span class="number">3</span>, weight: <span class="number">10</span>, path: <span class="number">4</span>-&gt;<span class="number">1</span>-&gt;<span class="number">2</span>-&gt;<span class="number">3</span></span><br><span class="line"><span class="number">4</span>-&gt;<span class="number">4</span>, weight: <span class="number">0</span>, path: <span class="number">4</span>-&gt;<span class="number">4</span></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>基本算法</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>基本算法</tag>
      </tags>
  </entry>
  <entry>
    <title>25.树的直径与最近公共祖先</title>
    <url>/posts/e783a848/</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>基本算法</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>基本算法</tag>
      </tags>
  </entry>
  <entry>
    <title>24.最小生成树</title>
    <url>/posts/21751e2c/</url>
    <content><![CDATA[<p>一、Kruskal算法<br>每次选择权值最小的边，若该边两点没有加入集合，就将他加入。<br>起初每个点的都是一个独立的集合，把边权从小到达排序，按照边权枚举边，用并查集判断两个是否在同一个集合，如果在一个集合就跳过当前边，反之就联通这两个集合。</p>
<p>O(mlogm)</p>
<p>二、Prim算法<br>每次选择当前点所连的边的最小值，然后把它连起来<br>有些类似Dijkstra<br>堆优化的算法时间复杂度为O(nlogn)</p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>基本算法</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>基本算法</tag>
      </tags>
  </entry>
  <entry>
    <title>26.Tarjan算法与无向图连通性</title>
    <url>/posts/53efa0e3/</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>基本算法</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>基本算法</tag>
      </tags>
  </entry>
  <entry>
    <title>28.网络流初步</title>
    <url>/posts/c24dd9c7/</url>
    <content><![CDATA[<p><a href="https://fanfansann.blog.csdn.net/article/details/105603064">https://fanfansann.blog.csdn.net/article/details/105603064</a></p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>基本算法</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>基本算法</tag>
      </tags>
  </entry>
  <entry>
    <title>27.二分图的匹配</title>
    <url>/posts/502f2b7b/</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>基本算法</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>基本算法</tag>
      </tags>
  </entry>
  <entry>
    <title>3.前缀和与差分</title>
    <url>/posts/f80c08cd/</url>
    <content><![CDATA[<h2 id="前缀和与差分"><a href="#前缀和与差分" class="headerlink" title="前缀和与差分"></a>前缀和与差分</h2><h2 id="前缀和"><a href="#前缀和" class="headerlink" title="前缀和"></a>前缀和</h2><p>给定一个序列，定义pre[i] &#x3D; pre[i-1] +a[i]</p>
<p>可求区间[l,r]的和：pre[r] - pre[l-1]</p>
<p>可求区间的[l,r]的异或和: pre[r]^pre[l-1]</p>
<h2 id="二维前缀和"><a href="#二维前缀和" class="headerlink" title="二维前缀和"></a>二维前缀和</h2><p>根据容器原理推导得到：</p>
<p>定义：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pre[i][j] = pre[i-1][j]+pre[i][j-1]=pre[i-1][j-1]+a[i][j],pre[i][j]表示的是（i，j)右下角的一个子矩形</span><br></pre></td></tr></table></figure>

<h3 id=""><a href="#" class="headerlink" title=""></a></h3>]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>基本算法</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>基本算法</tag>
      </tags>
  </entry>
  <entry>
    <title>5.倍增</title>
    <url>/posts/fb7ee697/</url>
    <content><![CDATA[<h2 id="倍增"><a href="#倍增" class="headerlink" title="倍增"></a>倍增</h2><p>倍增, 从字面的上意思看就是成倍的增长 ,这是指我们在进行递推时,如果状态空间很大,通常的线性递推无法满足时间和空间复杂度的要求 ,那么我们就可以通过成倍的增长,只递推状态空间中在 2 的整数次幂位置上的值作为代表 。当需要其他位置上的值时,我们只需要通过” 任意整数可以表示成若干个2的次幂项的和 “ 这一性质(13&#x3D;2^3^+2^2^+2^0^), 使用之前求出的代表值拼成所需的值。 </p>
<h2 id="ST算法"><a href="#ST算法" class="headerlink" title="ST算法"></a>ST算法</h2><p> <strong>ST表</strong>（Sparse Table，<strong>稀疏表</strong>）是一种简单的数据结构，主要用来解决<strong>RMQ</strong>（Range Maximum&#x2F;Minimum Query，<strong>区间最大&#x2F;最小值查询</strong>）问题。它主要应用<strong>倍增</strong>的思想，可以实现 O(nlog⁡n) 预处理、 O(1) 查询。 </p>
<p><img src="/posts/fb7ee697/asset/1688108641061.png" alt="1688108641061"></p>
<p> 为了减少时间复杂度，可以用<strong>动态规划</strong>的方法进行<strong>预处理</strong>： </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">int f[MAXN][21]; // 第二维的大小根据数据范围决定，不小于log(MAXN)</span><br><span class="line">for (int i = 1; i &lt;= n; ++i)</span><br><span class="line">    f[i][0] = read(); // 读入数据</span><br><span class="line">for (int i = 1; i &lt;= 20; ++i)</span><br><span class="line">    for (int j = 1; j + (1 &lt;&lt; i) - 1 &lt;= n; ++j)</span><br><span class="line">        f[j][i] = max(f[j][i - 1], f[j + (1 &lt;&lt; (i - 1))][i - 1]);</span><br></pre></td></tr></table></figure>

<p> <img src="/posts/fb7ee697/asset/v2-22d8a24faea894fb8ddceae627093bbf_1440w.webp" alt="img"> </p>
<h2 id="求LCA最近公共祖先"><a href="#求LCA最近公共祖先" class="headerlink" title="求LCA最近公共祖先"></a>求LCA最近公共祖先</h2><blockquote>
<p> LCA（Least Common Ancestors），即最近公共祖先，是指在有根树中，找出某两个结点u和v最近的公共祖先。 </p>
</blockquote>
<p>先dfs预处理好深度，把父节点和 2^i^级的祖先存到数组里，init一个lg数组优化，然后开始从大到小利用倍增往上爬，爬到父节点的子节点，输出父节点。</p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>基本算法</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>基本算法</tag>
      </tags>
  </entry>
  <entry>
    <title>4.二分和三分</title>
    <url>/posts/3309261e/</url>
    <content><![CDATA[<h2 id="二分"><a href="#二分" class="headerlink" title="二分"></a>二分</h2><p> 二分是一个非常常见但是想要精通却很有讲究的一个垃圾 算法，二分的基础用法是在<strong>单调</strong>序列或<strong>单调</strong>函数中进行查找（二分查找），因此当问题的答案具有单调性，就可以通过二分把求解答案的问题转换成二分查找答案并判定答案的正确性（二分答案）。我们还可以用三分法去求解单峰函数的极值。 </p>
<p> 相信基础的二分大家都会，但是写出来二分不代表能A，因为二分的细节尤其重要，对于整数域上的二分，要注意终止边界和左右区间的取舍时的开闭情况，避免溜掉答案或造成死循环。对于实数域上的二分，要注意精度的问题。 </p>
<h3 id="整数域上的二分"><a href="#整数域上的二分" class="headerlink" title="整数域上的二分"></a>整数域上的二分</h3><blockquote>
<p>本文中的二分保证最终答案处于闭区间[l,r]以内，并以l&#x3D;r作为循环的结束条件</p>
</blockquote>
<p>在单调递增序列a中查找&gt;&#x3D;x的数中最小的一个(即x或x的后继)</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">int mid=l;</span><br><span class="line">while(l&lt;r)&#123;</span><br><span class="line">   mid = (l+r)/2;</span><br><span class="line">   if(a[mid]&gt;=x)&#123;</span><br><span class="line">    r = mid;</span><br><span class="line">   &#125;else&#123;</span><br><span class="line">   	l = mid+1;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p> 在单调递增序列a中查找&lt;&#x3D;x的数中最大的一个（即x或x的前驱） </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">while (l &lt; r) &#123;</span><br><span class="line">	int mid = (l + r + 1) / 2;</span><br><span class="line">	if (a[mid] &lt;= x) l = mid; </span><br><span class="line">	else r = mid - 1;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p> 二分的流程： </p>
<p>分析问题，确定左右半段哪一个是可行区间，以及mid 归属哪一半段</p>
<p>根据分析结果，选择<code>r=mid,l=mid+1,mid=(l+r)&gt;&gt;1</code>和<code>l=mid,r=dmi-1,mid=(l+r+1)&gt;&gt;1</code></p>
<p>二分终止条件是<code>l==r</code>，该值就是答案所在的位置。</p>
<h3 id="在实数域上的二分"><a href="#在实数域上的二分" class="headerlink" title="在实数域上的二分"></a>在实数域上的二分</h3><p> 实数域二分，<strong>设置eps法</strong> </p>
<p>一般eps &#x3D; 10^-(k+2)^ (k是需要保留的位数)</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">while(1+eps&lt;r)&#123;</span><br><span class="line">   double mid = (1+r)/2;</span><br><span class="line">   if(calc(mid))&#123;</span><br><span class="line">       r = mid;</span><br><span class="line">   &#125; else&#123;</span><br><span class="line">       l = mid;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p> 实数域二分，<strong>规定循环次数法</strong> </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">for (int i = 0; i &lt; 100; i++) &#123;</span><br><span class="line">	if(calc(mid))&#123;</span><br><span class="line">       r = mid;</span><br><span class="line">   &#125; else&#123;</span><br><span class="line">       l = mid;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="三分"><a href="#三分" class="headerlink" title="三分"></a>三分</h2><h3 id="三分求单峰函数极值"><a href="#三分求单峰函数极值" class="headerlink" title="三分求单峰函数极值"></a>三分求单峰函数极值</h3><p> 有一类函数称为单峰函数，它们拥有唯一的极大值点，在极大值点左侧严格单调上升，在极大值点右侧严格单调下降；或者拥有唯一的极小值点，在极小值点左侧严格单调下降，在极小值点右侧严格单调上升。 </p>
<p> 为了避免混淆，我们称后一种函数为单谷函数，对于单峰或单谷函数，可以用三分求其极值。 </p>
<p>单峰函数f(),函数定义域[l,r] 上取两个点lmid和rmid, l&lt;lmid&lt;rmid&lt;r,把函数分为三段：</p>
<p>如果f(lmid)&lt;f(rmid)则lmid和rmid要么同处于极大值点左侧，要么分别处于极大值点两侧，无论哪种情况，都可以确定极大值点在lmid右侧,可令l&#x3D;lmid.</p>
<p>如果f(lmid)&gt;f(rmid)则lmid和rmid要么同处于极大值点右侧，要么分别处于极大值点两侧，无论哪种情况，都可以确定极大值点在rmid左侧,可令r&#x3D;rmid.</p>
<p>如果f(lmid) &#x3D; f(rmid),对于严格单调的函数，此时取 l &#x3D; lmid 或者 r &#x3D; rmid 均可，对于非严格单调的函数，此时三分法不再使用。</p>
<h2 id="二分答案转化为判定"><a href="#二分答案转化为判定" class="headerlink" title="二分答案转化为判定"></a>二分答案转化为判定</h2><p>一个宏观的最优化问题也可以抽象为函数，其定义域是该问题下的可行方案，对这些可行方案进行评估得到的数值构成函数的值域，最优解就是评估最优方案（不妨设评估越高越优）。假设最优评分是S，显然对于所有&gt; S &gt;S&gt;S的值，都不存在一个合法的方案达到此评分，否则就与S的最优性矛盾，而对于所有的&lt; S &lt;S&lt;S，一定存在一个合法方案达到或超过此评分。这样的问题的值域就具有一种特殊的单调性，在S的一侧合法，另一侧不合法，就像一个在( − ∞ , S ] (-\infty, S](−∞,S]上为1，在( S , ∞ ) (S, \infty)(S,∞)上值为0的分段函数，可以通过二分找到这个分界点S。</p>
<p>借助二分，我们把求解最优解问题，转化为给定一个值m i d midmid，判断是否存在一个可行方案评分达到mid的问题。</p>
<blockquote>
<p><strong>N本书排成一行，已知第i本的厚度是Ai。把它们分成连续的M组，使T最小化。T表示厚度之和最大的一组的厚度。</strong></p>
</blockquote>
<p><strong>分析：</strong></p>
<p><strong>定义域：把书划分成M组的方案</strong></p>
<p><strong>值域（评分标准）：厚度之和最大的一组的厚度</strong></p>
<p><strong>假设最终答案为S ：每组&lt;S，分不完，不存在可行的分书方案；每组&gt;S，一定存在一种分书方案使组数不超过M。</strong></p>
<p><strong>分界点：分书可行性。</strong></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> n,m;</span><br><span class="line"><span class="type">int</span> a[<span class="number">50</span>];</span><br><span class="line"></span><br><span class="line"><span class="comment">//把n本书分m组，每组厚度之和&lt;=size，是否可行</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">valid</span><span class="params">(<span class="type">int</span> size)</span></span>&#123;</span><br><span class="line">  <span class="type">int</span> group=<span class="number">1</span>,rest = size;</span><br><span class="line">  <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=n;i++)&#123;</span><br><span class="line">    <span class="keyword">if</span>(rest&gt;=a[i]) rest-=a[i];</span><br><span class="line">    <span class="keyword">else</span> &#123;group++,rest = size-a[i];&#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> group&lt;=m;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//判定每组厚度之和不超过二分的值时，是否可行</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">  cin&gt;&gt;n&gt;&gt;m;</span><br><span class="line">  </span><br><span class="line">  <span class="type">int</span> r=<span class="number">0</span>;  </span><br><span class="line">  <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;n;i++)&#123;</span><br><span class="line">    cin&gt;&gt;a[i];</span><br><span class="line">    r+=a[i];</span><br><span class="line">  &#125;</span><br><span class="line">	<span class="type">int</span> l=<span class="number">0</span>; <span class="comment">//区间0-sum_of_ai</span></span><br><span class="line">  <span class="keyword">while</span>(l&lt;r)&#123;</span><br><span class="line">    <span class="type">int</span> mid = (l+r)/<span class="number">2</span>;</span><br><span class="line">    <span class="keyword">if</span>(<span class="built_in">valid</span>(mid)) r = mid; <span class="keyword">else</span> l = mid +<span class="number">1</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  cout&lt;&lt;l&lt;&lt;endl;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>基本算法</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>基本算法</tag>
      </tags>
  </entry>
  <entry>
    <title>6.贪心算法</title>
    <url>/posts/142cc63d/</url>
    <content><![CDATA[<h2 id="贪心"><a href="#贪心" class="headerlink" title="贪心"></a>贪心</h2><p> 贪心是一种在每一次决策时都采用当前意义下最优策略的算法，因此，使用<a href="https://so.csdn.net/so/search?q=%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95&spm=1001.2101.3001.7020">贪心算法</a>要求问题的整体最优性可以由局部最优性导出。 </p>
<p>贪心算法的正确性需要证明，常见的证明手段有：</p>
<ul>
<li>微扰（邻项交换） 证明在任意局面下，任何对局部最优策略的微小改变都会造成整体结果变差，经常用于以排序为贪心策略的证明。</li>
<li>范围缩放 证明任何对局部最优策略作用范围的扩展都不会造成整体结果变差。</li>
<li>决策包容性<br>证明在任意局面下，做出局部最优策略以后，在问题状态空间中的可达到集合包含了做出其他任何决策之后的可到达集合。换言之，这个局部最优解提供的可能性包含其他所有策略提供的可能性。</li>
<li>反证法</li>
<li>数学归纳法</li>
</ul>
]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>基本算法</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>基本算法</tag>
      </tags>
  </entry>
  <entry>
    <title>8.队列</title>
    <url>/posts/ab8e04e6/</url>
    <content><![CDATA[<h2 id="队列"><a href="#队列" class="headerlink" title="队列"></a>队列</h2><p> 队列是一种“<strong>先入先出</strong>”的线性数据结构。可用一个数组和两个变量优化为循环队列或者STL实现。比如循环队列queue，双端队列deque，优先队列（二叉堆）priority_queue。 </p>
<h3 id="团体队列"><a href="#团体队列" class="headerlink" title="团体队列"></a>团体队列<img src="/posts/ab8e04e6/asset/20200503162453758.png" alt="在这里插入图片描述"></h3><p> 简单的队列套队列问题。题意其实很简单，就是开n+1个队列，一个队列存当前队伍中有几组，剩下n个队列，存的是自己组的人。每次入队的时候都是找自己的组员进队，并且会插队，所以出队的时候是当前组的组员全部出队以后，这个组没了，出下一组的人。 </p>
<h3 id="模拟优先队列"><a href="#模拟优先队列" class="headerlink" title="模拟优先队列"></a>模拟优先队列</h3><p> <img src="/posts/ab8e04e6/asset/20200504115916991.png" alt="在这里插入图片描述"> </p>
<p>我们可以想一下，对于每一秒除了被切的哪一个所有的蚯蚓都增长q米，我们来维护3个队列，队列1表示最开始的蚯蚓，队列2表示每一次被切的蚯蚓被分开的较长的那一部分，队列3表示每一次被切的蚯蚓被分开的较短的那一部分。<br>我们先把原序列排序，因为不管怎么切，先被切的蚯蚓分成的两部分一定比后切的蚯蚓分成的两部分大(较大的部分和较大的部分比较，较小的部分和较小的部分比较)，所以我们可以省去每一秒增加每只蚯蚓的长度这个操作，转换成在查询砍那只蚯蚓时，把增加的长度算到蚯蚓的总长度上。<br>寻找每次砍哪一只蚯蚓就是在队列1、队列2、队列3的队头找一个算上增加的长度最大的蚯蚓，之后把他出队，切开的两部分分别进入队2、队3。</p>
<p> 对于增量的计算我们可以按照蚯蚓在队列中的标号，因为队列1中的蚯蚓直到被切是一直处于一种增长状态，所以直接加上<code>(当前时间-1) * q</code> 就可以了，而对于队列2和队列3的蚯蚓，他的增长是从被切掉那一刻的下一秒开始的，所以他的增长量则是<code>(当前时间-1-被切割的时间)*q</code>。 </p>
<h2 id="单调队列与单调栈"><a href="#单调队列与单调栈" class="headerlink" title="单调队列与单调栈"></a>单调队列与单调栈</h2><p>单调栈和单调队列与普通的栈，队列不同点就是要维护他们元素的单调性（单增或单减），来实现相应的效果。要注意的是单调栈和单调队列即可以用数组模拟，也可以直接使用STL（更方便易于理解），但是如果用STL的话，单调栈&#x2F;队列要在开始放入元素之前设置边界，单调递增就在边界（栈顶&#x2F;队首）赋值为负值（&lt;&#x3D;0），单调递减就在边界赋值为INF(极大值)。因为如果栈&#x2F;队列内无元素，那么s.top()是不合法的，这样就无法继续进行插入和删除操作来维护单调性。</p>
<p> <strong>如何维护单调：</strong><br>每输入一个新元素就比较它是否符合单调要求，符合就push进去，不符合就把它前面的pop掉。 </p>
<p> <strong>单调队列：</strong><br>例如滑动窗口的要求要最多存几个元素，所以一旦越界就pop，一旦不单调就pop；<br>单调队列里新人是一定要进来的，老人可能都比新人弱而被全员踢出，但是踢干净以后立刻新人就push_back进来了，所以不会为空 </p>
<p>###单调栈题</p>
<p><img src="/posts/ab8e04e6/asset/20200504104227398.png" alt="在这里插入图片描述"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include&lt;bits/stdc++.h&gt;</span><br><span class="line">using namespace std;</span><br><span class="line">int n,temp,a,b,cnt;</span><br><span class="line">stack&lt;int&gt;s;</span><br><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">    cin&gt;&gt;n;</span><br><span class="line">    s.push(-1);//设边界</span><br><span class="line">    cin&gt;&gt;a&gt;&gt;b;//本题中宽度没用</span><br><span class="line">    s.push(b);</span><br><span class="line">    for(int i=2;i&lt;=n;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        cin&gt;&gt;a&gt;&gt;b;</span><br><span class="line">        while(s.top()&gt;=b)//一旦单调（递增）被破坏就把大与新人的都pop掉</span><br><span class="line">        &#123;</span><br><span class="line">            temp=s.top();</span><br><span class="line">            if(temp==b)cnt++;//若有相同的则可以省一张海报</span><br><span class="line">            s.pop();</span><br><span class="line">        &#125;</span><br><span class="line">        s.push(b);</span><br><span class="line">    &#125;</span><br><span class="line">    cout&lt;&lt;n-cnt&lt;&lt;endl;//输出共需多少张海报即可</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="单调队列题"><a href="#单调队列题" class="headerlink" title="单调队列题"></a>单调队列题</h3><p> <strong>题目描述</strong><br>一个含有n项的数列(n&lt;&#x3D;2000000)，求出每一项前的m个数到它这个区间内的最小值。若前面的数不足m项则从第1个数开始，若前面没有数则输出0。 </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：</span><br><span class="line">6 2</span><br><span class="line">7 8 1 4 3 2</span><br><span class="line">输出：</span><br><span class="line">0</span><br><span class="line">7</span><br><span class="line">7</span><br><span class="line">1</span><br><span class="line">1</span><br><span class="line">3 </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p> 用STL中的deque实现的单调队列<br>注意这道题中新加入的成员是不能用的，必须等一个回合才能使用输出，所以应该模拟这个过程每次加入一个输出的是上一个加入时的最小值，所以只需要i&lt;n即可，第n个数没用 </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include&lt;bits/stdc++.h&gt;</span><br><span class="line">#include&lt;cstdio&gt;</span><br><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;algorithm&gt;</span><br><span class="line">#include&lt;cstring&gt;</span><br><span class="line">#include&lt;stdio.h&gt;</span><br><span class="line">#include&lt;cmath&gt;</span><br><span class="line">#define debug cout&lt;&lt;&quot;ok&quot;&lt;&lt;endl</span><br><span class="line">typedef long long ll;</span><br><span class="line">const int maxn=20000010;</span><br><span class="line">const int mod=1e9+7;</span><br><span class="line">using namespace std;</span><br><span class="line">struct node</span><br><span class="line">&#123;</span><br><span class="line">    int index,vis;//index表示入队时间（序号），vis表示大小（权值）</span><br><span class="line">&#125;a[maxn];</span><br><span class="line">deque&lt;node&gt;q;</span><br><span class="line">int n,m,minn[maxn];</span><br><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">    scanf(&quot;%d%d&quot;,&amp;n,&amp;m);</span><br><span class="line">    for(int i=1;i&lt;=n;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        scanf(&quot;%d&quot;,&amp;a[i].vis);</span><br><span class="line">        a[i].index=i-1;</span><br><span class="line">    &#125;</span><br><span class="line">    for(int i=1;i&lt;n;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        if(q.empty())printf(&quot;0\n&quot;);</span><br><span class="line">        while(!q.empty()&amp;&amp;q.back().vis&gt;=a[i].vis)//维护队列两端的数据</span><br><span class="line">            q.pop_back();//题目要求最小值，大于当前的值就直接pop掉</span><br><span class="line">        q.push_back(a[i]);//每一个都push_back进去</span><br><span class="line">        while(!q.empty()&amp;&amp;q.front().index+m&lt;i)//超过长度就把前面超的pop掉</span><br><span class="line">            q.pop_front();</span><br><span class="line">        printf(&quot;%d\n&quot;,q.front().vis);</span><br><span class="line">    &#125;</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><a href="https://blog.csdn.net/qq_44709990/article/details/120665261">https://blog.csdn.net/qq_44709990/article/details/120665261</a></p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>基本算法</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>基本算法</tag>
      </tags>
  </entry>
  <entry>
    <title>7.栈</title>
    <url>/posts/75c5506f/</url>
    <content><![CDATA[<h2 id="栈"><a href="#栈" class="headerlink" title="栈"></a>栈</h2><p>栈（stack）(last infirst out)后进先出<br>基础的栈相信大家都懂，stack可以直接使用STL，或者用一个数组和一个变量（记录栈顶位置）来实现栈结构。</p>
<p>使用时都要注意判空，不然就会RE！！</p>
<h2 id="0-AcWing-41-包含min函数的栈-（自己造栈）"><a href="#0-AcWing-41-包含min函数的栈-（自己造栈）" class="headerlink" title="0.AcWing 41. 包含min函数的栈 （自己造栈）"></a>0.AcWing 41. 包含min函数的栈 （自己造栈）</h2><p><img src="/posts/75c5506f/asset/202004281121410.png" alt="在这里插入图片描述"></p>
<p> 关于输出Min，直接维护一个单调栈，栈顶存的就是当前栈的最小值。 </p>
<h2 id="1-AcWing-128-编辑器-（对顶栈）"><a href="#1-AcWing-128-编辑器-（对顶栈）" class="headerlink" title="1.AcWing 128. 编辑器 （对顶栈）"></a>1.AcWing 128. 编辑器 （对顶栈）</h2><p> <img src="/posts/75c5506f/asset/20200428114053471.png" alt="在这里插入图片描述"> </p>
<p>解题思路<br>题意解析<br>分析题目意思,我们发现,这道题目需要我们资瓷,插入,删除,左移,右移,以及[1,k]<br>区间最大值查询</p>
<p>思路思索<br>对于这道题目而言,我们完全可以确定它是一道数据结构的题目,那么到底是什么具体的数据结构呢?</p>
<p>插入从最后一位插入,删除从最后一位删除,我们发现几乎重点的操作,统统都是和最后一位有关联.</p>
<p>于是我们大胆猜测,小心观察,就会发现这道题目,就是数据结构入门结构之栈<br>所有思路代码中,完美地注释了.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include &lt;bits/stdc++.h&gt;</span><br><span class="line">using namespace std;</span><br><span class="line">const int N=1e6+100;</span><br><span class="line">int t,x,sum[N],f[N],now;</span><br><span class="line">stack&lt;int&gt; a,b,c;</span><br><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">    while(scanf(&quot;%d\n&quot;,&amp;t)!=EOF)//之前在HDU提交,所以是多组数据</span><br><span class="line">    &#123;</span><br><span class="line">        a=c;//STL特性,这里就是清空操作</span><br><span class="line">        b=c;</span><br><span class="line">        f[0]=-1e7;//初始化</span><br><span class="line">        sum[0]=0;</span><br><span class="line">        for(int i=1;i&lt;=t;i++)</span><br><span class="line">        &#123;</span><br><span class="line">            char ch=getchar();//读入</span><br><span class="line">            if (ch==&#x27;I&#x27;)//插入操作</span><br><span class="line">            &#123;</span><br><span class="line">                scanf(&quot; %d&quot;,&amp;x);</span><br><span class="line">                a.push(x);//将a插入栈中</span><br><span class="line">                sum[a.size()]=sum[a.size()-1]+a.top();//前1~a.size()-1的前缀和,加上这个一个新来的,构成1~a.size()</span><br><span class="line">                f[a.size()]=max(f[a.size()-1],sum[a.size()]);//看是之前的最大值大,还是新来的最大值大</span><br><span class="line">            &#125;</span><br><span class="line">            if (ch==&#x27;D&#x27;)</span><br><span class="line">                if (!a.empty())//只要栈不为空,就删除</span><br><span class="line">                    a.pop();</span><br><span class="line">            if (ch==&#x27;L&#x27;)//左倾思想(博古+文化大革命)(手动滑稽)</span><br><span class="line">                if(!a.empty())//只要不为空</span><br><span class="line">                    b.push(a.top()),a.pop();//a+b等于整个插入序列,b负责管理当前光标右边的序列.</span><br><span class="line">            if (ch==&#x27;R&#x27;)//右倾思想(陈独秀)(手动滑稽)</span><br><span class="line">            &#123;</span><br><span class="line">                if (!b.empty())//b不为空</span><br><span class="line">                &#123;</span><br><span class="line">                    a.push(b.top());//a负责管理1~当前光标.所以现在a往右了,那么必然是要加入b栈的开头,因为b栈管理当前光标的右边.</span><br><span class="line">                    b.pop();</span><br><span class="line">                    sum[a.size()]=sum[a.size()-1]+a.top();//同样的还是重新定义.</span><br><span class="line">                    f[a.size()]=max(f[a.size()-1],sum[a.size()]);//见插入操作.</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            if (ch==&#x27;Q&#x27;)</span><br><span class="line">            &#123;</span><br><span class="line">                scanf(&quot; %d&quot;,&amp;x);</span><br><span class="line">                printf(&quot;%d\n&quot;,f[x]);//输出当前最大值区间.</span><br><span class="line">            &#125;</span><br><span class="line">            getchar();//换行符读入</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>基本算法</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>基本算法</tag>
      </tags>
  </entry>
  <entry>
    <title>9.链表</title>
    <url>/posts/f282dcb7/</url>
    <content><![CDATA[<h2 id="链表题"><a href="#链表题" class="headerlink" title="链表题"></a>链表题</h2><p><img src="/posts/f282dcb7/asset/1688119437587.png" alt="1688119437587"></p>
<p>链表解法：</p>
<p><img src="/posts/f282dcb7/asset/1688119488814.png" alt="1688119488814"></p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>基本算法</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>基本算法</tag>
      </tags>
  </entry>
  <entry>
    <title>2.平衡二叉树(AVL)</title>
    <url>/posts/6afedc17/</url>
    <content><![CDATA[<p>为了保证不退化成线性查找，就要维持树的平衡。这个平衡条件要容易保持，从而保证树的深度为O(logN)，很容易想到两种平衡条件：</p>
<ol>
<li>最简单的是要求左右子树具有相同的高度。</li>
<li>另一种是要求每个节点都必须有相同高度的左子树和右子树。</li>
</ol>
<p><img src="/posts/6afedc17/asset/424830-20190116155447233-575277652.png" alt="img"></p>
<p>然而，这两种要求都太严格而难以使用。</p>
<h3 id="1-AVL树-Adelson-Velskii-和-Laandis"><a href="#1-AVL树-Adelson-Velskii-和-Laandis" class="headerlink" title="1.AVL树(Adelson-Velskii 和 Laandis)"></a>1.AVL树(Adelson-Velskii 和 Laandis)</h3><p>AVL树得名于它的发明者 G.M. Adelson-Velsky 和 E.M. Landis，是最早被发明的一种平衡树。平衡二叉树本质上还是一颗二叉查找树，只是带上了平衡条件。</p>
<p>一棵平衡二叉树是每个节点的左子树和右子树的高度最多差1的二叉查找树。</p>
<ul>
<li>平衡二叉树是带有平衡条件的二叉查找树</li>
<li>平衡二叉树的每个节点的左子树和右子树的高度最多差1</li>
</ul>
<p><img src="/posts/6afedc17/asset/424830-20190116155706730-1556810640.png" alt="img"></p>
<h4 id="1-1AVL树的特点"><a href="#1-1AVL树的特点" class="headerlink" title="1.1AVL树的特点"></a><strong>1.1AVL树的特点</strong></h4><p>AVL树中的每个节点的左子树和右子树的高度差不会大于1。在插入时，检查新节点的插入点所在的最低子树的根。如果它的子节点的高度相差大于1，则会破坏原有的平衡性，因此需要进行旋转操作以达到再次平衡，此时会执行一次或两次旋转使他们的高度相等。然后算法向上移动，检查上面的节点，必要时均衡高度。这个检测检查所有路径一直向上，直到根为止。</p>
<h4 id="1-2-AVL树的缺点"><a href="#1-2-AVL树的缺点" class="headerlink" title="1.2.AVL树的缺点"></a><strong>1.2.AVL树的缺点</strong></h4><p>由于插入(或删除)一个节点时需要扫描两趟树，一次向下查找插入点，一次向上平衡树，所以AVL树不如下面介绍的红黑树效率高，也不如红黑树常用。</p>
<p>(也就是说为了保持平衡，平衡二叉树定义节点的左子树和右子树的高度差不大于1，这种规定过于严格，导致在做插入或删除操作时需要自底向上逐层检查节点的平衡性(高度差)，因此效率较低)</p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>排序树</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>排序树</tag>
      </tags>
  </entry>
  <entry>
    <title>1.二叉排序树(BST)</title>
    <url>/posts/da40e879/</url>
    <content><![CDATA[<p>二叉排序树，又叫二叉搜索树、有序二叉树（ordered binary tree）或排序二叉树（sorted binary tree）。</p>
<h3 id="1-BST树的特点"><a href="#1-BST树的特点" class="headerlink" title="1.BST树的特点"></a>1.BST树的特点</h3><p>排序二叉树要么是一棵空二叉树，要么是具有下列性质的二叉树：</p>
<ul>
<li>若它的左子树不空，则左子树上所有节点的值均小于它的根节点的值；</li>
<li>若它的右子树不空，则右子树上所有节点的值均大于它的根节点的值；</li>
<li>它的左、右子树也分别为排序二叉树。</li>
<li>没有键值相等的节点。</li>
</ul>
<p><img src="/posts/da40e879/asset/424830-20170525165031732-1038507491.png" alt="img"></p>
<p><strong>由排序二叉树的特点，我们很容易得出这样的结论：按中序遍历排序二叉树可以得到由小到大的有序序列。</strong>排序二叉树要求所有的元素都能够排序，也就是键要实现comparable接口。</p>
<h3 id="2-BST树的缺点"><a href="#2-BST树的缺点" class="headerlink" title="2.BST树的缺点"></a>2.BST树的缺点</h3><p>排序二叉树虽然可以快速检索，<strong>但出现最坏的情况——如果插入的节点集本身就是有序的(从小到大排列或从大到小排列)，在这种情况下，排序二叉树就退化成了普通链表，其检索效率就会很差。</strong> </p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>排序树</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>排序树</tag>
      </tags>
  </entry>
  <entry>
    <title>3.红黑树</title>
    <url>/posts/950e0d3f/</url>
    <content><![CDATA[<h3 id="2-红黑树-Red-Black-Tree"><a href="#2-红黑树-Red-Black-Tree" class="headerlink" title="2.红黑树(Red-Black Tree)"></a>2.红黑树(Red-Black Tree)</h3><p>红黑树是二叉搜索树的一种改进，是另一种平衡树。我们知道二叉搜索树在最坏的情况下退化成了一个链表，而红黑树在每一次插入或删除节点之后都会花O(log N)的时间来对树的结构作修改，以保持树的平衡。也就是说，红黑树的查找方法与二叉搜索树完全一样；插入和删除节点的方法前半部分与二叉搜索树完全一样，而后半部分添加了一些修改树的结构的操作。</p>
<p>红黑树的定义：</p>
<ol>
<li>每个节点是红色或者黑色</li>
<li>根节点是黑色</li>
<li>每个叶子节点都是黑色的(这里的叶子节点指的并非指6,11,15,22,27这样的节点，而是图中的NIL节点，表示这是树的尾端。)</li>
<li>对于任意的一个节点，其到尾端节点(NIL)的路径都包含了相同数目的黑节点。</li>
</ol>
<p><img src="/posts/950e0d3f/asset/424830-20170526165853591-61235113.png" alt="img"></p>
<p>参考：<a href="https://blog.csdn.net/chenhuajie123/article/details/11951777">一步一图一代码,一定要让你真正彻底明白红黑树</a></p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>排序树</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>排序树</tag>
      </tags>
  </entry>
  <entry>
    <title>6.B星树</title>
    <url>/posts/c4626f57/</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>排序树</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>排序树</tag>
      </tags>
  </entry>
  <entry>
    <title>5.B+树</title>
    <url>/posts/8bf1a1f2/</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>排序树</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>排序树</tag>
      </tags>
  </entry>
  <entry>
    <title>4.B树</title>
    <url>/posts/e5a556e2/</url>
    <content><![CDATA[<p>前面讲的BST、AVL、红黑树都是典型的<strong>二叉</strong>查找树结构，其查找的时间复杂度与树高相关。那么降低树高自然对查找效率是有所帮助的。另外还有一个比较实际的问题：就是在大量数据存储中实现查询的场景下，平衡二叉树由于树深度过大而造成磁盘IO读写过于频繁，进而导致效率低下。那么如何减少树的深度（当然不能减少查询数据量），一个基本的想法就是：</p>
<p>①. 每个节点存储多个元素 （但元素数量不能无限多，否则查找就退化成了节点内部的线性查找了）。</p>
<p>②. 摒弃二叉树结构而采用多分支(多叉)树（由于节点内元素数量不能无限多，自然子树的数量也就不会无限多了）。</p>
<p>这样我们就提出了一个新的查找树结构 ——多路查找树。 根据AVL给我们的启发，一颗平衡多路查找树(B树)自然可以使得数据的查找效率保证在O(logN)这样的对数级别上。</p>
<h3 id="1-B-树-B树，平衡多路查找树"><a href="#1-B-树-B树，平衡多路查找树" class="headerlink" title="1.B-树 (B树，平衡多路查找树)"></a>1.B-树 (B树，平衡多路查找树)</h3><p>可参考：《算法导论》第18章B树</p>
<p><strong>注意，这里的B-Tree中的减号只是分隔符，我们通常在书或博客中见到的B-Tree或者B~Tree实际上指的都是B树。</strong></p>
<p>B树是为磁盘或其他直接存储的辅助设备而设计的一种平衡搜索树。B树类似于红黑树，但它们在降低磁盘I&#x2F;O操作次数方面要更好一些。许多数据库使用B树或B树的变种来存储信息。B树与红黑树不同之处在于B树的节点可以有多个孩子。B树类似于红黑树，就是含有n个节点的B树的高度为O(lgn)。</p>
<h4 id="1-1B树的定义"><a href="#1-1B树的定义" class="headerlink" title="1.1B树的定义"></a>1.1B树的定义</h4><p>一棵m阶的B-Tree有如下特性：<br>　　1. 每个节点最多有m个孩子。<br>　　2. 除了根节点和叶子节点外，其它每个节点至少有Ceil(m&#x2F;2)个孩子。<br>　　3. 若根节点不是叶子节点，则至少有2个孩子<br>　　4. 所有叶子节点都在同一层，且不包含其它关键字信息<br>　　5. 每个非终端节点包含n个关键字信息（P0,P1,…Pn, k1,…kn）<br>　　6. 关键字的个数n满足：ceil(m&#x2F;2)-1 &lt;&#x3D; n &lt;&#x3D; m-1<br>　　7. ki(i&#x3D;1,…n)为关键字，且关键字升序排序。<br>　　8. Pi(i&#x3D;1,…n)为指向子树根节点的指针。P(i-1)指向的子树的所有节点关键字均小于ki，但都大于k(i-1)</p>
<h4 id="1-2B树的结构"><a href="#1-2B树的结构" class="headerlink" title="1.2B树的结构"></a>1.2B树的结构</h4><p>B-Tree中的每个节点根据实际情况可以包含大量的关键字信息和分支，如下图所示为一个3阶的B-Tree：</p>
<p><img src="/posts/e5a556e2/asset/424830-20190326150706037-1390683676.png" alt="img"></p>
<p>每个节点占用一个盘块的磁盘空间，一个节点上有两个升序排序的关键字和三个指向子树根节点的指针，指针存储的是子节点所在磁盘块的地址。两个关键词划分成的三个范围域对应三个指针指向的子树的数据的范围域。以根节点为例，关键字为17和35，P1指针指向的子树的数据范围为小于17，P2指针指向的子树的数据范围为17~35，P3指针指向的子树的数据范围为大于35。</p>
<h4 id="1-3B树的查找过程"><a href="#1-3B树的查找过程" class="headerlink" title="1.3B树的查找过程"></a>1.3B树的查找过程</h4><p>查找关键字29的过程：</p>
<ol>
<li>根据根节点找到磁盘块1，读入内存。【磁盘I&#x2F;O操作第1次】</li>
<li>比较关键字29在区间（17,35），找到磁盘块1的指针P2。</li>
<li>根据P2指针找到磁盘块3，读入内存。【磁盘I&#x2F;O操作第2次】</li>
<li>比较关键字29在区间（26,30），找到磁盘块3的指针P2。</li>
<li>根据P2指针找到磁盘块8，读入内存。【磁盘I&#x2F;O操作第3次】</li>
<li>在磁盘块8中的关键字列表中找到关键字29。</li>
</ol>
<p>由于节点内部的关键字是有序的，所以在节点内部的查找可以使用二分法进行。</p>
<p>分析上面过程，发现需要3次磁盘I&#x2F;O操作，和3次内存查找操作。由于内存中的关键字是一个有序表结构，可以利用二分法查找提高效率。而3次磁盘I&#x2F;O操作是影响整个B-Tree查找效率的决定因素。B-Tree相对于AVLTree缩减了节点个数，使每次磁盘I&#x2F;O取到内存的数据都发挥了作用，从而提高了查询效率。</p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>排序树</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>排序树</tag>
      </tags>
  </entry>
  <entry>
    <title>排序树对比</title>
    <url>/posts/b29d54b0/</url>
    <content><![CDATA[<h2 id="问题：有了二叉查找树、平衡树（AVL），为啥还需要红黑树？"><a href="#问题：有了二叉查找树、平衡树（AVL），为啥还需要红黑树？" class="headerlink" title="问题：有了二叉查找树、平衡树（AVL），为啥还需要红黑树？"></a>问题：<strong>有了二叉查找树、平衡树（AVL），为啥还需要红黑树？</strong></h2><p>答：极端情况下，二叉树会退化成链表，时间复杂度从O(logn)退化为O(n)。所以有了平衡二叉树。</p>
<p>平衡二叉树对平衡的要求过于严格——每个节点的左右子树的高度差最多为1。这样导致每次进行插入或删除时都会破坏平衡规则，需要进行左旋和右旋来调整。所以有了红黑树。红黑树的特点如下：</p>
<p>红黑树具有如下特点：</p>
<p>1、具有二叉查找树的特点。</p>
<p>2、根节点是黑色的；</p>
<p>3、每个叶子节点都是黑色的空节点（NIL），也就是说，叶子节点不存数据。</p>
<p>4、任何相邻的节点都不能同时为红色，也就是说，红色节点是被黑色节点隔开的。</p>
<p>5、每个节点，从该节点到达其可达的叶子节点是所有路径，都包含相同数目的黑色节点。</p>
<p>正是由于红黑树的这种特点，使得它能够在最坏情况下，也能在 O(logn) 的时间复杂度查找到某个节点。</p>
<p>不过与平衡树不同的是，红黑树在插入、删除等操作时不会像平衡树那样频繁着破坏红黑树的规则，所以不需要频繁的调整，这也是我们为什么大多数情况下使用红黑树的原因。</p>
<p>但是，单单在查找效率方面，平衡树比红黑树快。所以，红黑树是一种不大严格的平衡树，可以说是一个折中发方案。</p>
<p>总之：平衡树是为了解决二叉查找树退化为链表的情况，而红黑树是为了解决平衡树在插入、删除等操作需要频繁调整的情况。</p>
<p>参考：</p>
<p><a href="https://blog.csdn.net/weixin_30531261/article/details/79312676">一步步分析为什么B+树适合作为索引的结构</a></p>
<p><a href="https://blog.csdn.net/u013235478/article/details/50625677">Mysql索引分析</a></p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>排序树</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>排序树</tag>
      </tags>
  </entry>
  <entry>
    <title>基数排序</title>
    <url>/posts/6367b42a/</url>
    <content><![CDATA[<h2 id="基数排序（RadixSort）"><a href="#基数排序（RadixSort）" class="headerlink" title="基数排序（RadixSort）"></a>基数排序（RadixSort）</h2><p>基数排序（Radix sort）是一种非比较型整数排序算法。</p>
<h3 id="1-基本思想"><a href="#1-基本思想" class="headerlink" title="1. 基本思想"></a>1. 基本思想</h3><p>原理是将整数按位数切割成不同的数字，然后按每个位数分别比较。基数排序的方式可以采用LSD（Least significant digital）或MSD（Most significant digital），LSD的排序方式由键值的最右边开始，而MSD则相反，由键值的最左边开始。</p>
<ul>
<li><strong>MSD</strong>：先从高位开始进行排序，在每个关键字上，可采用计数排序</li>
<li><strong>LSD</strong>：先从低位开始进行排序，在每个关键字上，可采用桶排序</li>
</ul>
<h3 id="2-实现逻辑"><a href="#2-实现逻辑" class="headerlink" title="2. 实现逻辑"></a>2. 实现逻辑</h3><blockquote>
<p>① 将所有待比较数值（正整数）统一为同样的数位长度，数位较短的数前面补零。<br>        ② 从最低位开始，依次进行一次排序。<br>        ③ 这样从最低位排序一直到最高位排序完成以后, 数列就变成一个有序序列。</p>
</blockquote>
<h3 id="3-演示"><a href="#3-演示" class="headerlink" title="3.演示"></a>3.演示</h3><p> 分步图示说明：设有数组 array &#x3D; {53, 3, 542, 748, 14, 214, 154, 63, 616}，对其进行基数排序： </p>
<p><img src="/posts/6367b42a/asset/v2-5ae4857fa248035ecec780583c5e3303_720w.jpg" alt="img"></p>
<p>在上图中，首先将所有待比较数字统一为统一位数长度，接着从最低位开始，依次进行排序。</p>
<ul>
<li>按照个位数进行排序。</li>
<li>按照十位数进行排序。</li>
<li>按照百位数进行排序。</li>
</ul>
<p>排序后，数列就变成了一个有序序列。</p>
<h3 id="4-复杂度分析"><a href="#4-复杂度分析" class="headerlink" title="4. 复杂度分析"></a>4. 复杂度分析</h3><blockquote>
<p>时间复杂度：O(k*N)<br>        空间复杂度：O(k + N)<br>        稳定性：稳定</p>
</blockquote>
<p>设待排序的数组R[1..n]，数组中最大的数是d位数，基数为r（如基数为10，即10进制，最大有10种可能，即最多需要10个桶来映射数组元素）。</p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>排序算法</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>排序算法</tag>
      </tags>
  </entry>
  <entry>
    <title>归并排序</title>
    <url>/posts/1599bffe/</url>
    <content><![CDATA[<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">public class MergeSort &#123;</span><br><span class="line">    int data[];</span><br><span class="line">    MergeSort(int[] data)&#123;</span><br><span class="line">        this.data = data;</span><br><span class="line">    &#125;</span><br><span class="line">    public void sort(int l,int r)&#123;</span><br><span class="line">        int[] tmp = new int[r-l+1];</span><br><span class="line">        sort0(l,r,tmp,0,r-l);</span><br><span class="line">    &#125;</span><br><span class="line">    public void sort0(int l,int r,int[] tmp,int lt,int rt)&#123;</span><br><span class="line">        if(l&lt;r)&#123;</span><br><span class="line">            int mid = (l+r)/2;</span><br><span class="line">            sort0(l,mid,tmp,lt,mid-l+lt);</span><br><span class="line">            sort0(mid+1,r,tmp,mid+1-l+lt,rt);</span><br><span class="line">            merge(l,r,tmp,lt,rt);</span><br><span class="line">            for (int i = l,t=lt; i &lt;=r ; i++,t++) &#123;</span><br><span class="line">                data[i]=tmp[t];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(l+&quot; &quot;+r+&quot; &quot;+Arrays.toString(data));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    private void merge(int l, int r,int[] tmp,int lt,int rt) &#123;</span><br><span class="line">        int r1 = (l+r)/2;</span><br><span class="line">        int l2 = r1+1;</span><br><span class="line">        while (l&lt;=r1&amp;&amp;l2&lt;=r)&#123;</span><br><span class="line">            if(data[l]&lt;=data[l2])&#123;</span><br><span class="line">                tmp[lt]=data[l];</span><br><span class="line">                l++;</span><br><span class="line">            &#125;else &#123;</span><br><span class="line">                tmp[lt]=data[l2];</span><br><span class="line">                l2++;</span><br><span class="line">            &#125;</span><br><span class="line">            lt++;</span><br><span class="line">        &#125;</span><br><span class="line">        if(l&gt;r1)&#123;</span><br><span class="line">            l=l2;</span><br><span class="line">        &#125;</span><br><span class="line">        while (lt&lt;=rt)&#123;</span><br><span class="line">            tmp[lt]=data[l];</span><br><span class="line">            lt++;</span><br><span class="line">            l++;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        int[] data = new int[]&#123;8,6,9,2,5,1,7,10,3,4&#125;;</span><br><span class="line">        MergeSort ms = new MergeSort(data);</span><br><span class="line">        ms.sort(0,data.length-1);</span><br><span class="line">        System.out.println(Arrays.toString(data));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>排序算法</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>排序算法</tag>
      </tags>
  </entry>
  <entry>
    <title>时间复杂度</title>
    <url>/posts/4b6d6bc1/</url>
    <content><![CDATA[<p><img src="/posts/4b6d6bc1/asset/196518-584a80a392639ce7.webp" alt="img"></p>
<p>快排最坏情况: 每次分成的两个区，小的区长度为1，也就是每次选到的中枢都是边界值。如果每次都是选分区第一个元素作为中枢，一个完全倒序的数组，就是O(n^2^)</p>
<p>选边界元素当中枢，，可以避免中枢被频繁交换，其中大部分交换还是无效的。</p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>排序算法</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>排序算法</tag>
      </tags>
  </entry>
  <entry>
    <title>桶排序</title>
    <url>/posts/9fe164cc/</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>排序算法</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>排序算法</tag>
      </tags>
  </entry>
  <entry>
    <title>二分搜索</title>
    <url>/posts/98b35abd/</url>
    <content><![CDATA[<h3 id="递归实现"><a href="#递归实现" class="headerlink" title="递归实现"></a>递归实现</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="非递归实现"><a href="#非递归实现" class="headerlink" title="非递归实现"></a>非递归实现</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>搜索</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>搜索</tag>
      </tags>
  </entry>
  <entry>
    <title>思考</title>
    <url>/posts/67d01b1e/</url>
    <content><![CDATA[<p>current thread not owner</p>
<p>join yield使用场景</p>
]]></content>
      <categories>
        <category>读书笔记</category>
        <category>java多线程编程深入详解</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>java多线程编程深入详解</tag>
      </tags>
  </entry>
  <entry>
    <title>多进程多线程概述</title>
    <url>/posts/a2108865/</url>
    <content><![CDATA[<h1 id="多线程多进程概述"><a href="#多线程多进程概述" class="headerlink" title="多线程多进程概述"></a>多线程多进程概述</h1><h2 id="进程与线程"><a href="#进程与线程" class="headerlink" title="进程与线程"></a>进程与线程</h2><p>进程英文单词 process，有运行的意思，顾名思义，他必须是运行着的才能称之为进程；<br>        线程英文单词 thread，有丝线的意思，就是颗粒很细，力度很小，因此他要依附于进程，<br>所以我们可以姑且这样认为，没有进程肯定谈不上有线程；</p>
<h2 id="没有真正意义上的多线程"><a href="#没有真正意义上的多线程" class="headerlink" title="没有真正意义上的多线程"></a>没有真正意义上的多线程</h2><p>了解 CPU（单核）的人都知道，CPU 在同一个时刻只能给一个程序分配资源，也就是赋<br>予一个程序运行权，那么我们看到一次能运行好几个程序其实是 CPU 来回切换执行权，所<br>以让别人以为是并发运行，只是切换的速度很快（取决于 CPU 的主频）所以没有真正意义<br>上的并发；</p>
<h2 id="纠结的思考"><a href="#纠结的思考" class="headerlink" title="纠结的思考"></a>纠结的思考</h2><p>刚才的程序我们看到的已经有两个线程的存在了，我之前说过，一个进程至少有一<br>个执行单元，可以理解为至少有一个线程在运行，那么 main 函数应该就是一个线程，因为<br>它是程序的入口，然后我们又写了一个匿名类它显示的实现了 Runnable 接口，并且构造了<br>一个 Thread 类，因此它也是一个线程，因此有两个线程在同时运行问题往往没有那么简单，这也是本小节名字“纠结的思考”的来源，他真的是两个线程<br>么？难道 JVM 不做些什么吗？最起码我们应该联想到它应该有一个后台线程负责管理堆栈<br>信息管理垃圾的清理工作啊，因此上述的代码远远不止于一个线程，但是往往这样的钻牛角<br>尖会让我们学习 Thread API 产生很多顾虑，因此我们可以暂且不用去管 JVM 在有多少个线<br>程在支撑着我们的程序，但是我们最起码应该有这样的意识，这样也不至于在学习的路上浅<br>尝辄止。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul>
<li>Main 函数本身其实就是一个线程，我们称他为主线程；</li>
<li>实现多线程我们可以继承 Thread 类，也可以继承 Runnable 接口；</li>
<li>没有严格意义上的并发；</li>
<li>JVM 自身有很多后台线程在运行;</li>
</ul>
<h1 id="多线程详解"><a href="#多线程详解" class="headerlink" title="多线程详解"></a>多线程详解</h1><h2 id="多线程的创建"><a href="#多线程的创建" class="headerlink" title="多线程的创建"></a>多线程的创建</h2><h3 id="继承Thread创建线程"><a href="#继承Thread创建线程" class="headerlink" title="继承Thread创建线程"></a>继承Thread创建线程</h3><p>实现一个线程的一种方式为成为 Thread<br>的子类，也就是继承 Thread，然后重写 run 方法，其中 run 方法是线程的执行代码片段；</p>
<p>可以总结创建并运行一个线程有三个步骤；</p>
<ul>
<li>继承 Thread 类；</li>
<li>重写 run 方法；</li>
<li>调用线程的 start 方法（启动线程，调用 run 方法）</li>
</ul>
<p><img src="/posts/a2108865/asset/1686907971737.png" alt="1686907971737"></p>
<p>首先我们继承了 Thread 类，我们也重写了 run 方法，我们也在 main 方法中构造了一个<br>Thread 类然后调用了 start 方法；因此线程被创建并且被运行了</p>
<h4 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h4><p>为什么我重写的是 run 方法，却要调用 start 方法来启动它，我们如果直接调用线程实<br>例的 run 方法不行么？可以，当然可以因为它是成员函数，调用当然是无可厚非的事情了，<br>但是为什么他不代表启动了线程呢？</p>
<h4 id="父类实现算法，子类实现细节"><a href="#父类实现算法，子类实现细节" class="headerlink" title="父类实现算法，子类实现细节"></a>父类实现算法，子类实现细节</h4><p>在程序的设计中我们经常会将算法进行抽象，因为它有很多种运算的可能，所以我们为<br>了更好地扩展，我们将算法进行了抽象，并且统一交给父类进行实现，子类只需要知道某个<br>单元模块的功能即可，具体是如何穿插起来的子类不用去关心，</p>
<p><strong>为什么实现模块的抽象方法都是 protected 的呢?</strong><br>因为我们不想让调用者关注到我们实现的细节，这也是面向对象思想封装的一个体现；</p>
<p><strong>为什么 display 方法是不可继承的呢？</strong><br>因为算法一旦确定就不允许更改，更改也只允许算法的所有者也就是他的主人更改，如<br>果调用者都可通过继承进行修改，那么算法将没有严谨性可言；</p>
<h4 id="Thread中的Template-Design"><a href="#Thread中的Template-Design" class="headerlink" title="Thread中的Template Design"></a>Thread中的Template Design</h4><p>打开代码发现 start 代码中调用了 JNI 函数 start0，他就用到了模板模式；读者可以自己<br>查看源码看看；</p>
<h3 id="线程的状态"><a href="#线程的状态" class="headerlink" title="线程的状态"></a>线程的状态</h3><p><img src="/posts/a2108865/asset/1686908639994.png" alt="1686908639994"></p>
<p><strong>线程的初始化：</strong></p>
<p>线程的初始化状态就是我们所说的创建了一个线程，也就是说实例化了一个 Thread 的<br>子类，就等着被 start，初始化状态应该是很容易理解的状态；</p>
<p><strong>线程的运行状态</strong></p>
<p>线程的运行状态就是我们当创建完线程之后，显式的调用了 start 方法，此时线程就处<br>于运行状态，可是实际是这样的么？这就要看 CPU 的脸色了，因此我刚才的说法只能说对<br>了一半，但是不够严谨，线程被 start 之后并不一定会马上运行，因此还有一个中间状态叫<br>做临时状态我之所以没有在上图中画，是因为我觉得这个状态可以不用太多的关注，所谓临<br>时状态就是指，在 CPU 的执行队列当中，等待 CPU 轮询进行执行，说白了就是在等待获取<br>执行权；</p>
<p><strong>线程的冻结状态</strong></p>
<p>所谓线程的冻结状态就是，线程被调用了 sleep 方法或者调用了 wait 方法之后，放弃了CPU 的执行权，根据上图的箭头可以看到这个时候的线程能够继续回到运行状态，也就是说重新获取了 CPU 的执行权，当然它也可以直接到死亡状态，比如被中断，或者出现异常；</p>
<p><strong>线程的死亡状态</strong></p>
<p>线程在什么情况下能够到死亡状态呢？第一种是出现了致命的异常导致线程被死亡，另<br>外一种是线程的执行逻辑执行完毕，线程也就正常死亡；死亡后的线程不可能再回到任何一<br>个状态；</p>
<h3 id="思考-1"><a href="#思考-1" class="headerlink" title="思考"></a>思考</h3><p><strong>线程被 start 了为什么不能严格认为是运行状态呢？</strong></p>
<p>因为 CPU 有一个执行权的问题，也就是说线程被 start 之后只具备运行资格，但未必获取到了执行权，因此不能严格认定他为运行状态；</p>
<p><strong>线程冻结之后为什么还能够回到运行状态呢？</strong></p>
<p>因为线程冻结之后其实他并没有死亡，他只是放弃了运行权，并且他已经没有运行资格<br>了，只有在解冻之后他才有可能获取运行资格，然后获取执行权；</p>
<p><strong>线程的这几种状态是如何切换的呢？</strong></p>
<p>1、 初始化状态只能到运行状态；<br>        2、 运行状态能到冻结状态也能到死亡状态；<br>        3、 冻结状态能到运行状态也能到死亡状态；<br>        4、 死亡状态只能接受死亡的事实；</p>
<h3 id="实现Runnable接口创建线程"><a href="#实现Runnable接口创建线程" class="headerlink" title="实现Runnable接口创建线程"></a>实现Runnable接口创建线程</h3><p>Runnable 只是一个任务的接口，他并不是一个线程，他的出现是为了将线<br>程和业务执行逻辑分离</p>
<h3 id="Runnable和Thread的区别"><a href="#Runnable和Thread的区别" class="headerlink" title="Runnable和Thread的区别"></a>Runnable和Thread的区别</h3><ul>
<li><p>Runnable 就是一个可执行任务的标识而已，仅此而已；而 Thread 才是线程所有 API 的体现；</p>
</li>
<li><p>继承了 Thread 父类就没有办法去继承其他类，而实现了 Runnable 接口也可以继承其他类并且实现其他接口，<strong>这个区别也是很多书中千篇一律提到的，其实 Java 中的对象即使继承了其他类，也可以通过再构造一个父类的方式继承很多个类，或者通过内部类的方式继承很多个类，因此这个区别个人觉得不痛不痒；</strong></p>
</li>
<li><p>将任务执行单元和线程的执行控制区分开来，这才是引入 Runnable 最主要的目的，<br>Thread 你就是一个线程的操作者，或者独裁者，你有 Thread 的所有方法，而 Runnable只是一个任务的标识，只有实现了它才能称之为一个任务，这也符合面向对象接口的逻辑，接口其实就是行为的规范和标识；</p>
</li>
</ul>
<h3 id="线程中的策略模式"><a href="#线程中的策略模式" class="headerlink" title="线程中的策略模式"></a>线程中的策略模式</h3><p>我们可以姑且认为 Thread 是骨架，是提供功能的，而 Runnable 只是其中某个业务逻辑的一种实现罢了，为什么说只是一种实现呢？因为业务逻辑会是很复杂，也会是千变万化的，因此我们需要对它进行高度的抽象，这样才能将具体业务逻辑与抽象分离，程序的可扩展性才能够强，该模式也是本人在编码的时候非常喜欢的一种设计思想；</p>
<p>相信大家就会明白为什么需要有 Runnable 的出现，也能体会到我为什么说将 Thread 和Runnable 来进行比较本身就是一个不合适的提议，<strong>因为他们关注的东西就不是一个事情，一个负责线程本身的功能，另外一个则专注于业务逻辑的实现</strong></p>
<h3 id="线程名字"><a href="#线程名字" class="headerlink" title="线程名字"></a>线程名字</h3><p><strong>线程名字的默认编号</strong></p>
<p>线程的名字默认是这样命名的 thread-n(其中 n 是从 0 开始的数字)当然你也可以通过显<br>式的方式进行设定，比如他有 setName 方法，并且有 Thread(String name)这样的构造函数传递名字，并且有 getName()方法获取名字等</p>
<p><strong>线程名字的获取方式</strong><br>如何获取当前运行的线程名字呢？我们知道 main 函数并没有继承 Thread 也就是说我们<br>不能通过 getName 这样的 API 获取名字，那么我们应该如何获取呢，其实 Thread 类提<br>供了一个静态方法 Thread.currentThread()就可以获取当前运行的线程，如果获取了线程<br>那么获取他的名字应该是易如反掌的事情了；</p>
<h2 id="线程的同步"><a href="#线程的同步" class="headerlink" title="线程的同步"></a>线程的同步</h2><p>那个叫号小程序，如果您多运行几次，或者将程序中的 max_value 修<br>改大之后，您可能会发现有这样的问题，为什么有些号码没有显示出来，相反有些号码则被<br>显示了几次，这到底是真么回事呢？可以看到不仅有重复的号码出现，并且有超过 500 的情况出现，这到底是由于什么原因引起的呢？</p>
<p><img src="/posts/a2108865/asset/1686912727213.png" alt="1686912727213"></p>
<p>假设三个线程现在同时执行到了（1）这个位置，判断条件都满足也就是说都小于 500，好的我们假定一个数字此时刚好是 499，接着往下分析，假设此时 1 号线程执行到了（2）这个位置，此时 CPU 恰恰将它的执行权切换到了 2 号线程，那么由于 2 号线程在 1 这个位置上进行过判断条件满足，因此它直接输出 500，这个应该不难理解，2 号线程执行完毕之后继续回到了（1）的位置，但是条件不成立，它自己退出了，因此 CPU 又将执行权转到了1 号线程，一号线程起来之后就执行输出语句，因此变成了 501，回去（1）位置之后判断发现条件不符合退出，现在只剩下 3 号线程，3 号线程也不用再进行判断了，直接到（2）号位置执行输出语句，因此输出了 502，至于重复输出的根据这样的逻辑也是能够解释通过的，读者可以自己进行解释；</p>
<p>为什么会出现这样的问题呢？因为我们需要访问的数据没有被保护，这就是多线程最最<br>令人头疼的地方，线程安全，多线程之间的数据共享引发的安全问题</p>
<h3 id="同步代码块"><a href="#同步代码块" class="headerlink" title="同步代码块"></a>同步代码块</h3><h4 id="给共享数据加锁"><a href="#给共享数据加锁" class="headerlink" title="给共享数据加锁"></a>给共享数据加锁</h4><p>可以看到我们的代码中增加了一个 synchronized 这样的关键字，他的意思就是线程的同步，立即的通俗来讲就是给代码或者业务逻辑加锁，<strong>何为加锁呢？就是我们将部分数据保护起来，每次只能有一个线程进行访问，</strong>举个最简单的例子，假设有一个单行道，不管后面的人是老老实实排队的，还是从中间翻越过来的，还吃打架打赢挤过来的，但是单行道的出口总是只能有一个人才能通过！通过单行道的那个门口就是我们所说的锁，那程序加了锁之后是如何运行的呢？</p>
<p><strong>同步代码块的有效范围</strong></p>
<p>看到这里有些人就要问了，既然加了锁，我们的代码就只能被一个线程调用，这样岂不<br>是降低了效率，在同步代码的部分并没有多线程并发的情况出现呀？如果你能想到这一点，<br>就说明你对锁的机制了解的差不多了，的确，情况的确如此，因为我们要尽量的缩小同步锁<br>的范围，有什么原则么？其实如果程序写多了，就会想到我们同步代码块最小的粒度应该放<br>在共享数据的上下文，或者说共享数据被操作的上下文中，</p>
<p>####如何定义一个锁</p>
<ul>
<li><p>所谓加锁，就是为了防止多个线程同时操作一份数据，如果多个线程操作的数据都是各自的，那么就没有加锁的必要</p>
</li>
<li><p>共享数据的锁对于访问他们的线程来说必须是同一份，否则锁只能私有的锁，各锁个的，起不到保护共享数据的目的，试想一下将 Object lock 的定义放到 run 方法里面，每次都会实例化一个 lock，每个线程获取的锁都是不一样的，也就没有争抢可言，说的在通俗一点甲楼有一个门上了锁，A 要进门，乙楼有一个门上了锁 B 要进门，A 和 B 抢的不是一个门，因此不存在数据保护或者共享；</p>
</li>
<li><p>锁的定义可以是任意的一个对象，该对象可以不参与任何运算，只要保证在访问的多个线程看来他是唯一的即可；</p>
</li>
</ul>
<p>####同步方法</p>
<p>其实方法的同步和代码块的公布大相径庭就是在方法名前面加上 synchronized 关键字，具体的格式如何呢？我这里简单的写一下</p>
<p>Private|default|protected|public   [static]   synchronized   void|return  type methodName(Parameters)</p>
<h4 id="同步-run-方法"><a href="#同步-run-方法" class="headerlink" title="同步 run 方法"></a>同步 run 方法</h4><p>Run 方法是否可以加 synchronized 关键字，当然是可以的，这个在任何时候都符合语法规范，但是<strong>为什么不能将 run 方法同步</strong>？如果您仔细阅读了我们对 CPU 执行权那部分的分析之后，这个问题也许您自己都已经找到答案了，<strong>当第一个线程获取到了 CPU 的执行权之后，进入 run 方法，一定是执行完毕所有的逻辑才会退出，</strong>因为 run 方法加了锁，其他线程只有等待的份，地一个线程执行完毕退出，其他线程获取到了锁，想要执行，一看判断已经不符合则自动退出；因此 run 方法加锁，<strong>真实情况是会有多个线程运行，但是只有一个线程执行业务逻辑，其他线程都等于阻塞状态，</strong>如果不相信，可以尝试一下，打印出来的信息一定只是一个线程相关的；</p>
<p>####同步总结</p>
<p>不管是同步代码块或者同步方法，我们需要事先确定的是：“<strong>当同一份的数据被多个线</strong><br><strong>程操作的时候才考虑同步</strong>”，否则将会产生效率的问题</p>
<p>同一份数据，如果不同的线程访问的不是同一份数据，就没有必要加锁保持同步</p>
<p>多个线程访问，多个线程访问的时候采取考虑同步，如果一份数据只是被一个线程访问，就没有必要进行同步；</p>
<p>多个线程同步的代码块必须是同一个锁</p>
<h3 id="this-锁与static锁"><a href="#this-锁与static锁" class="headerlink" title="this 锁与static锁"></a>this 锁与static锁</h3><p>####this锁</p>
<p>同步函数其实用到的锁就是 this 锁，为什么他用到的是 this 锁呢？</p>
<p>分别启动了两个线程，分别用来执行 ClassA 中的两个方法 A 和 B，两个方法都是加了锁的，也就是说某个线程尽到方法 A 中其他线程就不能进入 A，但是另一个线程应该能进入 B，但是我们等了半天方法 B 仍然没有输出，因此我们得出一个结论，他们的锁是同一个，至于是哪一个锁呢？答案就是 this 锁；</p>
<p>####static 锁</p>
<p>静态锁，锁是类的字节码信息，因此如果一个类的函数为静态方法，那么我们需要通过<br>该类的 class 信息进行加锁；</p>
<h4 id="线程的休眠"><a href="#线程的休眠" class="headerlink" title="线程的休眠"></a>线程的休眠</h4><p><img src="/posts/a2108865/asset/1686924475386.png" alt="1686924475386"></p>
<h4 id="单例模式的详解"><a href="#单例模式的详解" class="headerlink" title="单例模式的详解"></a>单例模式的详解</h4><p>了解单例设计模式的人都知道，单例中涉及的类他在内存之中始终是独一份存在的，如果存在两份则将出现问题，并且单例模式有两种相对比较有特点的形式，那就是饿汉式与懒<br>汉式单例模式，</p>
<p><strong>饿汉式单例模式</strong></p>
<p>所谓饿汉式单例设计模式，就是将类的静态实例作为该类的一个成员变量，也就是说在<br>JVM 加载它的时候就已经创建了该类的实例，因此它不会存在多线程的安全问题</p>
<p><img src="/posts/a2108865/asset/1686924617539.png" alt="1686924617539"></p>
<p>可以看到上述代码中的单例不存在线程安全的问题，但是他有一个性能上面的问题，那<br>就是提前对实例进行了初始化或者说构造，假设构造该类需要很多的性能消耗，如果代码写<br>成这个样子将会提前完成构造，又假设我们在系统运行过程中压根就没有对该实例进行使用，那岂不是很浪费系统的资源呢？</p>
<p><strong>懒汉式单例模式</strong></p>
<p>所谓懒汉式单例模式的意思就是，实例虽然作为该类的一个实例变量，但是他不主动进<br>行创建，如果你不使用它那么他将会永远不被创建，只有你在第一次使用它的时候才会被创<br>建，并且得到保持；</p>
<p><img src="/posts/a2108865/asset/1686924797726.png" alt="1686924797726"></p>
<p>上述的代码就是我们所说的懒汉式单例模式，但是根据上文中的关于线程安全问题的分<br>析我们不难发出现，instance 有可能会被创建两次</p>
<p>那么我们应该如何避免多线程引起的问题呢，看到这里您可能想到了用 synchronized 这个关键字来解决问题，</p>
<p><img src="/posts/a2108865/asset/1686924996320.png" alt="1686924996320"></p>
<p>但是该方法的效率将是相当低下的，因为每一次调用都要获取锁，判断锁的状态，因此<br>就会出现解决了安全问题，带来了效率问题，当然安全问题和效率问题本来就是两个很不可<br>调和的矛盾，但是我们也不应该就此妥协，需要尽我们的智慧既解决了安全问题又带来了最<br>小的效率影响；我们将程序写成如下的样子</p>
<p><img src="/posts/a2108865/asset/1686925210905.png" alt="1686925210905"></p>
<p><img src="/posts/a2108865/asset/1686925230639.png" alt="1686925230639"></p>
<p>上述代码带来了哪些改变又如何将效率的损耗降到了最低</p>
<p><img src="/posts/a2108865/asset/1686925308749.png" alt="1686925308749"></p>
<p>通过上述代码的分析，我们不难发现，锁的等待或者争抢最多发生两次，也就是同步代<br>码块中的代码最多被执行两次，如此一来，安全问题解决了，效率问题也被解决掉了。</p>
<h3 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h3><p>多线程同步锁总是以牺牲系统性能为代价的，但是比牺牲性能代价更加严重的将是死锁，程序一旦出现死锁的状况，将会挂死而并不是退出，有时候死锁的问题是很难排查的，尤其是在较大的项目中多人协作的项目中，死锁是一个很头疼的问题，所以我们应该在编写程序的时候规避掉死锁，为了规避死锁，我们首先需要写出一个死锁程序，这样会很清楚什么是死锁，然后又如何避免死锁；</p>
<p><strong>什么是死锁</strong></p>
<p>假设有两个线程 A 和 B，其中 A 持有 B 想要的锁，而 B 持有 A 想要的锁，两个都在等<br>待各自释放所需要的锁，这样的情况很容易引起死锁现象的发生，</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">package org.cy.thread;</span><br><span class="line"></span><br><span class="line">public class DeadLock &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        Dead d = new Dead();</span><br><span class="line">        Thread t1 = new Thread(new Runnable() &#123;</span><br><span class="line">            @Override</span><br><span class="line">            public void run() &#123;</span><br><span class="line">                while (true)&#123;</span><br><span class="line">                    d.methodA();</span><br><span class="line">                    try &#123;</span><br><span class="line">                        Thread.sleep(10);</span><br><span class="line">                    &#125; catch (InterruptedException e) &#123;</span><br><span class="line">                        e.printStackTrace();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        Thread t2 = new Thread(new Runnable() &#123;</span><br><span class="line">            @Override</span><br><span class="line">            public void run() &#123;</span><br><span class="line">                while (true)&#123;</span><br><span class="line">                    d.methodB();</span><br><span class="line">                    try &#123;</span><br><span class="line">                        Thread.sleep(10);</span><br><span class="line">                    &#125; catch (InterruptedException e) &#123;</span><br><span class="line">                        e.printStackTrace();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        t1.start();</span><br><span class="line">        t2.start();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">class Dead&#123;</span><br><span class="line">    private Object lock = new Object();</span><br><span class="line">    private int x=0;</span><br><span class="line">    public void methodA()&#123;</span><br><span class="line">        synchronized (lock)&#123;</span><br><span class="line">            synchronized (this)&#123;</span><br><span class="line">                System.out.println(&quot;a .. &quot;+(x++));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    public void methodB()&#123;</span><br><span class="line">        synchronized (this)&#123;</span><br><span class="line">            synchronized (lock)&#123;</span><br><span class="line">                System.out.println(&quot;b .. &quot;+(x++));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><img src="/posts/a2108865/asset/1686926522257.png" alt="1686926522257"></p>
<p>可以看到程序运行到一定地步就阻塞住了，然后没有任何输出，但是程序并没有停止，<br>而是出现了挂死；</p>
<p>用jstack查看：</p>
<p><img src="/posts/a2108865/asset/1686927148117.png" alt="1686927148117"></p>
<h3 id="如何避免死锁"><a href="#如何避免死锁" class="headerlink" title="如何避免死锁"></a>如何避免死锁</h3><p>从刚才的代码中可以看出我们实现死锁的方式是同步代码块中的同步，因此在日常的开<br>发过程中应该避免使用这样的情况，如果有这样的情况出现也要认真的推演，反复地琢磨，<br>万不得已的请看下才考虑同步代码块中有同步代码块；</p>
<h1 id="线程间的通讯"><a href="#线程间的通讯" class="headerlink" title="线程间的通讯"></a>线程间的通讯</h1><h3 id="生产者消费者"><a href="#生产者消费者" class="headerlink" title="生产者消费者"></a>生产者消费者</h3><p>一个线程实现让 x++（模拟我们在创建 X 值）而另外一个线程<br>则是不断的消费 X 值（也就是上述代码中打印而已）</p>
<p><img src="/posts/a2108865/asset/1686930256947.png" alt="1686930256947"></p>
<p>真正意义上的生产者消费者应该是这样的，生产一个消费一个，如果没有生产那就没有<br>消费，没有被消费完毕就不应该进行生产，因此我们将推出两个比较重要的方法，那就是<br>wait 和 notify，只启动了一个生产线程和一个消费线程；系统运行并没有什么异样。但是当多个生产者和消费者时，就会出现死锁的问题或者生产多次消费一次，或者生产一次消费多次，为什么会出现上述现象呢？</p>
<p>改成notifyAll就行了。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> org.cy.thread;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Demo1</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">NumFactory</span> <span class="variable">f</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">NumFactory</span>();</span><br><span class="line">        <span class="type">Runnable</span> <span class="variable">r1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Runnable</span>() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">                <span class="keyword">while</span> (<span class="literal">true</span>)&#123;</span><br><span class="line">                    f.create();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;</span><br><span class="line">        <span class="type">Runnable</span> <span class="variable">r2</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Runnable</span>() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">                <span class="keyword">while</span> (<span class="literal">true</span>)&#123;</span><br><span class="line">                    f.consume();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">Thread</span>(r1).start();</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">Thread</span>(r2).start();</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">Thread</span>(r1).start();</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">Thread</span>(r2).start();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NumFactory</span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Object lock=<span class="keyword">new</span> <span class="title class_">Object</span>();</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> x=<span class="number">0</span>;</span><br><span class="line">    <span class="type">boolean</span> <span class="variable">created</span> <span class="operator">=</span> <span class="literal">false</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">create</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">synchronized</span> (lock)&#123;</span><br><span class="line">            <span class="keyword">if</span>(!created)&#123;</span><br><span class="line">                System.out.println(Thread.currentThread().getId()+<span class="string">&quot; create &quot;</span>+(++x));</span><br><span class="line">                created=<span class="literal">true</span>;</span><br><span class="line">                lock.notifyAll();</span><br><span class="line">            &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    lock.wait();</span><br><span class="line">                &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">consume</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">synchronized</span> (lock)&#123;</span><br><span class="line">            <span class="keyword">if</span>(created)&#123;</span><br><span class="line">                System.out.println(Thread.currentThread().getId()+<span class="string">&quot; consume &quot;</span>+(--x));</span><br><span class="line">                created=<span class="literal">false</span>;</span><br><span class="line">                lock.notifyAll();</span><br><span class="line">            &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    lock.wait();</span><br><span class="line">                &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="wait"><a href="#wait" class="headerlink" title="wait"></a>wait</h3><p>wait 方法和之前的 sleep 一样就是放弃 CPU 执行权，但是他和 sleep 不一样的地方是需要等待另外一个持有相同锁的线程对其进行唤醒操作，并且 wait 方法必须有一个同步锁，否则会抛出一个异常 java.lang.IllegalMonitorStateException: current thread not owner</p>
<h3 id="notify-详解"><a href="#notify-详解" class="headerlink" title="notify 详解"></a>notify 详解</h3><p>notify 方法就是将之前处在临时状态的线程唤醒，并且获取执行权，等待 CPU 的再次调度，但是有一点需要注意的是必须和之前的 wait 方法用到的锁是同一个；</p>
<p>###notifyAll 详解</p>
<p>notify 方法是唤醒一个正处在阻塞状态的线程，那他到底唤醒的是谁呢？其实在 JVM 中也存在一个线程队列或者线程池的概念，我们看看下图中的表示，关于 wait 和 notify 中的线程两者均使用的是一把锁，否则将没有可以探讨的必要；</p>
<p><img src="/posts/a2108865/asset/1686970559762.png" alt="1686970559762"></p>
<p>从该图中可以看出，notify 方法将严格按照 FIFO（先进先出）的方式唤醒在线程队列中的与自己持有同样一把锁的线程；通过上图读者应该很清楚 notify 的作用，那么 notifyAll的作用是什么呢？请看下图</p>
<p><img src="/posts/a2108865/asset/1686970602173.png" alt="1686970602173"></p>
<p>通过上图的描述，我们可以看出 notifyAll 方法是将所有 wait 中的线程都进行唤醒，当<br>然前提就是唤醒的线程持有和自己一样的锁，否则将不能被唤醒；</p>
<h1 id="守护线程与线程的优先级"><a href="#守护线程与线程的优先级" class="headerlink" title="守护线程与线程的优先级"></a>守护线程与线程的优先级</h1><h3 id="守护线程"><a href="#守护线程" class="headerlink" title="守护线程"></a>守护线程</h3><p>什么叫做守护线程，你可以简单的将其理解为一个后台线程，他的特点主要是，主线程<br>一旦运行结束，它就会随之结束，不管运行没运行完毕，都会随之结束，（应该是所有非后台线程运行结束，它也随之结束）</p>
<p>守护线程的设置也是相当简单，只需要将线程的 Daemon设置为 true 即可</p>
<h3 id="线程的-yield"><a href="#线程的-yield" class="headerlink" title="线程的 yield"></a>线程的 yield</h3><p>线程的 yield 方法就是短暂放弃 CPU 执行权，但是它刹那点就和其他线程争抢 CPU 执行权；</p>
<p>Thread.yield()方法作用是：暂停当前正在执行的线程对象，并执行其他线程。</p>
<p>yield()应该做的是让当前运行线程回到可运行状态，以允许具有相同优先级的其他线程获得运行机会。因此，使用yield()的目的是让相同优先级的线程之间能适当的轮转执行。但是，实际中无法保证yield()达到让步目的，因为让步的线程还有可能被线程调度程序再次选中。</p>
<p>结论：yield()从未导致线程转到等待&#x2F;睡眠&#x2F;阻塞状态。在大多数情况下，yield()将导致线程从运行状态转到可运行状态，但有可能没有效果。<br>暂停当前正在执行的线程对象，并执行其他线程。</p>
<h3 id="线程的停止"><a href="#线程的停止" class="headerlink" title="线程的停止"></a>线程的停止</h3><p>线程的停止，之前调用 stop 方法可以停止，但是该方法目前也被过期掉了，因为它存<br>在线程安全问题，但是我们也有自己的方法让线程停止，我们一般在线程的 run 方法中会是一个死循环，因此线程的停止一般有两种方式</p>
<ul>
<li><p>Run 方法中的业务逻辑执行完毕；</p>
</li>
<li><p>死循环退出；</p>
</li>
</ul>
<h3 id="线程的优先级"><a href="#线程的优先级" class="headerlink" title="线程的优先级"></a>线程的优先级</h3><p>线程的优先级别为 5，没一个线程但是我们可以通过设置提高或者降低线程的优先级别，所谓线程的优先级别高就是获得 CPU 执行权的几率高，但是企图通过线程优先级设置来进行业务的控制这个是不可行的  void setPriority(int newPriority)</p>
<h3 id="线程-Join"><a href="#线程-Join" class="headerlink" title="线程 Join"></a>线程 Join</h3><p>通过字面意思就可以理解到，线程的 Join 方法就是临时加入一个线程，等到该线程执<br>行结束之后才能运行主线程</p>
<h3 id="线程的-interrupt"><a href="#线程的-interrupt" class="headerlink" title="线程的 interrupt"></a>线程的 interrupt</h3><p>Interrupt 方法的作用就是将处在阻塞中的线程打断，也就是线程将从阻塞状态转换到临时状态或者其他状态，执行该方法会抛出一个异常，也就是 wait 方法或者 sleep 方法中我们经常需要捕获的异常 InterruptedException</p>
<p>#线程池的实现</p>
<p>线程的创建和销毁是比较消耗系统性能的，所以如何将已创建线程再次复用就可以避免线程创建和销毁带来的消耗</p>
<h3 id="线程组"><a href="#线程组" class="headerlink" title="线程组"></a>线程组</h3><p>线程组顾名思义就是一组线程的意思，将一组线程存放在一个组里面，方便管理，方便<br>监控，相比 Thread，ThreadGroup 的使用并不是那么频繁，说实话我在日常的工作中也几乎很少用到 ThreadGroup，</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">package org.cy.thread.threadpool;</span><br><span class="line"></span><br><span class="line">public class ThreadGroupDemo &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        ThreadGroup tg = new ThreadGroup(&quot;tg1&quot;);</span><br><span class="line">        Runnable r = new Runnable() &#123;</span><br><span class="line">            @Override</span><br><span class="line">            public void run() &#123;</span><br><span class="line">                while (true)&#123;</span><br><span class="line">                    System.out.println(Thread.currentThread().getName()+&quot; ... &quot;+Thread.currentThread().getThreadGroup().getName());</span><br><span class="line">                    try &#123;</span><br><span class="line">                        Thread.sleep(1000);</span><br><span class="line">                    &#125; catch (InterruptedException e) &#123;</span><br><span class="line">                        e.printStackTrace();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;</span><br><span class="line">        Thread t1 = new Thread(tg,r,&quot;t1&quot;);</span><br><span class="line">        Thread t2 = new Thread(tg,r,&quot;t2&quot;);</span><br><span class="line">        Thread t3 = new Thread(tg,r,&quot;t3&quot;);</span><br><span class="line">        t1.start();</span><br><span class="line">        System.out.println(tg.activeCount());</span><br><span class="line">        t2.start();</span><br><span class="line">        System.out.println(tg.activeCount());</span><br><span class="line">        t3.start();</span><br><span class="line">        System.out.println(tg.activeCount());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>另外一种创建方式:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ThreadGroup tg2 = new ThreadGroup(tg,&quot;tg2&quot;);</span><br></pre></td></tr></table></figure>

<p>可以看到线程组的创建可以将另外一个线程组作为参数传递进去，该线程组就称之为父<br>线程组，在该线程组中可以通过 getParent()方法获取父线程组，当然也可以查看到父线程组中线程的状态等；</p>
<p><img src="/posts/a2108865/asset/1686974463968.png" alt="1686974463968"></p>
<p><img src="/posts/a2108865/asset/1686974486333.png" alt="1686974486333"></p>
<p>enumerate 方法其实就是线程引用的拷贝，并不是深入克隆</p>
<h2 id="线程池雏形"><a href="#线程池雏形" class="headerlink" title="线程池雏形"></a>线程池雏形</h2><p>线程池应该最起码具备的就是如下几个特点，在接下来的文字中我们将会围绕着这几点<br>然后一一进行实现</p>
<ul>
<li>任务队列；</li>
<li>线程管理者；</li>
<li>最大线程活跃数；</li>
<li>线程最小数；</li>
<li>线程最大数；</li>
</ul>
<p>###最小线程数</p>
<p>既然是线程池，里面的线程应该不止一个，因此它有若干个，也就是线程池初始化的时<br>候需要创建的线程最小数</p>
<p>###最大线程数</p>
<p>虽然线程中有很多个线程，但是也是有个极限的吧，因此最大线程就是限制线程池中最<br>大的线程数，那么当线程池中的线程已经不能满足任务时，这个时候需要采取哪些策略呢？<br>当然方式有很多种，等待，抛出异常告知调用者，放入任务队列中等</p>
<p>###最大活跃线程数</p>
<p>当线程池的线程需要超过最小线程数时，他需要增加到一个不超过最大线程数的值，这个时候他就重新动态的开辟一个线程，当线程的需求量不是太大的时候，线程池就有义务负责销毁线程释放 CPU，内存等资源，那么应该如何释放这些线程呢？那就释放到活跃线程数的这个值；</p>
<p>###属性之间的关系</p>
<p>最小线程数&lt;&#x3D;最大活跃线程数&lt;&#x3D;最大线程数</p>
<p>###任务队列属性</p>
<p>我们的任务都是存放在队列之中，但是严格来说，一个任务队列应该还有如下的一些最基本特点；</p>
<ul>
<li>任务队列最大任务数</li>
<li>超过最大任务数该如何处理；</li>
<li>任务队列中的任务状态监控</li>
</ul>
<p>###线程状态的监控</p>
<p>所谓线程的状态监控就是指通过回调或者监听的手段，得知当前运行线程运行的状况，<br>启动，运行中，正常结束，异常结束等状况</p>
<p><img src="/posts/a2108865/asset/1686993062247.png" alt="1686993062247"></p>
<p>可以看到，扮演这个比较重要角色的接口是 Thread.UncaughtExceptionHandler，运行之后我们发现，线程意外死亡被我们很好的捕获到了</p>
]]></content>
      <categories>
        <category>读书笔记</category>
        <category>java多线程编程深入详解</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>java多线程编程深入详解</tag>
      </tags>
  </entry>
  <entry>
    <title>设计模式</title>
    <url>/posts/364ea8cc/</url>
    <content><![CDATA[<p>模板设计模式</p>
<p>策略模式</p>
<p>单例模式（多线程版本）</p>
<p>生产者消费者模式</p>
]]></content>
      <categories>
        <category>读书笔记</category>
        <category>java多线程编程深入详解</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>java多线程编程深入详解</tag>
      </tags>
  </entry>
  <entry>
    <title>mysql王者晋级之路</title>
    <url>/posts/115d16e7/</url>
    <content><![CDATA[<h2 id="存储引擎"><a href="#存储引擎" class="headerlink" title="存储引擎"></a>存储引擎</h2><p>InnoDB、Mysql、Memory、blackhole等</p>
<p><img src="/posts/115d16e7/asset/1687768365725.png" alt="1687768365725"></p>
<p><img src="/posts/115d16e7/asset/1687768385011.png" alt="1687768385011"></p>
<p>现在数据库默认的版本存储引擎时InnoDB,并且Msql8.0宣布InnoDB存储数据字典，MylSAM彻底从MyQL数据库中剥离开，被废弃了。</p>
<p>建议把线上的MyISM的存储引擎表全部转化成InnoDB表存储。下面是两种之间的主要区别</p>
<p><img src="/posts/115d16e7/asset/1687768646223.png" alt="1687768646223"></p>
<p>可以看出InnoDB存储引擎的优势很明显。</p>
<p>##表</p>
<h3 id="整型"><a href="#整型" class="headerlink" title="整型"></a>整型</h3><p>int   tinyint  使用最多</p>
<p><img src="/posts/115d16e7/asset/1687771979891.png" alt="1687771979891"></p>
<p><img src="/posts/115d16e7/asset/1687772000859.png" alt="1687772000859"></p>
<p>id 一般都选择int，基本不用bigint这种，因为int unsigned数值范围可以达到43亿</p>
<p>问题：int(4)和int(10)有区别吗？</p>
<p>Int(n) 括号里面的数字无论写成多少，都是占四个字节，最多能存10位数字。n不是代表能存多少位数，只是显示宽度。所以两者没有区别。但如果定义了zerofill，就有区别了，比如写入一个1，int(4)会写成0001，int(10)会写成0000000001.</p>
<p><img src="/posts/115d16e7/asset/1687772412789.png" alt="1687772412789"></p>
<p><img src="/posts/115d16e7/asset/1687772443967.png" alt="1687772443967"></p>
<h3 id="浮点型"><a href="#浮点型" class="headerlink" title="浮点型"></a>浮点型</h3><p><img src="/posts/115d16e7/asset/1687772496719.png" alt="1687772496719"></p>
<p>避免使用浮点型，因为他属于并不精确的类型，生产中不建议使用float和double。</p>
<p>在生产环境中，我们大多数使用decimal来存储金钱字段，但是数值运算过程中，还是会转成浮点数来运算，而且在运算过程中会出现四舍五入的情况，这样就造成了金额的不准确。</p>
<p>decimal(6,2)   6代表整数加小数部分的总长度，2代表小数点后的保留位数，插入的值的小数部分会自动补齐或者四舍五入。插入的数字的整数部分长度不能超过M-D位，否则不能成功插入，会报超出范围的错误。</p>
<p>对于交易类的平台，这种四舍五入的现象还是要避免的，可以使用int来存储金钱，int单位为分，这样就不存在四舍五入了，让数据更精确。</p>
<h3 id="时间类型"><a href="#时间类型" class="headerlink" title="时间类型"></a>时间类型</h3><p><img src="/posts/115d16e7/asset/1687773196369.png" alt="1687773196369"></p>
<p>也可以使用int类型来存储时间，可以通过两个函数转换来，unix_timestamp和from_unixtime</p>
<h3 id="字符串类型"><a href="#字符串类型" class="headerlink" title="字符串类型"></a>字符串类型</h3><p><img src="/posts/115d16e7/asset/1687773385247.png" alt="1687773385247"></p>
<p>text和blob这种存大量文字或者存图片的大数据类型建议不要与业务表放在一起。主要业务表切忌出现这样类型的字段。</p>
<p>问题：Char和VarChar的区别？</p>
<p>Char类型用于定长字符串，并且范围为0-255.如果字符数没有达到定义的位数，会在后面用空格补齐全存入数据库，如果超过大小，会被截断。</p>
<p>Varchar是变长长度，长度范围为0-65535，存储时，不会在后面补空格；如果超过指定长度，也会截断。可以根据实际内容动态地改变存储值地长度，在不确定需要多少字符时，可以大大地节约磁盘空间，提高存储效率。会使用多余字节记录长度，&lt;255一个字节，&gt;255两个字节</p>
<p><img src="/posts/115d16e7/asset/1687773991188.png" alt="1687773991188"></p>
<p>问题：IPv4这样地字段，选择什么类型数据存储合适？</p>
<p>推荐使用int类型类存储ip字段，可int不是整数吗，怎么可以存字符串呢？这里使用到inet_aton和inet_ntoa两个函数</p>
<h3 id="表碎片产生的原因"><a href="#表碎片产生的原因" class="headerlink" title="表碎片产生的原因"></a>表碎片产生的原因</h3><p><img src="/./asset/1687794828234.png" alt="1687794828234"></p>
<p><img src="/./asset/1687794992864.png" alt="1687794992864"></p>
<p><img src="/./asset/1687795034807.png" alt="1687795034807"></p>
<p><img src="/./asset/1687795060611.png" alt="1687795060611"></p>
<h3 id="mysql-库表常用命令总结"><a href="#mysql-库表常用命令总结" class="headerlink" title="mysql 库表常用命令总结"></a>mysql 库表常用命令总结</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">use database   选择数据库</span><br><span class="line">show databases 查看所有数据库</span><br><span class="line">show tables  查看某库下所有表</span><br><span class="line">crate database database_name  创建数据库</span><br><span class="line">drop database database_name 删除数据库</span><br><span class="line">create table table_name(字段列表) 创建表</span><br><span class="line">drop table table_name 删除表</span><br><span class="line">delete from table_name(where)或者truncate table table_name 只删除表数据</span><br><span class="line">insert into table_name(字段列表) values (对应字段地值) 往表插入数据</span><br><span class="line">update table_name set: 字段值=某值(where) 更新表中某行数据</span><br><span class="line">select * from table_name (where) 查询表中数据</span><br><span class="line">show create table table_name \G 查看建表语句</span><br><span class="line">desc table_name 查看表结构</span><br><span class="line">show table status 获取表基础信息</span><br><span class="line">show index from table_name 查看当前表下索引地情况</span><br><span class="line">show full processlist 查看数据库当前连接地情况</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>##索引</p>
<p>###二叉树结构</p>
<p>B+树是由  二叉树-&gt;平衡二叉树-&gt;b树  演化而来地。</p>
<p><img src="/posts/115d16e7/asset/1687775957789.png" alt="1687775957789"></p>
<h3 id="平衡二叉树"><a href="#平衡二叉树" class="headerlink" title="平衡二叉树"></a>平衡二叉树</h3><p>二叉树随着节点地深度加大时，查询地均分复杂度就会上升，为了提供更快地查询速度，平衡树就出现了。必须满足左右两个子树地高度差地绝对值不超过1，且它地左右子树都是一颗平衡二叉树。它和二叉树地区别在于随时要保证插入后地整颗二叉树是平衡地。它会左旋或者右旋来使不平衡地树变成平横树。</p>
<p><img src="/posts/115d16e7/asset/1687776200360.png" alt="1687776200360"></p>
<h3 id="b树结构"><a href="#b树结构" class="headerlink" title="b树结构"></a>b树结构</h3><p>有些书说索引结构是Btree，其实不正确。mysql地索引结构是B+tree,下图为Btree的结构</p>
<p><img src="/posts/115d16e7/asset/1687776324267.png" alt="1687776324267"></p>
<p>所有的叶子节点都在同一层，叶子结点都出现在同一层，叶子节点不包含任何关键字的信息。</p>
<h3 id="b-树"><a href="#b-树" class="headerlink" title="b+树"></a>b+树</h3><p>是btree的变体，定义与btree基本相同，但它所有关键字的信息都出现在叶子节点中，并且包含这些关键字记录的指针，叶子节点可以按照关键字的大小顺序链接。还有它所有的数据都保存在叶子节点中，这是区别于btree结构最主要的特点。</p>
<p><img src="/posts/115d16e7/asset/1687777607677.png" alt="1687777607677"></p>
<p>B+树索引是双向链表结构，而且用B+tree结构做索引要比Btree块，可以看出访问关键字的顺序是连续的，不用再访问上一个节点，而且叶子节点包含所有数据信息。</p>
<h4 id="聚集索引和普通索引"><a href="#聚集索引和普通索引" class="headerlink" title="聚集索引和普通索引"></a>聚集索引和普通索引</h4><p>MySQL数据库的B+tree索引其实可以分为两大类，一类叫聚集索引，一类叫非聚集索引，也就是普通索引。</p>
<p>聚集索引叶子节点存放表中所有行数据记录的信息，所以经常会说数据即索引，索引即数据。<strong>创建表时，要显示为表指定一个主键（聚集索引），如果不主动创建主键，那么InnoDB会选择第一个不包含null值的唯一索引作为主键。如果唯一索引都没有，InnoDB就会为该表默认生成一个6字节的rowid作为主键</strong></p>
<p>普通索引在叶子节点并不包含所有行的数据记录，只是会在叶子节点存有自己本身的键值和主键的值。在检索数据时，通过普通索引叶子节点上的主键来获取到想要查找的行数据记录</p>
<p><img src="/posts/115d16e7/asset/1687777900715.png" alt="1687777900715"></p>
<p>普通索引的创建语法</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">alter table table_name add index (索引字段)</span><br><span class="line">或者</span><br><span class="line">create index index_name on table_name(索引字段)</span><br></pre></td></tr></table></figure>

<p>通常使用show index from table_name 来查看表中有那些索引。还可用explain命令查看sql语句的执行计划，判断添加索引后，优化器是否生成了更高效的执行计划。</p>
<p><img src="/posts/115d16e7/asset/1687778242689.png" alt="1687778242689"></p>
<p><img src="/posts/115d16e7/asset/1687778257645.png" alt="1687778257645"></p>
<p><img src="/posts/115d16e7/asset/1687778298642.png" alt="1687778298642"></p>
<p><img src="/posts/115d16e7/asset/1687778351949.png" alt="1687778351949"></p>
<p><img src="/posts/115d16e7/asset/1687778370663.png" alt="1687778370663"></p>
<p><img src="/posts/115d16e7/asset/1687778691528.png" alt="1687778691528"></p>
<p><img src="/posts/115d16e7/asset/1687778805400.png" alt="1687778805400"></p>
<h4 id="主键索引和唯一索引"><a href="#主键索引和唯一索引" class="headerlink" title="主键索引和唯一索引"></a>主键索引和唯一索引</h4><p>主键索引其实就是唯一索引，每张表中有且仅有一个主键，可以由表中一个或多个字段组成。主键索引必须满足三个条件，主键值必须唯一：不能包含null值；一定要保证该值是自增属性。使用自增列做索引，可以保证写入数据的顺序也是自增的，这就在很大程度上提高了存取效率。</p>
<p>创建主键的语法</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">alter table table_name add primary key(column);</span><br></pre></td></tr></table></figure>

<p>唯一索引是约束条件的一种，其实就是不允许有重复值，但是可以运行有null值。唯一索引可以有多个</p>
<p>创建唯一索引的语法</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">alter table table_name add unique(column)</span><br></pre></td></tr></table></figure>

<h4 id="覆盖索引"><a href="#覆盖索引" class="headerlink" title="覆盖索引"></a>覆盖索引</h4><p>只需通过索引就可以返回查询所需要的数据，而不必在查到索引之后再去回表查询数据了。这样就减少了大量的i&#x2F;0操作，查询速度也相当块。</p>
<p>比如，想要查询主键id字段，而且在查询条件中name字段是普通索引，之但普通索引中包含主键的值，相当于（name，id）那么这条语句就使用了覆盖索引，出现了using index。</p>
<p>**如果使用覆盖索引，一定要让select列出所需要的列。坚决不可以直接写出select ***</p>
<h4 id="前缀索引"><a href="#前缀索引" class="headerlink" title="前缀索引"></a>前缀索引</h4><p>对应BLOB、TEXT。或者很长的VARCHAR类型的列，为它的前几个字符建立索引，这样的索引就叫做前缀索引，这样建立的索引更小，所以查询更快，但也有坏处，他不能在ordery by或group by中使用前缀索引，也不能把他们用作覆盖索引</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> table_name <span class="keyword">add</span> key(column_name(prefix_length));</span><br></pre></td></tr></table></figure>

<h4 id="联合索引"><a href="#联合索引" class="headerlink" title="联合索引"></a>联合索引</h4><p>联合索引又叫复合索引，是在表中两个以上的列上创建的索引，利用索引中的附加表，可以缩小检索的段池范围，更快的搜索到数据。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">create index idx_c1_c2 on t (c1,c2);  可以用到从索引和c1,c2索引</span><br></pre></td></tr></table></figure>

<p>联合索引使用过程中，必须满足最左前缀原则。一般把选择性高的列放在前面。一条查询语句可以只使用索引的一部分，但必须从最左侧开始。</p>
<p><img src="/posts/115d16e7/asset/1687791962554.png" alt="1687791962554"></p>
<p><img src="/posts/115d16e7/asset/1687792013621.png" alt="1687792013621"></p>
<h3 id="哈希索引"><a href="#哈希索引" class="headerlink" title="哈希索引"></a>哈希索引</h3><p><img src="/posts/115d16e7/asset/1687792152768.png" alt="1687792152768"></p>
<p>###索引总结</p>
<p><strong>索引的优点</strong></p>
<ul>
<li>提高数据检索效率</li>
<li>提高聚合函数效率</li>
<li>提高排序效率</li>
<li>使用覆盖索引可以避免会标</li>
</ul>
<p><strong>索引创建的四不要</strong></p>
<ul>
<li>选择性低的字段不要创建索引 （例如sex，status）</li>
<li>很少查询的列不要创建索引</li>
<li>大数据类型字段不要创建索引</li>
<li>尽量避免使用null，应该指定列为not null（在mysql中，含有空值的列很难进行查询优化，他们会使得索引、索引的统计信息及比较运算更加复杂，可以使用空字符串代替空值）</li>
</ul>
<p>使用不到索引的情况</p>
<ul>
<li><p>通过索引扫描的行记录超过全表30%，优化器就不会走索引，而变成全表索引。</p>
</li>
<li><p>联合索引中，第一个查询条件不是最左索引列</p>
</li>
<li><p>联合索引中，第一个索引列使用范围查询，指南用到部分索引，有ICP出现（范围查询是指&lt; 、&#x3D;、 &lt;&#x3D;、 between and）</p>
</li>
<li><p>联合索引中，第一个查询条件不是最左前缀列</p>
</li>
<li><p>模糊查询条件列最左以通配符%开始（可以考虑放到子查询里面）</p>
</li>
<li><p>两个单列索引，一个用于检索，一个用于排序。这种情况下只能使用到一个索引。因为查询语句中最多使用一个索引，考虑建立联合索引</p>
</li>
<li><p>查询字段上面有索引，但是使用了函数运算</p>
</li>
</ul>
<p>##事务<br>  事务其实就是一组DML（insert，delete，update）语句的集合。MySQL数据库InnoDB存储引擎支持事务，MyISAM不支持。而且MySQL的事务默认是自提交模式，如果想要开启事务，必须以begin命令开始，以commit或者rollback命令结束。</p>
<h3 id="事务的特性"><a href="#事务的特性" class="headerlink" title="事务的特性"></a>事务的特性</h3><ol>
<li>原子性<br>事务中包含的所有操作要么都做，要么都不做，保证数据库是一致的。</li>
<li>一致性<br>数据库中的数据在事务操作前和事务处理后都必须满足业务规则约束。</li>
<li>隔离性<br>数据库允许多个并发事务同时对数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。</li>
<li>持久性<br>事务处理结束后，对数据的修改就是永久的，即使系统发生故障也不会丢失</li>
</ol>
<h3 id="事务语句"><a href="#事务语句" class="headerlink" title="事务语句"></a>事务语句</h3><p>事务的开启语句是由begin 或者start transaction命令来开始的，或者把自提交特性关掉（set autocommit&#x3D;0命令）事务结束语句通常使用commit或者rollback显示结束。commit代表提交事务，使得已对数据库的所有修改改为永久性。rollback代表回滚事务，撤销正在进行的所有未提交的修改。</p>
<p><img src="/./asset/1687850088508.png" alt="1687850088508"></p>
<p><img src="/./asset/1687850169056.png" alt="1687850169056"></p>
<h3 id="truncate和delete的区别"><a href="#truncate和delete的区别" class="headerlink" title="truncate和delete的区别"></a>truncate和delete的区别</h3><p>truncate是DDL语句操作，delete是DML语句操作，他们的共同点都是清空表内的数据，但truncate在事务中不能被回滚，而且truncate会清空表的自增属性。</p>
<ol>
<li>truncate不能回滚，delete可以回滚</li>
<li>truncate清空表的自增id属性，从1重新开始记录，而delete则不会。</li>
</ol>
<p><img src="/./asset/1687850797419.png" alt="1687850797419"></p>
<p><img src="/./asset/1687850857646.png" alt="1687850857646"></p>
<p><img src="/./asset/1687850872578.png" alt="1687850872578"></p>
<h3 id="事务的隔离级别"><a href="#事务的隔离级别" class="headerlink" title="事务的隔离级别"></a>事务的隔离级别</h3><p>MySQL InnoDB存储引擎实现SQL标准的4种隔离级别，用来限定事务内外的哪些改变是可见的，哪些是不可见的。低级别的隔离级一般支持更高的并发处理，并拥有更低的系统开销。查看当前数据库的隔离级别命令,默认级别是REPEATABLE-READ</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">show variable like &#x27;%tx_isolation%&#x27;</span><br><span class="line">set global|session transaction isolation level</span><br></pre></td></tr></table></figure>

<ol>
<li><p>读未提交（read uncommitted），简称RU，在其中一个事务中，可以读取到其他事务未提交的数据变化。这种读取其他会话还没提交的事务，叫做脏读现象。在生产环境不建议使用。</p>
</li>
<li><p>读已提交（read committed），简称RC，<strong>在其中一个事务中，可以读取到其他事务已经提交的数据变化</strong>，这种读取也可以叫做不可重复读，允许幻读现象的发生，是Oracle数据库默认的事务隔离级别，</p>
</li>
<li><p>可重复读（repetable read），简称RR，它是MySQL默认的事务隔离级别，在其中一个事务中，直到事务结束前，<strong>都可以反复读取到事务刚开始时看到的数据</strong>，并不会发生变化，避免了脏读。不可重复读和幻读现象的发生。</p>
</li>
<li><p>串行（serizlizable）在每个读的数据行上都加表级共享锁，在每次写数据时都要加表级排他锁。这就会造成InnoDB的并发能力下降，大量的超时和锁竞争就会发生。不建议使用到生产环境中。</p>
</li>
</ol>
<h3 id="脏读、不可重复读、幻读和可重复读"><a href="#脏读、不可重复读、幻读和可重复读" class="headerlink" title="脏读、不可重复读、幻读和可重复读"></a>脏读、不可重复读、幻读和可重复读</h3><h4 id="脏读"><a href="#脏读" class="headerlink" title="脏读"></a>脏读</h4><p>脏读是在事务隔离级别读未提交（RU）中出现的现象。一个事务读取到了其他事务还没有提交的数据。</p>
<p><img src="/./asset/1687854477167.png" alt="1687854477167"></p>
<p><img src="/posts/115d16e7/asset/1687854510391.png" alt="1687854510391"></p>
<h4 id="不可重复读与幻读"><a href="#不可重复读与幻读" class="headerlink" title="不可重复读与幻读"></a>不可重复读与幻读</h4><p>在其中一个事务中，读取到了其他事务针对旧数据的修改记录（常见操作就是update或者delete）</p>
<p>幻读是指其中一个事务，读取到了其他事务新增的数据，仿佛出现了幻影现象（常见的就是insert语句）。这种读的现象允许出现在读已提交的事务隔离级别中</p>
<p><img src="/./asset/1687854798875.png" alt="1687854798875"></p>
<h4 id="可重复读"><a href="#可重复读" class="headerlink" title="可重复读"></a>可重复读</h4><p>是MySQL数据库默认的事务隔离级别。它消除了脏读、不可重复读、幻读现象，很好的保证了事务的一致性。</p>
<p><img src="/./asset/1687855020232.png" alt="1687855020232"></p>
<p><img src="/./asset/1687855062341.png" alt="1687855062341"></p>
<h2 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h2><p>简单来说就是为了保证数据库数据的一致性，使共享资源在被并发访问时变得有序而设计的一种规则</p>
<p>InnoDB支持行锁，有时也会升级为表锁，MyISAM只支持表锁</p>
<ul>
<li>表锁的特点就是开销小、加锁快；锁粒度大，发生锁冲突的概率高。并发度相对低。</li>
<li>行锁的特定就是开销大，加锁慢；会出现死锁；锁粒度小，发生锁冲突的概率低，并发度也相对较高。</li>
</ul>
<h3 id="InnoDB的锁类型"><a href="#InnoDB的锁类型" class="headerlink" title="InnoDB的锁类型"></a>InnoDB的锁类型</h3><p>主要有读锁（共享锁），写锁（排他锁），意向锁和MDL锁。</p>
<h4 id="读锁"><a href="#读锁" class="headerlink" title="读锁"></a>读锁</h4><p>读锁简称S锁，一个是为u会的了一个数据行的读锁，其他事务能获得该行对应的读锁，但不能获得写锁，即一个事务在读一个数据行时，其他事务也可以读，但不能对该数据行进行增删改查的操作。</p>
<p>两者select方式，一种就不加任何锁，直接返回结果，这就是一致性非锁定读。一种是通过select lock in share mode 在被读取的行记录的范围加一个读锁，让其他事务可以读，但是想要申请加写锁，那就会被阻塞。</p>
<p>###写锁</p>
<p>写锁简称X锁，一个事务获取了一个数据行的写锁，其他事务就不能再获取该行的其他锁，写锁优先级最高。写锁的应用就很简单了，一些DML语句的操作就会对行记录加写锁</p>
<p>比较特殊的就是select for update，它就会对读取的行记录加一个写锁，那么其他任何事务就不能对被锁定的行加上任何锁了，要不然会被阻塞。</p>
<h3 id="避免死锁的方法"><a href="#避免死锁的方法" class="headerlink" title="避免死锁的方法"></a>避免死锁的方法</h3><ul>
<li><p>如果不同程序会并发存取多个表，或者涉及多行记录时，尽量约定以相同的顺序访问表，可以大大降低死锁的机会</p>
</li>
<li><p>业务中尽量采用小事务，避免大事务，要及时提交或者回滚事务，可减少死锁产生的概率</p>
</li>
<li><p>在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁产生的概率</p>
</li>
<li><p>对于非常容易产生死锁的业务部分，可以尝试使用升级锁粒度，通过表锁来减少死锁产生的概率</p>
</li>
</ul>
<p>##备份恢复</p>
<p><img src="/./asset/1687856499872.png" alt="1687856499872"></p>
<h3 id="冷备及恢复"><a href="#冷备及恢复" class="headerlink" title="冷备及恢复"></a>冷备及恢复</h3><p>冷备：数据库处于关闭状态下的备份，好处是保证数据库的完整，备份过程简单并且恢复速度相对块一些</p>
<h3 id="热备及恢复"><a href="#热备及恢复" class="headerlink" title="热备及恢复"></a>热备及恢复</h3><p>数据库处于运行状态下的备份，不影响现有业务的正常运行。细分为逻辑文件备份和裸文件备份。</p>
]]></content>
      <categories>
        <category>读书笔记</category>
        <category>mysql王者晋级之路</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>mysql王者晋级之路</tag>
      </tags>
  </entry>
  <entry>
    <title>双指针</title>
    <url>/posts/91a7e4d1/</url>
    <content><![CDATA[<h2 id="双指针"><a href="#双指针" class="headerlink" title="双指针"></a>双指针</h2><p>双指针，指的是在遍历对象的过程中，不是普通的使用单个指针进行访问，<br>而是使用两个相同方向（快慢指针）或者相反方向（对撞指针）的指针进行扫描，<br>从而达到相应的目的。<br>充分使用了数组有序的特征</p>
<h3 id="用法"><a href="#用法" class="headerlink" title="用法"></a>用法</h3><h4 id="对撞指针"><a href="#对撞指针" class="headerlink" title="对撞指针"></a>对撞指针</h4><p>对撞指针是指在有序数组中，将指向最左侧的索引定义为左指针(left)，<br>最右侧的定义为右指针(right)，然后从两头向中间进行数组遍历。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">function fn (list) &#123;</span><br><span class="line">  var left = 0;</span><br><span class="line">  var right = list.length - 1;</span><br><span class="line"></span><br><span class="line">  //遍历数组</span><br><span class="line">  while (left &lt;= right) &#123;</span><br><span class="line">    left++;</span><br><span class="line">    // 一些条件判断 和处理</span><br><span class="line">    ... ...</span><br><span class="line">    right--;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="快慢指针"><a href="#快慢指针" class="headerlink" title="快慢指针"></a>快慢指针</h4><p>快慢指针也是双指针，但是两个指针从同一侧开始遍历数组，<br>将这两个指针分别定义为快指针（fast）和慢指针（slow），<br>两个指针以不同的策略移动，直到两个指针的值相等（或其他特殊条件）为止，<br>如fast每次增长两个，slow每次增长一个。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">var hasCycle = function(head) &#123;</span><br><span class="line">  if (head === null || head.next === null) &#123;</span><br><span class="line">    return false</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  let slow = head</span><br><span class="line">  let fast = head.next</span><br><span class="line"></span><br><span class="line">  while (slow !== fast) &#123;</span><br><span class="line">    if (fast === null || fast.next === null) &#123;</span><br><span class="line">      return false</span><br><span class="line">    &#125;</span><br><span class="line">    slow = slow.next</span><br><span class="line">    fast = fast.next.next</span><br><span class="line">  &#125;</span><br><span class="line">  return true</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>当遇到有序数组时，应该优先想到双指针来解决问题，因两个指针的同时遍历会减少空间复杂度和时间复杂度。</p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>其他</category>
        <category>template</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>其他</tag>
        <tag>template</tag>
      </tags>
  </entry>
  <entry>
    <title>回溯法</title>
    <url>/posts/3635a217/</url>
    <content><![CDATA[<p>##回溯法</p>
<p>###基本原理：递归<br>###套路模板:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">res = []</span><br><span class="line">state = []</span><br><span class="line">p,q,r</span><br><span class="line">def back(状态，条件...)：</span><br><span class="line">    if 不满足条件</span><br><span class="line">        return</span><br><span class="line">    elif 状态满足要求</span><br><span class="line">        res.apend(state)</span><br><span class="line">        return</span><br><span class="line">    递归过程</span><br><span class="line">    back(状态，条件...)</span><br><span class="line">return res</span><br><span class="line">    </span><br></pre></td></tr></table></figure>
<p>###使用回溯法的明显标志<br>1.排列、组合（子集、幂集、字符全排列）<br>2.数值、字符串，给定一个特定规则，尝试搜索迭代找到这个解<br>3.二维数组下的DFS搜索（八皇后、黄金矿工、数独）<br>###加速方法<br>####传递数组下标而不是整个剩余数组<br>####剪枝<br>利用已知的先验条件，将后面不可能满足任务目标的搜索路径去掉<br>####构建图<br>将题目给出的数组数据建立联系，尝试构建一个图，回溯法转换为对图的DFS搜索，极大缩小了解空间<br>####回溯法转构造法</p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>其他</category>
        <category>template</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>其他</tag>
        <tag>template</tag>
      </tags>
  </entry>
  <entry>
    <title>冒泡排序</title>
    <url>/posts/14e6f1eb/</url>
    <content><![CDATA[<h2 id="代码编写"><a href="#代码编写" class="headerlink" title="代码编写"></a>代码编写</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span>  <span class="keyword">void</span> <span class="title function_">swap</span><span class="params">(<span class="type">int</span> i,<span class="type">int</span> j)</span>&#123;</span><br><span class="line">       <span class="type">int</span> <span class="variable">mid</span> <span class="operator">=</span> data[i];</span><br><span class="line">       data[i] = data[j];</span><br><span class="line">       data[j] = mid;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">public</span>  <span class="keyword">void</span> <span class="title function_">sort</span><span class="params">(<span class="type">int</span> l,<span class="type">int</span> r)</span>&#123;</span><br><span class="line">       <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">1</span>; i &lt;r-l+<span class="number">1</span> ; i++) &#123;     <span class="comment">//控制需要冒泡趟数</span></span><br><span class="line">           <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">j</span> <span class="operator">=</span> l; j &lt;= r-i; j++) &#123;   <span class="comment">//冒泡范围</span></span><br><span class="line">               <span class="keyword">if</span>(data[j]&gt;data[j+<span class="number">1</span>])&#123;  <span class="comment">//每次把最大的冒泡到最后面</span></span><br><span class="line">                   swap(j,j+<span class="number">1</span>);</span><br><span class="line">               &#125;</span><br><span class="line">           &#125;</span><br><span class="line">           System.out.println(Arrays.toString(data));</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>

<p>其实可以这么理解。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span>  <span class="keyword">void</span> <span class="title function_">sort</span><span class="params">(<span class="type">int</span> l,<span class="type">int</span> r)</span>&#123;</span><br><span class="line">       <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> r-l; i &gt;<span class="number">0</span> ; i--) &#123;     <span class="comment">//还需要冒泡的趟数</span></span><br><span class="line">           <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">j</span> <span class="operator">=</span> l; j &lt; l+i; j++) &#123;  <span class="comment">//冒泡范围</span></span><br><span class="line">               <span class="keyword">if</span>(data[j]&gt;data[j+<span class="number">1</span>])&#123;  <span class="comment">//每次把最大的冒泡到最后面</span></span><br><span class="line">                   swap(j,j+<span class="number">1</span>);</span><br><span class="line">               &#125;</span><br><span class="line">           &#125;</span><br><span class="line">           System.out.println(Arrays.toString(data));</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>排序算法</category>
        <category>交换排序</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>排序算法</tag>
        <tag>交换排序</tag>
      </tags>
  </entry>
  <entry>
    <title>快速排序</title>
    <url>/posts/ff8068c0/</url>
    <content><![CDATA[<p>##快速排序（Quick Sort）</p>
<p>快速排序，又称划分交换排序（partition-exchange sort）</p>
<h3 id="1-基本思想"><a href="#1-基本思想" class="headerlink" title="1.基本思想"></a>1.基本思想</h3><p>通过一趟排序将待排记录分隔成独立的两部分，其中一部分记录的关键字均比另一部分的关键字小，则可分别对这两部分记录继续进行排序，以达到整个序列有序。</p>
<h3 id="2-实现逻辑"><a href="#2-实现逻辑" class="headerlink" title="2. 实现逻辑"></a>2. 实现逻辑</h3><p>快速排序使用分治法（Divide and conquer）策略来把一个序列（list）分为两个子序列（sub-lists）。</p>
<blockquote>
<p>① 从数列中挑出一个元素，称为 “基准”（pivot），<br>② 重新排序数列，所有元素比基准值小的摆放在基准前面，所有元素比基准值大的摆在基准的后面（相同的数可以到任一边）。在这个分区退出之后，该基准就处于数列的中间位置。这个称为分区（partition）操作。<br>③ 递归地（recursive）把小于基准值元素的子数列和大于基准值元素的子数列排序。</p>
</blockquote>
<p>递归到最底部时，数列的大小是零或一，也就是已经排序好了。这个算法一定会结束，因为在每次的迭代（iteration）中，它至少会把一个元素摆到它最后的位置</p>
<p>###3. 动图演示</p>
<p><img src="/posts/ff8068c0/asset/v2-d4e5d0a778dba725091d8317e6bac939_b.webp" alt="动图">去。</p>
<h3 id="4-复杂度"><a href="#4-复杂度" class="headerlink" title="4. 复杂度"></a>4. 复杂度</h3><blockquote>
<p>平均时间复杂度：O(NlogN)<br>最佳时间复杂度：O(NlogN)<br>最差时间复杂度：O(N^2)<br>空间复杂度：根据实现方式的不同而不同</p>
</blockquote>
<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">QuickSort</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span>[] data;</span><br><span class="line">    QuickSort(<span class="type">int</span>[] data)&#123;</span><br><span class="line">        <span class="built_in">this</span>.data=data;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">swap</span><span class="params">(<span class="type">int</span> i,<span class="type">int</span> j)</span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(i==j) <span class="keyword">return</span>;</span><br><span class="line">        <span class="type">int</span> <span class="variable">mid</span> <span class="operator">=</span> data[i];</span><br><span class="line">        data[i]=data[j];</span><br><span class="line">        data[j]=mid;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">sort</span><span class="params">()</span>&#123;</span><br><span class="line">        sort0(<span class="number">0</span>,data.length-<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">sort0</span><span class="params">(<span class="type">int</span> l,<span class="type">int</span> r)</span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(l&lt;r)&#123;</span><br><span class="line">            <span class="type">int</span> <span class="variable">mid</span> <span class="operator">=</span> part(l,r);</span><br><span class="line">            sort0(l,mid-<span class="number">1</span>);</span><br><span class="line">            sort0(mid+<span class="number">1</span>,r);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> <span class="title function_">part</span><span class="params">(<span class="type">int</span> l, <span class="type">int</span> r)</span> &#123;</span><br><span class="line">        <span class="type">int</span> <span class="variable">pValue</span> <span class="operator">=</span> data[r];</span><br><span class="line">        <span class="type">int</span> lp=l,rp=r-<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span> (rp&gt;lp)&#123;</span><br><span class="line">            <span class="keyword">while</span> (lp&lt;rp&amp;&amp;data[lp]&lt;pValue)&#123;</span><br><span class="line">                lp++;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">while</span> (rp&gt;lp&amp;&amp;data[rp]&gt;=pValue)&#123;</span><br><span class="line">                rp--;</span><br><span class="line">            &#125;</span><br><span class="line">            swap(rp,lp);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(data[lp]&gt;=pValue)&#123;</span><br><span class="line">            swap(r,lp);</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(l+<span class="string">&quot;  &quot;</span>+r+<span class="string">&quot;  &quot;</span>+lp+<span class="string">&quot;  &quot;</span>+rp+<span class="string">&quot;  &quot;</span>+pValue+<span class="string">&quot;  &quot;</span>+Arrays.toString(data));</span><br><span class="line">        <span class="keyword">return</span> lp;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">int</span>[] data = <span class="keyword">new</span> <span class="title class_">int</span>[]&#123;<span class="number">8</span>,<span class="number">6</span>,<span class="number">9</span>,<span class="number">2</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">7</span>,<span class="number">10</span>,<span class="number">3</span>,<span class="number">4</span>&#125;;</span><br><span class="line">        <span class="type">QuickSort</span> <span class="variable">qs</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">QuickSort</span>(data);</span><br><span class="line">        System.out.println(Arrays.toString(data));</span><br><span class="line">        qs.sort();</span><br><span class="line">        System.out.println(Arrays.toString(data));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="非递归实现"><a href="#非递归实现" class="headerlink" title="非递归实现"></a>非递归实现</h3><p>使用栈或队列</p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>排序算法</category>
        <category>交换排序</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>排序算法</tag>
        <tag>交换排序</tag>
      </tags>
  </entry>
  <entry>
    <title>redis入门指南</title>
    <url>/posts/2075dfe/</url>
    <content><![CDATA[<h1 id="redis入门指南"><a href="#redis入门指南" class="headerlink" title="redis入门指南"></a>redis入门指南</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><h3 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h3><h4 id="存储结构"><a href="#存储结构" class="headerlink" title="存储结构"></a>存储结构</h4><p>Redis是REmote DIctionary Server（远程字典服务器）的缩写，它以字典结构存储数<br>据，并允许其他应用通过TCP协议读写字典中的内容。同大多数脚本语言中的字典一样，<br>Redis字典中的键值除了可以是字符串，还可以是其他数据类型。到目前为止 Redis 支持的键<br>值数据类型如下</p>
<p>● 字符串类型<br>        ● 散列类型<br>        ● 列表类型<br>        ● 集合类型<br>        ● 有序集合类型</p>
<h4 id="内存存储与持久化"><a href="#内存存储与持久化" class="headerlink" title="内存存储与持久化"></a>内存存储与持久化</h4><p>Redis 数据库中的所有数据都存储在内存中。</p>
<p>由于内存的读写速度远快于硬盘，因此Redis在性能上对比其他基于硬盘存储的数据库有非常明显的优势，在一台普通的笔记本电脑上，Redis可以在一秒内读写超过10万个键值。</p>
<h4 id="功能丰富"><a href="#功能丰富" class="headerlink" title="功能丰富"></a>功能丰富</h4><p>Redis 虽然是作为数据库开发的，但由于其提供了丰富的功能，越来越多的人将其用作<br>缓存、队列系统等。Redis可谓是名副其实的多面手。</p>
<p>Redis 可以为每个键设置生存时间（Time To Live，TTL），生存时间到期后键会自动被<br>删除。这一功能配合出色的性能让Redis可以作为缓存系统来使用，而且由于Redis支持持久<br>化和丰富的数据类型，使其成为了另一个非常流行的缓存系统Memcached的有力竞争者。</p>
<p>在性能上 Redis是单线程模型，而Memcached支持多线程，所以在多核服务器上后者的性能理论上相对更高一些。然而，前面已经介绍过，Redis的性能已经足够优异，在绝大部分场合下其性能都不会成为瓶颈，所以在使用时更应该关心的是二者在功能上的区别。随着Redis 3.0 的推出，标志着<br>Memcached几乎所有功能都成为了Redis的子集。同时，Redis对集群的支持使得Memcached<br>原有的第三方集群工具不再成为优势。因此，在新项目中使用Redis代替Memcached将会是<br>非常好的选择。</p>
<p>作为缓存系统，Redis 还可以限定数据占用的最大内存空间，在数据达到空间限制后可<br>以按照一定的规则自动淘汰不需要的键。</p>
<p>Redis 的列表类型键可以用来实现队列，并且支持阻塞式读取，可以很容易<br>地实现一个高性能的优先级队列。同时在更高层面上，Redis 还支持“发布&#x2F;订阅”的消息模<br>式，可以基于此构建聊天室[6] 等系统。</p>
<h4 id="简单稳定"><a href="#简单稳定" class="headerlink" title="简单稳定"></a>简单稳定</h4><p>Redis 直观的存储结构使得通过程序与Redis交互十分简单。在Redis中使用命令来读写数据，命令语句之于Redis就相当于SQL语言之于关系数据库。</p>
<p>Redis提供了几十种不同编程语言的客户端库，这些库都很好地封装了Redis的命令，使<br>得在程序中与 Redis 进行交互变得更容易。有些库还提供了可以将编程语言中的数据类型直<br>接以相应的形式存储到Redis中（如将数组直接以列表类型存入Redis）的简单方法，使用起<br>来非常方便。</p>
<h2 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h2><p>Redis服务器默认会使用6379端口 ，通过–port参数可以自定义端口号</p>
<p>考虑到 Redis 有可能正在将内存中的数据同步到硬盘中，强行终止 Redis 进程可能会导<br>致数据丢失。正确停止Redis的方式应该是向Redis发送SHUTDOWN命令</p>
<p>当Redis收到SHUTDOWN命令后，会先断开所有客户端连接，然后根据配置执行持久<br>化，最后完成退出。</p>
<p>Redis可以妥善处理 SIGTERM信号，所以使用 kill Redis 进程的 PID也可以正常结束<br>Redis，效果与发送SHUTDOWN命令一样。</p>
<p>Redis是一个字典结构的存储服务器，而实际上一个Redis实例提供了多个用<br>来存储数据的字典，客户端可以指定将数据存储在哪个字典中。这与我们熟知的在一个关系<br>数据库实例中可以创建多个数据库类似，所以可以将其中的每个字典都理解成一个独立的数<br>据库。</p>
<p>每个数据库对外都是以一个从0开始的递增数字命名，Redis默认支持16个数据库，可以<br>通过配置参数databases来修改这一数字。客户端与Redis建立连接后会自动选择0号数据库，<br>不过可以随时使用SELECT命令更换数据库，</p>
<p>然而这些以数字命名的数据库又与我们理解的数据库有所区别。首先 Redis 不支持自定<br>义数据库的名字，每个数据库都以编号命名，开发者必须自己记录哪些数据库存储了哪些数<br>据。另外 Redis 也不支持为每个数据库设置不同的访问密码，所以一个客户端要么可以访问<br>全部数据库，要么连一个数据库也没有权限访问。最重要的一点是多个数据库之间并不是完<br>全隔离的，比如FLUSHALL命令可以清空一个Redis实例中所有数据库中的数据。</p>
<h2 id="入门"><a href="#入门" class="headerlink" title="入门"></a>入门</h2><h3 id="基本命令"><a href="#基本命令" class="headerlink" title="基本命令"></a>基本命令</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">keys pattern        pattern支持glob风格通配符格式</span><br><span class="line">exists key          如果键存在则返回整数类型1，否则返回0</span><br><span class="line">del key	[key ...]	可以删除一个或多个键，返回值是删除的键的个数。</span><br><span class="line">type key             TYPE命令用来获得键值的数据类型，返回值可能是string,（字符串类型            hash（散列类型）、list（列表类型）、set（集合类型）、zset（有序集合类型）。</span><br></pre></td></tr></table></figure>

<h3 id="字符串类型"><a href="#字符串类型" class="headerlink" title="字符串类型"></a>字符串类型</h3><p>字符串类型是 Redis 中最基本的数据类型，它能存储任何形式的字符串，包括二进制数<br>据。你可以用其存储用户的邮箱、JSON 化的对象甚至是一张图片。一个字符串类型键允许<br>存储的数据的最大容量是512 MB</p>
<p>字符串类型是其他4种数据类型的基础，其他数据类型和字符串类型的差别从某种角度<br>来说只是组织字符串的形式不同。</p>
<h4 id="命令"><a href="#命令" class="headerlink" title="命令"></a>命令</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">set key value     赋值</span><br><span class="line">get key           取值</span><br><span class="line">incr key          让当前键值递增并返回递增的值</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">incrby key increment  递增一个数值</span><br><span class="line">decr   key         递减</span><br><span class="line">decrby key decrement  减少某个值</span><br><span class="line">incrbyfloat key increment  递增一个双精度浮点数</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">append key value    向键值的末尾追加value，若键不存在，相当于set key value</span><br><span class="line">strlen key          返回键值的长度，如果不存在返回0</span><br><span class="line">mget key [key ...]  同时获得多个键值</span><br><span class="line">mset key value [key value ...]   同时设置多个键值,MGET/MSET 与GET/SET 相似，不过								MGET/MSET 可以同时获得/设置多个键的键值。</span><br></pre></td></tr></table></figure>



<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">一个字节由8个二进制位组成，Redis提供了4个命令可以直接对二进制位进行操作:            getbit key offset                获得一个字符串类型键指定位置的二进制位的值（0或1）</span><br><span class="line">setbit key offset value          设置字符串类型键指定位置的二进制位的值,返回旧值</span><br><span class="line">bitcount key offset [start][end] 获得字符串类型键中值是1的二进制位个数</span><br><span class="line">bitop operation destkey key [key...]     BITOP命令可以对多个字符串类型键进行位运									算，并将结果存储在destkey参数指定的键中。BITOP命令								   支持的运算操作有AND、OR、XOR和NOT</span><br></pre></td></tr></table></figure>

<h3 id="散列"><a href="#散列" class="headerlink" title="散列"></a>散列</h3><p>Redis 是采用字典结构以键值对的形式存储数据的，而散列类型（hash）的键值也是一种字典结构，其存储了字段（field）和字段值的映射，但字段值只能是字符串，不支持其他数据类型，换句话说，散列类型不能嵌套其他的数据类型。一个散列类型键可以包含至多232−1个字段。提示 除了散列类型，Redis 的其他数据类型同样不支持数据类型嵌套。比如集合类型的每个元素都只能是字符串，不能是另一个集合或散列表等。</p>
<p>散列类型适合存储对象：使用对象类别和 ID 构成键名，使用字段表示对象的属性，而<br>字段值则存储属性值。</p>
<h4 id="命令-1"><a href="#命令-1" class="headerlink" title="命令"></a>命令</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hset key field value                   给字段赋值</span><br><span class="line">hget key field                         获得字段的值</span><br><span class="line">hmset key field value [field value ...] 同时设置多个字段的值</span><br><span class="line">hmget key field [field ...]             同时获得多个字段的值</span><br><span class="line">hgetall key                             获取键中所有字段和字段值</span><br></pre></td></tr></table></figure>

<p>HSET 命令的方便之处在于不区分插入和更新操作，这意味着修改数据时不用事先判断<br>字段是否存在来决定要执行的是插入操作（update）还是更新操作（insert）当执行的是插<br>入操作时（即之前字段不存在）HSET命令会返回1，当执行的是更新操作时（即之前字段已<br>经存在）HSET命令会返回0。</p>
<p>提示 在Redis中每个键都属于一个明确的数据类型，如通过 HSET命令建立的键是散列类<br>型，通过SET命令建立的键是字符串类型等等。使用一种数据类型的命令操作另一种数据类<br>型的键会提示错误：”ERR Operation against a key holding the wrong kind of value”</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hexists key field   判断一个字段是否存在。如果存在则返回1，否则返回0（如果键不存在也会返回0）。</span><br><span class="line"></span><br><span class="line">hsetnx key field value  与HSET命令类似，区别在于如果字段已经存在，HSETNX命令将不</span><br><span class="line">执行任何操作。</span><br><span class="line"></span><br><span class="line">hincrby key field increment   可以使字段值增加指定的整数,散列类型没有 HINCR 命令</span><br><span class="line"></span><br><span class="line">hdel key field [field ...]   删除一个或多个字段，返回值是被删除的字段个数</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hkeys key               需要获取键中所有字段的名字而不需要字段值  </span><br><span class="line">hvals key               获得键中所有字段值</span><br><span class="line">hlen key                获得字段数量</span><br></pre></td></tr></table></figure>

<h3 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h3><p>列表类型（list）可以存储一个有序的字符串列表，常用的操作是向列表两端添加元素，<br>或者获得列表的某一个片段。</p>
<p>列表类型内部是使用双向链表（double linked list）实现的，所以向列表两端添加元素的<br>时间复杂度为O(1)，获取越接近两端的元素速度就越快。这意味着即使是一个有几千万个元<br>素的列表，获取头部或尾部的10条记录也是极快的（和从只有20个元素的列表中获取头部或<br>尾部的10条记录的速度是一样的）。</p>
<p>不过使用链表的代价是通过索引访问元素比较慢。</p>
<p>这种特性使列表类型能非常快速地完成关系数据库难以应付的场景：如社交网站的新鲜<br>事，我们关心的只是最新的内容，使用列表类型存储，即使新鲜事的总数达到几千万个，获<br>取其中最新的100条数据也是极快的。同样因为在两端插入记录的时间复杂度是O(1)，列表<br>类型也适合用来记录日志，可以保证加入新日志的速度不会受到已有日志数量的影响。</p>
<p>借助列表类型，Redis还可以作为队列使用</p>
<p>与散列类型键最多能容纳的字段数量相同，一个列表类型键最多能容纳232−1个元素。</p>
<h4 id="命令-2"><a href="#命令-2" class="headerlink" title="命令"></a>命令</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">lpush key value [value]     向列表左边增加元素，返回值表示增加元素后列表的长度。</span><br><span class="line">rpush key value [value]     向列表右边增加元素</span><br><span class="line">lpop key    从列表左边弹出一个元素,第一步是将列表左边的元素从列表中移除，第二步是返回被移             除的元素值。</span><br><span class="line">rpop key    从列表右边弹出一个元素</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">llen key    获取列表中元素的个数,当键不存在时LLEN会返回0：</span><br><span class="line">lrange key start stop    返回索引从 start到 stop之间的所有元素（包含两端的元素）</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">lrem key count value    删除列表中前count个值为value的元素，返回值是实际删除的元素个数。</span><br><span class="line">（1）当 count &gt; 0时 LREM 命令会从列表左边开始删除前 count 个值为 value的元素。</span><br><span class="line">（2）当 count &lt; 0时 LREM 命令会从列表右边开始删除前|count|个值为 value 的元素。</span><br><span class="line">（3）当 count = 0是 LREM命令会删除所有值为 value的元素。</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">lindex key index          返回指定索引的元素，索引从0开始,如果index是负数则表示从右边开始计算的索引，最右边元素的索引是−1</span><br><span class="line">lset key index value  将索引为index的元素赋值为value</span><br><span class="line">ltrim key start end   删除指定索引范围之外的所有元素</span><br><span class="line">linsert key before|after pivot value  在列表中从左到右查找值为 pivot 的元素，然后根据第二个参数是</span><br><span class="line">BEFORE还是AFTER来决定将value插入到该元素的前面还是后面。</span><br><span class="line"></span><br><span class="line">rpoplpush source destination    将元素从一个列表转到另一个列表</span><br></pre></td></tr></table></figure>

<h3 id="集合类型"><a href="#集合类型" class="headerlink" title="集合类型"></a>集合类型</h3><p>在集合中的每个元素都是不同的，且没有顺序。一个集合类型（set）键可以存储至多232 −1个（相信这个数字对大家来说已经很熟悉了）字符串。</p>
<p>集合类型的常用操作是向集合中加入或删除元素、判断某个元素是否存在等，由于集合<br>类型在Redis内部是使用值为空的散列表（hash table）实现的所以这些操作的时间复杂度都<br>是O(1)。最方便的是多个集合类型键之间还可以进行并集、交集和差集运算，稍后就会看到<br>灵活运用这一特性带来的便利。</p>
<h4 id="命令-3"><a href="#命令-3" class="headerlink" title="命令"></a>命令</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sadd key member [member ...]   向集合中增加一个或多个元素，如果键不存在则会自动创建。</span><br><span class="line">srem key member [member ...]   从集合中删除一个或多个元素，并返回删除成功的个数</span><br><span class="line">smembers key                   返回集合中的所有元素</span><br><span class="line">sismember key member     判断一个元素是否在集合中是一个时间复杂度为O(1)的操作</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sdiff key [key ...]            对多个集合执行差集运算</span><br><span class="line">sinter key [key ...]           对多个集合执行交集运算</span><br><span class="line">sunion key [key ...]           对多个集合执行并集运算</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">scard key         获得集合中的元素个数</span><br><span class="line">sdiffstore destination key [key ...]   不会直接返回运算结果，</span><br><span class="line">而是将结果存储在destination键中。</span><br><span class="line">sinterstore destination key [key ...]</span><br><span class="line">sunionstore destination key [key ...]</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">srandmember key [count]   随机获得集合中的元素</span><br><span class="line">还可以传递count参数来一次随机获得多个元素，根据count的正负不同，具体表现也不同。</span><br><span class="line">1）当count为正数时，SRANDMEMBER会随机从集合里获得count个不重复的元素。</span><br><span class="line">如果count的值大于集合中的元素个数，则SRANDMEMBER会返回集合中的全部元素。</span><br><span class="line">2）当count为负数时，SRANDMEMBER会随机从集合里获得|count|个的元素，这些元</span><br><span class="line">素有可能相同。</span><br><span class="line">SRANDMEMBER 命令返回的数据似乎并不是非常的随机出现这种情况是由集合类型采用的存储结构（散列表）造成的。散列表使用散列函数将元素映射到不同的存储位置（桶）上以实现O(1)时间复杂度的元素查找，举个例子，当使用散列表存储元素b时，使用散列函数计算出b的散列值是0，所以将b存入编号为0的桶（bucket）中，下次要查找b时就可以用同样的散列函数再次计算b的散列值并直接到相</span><br><span class="line">应的桶中找到 b。当两个不同的元素的散列值相同时会出现冲突，Redis 使用拉链法来解决冲</span><br><span class="line">突，即将散列值冲突的元素以链表的形式存入同一桶中，查找元素时先找到元素对应的桶，</span><br><span class="line">然后再从桶中的链表中找到对应的元素。使用SRANDMEMBER命令从集合中获得一个随机</span><br><span class="line">元素时，Redis首先会从所有桶中随机选择一个桶，然后再从桶中的所有元素中随机选择一个</span><br><span class="line">元素，所以元素所在的桶中的元素数量越少，其被随机选中的可能性就越大，</span><br></pre></td></tr></table></figure>

<h3 id="有序集合"><a href="#有序集合" class="headerlink" title="有序集合"></a>有序集合</h3><p>在集合类型的基础上有序集合类型为集合中的每个元素都关联了一个分数，这使得我们<br>不仅可以完成插入、删除和判断元素是否存在等集合类型支持的操作，还能够获得分数最高<br>（或最低）的前N个元素、获得指定分数范围内的元素等与分数有关的操作。虽然集合中每<br>个元素都是不同的，但是它们的分数却可以相同。</p>
<p>有序集合类型在某些方面和列表类型有些相似。<br>（1）二者都是有序的。（2）二者都可以获得某一范围的元素。</p>
<p>但是二者有着很大的区别，这使得它们的应用场景也是不同的。<br>（1）列表类型是通过链表实现的，获取靠近两端的数据速度极快，而当元素增多后，<br>访问中间数据的速度会较慢，所以它更加适合实现如“新鲜事”或“日志”这样很少访问中间元<br>素的应用。（2）有序集合类型是使用散列表和跳跃表（Skip list）实现的，所以即使读取位于中间<br>部分的数据速度也很快（时间复杂度是O(log(N))）（3）列表中不能简单地调整某个元素的位置，但是有序集合可以（通过更改这个元素的分数）。（4）有序集合要比列表类型更耗费内存。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">zadd key score member [score member ...] 加入一个元素和该元素的分数,如果该元素已经存在则会用新的分数替换原有的分数</span><br><span class="line">zscore key member获得元素的分数</span><br><span class="line">zrange key start stop [withscores]  按照元素分数从小到大的顺序返回索引从 start到stop之间的所有元素,如果需要同时获得元素的分数的话可以在 ZRANGE 命令的尾部加上 WITHSCORES 参数，如果两个元素的分数相同，Redis会按照字典顺序（即&quot;0&quot;&lt;&quot;9&quot;&lt;&quot;A&quot;&lt;&quot;Z&quot;&lt;&quot;a&quot;&lt;&quot;z&quot;这样的顺序）来进行排列。再进一步，如果元素的值是中文怎么处理呢？答案是取决于中文的编码方</span><br><span class="line">式，如使用UTF-8编码</span><br><span class="line">zrevrange key start stop [withscores]  按照元素分数从大到小的顺序给出结果</span><br><span class="line"></span><br><span class="line">zrangebyscore min max [withscores][limit offset count] 该命令按照元素分数从小到大</span><br><span class="line">的顺序返回分数在min和max之间（包含min和max）的元素,</span><br><span class="line">如果希望分数范围不包含端点值，可以在分数前加上“(”符号</span><br><span class="line">min和max还支持无穷大，同ZADD命令一样，-inf和+inf分别表示负无穷和正无穷。比如你希望得到所有分数高于80分（不包含80分）的人的名单，但你却不知道最高分是多少,（虽然有些背离现实，但是为了叙述方便，这里假设可以获得的分数是无上限的），这时就可以用上+inf了</span><br><span class="line"> LIMIT offset count</span><br><span class="line">与 SQL 中的用法基本相同，即在获得的元素列表的基础上向后偏移offset个元素，并且只获</span><br><span class="line">取前count个元素。</span><br><span class="line">ZINCRBY key increment member   命令可以增加一个元素的分数，返回值是更改后的分数。</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">zcard key 获得集合中元素的数量</span><br><span class="line">zcount key min max 获得指定分数范围内的元素个数</span><br><span class="line">zrem key member[member ...] 删除一个或多个元素</span><br><span class="line">zremrangebyrank key start stop 按照元素分数从小到大的顺序（即索引 0表示最小的值）</span><br><span class="line">删除处在指定排名范围内的所有元素，并返回删除的元素数量。</span><br><span class="line">zremrangebyscore key min max  删除指定分数范围内的所有元素</span><br><span class="line">zrank key member  按照元素分数从小到大的顺序获得指定的元素的排名（从0开始，即分数</span><br><span class="line">最小的元素排名为0）。</span><br><span class="line">zinterstore</span><br></pre></td></tr></table></figure>

<h2 id="进阶"><a href="#进阶" class="headerlink" title="进阶"></a>进阶</h2><h3 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h3><p>Redis中的事务（transaction）是一组命令的集合。事务同命令一样都是 Redis 的最小执<br>行单位，一个事务中的命令要么都执行，要么都不执行。</p>
<p>事务的原理是先将属于一个事务的命令发送给Redis，然后再让Redis依次执行这些命<br>令。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">redis&gt; multi</span><br><span class="line">ok</span><br><span class="line">redis&gt; sadd &quot;user:1:following&quot; 2</span><br><span class="line">queued</span><br><span class="line">redis&gt; sadd &quot;user:2:followers&quot; 1</span><br><span class="line">queued</span><br><span class="line">redis&gt; exec</span><br><span class="line">1)(integer) 1</span><br><span class="line">2)(integer) 1</span><br><span class="line">首先使用MULTI命令告诉Redis：“下面我发给你的命令属于同一个事务，你先不要执行，而是把它们暂时存起来。”Redis回答：“OK。”</span><br><span class="line">而后我们发送了两个 SADD命令来实现关注和被关注操作，可以看到 Redis 遵守了承诺，没有执行这些命令，而是返回QUEUED表示这两条命令已经进入等待执行的事务队列中了。</span><br><span class="line">当把所有要在同一个事务中执行的命令都发给 Redis 后，我们使用 EXEC 命令告诉Redis</span><br><span class="line">将等待执行的事务队列中的所有命令（即刚才所有返回QUEUED的命令）按照发送顺序依次执行。EXEC 命令的返回值就是这些命令的返回值组成的列表，返回值顺序和命令的顺序相同。</span><br><span class="line"></span><br><span class="line">Redis保证一个事务中的所有命令要么都执行，要么都不执行。如果在发送EXEC命令前客户端断线了，则 Redis 会清空事务队列，事务中的所有命令都不会执行。而一旦客户端发送了EXEC命令，所有的命令就都会被执行，即使此后客户端断线也没关系，因为Redis中已经记录了所有要执行的命令。</span><br><span class="line">除此之外，Redis 的事务还能保证一个事务内的命令依次执行而不被其他命令插入。试想客户端A需要执行几条命令，同时客户端B发送了一条命令，如果不使用事务，则客户端B的命令可能会插入到客户端A的几条命令中执行。如果不希望发生这种情况，也可以使用事务。</span><br></pre></td></tr></table></figure>

<h3 id="错误处理"><a href="#错误处理" class="headerlink" title="错误处理"></a>错误处理</h3><p>如果一个事务中的某个命令执行出错，Redis 会怎样处理呢？要回答这个问题，首先需要知道什么原因会导致命令执行出错。</p>
<p>（1）语法错误。语法错误指命令不存在或者命令参数的个数不对。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt; multi</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; set name itingyu</span><br><span class="line">QUEUED</span><br><span class="line">127.0.0.1:6379&gt; set age</span><br><span class="line">(error) ERR wrong number of arguments for &#x27;set&#x27; command</span><br><span class="line">127.0.0.1:6379&gt; errorcommand age</span><br><span class="line">(error) ERR unknown command &#x27;errorcommand&#x27;</span><br><span class="line">127.0.0.1:6379&gt; exec</span><br><span class="line">(error) EXECABORT Transaction discarded because of previous errors.</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure>

<p>跟在MULTI命令后执行了3个命令：一个是正确的命令，成功地加入事务队列；其余两<br>个命令都有语法错误。而只要有一个命令有语法错误，执行 EXEC 命令后 Redis 就会直接返<br>回错误，连语法正确的命令也不会执行。</p>
<p>（2）运行错误。运行错误指在命令执行时出现的错误，比如使用散列类型的命令操作<br>集合类型的键，这种错误在实际执行之前 Redis 是无法发现的，所以在事务里这样的命令是<br>会被 Redis 接受并执行的。如果事务里的一条命令出现了运行错误，事务里其他的命令依然<br>会继续执行（包括出错命令之后的命令）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt; multi</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; set key 1</span><br><span class="line">QUEUED</span><br><span class="line">127.0.0.1:6379&gt; sadd key 2</span><br><span class="line">QUEUED</span><br><span class="line">127.0.0.1:6379&gt; set key 3</span><br><span class="line">QUEUED</span><br><span class="line">127.0.0.1:6379&gt; exec</span><br><span class="line">1) OK</span><br><span class="line">2) (error) WRONGTYPE Operation against a key holding the wrong kind of value</span><br><span class="line">3) OK</span><br><span class="line">127.0.0.1:6379&gt; get key</span><br><span class="line">&quot;3&quot;</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure>

<p>可见虽然 SADD key 2出现了错误，但是 SET key 3依然执行了。<br>Redis的事务没有关系数据库事务提供的回滚（rollback）[1] 功能。为此开发者必须在事<br>务执行出错后自己收拾剩下的摊子（将数据库复原回事务执行前的状态等）。</p>
<p>不过由于 Redis 不支持回滚功能，也使得 Redis 在事务上可以保持简洁和快速。另外回<br>顾刚才提到的会导致事务执行失败的两种错误，其中语法错误完全可以在开发时找出并解<br>决，另外如果能够很好地规划数据库（保证键名规范等）的使用，是不会出现如命令与数据<br>类型不匹配这样的运行错误的。</p>
<h3 id="watch命令介绍"><a href="#watch命令介绍" class="headerlink" title="watch命令介绍"></a>watch命令介绍</h3><p>我们已经知道在一个事务中只有当所有命令都依次执行完后才能得到每个结果的返回<br>值，可是有些情况下需要先获得一条命令的返回值，然后再根据这个值执行下一条命令。例<br>如介绍INCR命令时曾经说过使用GET和SET命令自己实现incr函数会出现竞态条件，</p>
<p>肯定会有很多读者想到可以用事务来实现incr函数以防止竞态条件，可是因为事务中的<br>每个命令的执行结果都是最后一起返回的，所以无法将前一条命令的结果作为下一条命令的<br>参数，即在执行SET命令时无法获得GET命令的返回值，也就无法做到增1的功能了。</p>
<p>我们需要换一种思路。即在GET获得键值后保证该键值不被其他客户端修改，直到函数执行完成后才允许其他客户端修改该键键值，这样也可以防止竞态条件。要实现这一思路需要请出事务家族的另一位成员：WATCH。</p>
<p>WATCH 命令可以监控一个或多个键，一旦其中有一个键被修改（或删除），之后的事务就不会执行。监控一直持续到EXEC 命令（事务中的命令是在 EXEC 之后才执行的，所以在 MULTI 命令后可以修改WATCH监控的键值）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt; set key 1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; watch key</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; set key 2</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; multi</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; set key 3</span><br><span class="line">QUEUED</span><br><span class="line">127.0.0.1:6379&gt; exec</span><br><span class="line">(nil)</span><br><span class="line">127.0.0.1:6379&gt; get key</span><br><span class="line">&quot;2&quot;</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure>

<p>上例中在执行 WATCH命令后、事务执行前修改了key的值（即 SET key 2），所以最后<br>事务中的命令 SET key 3没有执行，EXEC命令返回空结果。</p>
<p>学会了WATCH命令就可以通过事务自己实现incr函数了</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def incr($key)</span><br><span class="line">	WATCH $key</span><br><span class="line">	$value = GET $key</span><br><span class="line">	if not $value</span><br><span class="line">	$value = 0</span><br><span class="line">	$value = $value + 1</span><br><span class="line">	MULTI</span><br><span class="line">	SET $key, $value</span><br><span class="line">	result = EXEC</span><br><span class="line">	return result[0]</span><br></pre></td></tr></table></figure>

<p>因为EXEC命令返回值是多行字符串类型，所以代码中使用result[0]来获得其中第一个结<br>果。</p>
<p>提示 由于WATCH命令的作用只是当被监控的键值被修改后阻止之后一个事务的执行，<br>而不能保证其他客户端不修改这一键值，所以我们需要在EXEC执行失败后重新执行整个函<br>数。</p>
<p><strong>执行 EXEC 命令后会取消对所有键的监控，如果不想执行事务中的命令也可以使用</strong><br><strong>UNWATCH命令来取消监控。</strong></p>
<p>在代码中会判断要赋值的字段是否存在，如果字段不存在的话就不执行事务中的命令，<br>但需要使用UNWATCH命令来保证下一个事务的执行不会受到影响。</p>
<h2 id="过期时间"><a href="#过期时间" class="headerlink" title="过期时间"></a>过期时间</h2><p>在实际的开发中经常会遇到一些有时效的数据，比如限时优惠活动、缓存或验证码等，<br>过了一定的时间就需要删除这些数据。在关系数据库中一般需要额外的一个字段记录到期时<br>间，然后定期检测删除过期数据。而在Redis中可以使用 EXPIRE命令设置一个键的过期时<br>间，到时间后Redis会自动删除它。</p>
<h3 id="命令介绍"><a href="#命令介绍" class="headerlink" title="命令介绍"></a>命令介绍</h3><p>EXPIRE 命令的使用方法为 <strong>EXPIRE key seconds</strong>，其中 seconds 参数表示键的过期时<br>间，单位是秒。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt; keys *</span><br><span class="line">1) &quot;mylist&quot;</span><br><span class="line">127.0.0.1:6379&gt; expire mylist 1</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; keys *</span><br><span class="line">(empty list or set)</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure>

<p>如果想知道一个键还有多久的时间会被删除，可以使用<strong>TTL命令。返回值是键的剩余时</strong><br><strong>间（单位是秒）,</strong></p>
<p><strong>当键不存在时TTL命令会返回−2。</strong></p>
<p>那么<strong>没有为键设置过期时间（即永久存在</strong>，这是建立一个键后的默认情况）的情况下会<br>返回什么呢？答案是<strong>返回−1</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt; keys *</span><br><span class="line">(empty list or set)</span><br><span class="line">127.0.0.1:6379&gt; set key 1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; ttl key</span><br><span class="line">(integer) -1</span><br><span class="line">127.0.0.1:6379&gt; expire key 10</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; ttl key</span><br><span class="line">(integer) 7</span><br><span class="line">127.0.0.1:6379&gt; ttl key</span><br><span class="line">(integer) 5</span><br><span class="line">127.0.0.1:6379&gt; ttl key</span><br><span class="line">(integer) 4</span><br><span class="line">127.0.0.1:6379&gt; ttl key</span><br><span class="line">(integer) 3</span><br><span class="line">127.0.0.1:6379&gt; ttl key</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; ttl key</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; ttl key</span><br><span class="line">(integer) -2</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure>

<p>如果想取消键的过期时间设置（即将键恢复成永久的），则可以使用PERSIST命令。如<br>果过期时间被成功清除则返回1；否则返回0（因为键不存在或键本来就是永久的）：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt; set key 1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; expire key 20</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; ttl key</span><br><span class="line">(integer) 17</span><br><span class="line">127.0.0.1:6379&gt; persist key</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; ttl key</span><br><span class="line">(integer) -1</span><br><span class="line">127.0.0.1:6379&gt; persist key</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; persist key1</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure>

<p>除了PERSIST命令之外，使用SET或GETSET命令为键赋值也会同时清除键的过期时间</p>
<p>其他只对键值进行操作的命令（如INCR、LPUSH、HSET、ZREM）均不会影响键的过期时间。EXPIRE命令的seconds参数必须是整数，所以最小单位是1秒。如果想要更精确的控制键的过期时间应该使用 PEXPIRE命令，PEXPIRE命令与 EXPIRE的唯一区别是前者的时间单位是毫秒，即 PEXPIRE key 1000 与 EXPIRE key 1 等价。对应地可以用 PTTL命令以毫秒为单位返回键的剩余时间。</p>
<p><strong>提示 如果使用 WATCH命令监测了一个拥有过期时间的键，该键时间到期自动删除并不</strong><br><strong>会被WATCH命令认为该键被改变。</strong></p>
<p>另外还有两个相对不太常用的命令：EXPIREAT和PEXPIREAT。EXPIREAT命令与EXPIRE命令的差别在于前者使用Unix时间作为第二个参数表示键的过期时刻。PEXPIREAT命令与EXPIREAT命令的区别是前者的时间单位是毫秒。</p>
<h3 id="实现访问速率限制"><a href="#实现访问速率限制" class="headerlink" title="实现访问速率限制"></a>实现访问速率限制</h3><p>为了减轻服务器的压力，需要限制每个用户（以IP计）一段时间的最大访问量。与时间有关的操作很容易想到EXPIRE命令。</p>
<p>例如要限制每分钟每个用户最多只能访问100个页面，思路是对每个用户使用一个名为<br>rate.limiting:用户 IP的字符串类型键，每次用户访问则使用 INCR命令递增该键的键值，如果<br>递增后的值是1（第一次访问页面），则同时还要设置该键的过期时间为1分钟。这样每次用<br>户访问页面时都读取该键的键值，如果超过了100就表明该用户的访问频率超过了限制，需<br>要提示用户稍后访问。该键每分钟会自动被删除，所以下一分钟用户的访问次数又会重新计<br>算，也就达到了限制访问频率的目的。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$isKeyExists = EXISTS rate.limiting:$IP</span><br><span class="line">if $isKeyExists is 1</span><br><span class="line">	$times = INCR rate.limiting:$IP</span><br><span class="line">	if $times &gt; 100</span><br><span class="line">	print 访问频率超过了限制，请稍后再试。</span><br><span class="line">	exit</span><br><span class="line">else</span><br><span class="line">	MULTI</span><br><span class="line">	INCR rate.limiting:$IP</span><br><span class="line">	EXPIRE $keyName, 60</span><br><span class="line">	EXEC</span><br></pre></td></tr></table></figure>

<p>事实上，4.2.2节中的代码仍然有个问题：如果一个用户在一分钟的第一秒访问了一次博<br>客，在同一分钟的最后一秒访问了9次，又在下一分钟的第一秒访问了10次，这样的访问是<br>可以通过现在的访问频率限制的，但实际上该用户在2秒内访问了19次博客，这与每个用户<br>每分钟只能访问10次的限制差距较大。尽管这种情况比较极端，但是在一些场合中还是需要<br>粒度更小的控制方案。如果要精确地保证每分钟最多访问10次，需要记录下用户每次访问的<br>时间。因此对每个用户，我们使用一个列表类型的键来记录他最近10次访问博客的时间。一<br>旦键中的元素超过 10 个，就判断时间最早的元素距现在的时间是否小于 1分钟。如果是则表<br>示用户最近1分钟的访问次数超过了10次；如果不是就将现在的时间加入到列表中，同时把<br>最早的元素删除。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$listLength = LLEN rate.limiting:$IP</span><br><span class="line">if $listLength &lt; 10</span><br><span class="line">	LPUSH rate.limiting:$IP, now()</span><br><span class="line">else</span><br><span class="line">	$time = LINDEX rate.limiting:$IP, -1</span><br><span class="line">	if now() - $time &lt; 60</span><br><span class="line">	print 访问频率超过了限制，请稍后再试。</span><br><span class="line">	else</span><br><span class="line">	LPUSH rate.limiting:$IP, now()</span><br><span class="line">	LTRIM rate.limiting:$IP, 0, 9</span><br></pre></td></tr></table></figure>

<p>代码中 now()的功能是获得当前的 Unix 时间。由于需要记录每次访问的时间，所以当要<br>限制“A时间最多访问B次”时，如果“B”的数值较大，此方法会占用较多的存储空间，实际使<br>用时还需要开发者自己去权衡。除此之外该方法也会出现竞态条件，同样可以通过脚本功能<br>避免，具体在第6章会介绍到。</p>
<h3 id="实现缓存"><a href="#实现缓存" class="headerlink" title="实现缓存"></a>实现缓存</h3><p>为了提高网站的负载能力，常常需要将一些访问频率较高但是对CPU或IO资源消耗较大的操作的结果缓存起来，并希望让这些缓存过一段时间自动过期。</p>
<p>比如教务网站要对全校所有学生的各个科目的成绩汇总排名，并在首页上显示前10名的学生姓名，由于计算过程较耗资源，所以可以将结果使用一个 Redis 的字符串键缓存起来。由于学生成绩总在不断地变化，需要每隔两个小时就重新计算一次排名，这可以通过给键设置过期时间的方式实现。每次用户访问首页时程序先查询缓存键是否存在，如果存在则直接使用缓存的值；否则重新计算排名并将计算结果赋值给该键并同时设置该键的过期时间为两个小时。</p>
<p>当服务器内存有限时，如果大量地使用缓存键且过期时间设置得过长就会导致 Redis 占满内存；另一方面如果为了防止 Redis 占用内存过大而将缓存键的过期时间设得太短，就可能导致缓存命中率过低并且大量内存白白地闲置。实际开发中会发现很难为缓存键设置合理的过期时间，为此可以限制 Redis 能够使用的最大内存，并让Redis按照一定的规则淘汰不需要的缓存键，这种方式在只将Redis用作缓存系统时非常实用。</p>
<p>具体的设置方法为：修改配置文件的maxmemory参数，限制Redis最大可用内存大小（单位是字节），当超出了这个限制时Redis会依据maxmemory-policy参数指定的策略来删除不需要的键直到Redis占用的内存小于指定内存。maxmemory-policy支持的规则如表4-1所示。其中的LRU（Least Recently Used）算法即“最近最少使用”，其认为最近最少使用的键在未来一段时间内也不会被用到，即当需要空间时这些键是可以被删除的。如当maxmemory-policy设为allkeys-lru时，一旦Redis占用的内存超过了限制值，Redis会不断地删除数据库中最近最少使用的键[2] ，直到占用的内存小于限制值。</p>
<h2 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h2><p>有序集合常见的使用场景是大数据排序，如游戏的玩家排行榜，所以很少会需要获得键中的全部数据。同样 Redis 认为开发者在做完交集、并集运算后不需要直接获得全部结果，而是会希望将结果存入新的键中以便后续处理。这解释了为什么有序集合只有ZINTERSTORE和ZUNIONSTORE命令而没有ZINTER和ZUNION命令。</p>
<h3 id="SORT命令"><a href="#SORT命令" class="headerlink" title="SORT命令"></a>SORT命令</h3><p>SORT命令可以对列表类型、集合类型和有序集合类型键进行排序，并且可以完成与关系数据库中的连接查询相类似的任务。除了集合类型，SORT 命令还可以对列表类型和有序集合类型进行排序，在对有序集合类型排序时会忽略元素的分数，只针对元素自身的值进行排序。</p>
<p>SORT 命令默认是按照从小到大的顺序排列，SORT命令的DESC参数可以实现<br>将元素按照从大到小的顺序排列。</p>
<p>SORT命令还支持LIMIT参数来返回指定范围的结果。用法和 SQL 语句一样，LIMIT offset count，表示跳过前 offset 个元素并获取之后的count个元素。</p>
<h3 id="by参数"><a href="#by参数" class="headerlink" title="by参数"></a>by参数</h3><p>BY参数的语法为BY参考键。其中参考键可以是字符串类型键或者是散列类型键的某个<br>字段（表示为键名-&gt;字段名）。如果提供了 BY 参数，SORT 命令将不再依据元素自身的值<br>进行排序，而是对每个元素使用元素的值替换参考键中的第一个“*”并获取其值，然后依据<br>该值对元素排序。</p>
<h3 id="Get参数"><a href="#Get参数" class="headerlink" title="Get参数"></a>Get参数</h3><p>GET参数不影响排序，它的作用是使 SORT命令的返回结果不再是元素自身的值，而是<br>GET参数中指定的键值。</p>
<p>GET参数的规则和BY参数一样，GET参数也支持字符串类型和散列<br>类型的键，并使用“*”作为占位符。</p>
<p>在一个SORT命令中可以有多个GET参数（而BY参数只能有一个）</p>
<p>可见有N个GET参数，每个元素返回的结果就有N行。这时有个问题：如果还需要返回<br>文章ID 该怎么办？答案是使用 GET #。也就是说，GET #会返回元素本身的值。</p>
<h3 id="store参数"><a href="#store参数" class="headerlink" title="store参数"></a>store参数</h3><p>默认情况下SORT会直接返回排序结果，如果希望保存排序结果，可以使用STORE参<br>数。</p>
<p>保存后的键的类型为列表类型，如果键已经存在则会覆盖它。加上STORE参数后SORT<br>命令的返回值为结果的个数。</p>
<p>STORE参数常用来结合EXPIRE命令缓存排序结果</p>
<h3 id="性能优化"><a href="#性能优化" class="headerlink" title="性能优化"></a>性能优化</h3><p>SORT是Redis中最强大最复杂的命令之一，如果使用不好很容易成为性能瓶颈。SORT命<br>令的时间复杂度是O(n+mlog(m))，其中n表示要排序的列表（集合或有序集合）中的元素个<br>数，m表示要返回的元素个数。当n较大的时候SORT命令的性能相对较低，并且Redis在排序<br>前会建立一个长度为n[4] 的容器来存储待排序的元素，虽然是一个临时的过程，但如果同时<br>进行较多的大数据量排序操作则会严重影响性能。</p>
<p>所以开发中使用SORT命令时需要注意以下几点。<br>（1）尽可能减少待排序键中元素的数量（使N尽可能小）。<br>（2）使用LIMIT参数只获取需要的数据（使M尽可能小）。<br>（3）如果要排序的数据数量较大，尽可能使用STORE参数将结果缓存。</p>
<h2 id="消息通知"><a href="#消息通知" class="headerlink" title="消息通知"></a>消息通知</h2><h3 id="任务队列"><a href="#任务队列" class="headerlink" title="任务队列"></a>任务队列</h3><p>当页面需要进行如发送邮件、复杂数据运算等耗时较长的操作时会阻塞页面的渲染。为了避免用户等待太久，应该使用独立的线程来完成这类操作。不过一些编程语言或框架不易实现多线程，这时很容易就会想到通过其他进程来实现。就小白的例子来说，设想有一个进程能够完成发邮件的功能，那么在页面中只需要想办法通知这个进程向指定的地址发送邮件就可以了。</p>
<p>通知的过程可以借助任务队列来实现。任务队列顾名思义，就是“传递任务的队列”。与<br>任务队列进行交互的实体有两类，一类是生产者（producer），另一类是消费者<br>（consumer）。生产者会将需要处理的任务放入任务队列中，而消费者则不断地从任务队列<br>中读入任务信息并执行。</p>
<p>对于发邮件这个操作来说页面程序就是生产者，而发邮件的进程就是消费者。当需要发<br>送邮件时，页面程序会将收件地址、邮件主题和邮件正文组装成一个任务后存入任务队列<br>中。同时发邮件的进程会不断检查任务队列，一旦发现有新的任务便会将其从队列中取出并<br>执行。由此实现了进程间的通信。</p>
<p>使用任务队列有如下好处。</p>
<p>1．松耦合<br>        生产者和消费者无需知道彼此的实现细节，只需要约定好任务的描述格式。这使得生产<br>者和消费者可以由不同的团队使用不同的编程语言编写。</p>
<p>2．易于扩展<br>        消费者可以有多个，而且可以分布在不同的服务器中，如图4-1所示。借此可以轻易地降低单台服务器的负载。</p>
<h3 id="使用redis实现任务队列"><a href="#使用redis实现任务队列" class="headerlink" title="使用redis实现任务队列"></a>使用redis实现任务队列</h3><p>说到队列很自然就能想到Redis的列表类型，如果要实现任务队列，只需要让生产者将任务使用LPUSH命令加入到某个键中，另一边让消费者不断地使用RPOP命令从该键中取出任务即可。</p>
<p>BRPOP命令和RPOP命令相似，唯一的区别是当列表中没有元素时BRPOP命令会一直阻<br>塞住连接，直到有新元素加入。</p>
<p>BRPOP命令接收两个参数，第一个是键名，第二个是超时时间，单位是秒。当超过了此<br>时间仍然没有获得新元素的话就会返回 nil。上例中超时时间为”0”，表示不限制等待的时<br>间，即如果没有新元素加入列表就会永远阻塞下去。</p>
<p>除了 BRPOP命令外，Redis 还提供了 BLPOP，和 BRPOP的区别在与从队列取元素时<br>BLPOP会从队列左边取。</p>
<h3 id="发布订阅模式"><a href="#发布订阅模式" class="headerlink" title="发布订阅模式"></a>发布订阅模式</h3><p>发布者发布消息的命令是 PUBLISH，用法是 PUBLISH channel message，PUBLISH 命令的返回值表示接收到这条消息的订阅者数量。因为此时没有客户端订阅channel.1，所以返回0。发出去的消息不会被持久化，也就是说当有客户端订阅channel.1后只能收到后续发布到该频道的消息，之前发送的就收不到了。</p>
<p>订阅频道的命令是 SUBSCRIBE，可以同时订阅多个频道，用法是 SUBSCRIBE channel<br>[channel …]。执行 SUBSCRIBE 命令后客户端会进入订阅状态，处于此状态下客户端不能使用除<br>SUBSCRIBE、UNSUBSCRIBE、PSUBSCRIBE和PUNSUBSCRIBE这4个属于“发布&#x2F;订阅”模式<br>的命令之外的命令（后面3个命令会在下面介绍），否则会报错。</p>
<p>进入订阅状态后客户端可能收到3种类型的回复。每种类型的回复都包含 3 个值，第一<br>个值是消息的类型，根据消息类型的不同，第二、三个值的含义也不同。消息类型可能的取<br>值有以下3个。<br>（1）subscribe。表示订阅成功的反馈信息。第二个值是订阅成功的频道名称，第三个值<br>是当前客户端订阅的频道数量。<br>（2）message。这个类型的回复是我们最关心的，它表示接收到的消息。第二个值表示<br>产生消息的频道名称，第三个值是消息的内容。<br>（3）unsubscribe。表示成功取消订阅某个频道。第二个值是对应的频道名称，第三个值<br>是当前客户端订阅的频道数量，当此值为0时客户端会退出订阅状态，之后就可以执行其他<br>非“发布&#x2F;订阅”模式的命令了。</p>
<p>使用 UNSUBSCRIBE 命令可以取消订阅指定的频道，用法为 UNSUBSCRIBE [channel<br>[channel …]]，如果不指定频道则会取消订阅所有频道</p>
<h3 id="按照规则订阅"><a href="#按照规则订阅" class="headerlink" title="按照规则订阅"></a>按照规则订阅</h3><p>除了可以使用SUBSCRIBE命令订阅指定名称的频道外，还可以使用PSUBSCRIBE命令订<br>阅指定的规则。规则支持glob风格通配符格式</p>
<p>PUNSUBSCRIBE 命令可以退订指定的规则，用法是 PUNSUBSCRIBE [pattern [pattern<br>…]]，如果没有参数则会退订所有规则。</p>
<h3 id="管道"><a href="#管道" class="headerlink" title="管道"></a>管道</h3><p>在执行多个命令时每条命令都需要等待上一条命令执行完（即收到Redis的返回结果）才<br>能执行，即使命令不需要上一条命令的执行结果。如要获得post:1、post:2和post:3这3个键中<br>的title字段，需要执行3条命令，</p>
<p>Redis 的底层通信协议对管道（pipelining）提供了支持。通过管道可以一次性发送多条<br>命令并在执行完后一次性将结果返回，当一组命令中每条命令都不依赖于之前命令的执行结<br>果时就可以将这组命令一起通过管道发出。管道通过减少客户端与 Redis 的通信次数来实现<br>降低往返时延累计值的目的，</p>
<h2 id="节省空间"><a href="#节省空间" class="headerlink" title="节省空间"></a>节省空间</h2><h3 id="精简键名和键值"><a href="#精简键名和键值" class="headerlink" title="精简键名和键值"></a>精简键名和键值</h3><p>精简键名和键值是最直观的减少内存占用的方式，如将键名very.important.person:20改成<br>VIP:20。</p>
<p>又比如一个存储用户性别的字符串类型键的取值是male和female，我们可以将其修改成m和f来为每条记录节约几个字节的空间（更好的方法是使用0和1来表示性别，稍后会详细介绍原因）</p>
<h3 id="内部编码优化"><a href="#内部编码优化" class="headerlink" title="内部编码优化"></a>内部编码优化</h3><p>有时候仅凭精简键名和键值所减少的空间并不足以满足需求，这时就需要根据 Redis内<br>部编码规则来节省更多的空间。</p>
<p>Redis为每种数据类型都提供了两种内部编码方式，以散列类型为例，散列类型是通过散列表实现的，这样就可以实现O(1)时间复杂度的查找、赋值操作，然而当键中元素很少的时候，O(1)的操作并不会比O(n)有明显的性能提高，所以这种情况下Redis会采用一种更为紧凑但性能稍差（获取元素的时间复杂度为O(n)）的内部编码方式。</p>
<p>内部编码方式的选择对于开发者来说是透明的，Redis会根据实际情况自动调整。当键中<br>元素变多时Redis会自动将该键的内部编码方式转换成散列表。如果想查看一个键的内部编码<br>方式可以使用 OBJECT ENCODING 命令，</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt; set foo bar</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; object encoding foo</span><br><span class="line">&quot;embstr&quot;</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure>

<p><img src="/posts/2075dfe/asset/1687750554062.png" alt="1687750554062"></p>
<h2 id="java-与redis"><a href="#java-与redis" class="headerlink" title="java 与redis"></a>java 与redis</h2><h2 id="脚本"><a href="#脚本" class="headerlink" title="脚本"></a>脚本</h2><p>Redis在2.6版推出了脚本功能，允许开发者使用Lua语言编写脚本传到Redis中执行。在<br>Lua脚本中可以调用大部分的Redis命令，使用脚本的好处如下。<br>      （1）减少网络开销：使用脚本功能完成同样的操作只需要发送一个请求即可，减少了网络往返时延。</p>
<p>（2）原子操作：Redis 会将整个脚本作为一个整体执行，中间不会被其他命令插入。换<br>句话说在编写脚本的过程中无需担心会出现竞态条件，也就无需使用事务。事务可以完成的<br>所有功能都可以用脚本来实现。</p>
<p>（3）复用：客户端发送的脚本会永久存储在 Redis 中，这就意味着其他客户端（可以是<br>其他语言开发的项目）可以复用这一脚本而不需要使用代码完成同样的逻辑。</p>
<h3 id="访问速率控制"><a href="#访问速率控制" class="headerlink" title="访问速率控制"></a>访问速率控制</h3><p>因为无需考虑事务，使用Redis脚本实现访问频率限制非常简单。Lua代码如下：</p>
<figure class="highlight lua"><table><tr><td class="code"><pre><span class="line"><span class="keyword">local</span> times = redis.call(<span class="string">&#x27;incr&#x27;</span>, KEYS[<span class="number">1</span>])</span><br><span class="line"><span class="keyword">if</span> times == <span class="number">1</span> <span class="keyword">then</span></span><br><span class="line">	<span class="comment">-- KEYS[1]键刚创建，所以为其设置生存时间</span></span><br><span class="line">	redis.call(<span class="string">&#x27;expire&#x27;</span>, KEYS[<span class="number">1</span>], ARGV[<span class="number">1</span>])</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">if</span> times &gt; <span class="built_in">tonumber</span>(ARGV[<span class="number">2</span>]) <span class="keyword">then</span></span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">return</span> <span class="number">1</span></span><br></pre></td></tr></table></figure>

<p>那么，如何测试这个脚本呢？首先把这段代码存为ratelimiting.lua，然后在命名行中输<br>入：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">redis-cli --eval ratelimiting.lua </span><br></pre></td></tr></table></figure>

<h3 id="redis与lua"><a href="#redis与lua" class="headerlink" title="redis与lua"></a>redis与lua</h3><h4 id="在脚本中调用redis命令"><a href="#在脚本中调用redis命令" class="headerlink" title="在脚本中调用redis命令"></a>在脚本中调用redis命令</h4><p>在脚本中可以使用redis.call函数调用Redis命令。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">redis.call(&#x27;set&#x27;,&#x27;foo&#x27;,&#x27;bar&#x27;)</span><br><span class="line">local value = redis.call(&#x27;get&#x27;,&#x27;foo&#x27;)</span><br></pre></td></tr></table></figure>

<p>redis.call函数的返回值就是Redis命令的执行结果。Redis命令的返回值有5种类型，redis.call函数会将这5种类型的回复转换成对应的Lua的数据类型，空结果比较特殊，其对应Lua的false</p>
<p><img src="/posts/2075dfe/asset/1687751433210.png" alt="1687751433210"></p>
<p>Redis还提供了redis.pcall函数，功能与redis.call相同，唯一的区别是当命令执行出错时<br>redis.pcall会记录错误并继续执行，而redis.call会直接返回错误，不会继续执行。</p>
<h4 id="从脚本中返回值"><a href="#从脚本中返回值" class="headerlink" title="从脚本中返回值"></a>从脚本中返回值</h4><p>在很多情况下都需要脚本可以返回值，比如前面的访问频率限制脚本会返回访问频率是<br>否超限。在脚本中可以使用return语句将值返回给客户端，如果没有执行return语句则默认返<br>回nil。因为我们可以像调用其他Redis内置命令一样调用我们自己写的脚本，所以同样Redis<br>会自动将脚本返回值的Lua数据类型转换成Redis的返回值类型。</p>
<h4 id="脚本相关命令"><a href="#脚本相关命令" class="headerlink" title="脚本相关命令"></a>脚本相关命令</h4><p>eval 命令</p>
<p>evalsha命令</p>
<p>考虑到在脚本比较长的情况下，如果每次调用脚本都需要将整个脚本传给 Redis 会占用<br>较多的带宽。为了解决这个问题，Redis 提供了 EVALSHA命令允许开发者通过脚本内容的<br>SHA1 摘要来执行脚本，该命令的用法和 EVAL 一样，只不过是将脚本内容替换成脚本内容<br>的 SHA1 摘要。</p>
<h2 id="持久化"><a href="#持久化" class="headerlink" title="持久化"></a>持久化</h2><h3 id="RDB方式"><a href="#RDB方式" class="headerlink" title="RDB方式"></a>RDB方式</h3><p>RDB方式的持久化是通过快照（snapshotting）完成的，当符合一定条件时Redis会自动将<br>内存中的所有数据生成一份副本并存储在硬盘上，这个过程即为“快照”。</p>
<p>Redis会在以下几种情况下对数据进行快照：</p>
<ul>
<li><p>根据配置规则进行自动快照；</p>
</li>
<li><p>执行 FLUSHALL命令；</p>
</li>
<li><p>执行复制（replication）时。</p>
<h4 id="根据配置规则进行自动快照"><a href="#根据配置规则进行自动快照" class="headerlink" title="根据配置规则进行自动快照"></a>根据配置规则进行自动快照</h4></li>
</ul>
<p>Redis允许用户自定义快照条件，当符合快照条件时，Redis会自动执行快照操作。进行<br>快照的条件可以由用户在配置文件中自定义，由两个参数构成：时间窗口M和改动的键的个<br>数N。每当时间M内被更改的键的个数大于N时，即符合自动快照条件。</p>
<p>例如Redis安装目录中包含的样例配置文件中预置的3个条件：</p>
<p>sava 900 1</p>
<p>save 300 10</p>
<p>save 60 10000</p>
<p>每条快照条件占一行，并且以 save 参数开头。同时可以存在多个条件，条件之间<br>是“或”的关系。</p>
<h4 id="用户执行save或bgsave命令"><a href="#用户执行save或bgsave命令" class="headerlink" title="用户执行save或bgsave命令"></a>用户执行save或bgsave命令</h4><p>除了让 Redis 自动进行快照外，当进行服务重启、手动迁移以及备份时我们也会需要手<br>动执行快照操作。</p>
<p>save 命令</p>
<p>当执行SAVE命令时，Redis同步地进行快照操作，在快照执行的过程中会阻塞所有来自<br>客户端的请求。当数据库中的数据比较多时，这一过程会导致 Redis 较长时间不响应，所以<br>要尽量避免在生产环境中使用这一命令。</p>
<p>bgsave 命令</p>
<p>需要手动执行快照时推荐使用 BGSAVE 命令。BGSAVE 命令可以在后台异步地进行快<br>照操作，快照的同时服务器还可以继续响应来自客户端的请求。如果想知道快照是否完成，可以通过 LASTSAVE命令获取最近一次成功执行快照的时间，返回结果是一个Unix时间戳，</p>
<h4 id="执行flushall命令"><a href="#执行flushall命令" class="headerlink" title="执行flushall命令"></a>执行flushall命令</h4><p>当执行 FLUSHALL 命令时，Redis 会清除数据库中的所有数据。需要注意的是，不论清<br>空数据库的过程是否触发了自动快照条件，只要自动快照条件不为空，Redis就会执行一次快<br>照操作。当没有定义自动快照条件时，执行FLUSHALL则不会进行快照。</p>
<h4 id="执行复制时"><a href="#执行复制时" class="headerlink" title="执行复制时"></a>执行复制时</h4><p>当设置了主从模式时，Redis 会在复制初始化时进行自动快照。即使没有定义自动快照条<br>件，并且没有手动执行过快照操作，也会生成RDB快照文件。</p>
<h4 id="快照原理"><a href="#快照原理" class="headerlink" title="快照原理"></a>快照原理</h4><p>理清Redis实现快照的过程对我们了解快照文件的特性有很大的帮助。Redis默认会将快<br>照文件存储在Redis当前进程的工作目录中的dump.rdb文件中，可以通过配置dir和dbfilename<br>两个参数分别指定快照文件的存储路径和文件名。快照的过程如下。</p>
<p>1）Redis使用fork函数复制一份当前进程（父进程）的副本（子进程）；</p>
<p>2）父进程继续接收并处理客户端发来的命令，而子进程开始将内存中的数据写入硬<br>盘中的临时文件；</p>
<p>3）当子进程写入完所有数据后会用该临时文件替换旧的 RDB 文件，至此一次快照操<br>作完成。</p>
<p> 在执行 fork 的时候操作系统（类 Unix 操作系统）会使用写时复制（copy-on-<br>write）策略，即fork函数发生的一刻父子进程共享同一内存数据，当父进程要更改其中某片<br>数据时（如执行一个写命令），操作系统会将该片数据复制一份以保证子进程的数据不受影<br>响，所以新的RDB文件存储的是执行fork一刻的内存数据。</p>
<p>写时复制策略也保证了在 fork 的时刻虽然看上去生成了两份内存副本，但实际上内存的<br>占用量并不会增加一倍。这就意味着当系统内存只有2 GB，而Redis数据库的内存有1.5 GB<br>时，执行 fork后内存使用量并不会增加到3 GB（超出物理内存）。</p>
<p>通过上述过程可以发现Redis在进行快照的过程中不会修改RDB文件，只有快照结束后才<br>会将旧的文件替换成新的，也就是说任何时候 RDB 文件都是完整的。这使得我们可以通过<br>定时备份 RDB 文件来实现 Redis 数据库备份。</p>
<p>Redis启动后会读取RDB快照文件，将数据从硬盘载入到内存。根据数据量大小与结构和<br>服务器性能不同，这个时间也不同。通常将一个记录1000万个字符串类型键、大小为1 GB 的<br>快照文件载入到内存中需要花费20～30秒。</p>
<p>通过RDB方式实现持久化，一旦Redis异常退出，就会丢失最后一次快照以后更改的所有<br>数据。这就需要开发者根据具体的应用场合，通过组合设置自动快照条件的方式来将可能发<br>生的数据损失控制在能够接受的范围。例如，使用Redis存储缓存数据时，丢失最近几秒的数<br>据或者丢失最近更新的几十个键并不会有很大的影响。如果数据相对重要，希望将损失降到<br>最小，则可以使用AOF方式进行持久化。</p>
<h2 id="AOF方式"><a href="#AOF方式" class="headerlink" title="AOF方式"></a>AOF方式</h2><p>当使用Redis存储非临时数据时，一般需要打开AOF持久化来降低进程中止导致的数据丢<br>失。AOF可以将Redis执行的每一条写命令追加到硬盘文件中，这一过程显然会降低Redis 的<br>性能，但是大部分情况下这个影响是可以接受的，另外使用较快的硬盘可以提高AOF的性<br>能。</p>
<p>默认情况下Redis没有开启AOF（append only file）方式的持久化，可以通过 appendonly<br>参数启用：appendonly yes</p>
<p>开启AOF持久化后每执行一条会更改Redis中的数据的命令，Redis就会将该命令写入硬<br>盘中的AOF文件。AOF文件的保存位置和RDB文件的位置相同，都是通过dir参数设置的，默<br>认的文件名是appendonly.aof，可以通过appendfilename参数修改：</p>
<p>appendfilename appendonly.aof</p>
<p>每当达到一定条件时Redis就会自动重写AOF文件，这个条件可以在配置文件中设置：<br>auto-aof-rewrite-percentage 100<br>auto-aof-rewrite-min-size 64mb</p>
<p>auto-aof-rewrite-percentage参数的意义是当目前的AOF文件大小超过上一次重写时的<br>AOF文件大小的百分之多少时会再次进行重写，如果之前没有重写过，则以启动时的AOF文<br>件大小为依据。auto-aof-rewrite-min-size参数限制了允许重写的最小AOF文件大小，通常在<br>AOF文件很小的情况下即使其中有很多冗余的命令我们也并不太关心。除了让Redis自动执行<br>重写外，我们还可以主动使用BGREWRITEAOF命令手动执行AOF重写。</p>
<p>在启动时Redis会逐个执行AOF文件中的命令来将硬盘中的数据载入到内存中，载入的速<br>度相较RDB会慢一些。</p>
<h3 id="同步硬盘数据"><a href="#同步硬盘数据" class="headerlink" title="同步硬盘数据"></a>同步硬盘数据</h3><p>虽然每次执行更改数据库内容的操作时，AOF都会将命令记录在AOF文件中，但是事实<br>上，由于操作系统的缓存机制，数据并没有真正地写入硬盘，而是进入了系统的硬盘缓存。</p>
<p>在默认情况下系统每30秒会执行一次同步操作，以便将硬盘缓存中的内容真正地写入硬盘，<br>在这30秒的过程中如果系统异常退出则会导致硬盘缓存中的数据丢失。一般来讲启用AOF持<br>久化的应用都无法容忍这样的损失，这就需要Redis在写入AOF文件后主动要求系统将缓存内<br>容同步到硬盘中。在 Redis 中我们可以通过 appendfsync 参数设置同步的时机：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># appendfsync always</span><br><span class="line">appendfsync everysec</span><br><span class="line"># appendfsync no</span><br></pre></td></tr></table></figure>

<p>默认情况下Redis采用everysec规则，即每秒执行一次同步操作。always表示每次执行写<br>入都会执行同步，这是最安全也是最慢的方式。no表示不主动进行同步操作，而是完全交由<br>操作系统来做（即每30秒一次），这是最快但最不安全的方式。一般情况下使用默认值<br>everysec就足够了，既兼顾了性能又保证了安全。</p>
<p>Redis 允许同时开启 AOF 和 RDB，既保证了数据安全又使得进行备份等操作十分容易。<br>此时重新启动Redis后Redis会使用AOF文件来恢复数据，因为AOF方式的持久化可能丢失的<br>数据更少。</p>
<h2 id="集群"><a href="#集群" class="headerlink" title="集群"></a>集群</h2><p>现实中的项目通常需要若干台Redis服务器的支持：</p>
<p>（1）从结构上，单个 Redis 服务器会发生单点故障，同时一台服务器需要承受所有的请<br>求负载。这就需要为数据生成多个副本并分配在不同的服务器上；<br>        （2）从容量上，单个 Redis 服务器的内存非常容易成为存储瓶颈，所以需要进行数据分<br>片。</p>
<p>同时拥有多个 Redis 服务器后就会面临如何管理集群的问题，包括如何增加节点、故障<br>恢复等操作</p>
<h3 id="复制"><a href="#复制" class="headerlink" title="复制"></a>复制</h3><p>Redis提供了复制（replication）功能，可以实现当一台数据库中的数据更新后，自动将更新的数据同步到其他数据库上。</p>
<h4 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h4><p>在复制的概念中，数据库分为两类，一类是主数据库（master），另一类是从数据库[1]<br>（slave）。主数据库可以进行读写操作，当写操作导致数据变化时会自动将数据同步给从数<br>据库。而从数据库一般是只读的，并接受主数据库同步过来的数据。一个主数据库可以拥有<br>多个从数据库，而一个从数据库只能拥有一个主数据库，</p>
<p>在 Redis 中使用复制功能非常容易，只需要在从数据库的配置文件中加入“slaveof 主数<br>据库地址 主数据库端口”即可，主数据库无需进行任何配置</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">redis-server --port 6380 --slaveof 127.0.0.1 6379</span><br></pre></td></tr></table></figure>

<p>连接6379</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt; info replication</span><br><span class="line"># Replication</span><br><span class="line">role:master</span><br><span class="line">connected_slaves:1</span><br><span class="line">slave0:ip=127.0.0.1,port=6380,state=online,offset=43,lag=0</span><br><span class="line">master_repl_offset:43</span><br><span class="line">repl_backlog_active:1</span><br><span class="line">repl_backlog_size:1048576</span><br><span class="line">repl_backlog_first_byte_offset:2</span><br><span class="line">repl_backlog_histlen:42</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure>

<p>连接6380</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">C:\Users\cy&gt;redis-cli -p 6380</span><br><span class="line">127.0.0.1:6380&gt; info replication</span><br><span class="line"># Replication</span><br><span class="line">role:slave</span><br><span class="line">master_host:127.0.0.1</span><br><span class="line">master_port:6379</span><br><span class="line">master_link_status:up</span><br><span class="line">master_last_io_seconds_ago:6</span><br><span class="line">master_sync_in_progress:0</span><br><span class="line">slave_repl_offset:169</span><br><span class="line">slave_priority:100</span><br><span class="line">slave_read_only:1</span><br><span class="line">connected_slaves:0</span><br><span class="line">master_repl_offset:0</span><br><span class="line">repl_backlog_active:0</span><br><span class="line">repl_backlog_size:1048576</span><br><span class="line">repl_backlog_first_byte_offset:0</span><br><span class="line">repl_backlog_histlen:0</span><br><span class="line">127.0.0.1:6380&gt;</span><br></pre></td></tr></table></figure>

<p>6379 设置键值</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt; set foo bar</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure>

<p>6380获取</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6380&gt; get foo</span><br><span class="line">&quot;bar&quot;</span><br><span class="line">127.0.0.1:6380&gt; set key1 ww</span><br><span class="line">(error) READONLY You can&#x27;t write against a read only slave.</span><br><span class="line">127.0.0.1:6380&gt;</span><br></pre></td></tr></table></figure>

<p>可以通过设置从数据库的配置文件中的 slave-read-only 为 no 以使从数据库可写，但是<br>因为对从数据库的任何更改都不会同步给任何其他数据库，并且一旦主数据库中更新了对应<br>的数据就会覆盖从数据库中的改动，所以通常的场景下不应该设置从数据库可写，以免导致<br>易被忽略的潜在应用逻辑错误。</p>
<p>配置多台从数据库的方法也一样，在所有的从数据库的配置文件中都加上 slaveof参数指<br>向同一个主数据库即可。除了通过配置文件或命令行参数设置 slaveof参数，还可以在运行时使用 SLAVEOF命令修改：</p>
<p>redis&gt; SLAVEOF 127.0.0.1 6379</p>
<p>如果该数据库已经是其他主数据库的从数据库了，SLAVEOF命令会停止和原来数据库的<br>同步转而和新数据库同步。此外对于从数据库来说，还可以使用 SLAVEOF NO ONE命令来<br>使当前数据库停止接收其他数据库的同步并转换成为主数据库。</p>
<h4 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h4><p>当一个从数据库启动后，会向主数据库发送 SYNC 命令。同时主数据库接收到 SYNC命<br>令后会开始在后台保存快照（即RDB持久化的过程），并将保存快照期间接收到的命令缓存<br>起来。当快照完成后，Redis会将快照文件和所有缓存的命令发送给从数据库。从数据库收到<br>后，会载入快照文件并执行收到的缓存的命令。以上过程称为复制初始化。复制初始化结束<br>后，主数据库每当收到写命令时就会将命令同步给从数据库，从而保证主从数据库数据一<br>致。</p>
<p>当主从数据库之间的连接断开重连后，Redis 2.6以及之前的版本会重新进行复制初始化<br>（即主数据库重新保存快照并传送给从数据库），即使从数据库可以仅有几条命令没有收<br>到，主数据库也必须要将数据库里的所有数据重新传送给从数据库。这使得主从数据库断线<br>重连后的数据恢复过程效率很低下，在网络环境不好的时候这一问题尤其明显。Redis 2.8版<br>的一个重要改进就是断线重连能够支持有条件的增量数据传输，当从数据库重新连接上主数<br>据库后，主数据库只需要将断线期间执行的命令传送给从数据库，从而大大提高Redis复制的<br>实用性。</p>
<h4 id="图结构"><a href="#图结构" class="headerlink" title="图结构"></a>图结构</h4><p>从数据库不仅可以接收主数据库的同步数据，自己也可以同时作为主数据库存在，形成<br>类似图的结构，</p>
<h4 id="读写分离与一致性"><a href="#读写分离与一致性" class="headerlink" title="读写分离与一致性"></a>读写分离与一致性</h4><p>通过复制可以实现读写分离，以提高服务器的负载能力。在常见的场景中（如电子商务<br>网站），读的频率大于写，当单机的Redis无法应付大量的读请求时（尤其是较耗资源的请<br>求，如 SORT 命令等）可以通过复制功能建立多个从数据库节点，主数据库只进行写操作，<br>而从数据库负责读操作。这种一主多从的结构很适合读多写少的场景，</p>
<h4 id="从数据库持久化"><a href="#从数据库持久化" class="headerlink" title="从数据库持久化"></a>从数据库持久化</h4><p>另一个相对耗时的操作是持久化，为了提高性能，可以通过复制功能建立一个（或若干<br>个）从数据库，并在从数据库中启用持久化，同时在主数据库禁用持久化。当从数据库崩溃<br>重启后主数据库会自动将数据同步过来，所以无需担心数据丢失。</p>
<p>然而当主数据库崩溃时，情况就稍显复杂了。手工通过从数据库数据恢复主数据库数据<br>时，需要严格按照以下两步进行。</p>
<p>1）在从数据库中使用 SLAVEOF NO ONE命令将从数据库提升成主数据库继续服务。<br>        2）启动之前崩溃的主数据库，然后使用SLAVEOF命令将其设置成新的主数据库的从<br>数据库，即可将数据同步回来。</p>
<p>注意 当开启复制且主数据库关闭持久化功能时，一定不要使用 Supervisor 以及类似的进<br>程管理工具令主数据库崩溃后自动重启。同样当主数据库所在的服务器因故关闭时，也要避<br>免直接重新启动。这是因为当主数据库重新启动后，因为没有开启持久化功能，所以数据库<br>中所有数据都被清空，这时从数据库依然会从主数据库中接收数据，使得所有从数据库也被<br>清空，导致从数据库的持久化失去意义。</p>
<p>无论哪种情况，手工维护从数据库或主数据库的重启以及数据恢复都相对麻烦，好在<br>Redis提供了一种自动化方案哨兵来实现这一过程，避免了手工维护的麻烦和容易出错的问<br>题</p>
<h4 id="无硬盘复制"><a href="#无硬盘复制" class="headerlink" title="无硬盘复制"></a>无硬盘复制</h4><p>复制是基于RDB方式的持久化实现的，即主数据库端在后台保存 RDB 快照，从数据库端则接收并载入快照文件。这样的实现优点是可以显著地简化逻辑，复用已有的代码，但是缺点也很明显。</p>
<p>1）当主数据库禁用RDB快照时（即删除了所有的配置文件中的save语句），如果执行<br>了复制初始化操作，Redis依然会生成RDB快照，所以下次启动后主数据库会以该快照恢复数<br>据。因为复制发生的时间不能确定，这使得恢复的数据可能是任何时间点的。</p>
<p>2）因为复制初始化时需要在硬盘中创建RDB快照文件，所以如果硬盘性能很慢（如<br>网络硬盘）时这一过程会对性能产生影响。举例来说，当使用 Redis 做缓存系统时，因为不<br>需要持久化，所以服务器的硬盘读写速度可能较差。但是当该缓存系统使用一主多从的集群<br>架构时，每次和从数据库同步，Redis都会执行一次快照，同时对硬盘进行读写，导致性能降<br>低。repl-diskless-sync yes</p>
<h4 id="增量复制"><a href="#增量复制" class="headerlink" title="增量复制"></a>增量复制</h4><p>当主从数据库连接断开后，从数据库会发送SYNC命令来重新进行一次完整复制操作。这样即使断开期间数据库的变化很小（甚至没有），也需要将数据库中的所有数据重新快照并传送一次。在正常的网络应用环境中，这种实现方式显然不太理想。</p>
<p>增量复制是基于如下3点实现的。</p>
<p>（1）从数据库会存储主数据库的运行ID（run id）。每个Redis 运行实例均会拥有一个<br>唯一的运行ID，每当实例重启后，就会自动生成一个新的运行ID。</p>
<p>（2）在复制同步阶段，主数据库每将一个命令传送给从数据库时，都会同时把该命令<br>存放到一个积压队列（backlog）中，并记录下当前积压队列中存放的命令的偏移量范围。</p>
<p>（3）同时，从数据库接收到主数据库传来的命令时，会记录下该命令的偏移量。</p>
<p>不再发送 SYNC命令，取而代之的是发送 PSYNC，格式为“PSYNC主数<br>据库的运行 ID 断开前最新的命令偏移量”。主数据库收到 PSYNC命令后，会执行以下判断<br>来决定此次重连是否可以执行增量复制。</p>
<p>1）首先主数据库会判断从数据库传送来的运行ID是否和自己的运行ID相同。这一步<br>骤的意义在于确保从数据库之前确实是和自己同步的，以免从数据库拿到错误的数据（比如<br>主数据库在断线期间重启过，会造成数据的不一致）。</p>
<p>2）然后判断从数据库最后同步成功的命令偏移量是否在积压队列中，如果在则可以<br>执行增量复制，并将积压队列中相应的命令发送给从数据库。</p>
<p>如果此次重连不满足增量复制的条件，主数据库会进行一次全部同步（</p>
<h3 id="哨兵"><a href="#哨兵" class="headerlink" title="哨兵"></a>哨兵</h3><p>在一个典型的一主多从的Redis系统中，从数据库在整个系统中起到了数据冗余备份和读写分离的作用。当主数据库遇到异常中断服务后，开发者可以通过手动的方式选择一个从数据库来升格为主数据库，以使得系统能够继续提供服务。然而整个过程相对麻烦且需要人工介入，难以实现自动化。</p>
<p>哨兵的作用就是监控Redis系统的运行状况。它的功能包括以下两个</p>
<ul>
<li>监控主数据库和从数据库是否正常运行。</li>
<li>主数据库出现故障时自动将从数据库转换为主数据库。</li>
</ul>
<p>在一个一主多从的Redis系统中，可以使用多个哨兵进行监控任务以保证系统足够稳健，注意，此时不仅哨兵会同时监控主数据库和从数据库，哨兵之间也会互相监控。</p>
<p>配置哨兵。建立一个配置文件，如sentinel.conf，内容为：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sentinel monitor mymaster 127.0.0.1 6379 1</span><br></pre></td></tr></table></figure>

<p>mymaster表示要监控的主数据库的名字，可以自己定义一个.最后的1表示最低通过票数</p>
<p>需要注意的是，配置哨兵监控一个系统时，只需要配置其监控主数据库即可，哨兵会自<br>动发现所有复制该主数据库的从数据库</p>
<h4 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h4><p>一个哨兵进程启动时会读取配置文件的内容，通过如下的配置找出需要监控的主数据<br>库</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sentinel monitor master-name ip redis-port quorum</span><br></pre></td></tr></table></figure>

<p>其中 master-name 是一个由大小写字母、数字和“.-_”组成的主数据库的名字，因为考虑<br>到故障恢复后当前监控的系统的主数据库的地址和端口会产生变化，所以哨兵提供了命令可<br>以通过主数据库的名字获取当前系统的主数据库的地址和端口号。</p>
<p>ip表示当前系统中主数据库的地址，而redis-port则表示端口号。</p>
<p>quorum用来表示执行故障恢复操作前至少需要几个哨兵节点同意，</p>
<p>一个哨兵节点可以同时监控多个Redis主从系统，只需要提供多个sentinel monitor配置即<br>可，同时多个哨兵节点也可以同时监控同一个 Redis 主从系统，从而形成网状结构。</p>
<p>哨兵启动后，会与要监控的主数据库建立两条连接，这两个连接的建立方式与普通的<br>Redis客户端无异。其中一条连接用来订阅该主数据的__sentinel__:hello频道以获取其他同样<br>监控该数据库的哨兵节点的信息，另外哨兵也需要定期向主数据库发送 INFO 等命令来获取<br>主数据库本身的信息，因为4.4.4节介绍过当客户端的连接进入订阅模式时就不能再执行其他<br>命令了，所以这时哨兵会使用另外一条连接来发送这些命令。</p>
<p>和主数据库的连接建立完成后，哨兵会定时执行下面3个操作。<br>（1）每10秒哨兵会向主数据库和从数据库发送INFO命令。<br>（2）每 2 秒哨兵会向主数据库和从数据库的__sentinel__:hello 频道发送自己的信息。<br>（3）每1秒哨兵会向主数据库、从数据库和其他哨兵节点发送PING命令。</p>
<p>这3个操作贯穿哨兵进程的整个生命周期中，非常重要，可以说了解了这3个操作的意义<br>就能够了解哨兵工作原理的一半内容了。下面分别详细介绍。</p>
<p>首先，发送INFO命令使得哨兵可以获得当前数据库的相关信息（包括运行ID、复制信<br>息等）从而实现新节点的自动发现。前面说配置哨兵监控 Redis 主从系统时只需要指定主数<br>据库的信息即可，因为哨兵正是借助 INFO 命令来获取所有复制该主数据库的从数据库信息<br>的。启动后，哨兵向主数据库发送 INFO 命令，通过解析返回结果来得知从数据库列表，而<br>后对每个从数据库同样建立两个连接，两个连接的作用和前文介绍的与主数据库建立的两个<br>连接完全一致。在此之后，哨兵会每 10 秒定时向已知的所有主从数据库发送INFO命令来获<br>取信息更新并进行相应操作，比如对新增的从数据库建立连接并加入监控列表，对主从数据<br>库的角色变化（由故障恢复操作引起）进行信息更新等。</p>
<p>接下来哨兵向主从数据库的__sentinel__:hello 频道发送信息来与同样监控该数据库的哨<br>兵分享自己的信息。发送的消息内容为：</p>
<p>&lt;哨兵的地址&gt;, &lt;哨兵的端口&gt;, &lt;哨兵的运行 ID&gt;, &lt;哨兵的配臵版本&gt;, &lt;主数据库的名字&gt;, &lt;主数据库的地址&gt;, &lt;主数据库的端口&gt;, &lt;主数据库的配臵版本&gt;</p>
<p>可以看到消息包括的哨兵的基本信息，以及其监控的主数据库的信息。前文介绍过，哨<br>兵会订阅每个其监控的数据库的__sentinel__:hello频道，所以当其他哨兵收到消息后，会判断<br>发消息的哨兵是不是新发现的哨兵。如果是则将其加入已发现的哨兵列表中并创建一个到其<br>的连接（与数据库不同，哨兵与哨兵之间只会创建一条连接用来发送 PING命令，而不需要<br>创建另外一条连接来订阅频道，因为哨兵只需要订阅数据库的频道即可实现自动发现其他哨<br>兵）。同时哨兵会判断信息中主数据库的配置版本，如果该版本比当前记录的主数据库的版<br>本高，则更新主数据库的数据。配置版本的作用会在后面详细介绍。</p>
<p>实现了自动发现从数据库和其他哨兵节点后，哨兵要做的就是定时监控这些数据库和节<br>点有没有停止服务。这是通过每隔一定时间向这些节点发送PING命令实现的。时间间隔与<br>down-after-milliseconds选项有关，当down-after-milliseconds的值小于1秒时，哨兵会每隔<br>down-after-milliseconds指定的时间发送一次PING命令，当down-after-milliseconds的值大于1<br>秒时，哨兵会每隔1秒发送一次PING命令。</p>
<p>当超过down-after-milliseconds选项指定时间后，如果被PING的数据库或节点仍然未进<br>行回复，则哨兵认为其主观下线（subjectively down）。主观下线表示从当前的哨兵进程看<br>来，该节点已经下线。如果该节点是主数据库，则哨兵会进一步判断是否需要对其进行故障<br>恢复：哨兵发送 SENTINEL is-master-down-by-addr命令询问其他哨兵节点以了解他们是否<br>也认为该主数据库主观下线，如果达到指定数量时，哨兵会认为其客观下线（objectively<br>down），并选举领头的哨兵节点对主从系统发起故障恢复。这个指定数量即为前文介绍的<br>quorum参数。</p>
<p>虽然当前哨兵节点发现了主数据库客观下线，需要故障恢复，但是故障恢复需要由领头<br>的哨兵来完成，这样可以保证同一时间只有一个哨兵节点来执行故障恢复。选举领头哨兵的<br>过程使用了Raft算法，具体过程如下。</p>
<p>（1）发现主数据库客观下线的哨兵节点（下面称作A）向每个哨兵节点发送命令，要求<br>对方选自己成为领头哨兵。<br>        （2）如果目标哨兵节点没有选过其他人，则会同意将A设置成领头哨兵。<br>        （3）如果A发现有超过半数且超过quorum参数值的哨兵节点同意选自己成为领头哨<br>兵，则A成功成为领头哨兵。<br>        （4）当有多个哨兵节点同时参选领头哨兵，则会出现没有任何节点当选的可能。此时<br>每个参选节点将等待一个随机时间重新发起参选请求，进行下一轮选举，直到选举成功。</p>
<p>因为要成为领头哨兵必须有超过半数的哨兵节点支持，所以每次选举最多只会选出一个领头哨兵。</p>
<p>选出领头哨兵后，领头哨兵将会开始对主数据库进行故障恢复。故障恢复的过程相对简<br>单，具体如下。</p>
<p>首先领头哨兵将从停止服务的主数据库的从数据库中挑选一个来充当新的主数据库。挑<br>选的依据如下。<br>        （1）所有在线的从数据库中，选择优先级最高的从数据库。优先级可以通过slave-<br>priority选项来设置。<br>        （2）如果有多个最高优先级的从数据库，则复制的命令偏移量（见8.1.7节）越大（即<br>复制越完整）越优先。</p>
<p>（3）如果以上条件都一样，则选择运行ID较小的从数据库。</p>
<p>选出一个从数据库后，领头哨兵将向从数据库发送 SLAVEOF NO ONE命令使其升格为<br>主数据库。而后领头哨兵向其他从数据库发送SLAVEOF命令来使其成为新主数据库的从数据<br>库。最后一步则是更新内部的记录，将已经停止服务的旧的主数据库更新为新的主数据库的<br>从数据库，使得当其恢复服务时自动以从数据库的身份继续服务。</p>
<h4 id="哨兵的部署"><a href="#哨兵的部署" class="headerlink" title="哨兵的部署"></a>哨兵的部署</h4><p>如果一个主从系统中配置的哨兵较少，哨兵对整个系统的判断的可靠性就<br>会降低。极端情况下，当只有一个哨兵时，哨兵本身就可能会发生单点故障。整体来讲，相<br>对稳妥的哨兵部署方案是使得哨兵的视角尽可能地与每个节点的视角一致，</p>
<p>（1）为每个节点（无论是主数据库还是从数据库）部署一个哨兵；</p>
<p>（2）使每个哨兵与其对应的节点的网络环境相同或相近。</p>
<p>这样的部署方案可以保证哨兵的视角拥有较高的代表性和可靠性。举例一个例子：当网<br>络分区后，如果哨兵认为某个分区是主要分区，即意味着从每个节点观察，该分区均为主分<br>区。</p>
<p>同时设置 quorum 的值为 N&#x2F;2 + 1（其中 N 为哨兵节点数量），这样使得只有当大部分哨<br>兵节点同意后才会进行故障恢复。</p>
<p>当系统中的节点较多时，考虑到每个哨兵都会和系统中的所有节点建立连接，为每个节<br>点分配一个哨兵会产生较多连接，尤其是当进行客户端分片时使用多个哨兵节点监控多个主<br>数据库会因为 Redis 不支持连接复用而产生大量冗余连接，同时如果Redis节点负载较高，会在一定程度上影响其对哨兵的回复以及与其同机的哨兵与其他节点的通信。所以配置哨兵时还需要根据实际的生产环境情况进行选择。</p>
<h3 id="集群-1"><a href="#集群-1" class="headerlink" title="集群"></a>集群</h3><p>即使使用哨兵，此时的 Redis 集群的每个数据库依然存有集群中的所有数据，从而导致<br>集群的总数据存储量受限于可用存储内存最小的数据库节点，形成木桶效应。由于Redis中的<br>所有数据都是基于内存存储，这一问题就尤为突出了，尤其是当使用 Redis 做持久化存储服<br>务使用时。</p>
<p>客户端分片终归是有非常多的缺点，比如维护成本高，增加、移除节点较繁琐等。</p>
<p>集群的特点在于拥有和单机实例同样的性能，同时在网络分区后能够提供一定<br>的可访问性以及对主数据库故障恢复的支持。另外集群支持几乎所有的单机实例支持的命<br>令，对于涉及多键的命令（如MGET），如果每个键都位于同一个节点中，则可以正常支<br>持，否则会提示错误。除此之外集群还有一个限制是只能使用默认的0号数据库，如果执行<br>SELECT切换数据库则会提示错误。</p>
<p>哨兵与集群是两个独立的功能，但从特性来看哨兵可以视为集群的子集，当不需要数据<br>分片或者已经在客户端进行分片的场景下哨兵就足够使用了，但如果需要进行水平扩容，则<br>集群是一个非常好的选择。</p>
<h4 id="配置集群"><a href="#配置集群" class="headerlink" title="配置集群"></a>配置集群</h4><p>用集群，只需要将每个数据库节点的cluster-enabled配置选项打开即可。每个集群中至<br>少需要3个主数据库才能正常运行。</p>
<p>集群会将当前节点记录的集群状态持久化地存储在指定文件中，这个文件默认为当前工作目录下的nodes.conf文件。每个节点对应的文件必须不同，否则会造成启动失败，所以启动节点时要注意最后为每个节点使用不同的工作目录，或者通过cluster-config-file选项修改持久化文件的名称：cluster-config-file nodes.conf</p>
<p>启动后，可以使用Redis命令行客户端连接任意一个节点使用 INFO 命令来判断集群是否<br>正常启用了：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">redis&gt; INFO cluster</span><br><span class="line"># Cluster</span><br><span class="line">cluster_enabled:1</span><br></pre></td></tr></table></figure>

<p>其中cluster_enabled为1表示集群正常启用了。现在每个节点都是完全独立的，要将它们<br>加入同一个集群里还需要几个步骤。</p>
<p>Redis源代码中提供了一个辅助工具redis-trib.rb可以非常方便地完成这一任务。因为<br>redis-trib.rb是用Ruby语言编写的，所以运行前需要在服务器上安装Ruby程序，</p>
<p>使用redis-trib.rb来初始化集群，只需要执行：<br>$ &#x2F;path&#x2F;to&#x2F;redis-trib.rb create –replicas 1 127.0.0.1:6380 127.0.0.1:6381<br>127.0.0.1:6382 127.0.0.1:6383 127.0.0.1:6384 127.0.0.1:6385</p>
<p>其中 create参数表示要初始化集群，–replicas 1表示每个主数据库拥有的从数据库个数<br>为1，所以整个集群共有3（6&#x2F;2）个主数据库以及3个从数据库。</p>
<h2 id="管理"><a href="#管理" class="headerlink" title="管理"></a>管理</h2><h3 id="安全"><a href="#安全" class="headerlink" title="安全"></a>安全</h3><p>Redis的默认配置会接受来自任何地址发送来的请求，即在任何一个拥有公网IP的服务器<br>上启动 Redis 服务器，都可以被外界直接访问到。要更改这一设置，在配置文件中修改bind<br>参数，如只允许本机应用连接Redis，可以将bind参数改成：bind 127.0.0.1</p>
<p>bind参数只能绑定一个地址[2] ，如果想更自由地设置访问规则需要通过防火墙来完成</p>
<p>除此之外，还可以通过配置文件中的requirepass参数为Redis设置一个密码。客户端每次连接到 Redis 时都需要发送密码，否则 Redis 会拒绝执行客户端发来的命令。发送密码需要使用AUTH命令，由于Redis的性能极高，并且输入错误密码后Redis并不会进行主动延迟</p>
<p>提示 配置 Redis 复制的时候如果主数据库设置了密码，需要在从数据库的配置文件中通过masterauth参数设置主数据库的密码，以使从数据库连接主数据库时自动使用AUTH命令认证。</p>
<p>Redis 支持在配置文件中将命令重命名，比如将 FLUSHALL 命令重命名成一个比较复杂的名字，以保证只有自己的应用可以使用该命令。</p>
<p>rename-command FLUSHALL oyfekmjvmwxq5a9c8usofuo369x0it2k</p>
<p>如果希望直接禁用某个命令可以将命令重命名成空字符串。</p>
<h3 id="管理工具"><a href="#管理工具" class="headerlink" title="管理工具"></a>管理工具</h3><p>当一条命令执行时间超过限制时，Redis会将该命令的执行时间等信息加入耗时命令日志<br>（slow log）以供开发者查看。可以通过配置文件的 slowlog-log-slower-than参数设置这一限<br>制，要注意单位是微秒（1 000 000 微秒相当于1秒），默认值是10 000。耗时命令日志存储<br>在内存中，可以通过配置文件的 slowlog-max-len 参数来限制记录的条数。</p>
<h4 id="耗时日志"><a href="#耗时日志" class="headerlink" title="耗时日志"></a>耗时日志</h4><p>使用 SLOWLOG GET命令来获得当前的耗时命令日志</p>
<p>每条日志都由以下4个部分组成：<br>（1）该日志唯一ID；<br>（2）该命令执行的Unix时间；<br>（3）该命令的耗时时间，单位是微秒；<br>（4）命令及其参数。</p>
<h4 id="命令监控"><a href="#命令监控" class="headerlink" title="命令监控"></a>命令监控</h4><p>Redis提供了MONITOR命令来监控Redis执行的所有命令，redis-cli同样支持这个命令，<br>如在redis-cli中执行MONITOR：</p>
<p>这时 Redis 执行的任何命令都会在 redis-cli 中打印出来，</p>
<p>MONITOR命令非常影响Redis的性能，一个客户端使用MONITOR命令会降低Redis将近<br>一半的负载能力。所以MONITOR命令只适合用来调试和纠错。</p>
]]></content>
      <categories>
        <category>读书笔记</category>
        <category>redis入门指南</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>redis入门指南</tag>
      </tags>
  </entry>
  <entry>
    <title>希尔排序</title>
    <url>/posts/1ac49179/</url>
    <content><![CDATA[<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">sort</span><span class="params">(<span class="type">int</span> l,<span class="type">int</span> r)</span>&#123;</span><br><span class="line">       <span class="type">int</span> tmp;</span><br><span class="line">       <span class="type">int</span> <span class="variable">gap</span> <span class="operator">=</span> r-l+<span class="number">1</span>;</span><br><span class="line">       <span class="keyword">while</span> (gap&gt;<span class="number">1</span>)&#123;</span><br><span class="line">           gap=gap/<span class="number">2</span>;</span><br><span class="line">           System.out.println(<span class="string">&quot;gap: &quot;</span>+gap);</span><br><span class="line">           <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">d</span> <span class="operator">=</span> <span class="number">0</span>,j; d &lt; gap; d++) &#123;</span><br><span class="line">               <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> (l+d)+gap; i &lt;= r; i+=gap) &#123; <span class="comment">//起始值(l+d) 间隔gap</span></span><br><span class="line">                   tmp = data[i];</span><br><span class="line">                   <span class="keyword">for</span> (j= i; j&gt;=(l+d)+gap; j-=gap) &#123; <span class="comment">//直接插入排序</span></span><br><span class="line">                       <span class="keyword">if</span>(data[j]&lt;data[j-gap])&#123;</span><br><span class="line">                           data[j]=data[j-gap];</span><br><span class="line">                       &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">                           <span class="keyword">break</span>;</span><br><span class="line">                       &#125;</span><br><span class="line">                   &#125;</span><br><span class="line">                   data[j]=tmp;</span><br><span class="line">               &#125;</span><br><span class="line">           &#125;</span><br><span class="line">           System.out.println(Arrays.toString(data));</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>

<h2 id="希尔排序"><a href="#希尔排序" class="headerlink" title="希尔排序"></a>希尔排序</h2><p>希尔排序(Shell Sort)是插入排序的一种。也称缩小增量排序，是直接插入排序算法的一种更高效的改进版本。希尔排序是非稳定排序算法。该方法因DL．Shell于1959年提出而得名。希尔排序是记录按下标的一定增量分组，对每组使用直接插入排序算法排序；随着增量逐渐减少，每组包含的关键词越来越多，当增量减至1时，整个文件恰被分成一组，算法便终止。</p>
<p>我们分割待排序记录的目的是减少待排序记录的个数，并使整个序列向基本有序发展。而如上面这样分完组后，就各自排序的方法达不到我们的要求。因此，我们需要采取跳跃分割的策略：将相距某个“增量”的记录组成一个子序列，这样才能保证在子序列内分别进行直接插入排序后得到的结果是基本有序而不是局部有序。</p>
<p><img src="/posts/1ac49179/asset/20160518211420194.png" alt="img"></p>
<h3 id="操作步骤："><a href="#操作步骤：" class="headerlink" title="操作步骤："></a>操作步骤：</h3><p>初始时，有一个大小为 10 的无序序列。</p>
<p>（1）在第一趟排序中，我们不妨设 gap1 &#x3D; N &#x2F; 2 &#x3D; 5，即相隔距离为 5 的元素组成一组，可以分为 5 组。</p>
<p>（2）接下来，按照直接插入排序的方法对每个组进行排序。</p>
<p>在第二趟排序中，我们把上次的 gap 缩小一半，即 gap2 &#x3D; gap1 &#x2F; 2 &#x3D; 2 (取整数)。这样每相隔距离为 2 的元素组成一组，可以分为 2 组。</p>
<p>（3）按照直接插入排序的方法对每个组进行排序。</p>
<p>（4）在第三趟排序中，再次把 gap 缩小一半，即gap3 &#x3D; gap2 &#x2F; 2 &#x3D; 1。 这样相隔距离为 1 的元素组成一组，即只有一组。</p>
<p>（5）按照直接插入排序的方法对每个组进行排序。此时，排序已经结束。</p>
<h3 id="效率分析"><a href="#效率分析" class="headerlink" title="效率分析"></a>效率分析</h3><p><img src="/posts/1ac49179/asset/20160518211404834.png" alt="img"></p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>排序算法</category>
        <category>插入排序</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>排序算法</tag>
        <tag>插入排序</tag>
      </tags>
  </entry>
  <entry>
    <title>直接插入排序</title>
    <url>/posts/2b06d603/</url>
    <content><![CDATA[<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><h3 id="直接插入"><a href="#直接插入" class="headerlink" title="直接插入"></a>直接插入</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">sort</span><span class="params">(<span class="type">int</span> l,<span class="type">int</span> r)</span>&#123;</span><br><span class="line">    <span class="type">int</span> tmp;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> l+<span class="number">1</span>,j; i &lt;= r; i++) &#123;</span><br><span class="line">        tmp = data[i];</span><br><span class="line">        <span class="keyword">for</span> ( j = i; j &gt;<span class="number">0</span>; j--) &#123;    <span class="comment">//从后往前找</span></span><br><span class="line">            <span class="keyword">if</span>(data[j-<span class="number">1</span>]&gt;tmp)&#123;</span><br><span class="line">                data[j]=data[j-<span class="number">1</span>];   <span class="comment">//比它大的往后移</span></span><br><span class="line">            &#125;<span class="keyword">else</span> &#123;        </span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        data[j]=tmp;                <span class="comment">//填补空位</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="折半插入"><a href="#折半插入" class="headerlink" title="折半插入"></a>折半插入</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="type">int</span> <span class="title function_">lookForIndex</span><span class="params">(<span class="type">int</span> l, <span class="type">int</span> r, <span class="type">int</span> val)</span>&#123;</span><br><span class="line"></span><br><span class="line">       <span class="type">int</span> bl=l,br=r;</span><br><span class="line">       <span class="type">int</span> index=br;</span><br><span class="line">       <span class="keyword">if</span>(data[r]&lt;=val)&#123;  <span class="comment">//最大的数都小于等于它，就找不到</span></span><br><span class="line">           <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">       &#125;<span class="keyword">else</span> <span class="keyword">if</span>(data[l]&gt;val)&#123;  <span class="comment">//最小的数都大于它，直接插最前面</span></span><br><span class="line">           <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="keyword">while</span> (bl&lt;br)&#123;        <span class="comment">// data[l]&lt;= val &lt;data[r]  ,[l+1,r]中必有一个是最小的比val大的数，找到的数必比val大</span></span><br><span class="line">          </span><br><span class="line">           index = (bl+br)/<span class="number">2</span>;</span><br><span class="line">           <span class="keyword">if</span>(data[index]&gt;val)&#123;</span><br><span class="line">               br=index;</span><br><span class="line">           &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">               bl=index+<span class="number">1</span>;</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       index = br;   <span class="comment">//区间唯一，找到点了</span></span><br><span class="line">       <span class="keyword">return</span> index;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">sortByBinary</span><span class="params">(<span class="type">int</span> l,<span class="type">int</span> r)</span>&#123;</span><br><span class="line">       <span class="type">int</span> tmp,index;</span><br><span class="line">       <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> l+<span class="number">1</span>; i &lt;= r; i++) &#123;</span><br><span class="line">           tmp = data[i];</span><br><span class="line">           index = lookForIndex(l,i-<span class="number">1</span>,tmp);</span><br><span class="line">           <span class="keyword">if</span>(index&lt;<span class="number">0</span>)&#123;  <span class="comment">//找不到就不用插入了</span></span><br><span class="line">               <span class="keyword">continue</span>;</span><br><span class="line">           &#125;</span><br><span class="line">           <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">j</span> <span class="operator">=</span> i; j &gt;index; j--) &#123;</span><br><span class="line">               data[j]=data[j-<span class="number">1</span>];</span><br><span class="line">           &#125;</span><br><span class="line">           data[index]=tmp;</span><br><span class="line">           System.out.println(l+<span class="string">&quot; &quot;</span>+i+<span class="string">&quot; &quot;</span>+index+<span class="string">&quot; &quot;</span>+Arrays.toString(data));</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>排序算法</category>
        <category>插入排序</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>排序算法</tag>
        <tag>插入排序</tag>
      </tags>
  </entry>
  <entry>
    <title>堆排序</title>
    <url>/posts/c2a5fdc5/</url>
    <content><![CDATA[<p> 堆一般指的是二叉堆，顾名思义，二叉堆是完全二叉树或者近似完全二叉树 </p>
<h2 id="堆"><a href="#堆" class="headerlink" title="堆"></a>堆</h2><h3 id="1-堆的性质"><a href="#1-堆的性质" class="headerlink" title="1. 堆的性质"></a>1. 堆的性质</h3><blockquote>
<p>① 是一棵完全二叉树<br>② 每个节点的值都大于或等于其子节点的值，为最大堆；反之为最小堆。</p>
</blockquote>
<p><img src="https://pic4.zhimg.com/80/v2-a78e7c4a1cc919a322adc87b33006dab_720w.webp" alt="img"></p>
<h3 id="2-堆的存储"><a href="#2-堆的存储" class="headerlink" title="2. 堆的存储"></a>2. 堆的存储</h3><p>一般用数组来表示堆，下标为 i 的结点的父结点下标为(i-1)&#x2F;2；其左右子结点分别为 (2i + 1)、(2i + 2)</p>
<p><img src="https://pic4.zhimg.com/80/v2-54a318a1acd0cccb8ac0018ccf58815f_720w.webp" alt="img"></p>
<h3 id="3-堆的操作"><a href="#3-堆的操作" class="headerlink" title="3. 堆的操作"></a>3. 堆的操作</h3><p>在堆的数据结构中，堆中的最大值总是位于根节点(在优先队列中使用堆的话堆中的最小值位于根节点)。堆中定义以下几种操作：</p>
<blockquote>
<p>① <strong>最大堆调整（Max_Heapify）</strong>：将堆的末端子节点作调整，使得子节点永远小于父节点<br>② <strong>创建最大堆（Build_Max_Heap）</strong>：将堆所有数据重新排序<br>③ <strong>堆排序（HeapSort）</strong>：移除位在第一个数据的根节点，并做最大堆调整的递归运算</p>
</blockquote>
<p>##堆排序（Heap Sort）</p>
<p>堆排序（Heapsort）是指利用堆这种数据结构所设计的一种排序算法。堆积是一个近似完全二叉树的结构，并同时满足堆积的性质：即子结点的键值或索引总是小于（或者大于）它的父节点。</p>
<h3 id="1-基本思想"><a href="#1-基本思想" class="headerlink" title="1. 基本思想"></a>1. 基本思想</h3><p>利用大顶堆(小顶堆)堆顶记录的是最大关键字(最小关键字)这一特性，使得每次从无序中选择最大记录(最小记录)变得简单。</p>
<blockquote>
<p> ① 将待排序的序列构造成一个最大堆，此时序列的最大值为根节点<br>② 依次将根节点与待排序序列的最后一个元素交换<br>③ 再维护从根节点到该元素的前一个节点为最大堆，如此往复，最终得到一个递增序列 </p>
</blockquote>
<h3 id="2-实现逻辑"><a href="#2-实现逻辑" class="headerlink" title="2. 实现逻辑"></a>2. 实现逻辑</h3><blockquote>
<p>① 先将初始的R[0…n-1]建立成最大堆，此时是无序堆，而堆顶是最大元素。<br>② 再将堆顶R[0]和无序区的最后一个记录R[n-1]交换，由此得到新的无序区R[0…n-2]和有序区R[n-1]，且满足R[0…n-2].keys ≤ R[n-1].key<br>③ 由于交换后新的根R[1]可能违反堆性质，故应将当前无序区R[1..n-1]调整为堆。然后再次将R[1..n-1]中关键字最大的记录R[1]和该区间的最后一个记录R[n-1]交换，由此得到新的无序区R[1..n-2]和有序区R[n-1..n]，且仍满足关系R[1..n-2].keys≤R[n-1..n].keys，同样要将R[1..n-2]调整为堆。<br>④ 直到无序区只有一个元素为止。</p>
</blockquote>
<h3 id="3-动图演示"><a href="#3-动图演示" class="headerlink" title="3. 动图演示"></a>3. 动图演示</h3><p><img src="/posts/c2a5fdc5/asset/v2-b7907d351809293c60658b0b87053c66_b.webp" alt="动图"></p>
<p>堆排序算法的演示。首先，将元素进行重排，以匹配堆的条件。图中排序过程之前简单的绘出了堆树的结构。</p>
<p><video src="https://vdn.vzuu.com/SD/3bb38dfe-236a-11eb-8039-a6caf32b14c9.mp4?disable_local_cache=1&bu=078babd7&c=avc.0.0&f=mp4&expiration=1688228226&auth_key=1688228226-0-0-165a4e13b3983ec98069ec94ee08a81c&v=ali&pu=078babd7"></video><br><strong>分步解析说明</strong>：</p>
<p>实现堆排序需要解决两个问题：</p>
<blockquote>
<p>1、如何由一个无序序列建成一个堆？<br>2、如何在输出堆顶元素之后，调整剩余元素成为一个新的堆？</p>
</blockquote>
<p>假设给定一个组无序数列{100,5,3,11,6,8,7}，带着问题，我们对其进行堆排序操作进行分步操作说明。</p>
<h3 id="3-1-创建最大堆"><a href="#3-1-创建最大堆" class="headerlink" title="3.1 创建最大堆"></a>3.1 创建最大堆</h3><p>①首先我们将数组我们将数组从上至下按顺序排列，转换成二叉树：一个无序堆。每一个三角关系都是一个堆，上面是父节点，下面两个分叉是子节点，两个子节点俗称左孩子、右孩子；</p>
<p><img src="https://pic2.zhimg.com/80/v2-6db33bd4ddb7937ca5946283ef2acc5d_720w.webp" alt="img"></p>
<p>②转换成无序堆之后，我们要努力让这个无序堆变成最大堆(或是最小堆)，即每个堆里都实现父节点的值都大于任何一个子节点的值。</p>
<p><img src="https://pic2.zhimg.com/80/v2-6db33bd4ddb7937ca5946283ef2acc5d_720w.webp" alt="img"></p>
<p>③从最后一个堆开始，即左下角那个没有右孩子的那个堆开始；首先对比左右孩子，由于这个堆没有右孩子，所以只能用左孩子，左孩子的值比父节点的值小所以不需要交换。如果发生交换，要检测子节点是否为其他堆的父节点，如果是，递归进行同样的操作。</p>
<p>④第二次对比红色三角形内的堆，取较大的子节点，右孩子8胜出，和父节点比较，右孩子8大于父节点3，升级做父节点，与3交换位置，3的位置没有子节点，这个堆建成最大堆。</p>
<p><img src="https://pic1.zhimg.com/80/v2-29c3af6ba60e66f1d328c164d09b4adc_720w.webp" alt="img"></p>
<p>⑤对黄色三角形内堆进行排序，过程和上面一样，最终是右孩子33升为父节点，被交换的右孩子下面也没有子节点，所以直接结束对比。</p>
<p>⑥最顶部绿色的堆，堆顶100比左右孩子都大，所以不用交换，至此最大堆创建完成。</p>
<p><img src="https://pic4.zhimg.com/80/v2-cf88501a8092e7b0c4712aa81a875f03_720w.webp" alt="img"></p>
<h3 id="3-2-堆排序（最大堆调整）"><a href="#3-2-堆排序（最大堆调整）" class="headerlink" title="3.2 堆排序（最大堆调整）"></a>3.2 堆排序（最大堆调整）</h3><p>①首先将堆顶元素100交换至最底部7的位置，7升至堆顶，100所在的底部位置即为有序区，有序区不参与之后的任何对比。</p>
<p><img src="https://pic3.zhimg.com/80/v2-e96b570c470785e19936abceee95c8ca_720w.webp" alt="img"></p>
<p>②在7升至顶部之后，对顶部重新做最大堆调整，左孩子33代替7的位置。</p>
<p><img src="https://pic2.zhimg.com/80/v2-5bbfec3cb200b9fa7efcf29fe71fc7dd_720w.webp" alt="img"></p>
<p>③在7被交换下来后，下面还有子节点，所以需要继续与子节点对比，左孩子11比7大，所以11与7交换位置，交换位置后7下面为有序区，不参与对比，所以本轮结束，无序区再次形成一个最大堆。</p>
<p><img src="https://pic2.zhimg.com/80/v2-1f490e927a5d7d5e97e9609f7e99b6e5_720w.webp" alt="img"></p>
<p>④将最大堆堆顶33交换至堆末尾，扩大有序区；</p>
<p><img src="https://pic1.zhimg.com/80/v2-d77c2cf77a7b81041fba5871979f3910_720w.webp" alt="img"></p>
<p>⑤不断建立最大堆，并且扩大有序区，最终全部有序。</p>
<p><img src="https://pic3.zhimg.com/80/v2-724e54aaff73bd4c0bf5e5352fc673ce_720w.webp" alt="img"></p>
<h3 id="4-复杂度分析"><a href="#4-复杂度分析" class="headerlink" title="4. 复杂度分析"></a>4. 复杂度分析</h3><ul>
<li>平均时间复杂度：O(nlogn)</li>
<li>最佳时间复杂度：O(nlogn)</li>
<li>最差时间复杂度：O(nlogn)</li>
<li>稳定性：不稳定</li>
</ul>
<p>堆排序其实也是一种选择排序，是一种树形选择排序。只不过直接选择排序中，为了从R[1…n]中选择最大记录，需比较n-1次，然后从R[1…n-2]中选择最大记录需比较n-2次。事实上这n-2次比较中有很多已经在前面的n-1次比较中已经做过，而树形选择排序恰好利用树形的特点保存了部分前面的比较结果，因此可以减少比较次数。对于n个关键字序列，最坏情况下每个节点需比较log2(n)次，因此其最坏情况下时间复杂度为nlogn。堆排序为不稳定排序，不适合记录较少的排序。</p>
<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HeapSort</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> data[];</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">HeapSort</span><span class="params">(<span class="type">int</span>[] data)</span>&#123;</span><br><span class="line">        <span class="built_in">this</span>.data = data;</span><br><span class="line">    &#125;</span><br><span class="line">     <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">sink</span><span class="params">(<span class="type">int</span> index,<span class="type">int</span> len)</span>&#123;</span><br><span class="line">        <span class="type">int</span> <span class="variable">child</span> <span class="operator">=</span> (index&lt;&lt;<span class="number">1</span>)+<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">if</span>(child&gt;len-<span class="number">1</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">if</span>(child+<span class="number">1</span>&lt;len&amp;&amp;(data[child]&lt;data[child+<span class="number">1</span>]))&#123;</span><br><span class="line">                child++;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span>(data[index]&gt;=data[child])&#123;</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            swap(index,child);</span><br><span class="line">            sink(child,len);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">sort</span><span class="params">()</span>&#123;</span><br><span class="line">      <span class="comment">//可以用raise按顺序添加，建立大顶堆</span></span><br><span class="line"><span class="comment">//        for (int i = 0; i &lt; data.length ; i++) &#123;  </span></span><br><span class="line"><span class="comment">//            raise(i);</span></span><br><span class="line"><span class="comment">//        &#125;</span></span><br><span class="line"><span class="comment">//        System.out.println(Arrays.toString(data));</span></span><br><span class="line">        <span class="comment">// 用下面倒序调整，建立大顶堆</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> data.length/<span class="number">2</span>; i &gt;=<span class="number">0</span>; i--) &#123; </span><br><span class="line">            sink(i,data.length);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> data.length-<span class="number">1</span>; i &gt;<span class="number">0</span>; i--) &#123;</span><br><span class="line">            System.out.println(Arrays.toString(data));</span><br><span class="line">            swap(<span class="number">0</span>,i);</span><br><span class="line">            sink(<span class="number">0</span>,i);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">swap</span><span class="params">(<span class="type">int</span> i,<span class="type">int</span> j)</span>&#123;</span><br><span class="line">        data[i]^=data[j];</span><br><span class="line">        data[j]^=data[i];</span><br><span class="line">        data[i]^=data[j];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">raise</span><span class="params">(<span class="type">int</span> index)</span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(index==<span class="number">0</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(data[(index-<span class="number">1</span>)/<span class="number">2</span>]&gt;=data[index]) &#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        swap(index,(index-<span class="number">1</span>)/<span class="number">2</span>);</span><br><span class="line">        raise((index-<span class="number">1</span>)/<span class="number">2</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">int</span>[] data = <span class="keyword">new</span> <span class="title class_">int</span>[]&#123;<span class="number">8</span>,<span class="number">6</span>,<span class="number">9</span>,<span class="number">2</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">7</span>,<span class="number">10</span>,<span class="number">3</span>,<span class="number">4</span>&#125;;</span><br><span class="line">        <span class="type">HeapSort</span> <span class="variable">hs</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">HeapSort</span>(data);</span><br><span class="line">        hs.sort();</span><br><span class="line">        System.out.println(Arrays.toString(data));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>建堆两种方法：（两种方式产生的堆不一定一样，但根节点都是最大的）</p>
<ul>
<li>可以从头到尾上浮一边， （上浮操作，保证了父节点不小于子节点）</li>
<li>也可以从最后一个非叶子节点开始到根节点做下沉操作。（下沉操作，保证了节点的左右子树均是堆）</li>
</ul>
<p>将堆顶与最后元素交换后，因为左右子树都是堆，所以只要对堆顶做一次下沉操作即可。</p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>排序算法</category>
        <category>选择排序</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>排序算法</tag>
        <tag>选择排序</tag>
      </tags>
  </entry>
  <entry>
    <title>直接选择排序</title>
    <url>/posts/fe838328/</url>
    <content><![CDATA[<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">public void sort(int l, int r)&#123;</span><br><span class="line">       int min;</span><br><span class="line">       for (int i = l; i &lt; r; i++) &#123;</span><br><span class="line">           min = i;</span><br><span class="line">           for (int j = i+1; j &lt;=r; j++) &#123;</span><br><span class="line">               if(data[min]&gt;data[j])&#123;</span><br><span class="line">                   min = j;</span><br><span class="line">               &#125;</span><br><span class="line">           &#125;</span><br><span class="line">           swap(i,min);</span><br><span class="line">           System.out.println(Arrays.toString(data));</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>

<p>每次选出最小和最大的</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">public void sort(int l, int r)&#123;</span><br><span class="line">       int max;</span><br><span class="line">       int min;</span><br><span class="line">       while (l&lt;r)&#123;</span><br><span class="line">           max = r;</span><br><span class="line">           min = l;</span><br><span class="line">           if(data[l]&gt;data[r])&#123;</span><br><span class="line">               swap(r,l);</span><br><span class="line">           &#125;</span><br><span class="line">           for (int i = l+1; i &lt;r ; i++) &#123;</span><br><span class="line">               if(data[max]&lt;data[i])&#123;</span><br><span class="line">                   max = i;</span><br><span class="line">               &#125;</span><br><span class="line">               if(data[min]&gt;data[i])&#123;</span><br><span class="line">                   min = i;</span><br><span class="line">               &#125;</span><br><span class="line">           &#125;</span><br><span class="line">           swap(l,min);</span><br><span class="line">           swap(r,max);</span><br><span class="line">           l++;</span><br><span class="line">           r--;</span><br><span class="line">           System.out.println(Arrays.toString(data));</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>

<p>选择排序是不稳定的，考虑 5  5* 3   ，第一次就变成 3  5*  5，5 到了 5*后面，</p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>排序算法</category>
        <category>选择排序</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>排序算法</tag>
        <tag>选择排序</tag>
      </tags>
  </entry>
</search>
