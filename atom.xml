<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>itingyu的博客</title>
  
  <subtitle>记录一些琐事罢了</subtitle>
  <link href="https://itingyu.github.io/atom.xml" rel="self"/>
  
  <link href="https://itingyu.github.io/"/>
  <updated>2023-06-25T10:43:14.000Z</updated>
  <id>https://itingyu.github.io/</id>
  
  <author>
    <name>itingyu</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>redis入门指南</title>
    <link href="https://itingyu.github.io/posts/44832/"/>
    <id>https://itingyu.github.io/posts/44832/</id>
    <published>2023-06-19T08:37:37.000Z</published>
    <updated>2023-06-25T10:43:14.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="redis入门指南"><a href="#redis入门指南" class="headerlink" title="redis入门指南"></a>redis入门指南</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><h3 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h3><h4 id="存储结构"><a href="#存储结构" class="headerlink" title="存储结构"></a>存储结构</h4><p>Redis是REmote DIctionary Server（远程字典服务器）的缩写，它以字典结构存储数<br>据，并允许其他应用通过TCP协议读写字典中的内容。同大多数脚本语言中的字典一样，<br>Redis字典中的键值除了可以是字符串，还可以是其他数据类型。到目前为止 Redis 支持的键<br>值数据类型如下</p><p>● 字符串类型<br>        ● 散列类型<br>        ● 列表类型<br>        ● 集合类型<br>        ● 有序集合类型</p><h4 id="内存存储与持久化"><a href="#内存存储与持久化" class="headerlink" title="内存存储与持久化"></a>内存存储与持久化</h4><p>Redis 数据库中的所有数据都存储在内存中。</p><p>由于内存的读写速度远快于硬盘，因此Redis在性能上对比其他基于硬盘存储的数据库有非常明显的优势，在一台普通的笔记本电脑上，Redis可以在一秒内读写超过10万个键值。</p><h4 id="功能丰富"><a href="#功能丰富" class="headerlink" title="功能丰富"></a>功能丰富</h4><p>Redis 虽然是作为数据库开发的，但由于其提供了丰富的功能，越来越多的人将其用作<br>缓存、队列系统等。Redis可谓是名副其实的多面手。</p><p>Redis 可以为每个键设置生存时间（Time To Live，TTL），生存时间到期后键会自动被<br>删除。这一功能配合出色的性能让Redis可以作为缓存系统来使用，而且由于Redis支持持久<br>化和丰富的数据类型，使其成为了另一个非常流行的缓存系统Memcached的有力竞争者。</p><p>在性能上 Redis是单线程模型，而Memcached支持多线程，所以在多核服务器上后者的性能理论上相对更高一些。然而，前面已经介绍过，Redis的性能已经足够优异，在绝大部分场合下其性能都不会成为瓶颈，所以在使用时更应该关心的是二者在功能上的区别。随着Redis 3.0 的推出，标志着<br>Memcached几乎所有功能都成为了Redis的子集。同时，Redis对集群的支持使得Memcached<br>原有的第三方集群工具不再成为优势。因此，在新项目中使用Redis代替Memcached将会是<br>非常好的选择。</p><p>作为缓存系统，Redis 还可以限定数据占用的最大内存空间，在数据达到空间限制后可<br>以按照一定的规则自动淘汰不需要的键。</p><p>Redis 的列表类型键可以用来实现队列，并且支持阻塞式读取，可以很容易<br>地实现一个高性能的优先级队列。同时在更高层面上，Redis 还支持“发布&#x2F;订阅”的消息模<br>式，可以基于此构建聊天室[6] 等系统。</p><h4 id="简单稳定"><a href="#简单稳定" class="headerlink" title="简单稳定"></a>简单稳定</h4><p>Redis 直观的存储结构使得通过程序与Redis交互十分简单。在Redis中使用命令来读写数据，命令语句之于Redis就相当于SQL语言之于关系数据库。</p><p>Redis提供了几十种不同编程语言的客户端库，这些库都很好地封装了Redis的命令，使<br>得在程序中与 Redis 进行交互变得更容易。有些库还提供了可以将编程语言中的数据类型直<br>接以相应的形式存储到Redis中（如将数组直接以列表类型存入Redis）的简单方法，使用起<br>来非常方便。</p><h2 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h2><p>Redis服务器默认会使用6379端口 ，通过–port参数可以自定义端口号</p><p>考虑到 Redis 有可能正在将内存中的数据同步到硬盘中，强行终止 Redis 进程可能会导<br>致数据丢失。正确停止Redis的方式应该是向Redis发送SHUTDOWN命令</p><p>当Redis收到SHUTDOWN命令后，会先断开所有客户端连接，然后根据配置执行持久<br>化，最后完成退出。</p><p>Redis可以妥善处理 SIGTERM信号，所以使用 kill Redis 进程的 PID也可以正常结束<br>Redis，效果与发送SHUTDOWN命令一样。</p><p>Redis是一个字典结构的存储服务器，而实际上一个Redis实例提供了多个用<br>来存储数据的字典，客户端可以指定将数据存储在哪个字典中。这与我们熟知的在一个关系<br>数据库实例中可以创建多个数据库类似，所以可以将其中的每个字典都理解成一个独立的数<br>据库。</p><p>每个数据库对外都是以一个从0开始的递增数字命名，Redis默认支持16个数据库，可以<br>通过配置参数databases来修改这一数字。客户端与Redis建立连接后会自动选择0号数据库，<br>不过可以随时使用SELECT命令更换数据库，</p><p>然而这些以数字命名的数据库又与我们理解的数据库有所区别。首先 Redis 不支持自定<br>义数据库的名字，每个数据库都以编号命名，开发者必须自己记录哪些数据库存储了哪些数<br>据。另外 Redis 也不支持为每个数据库设置不同的访问密码，所以一个客户端要么可以访问<br>全部数据库，要么连一个数据库也没有权限访问。最重要的一点是多个数据库之间并不是完<br>全隔离的，比如FLUSHALL命令可以清空一个Redis实例中所有数据库中的数据。</p><h2 id="入门"><a href="#入门" class="headerlink" title="入门"></a>入门</h2><h3 id="基本命令"><a href="#基本命令" class="headerlink" title="基本命令"></a>基本命令</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">keys pattern        pattern支持glob风格通配符格式</span><br><span class="line">exists key          如果键存在则返回整数类型1，否则返回0</span><br><span class="line">del key[key ...]可以删除一个或多个键，返回值是删除的键的个数。</span><br><span class="line">type key             TYPE命令用来获得键值的数据类型，返回值可能是string,（字符串类型            hash（散列类型）、list（列表类型）、set（集合类型）、zset（有序集合类型）。</span><br></pre></td></tr></table></figure><h3 id="字符串类型"><a href="#字符串类型" class="headerlink" title="字符串类型"></a>字符串类型</h3><p>字符串类型是 Redis 中最基本的数据类型，它能存储任何形式的字符串，包括二进制数<br>据。你可以用其存储用户的邮箱、JSON 化的对象甚至是一张图片。一个字符串类型键允许<br>存储的数据的最大容量是512 MB</p><p>字符串类型是其他4种数据类型的基础，其他数据类型和字符串类型的差别从某种角度<br>来说只是组织字符串的形式不同。</p><h4 id="命令"><a href="#命令" class="headerlink" title="命令"></a>命令</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">set key value     赋值</span><br><span class="line">get key           取值</span><br><span class="line">incr key          让当前键值递增并返回递增的值</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">incrby key increment  递增一个数值</span><br><span class="line">decr   key         递减</span><br><span class="line">decrby key decrement  减少某个值</span><br><span class="line">incrbyfloat key increment  递增一个双精度浮点数</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">append key value    向键值的末尾追加value，若键不存在，相当于set key value</span><br><span class="line">strlen key          返回键值的长度，如果不存在返回0</span><br><span class="line">mget key [key ...]  同时获得多个键值</span><br><span class="line">mset key value [key value ...]   同时设置多个键值,MGET/MSET 与GET/SET 相似，不过MGET/MSET 可以同时获得/设置多个键的键值。</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">一个字节由8个二进制位组成，Redis提供了4个命令可以直接对二进制位进行操作:            getbit key offset                获得一个字符串类型键指定位置的二进制位的值（0或1）</span><br><span class="line">setbit key offset value          设置字符串类型键指定位置的二进制位的值,返回旧值</span><br><span class="line">bitcount key offset [start][end] 获得字符串类型键中值是1的二进制位个数</span><br><span class="line">bitop operation destkey key [key...]     BITOP命令可以对多个字符串类型键进行位运算，并将结果存储在destkey参数指定的键中。BITOP命令   支持的运算操作有AND、OR、XOR和NOT</span><br></pre></td></tr></table></figure><h3 id="散列"><a href="#散列" class="headerlink" title="散列"></a>散列</h3><p>Redis 是采用字典结构以键值对的形式存储数据的，而散列类型（hash）的键值也是一种字典结构，其存储了字段（field）和字段值的映射，但字段值只能是字符串，不支持其他数据类型，换句话说，散列类型不能嵌套其他的数据类型。一个散列类型键可以包含至多232−1个字段。提示 除了散列类型，Redis 的其他数据类型同样不支持数据类型嵌套。比如集合类型的每个元素都只能是字符串，不能是另一个集合或散列表等。</p><p>散列类型适合存储对象：使用对象类别和 ID 构成键名，使用字段表示对象的属性，而<br>字段值则存储属性值。</p><h4 id="命令-1"><a href="#命令-1" class="headerlink" title="命令"></a>命令</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hset key field value                   给字段赋值</span><br><span class="line">hget key field                         获得字段的值</span><br><span class="line">hmset key field value [field value ...] 同时设置多个字段的值</span><br><span class="line">hmget key field [field ...]             同时获得多个字段的值</span><br><span class="line">hgetall key                             获取键中所有字段和字段值</span><br></pre></td></tr></table></figure><p>HSET 命令的方便之处在于不区分插入和更新操作，这意味着修改数据时不用事先判断<br>字段是否存在来决定要执行的是插入操作（update）还是更新操作（insert）当执行的是插<br>入操作时（即之前字段不存在）HSET命令会返回1，当执行的是更新操作时（即之前字段已<br>经存在）HSET命令会返回0。</p><p>提示 在Redis中每个键都属于一个明确的数据类型，如通过 HSET命令建立的键是散列类<br>型，通过SET命令建立的键是字符串类型等等。使用一种数据类型的命令操作另一种数据类<br>型的键会提示错误：”ERR Operation against a key holding the wrong kind of value”</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">hexists key field   判断一个字段是否存在。如果存在则返回1，否则返回0（如果键不存在也会返回0）。</span><br><span class="line"></span><br><span class="line">hsetnx key field value  与HSET命令类似，区别在于如果字段已经存在，HSETNX命令将不</span><br><span class="line">执行任何操作。</span><br><span class="line"></span><br><span class="line">hincrby key field increment   可以使字段值增加指定的整数,散列类型没有 HINCR 命令</span><br><span class="line"></span><br><span class="line">hdel key field [field ...]   删除一个或多个字段，返回值是被删除的字段个数</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hkeys key               需要获取键中所有字段的名字而不需要字段值  </span><br><span class="line">hvals key               获得键中所有字段值</span><br><span class="line">hlen key                获得字段数量</span><br></pre></td></tr></table></figure><h3 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h3><p>列表类型（list）可以存储一个有序的字符串列表，常用的操作是向列表两端添加元素，<br>或者获得列表的某一个片段。</p><p>列表类型内部是使用双向链表（double linked list）实现的，所以向列表两端添加元素的<br>时间复杂度为O(1)，获取越接近两端的元素速度就越快。这意味着即使是一个有几千万个元<br>素的列表，获取头部或尾部的10条记录也是极快的（和从只有20个元素的列表中获取头部或<br>尾部的10条记录的速度是一样的）。</p><p>不过使用链表的代价是通过索引访问元素比较慢。</p><p>这种特性使列表类型能非常快速地完成关系数据库难以应付的场景：如社交网站的新鲜<br>事，我们关心的只是最新的内容，使用列表类型存储，即使新鲜事的总数达到几千万个，获<br>取其中最新的100条数据也是极快的。同样因为在两端插入记录的时间复杂度是O(1)，列表<br>类型也适合用来记录日志，可以保证加入新日志的速度不会受到已有日志数量的影响。</p><p>借助列表类型，Redis还可以作为队列使用</p><p>与散列类型键最多能容纳的字段数量相同，一个列表类型键最多能容纳232−1个元素。</p><h4 id="命令-2"><a href="#命令-2" class="headerlink" title="命令"></a>命令</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">lpush key value [value]     向列表左边增加元素，返回值表示增加元素后列表的长度。</span><br><span class="line">rpush key value [value]     向列表右边增加元素</span><br><span class="line">lpop key    从列表左边弹出一个元素,第一步是将列表左边的元素从列表中移除，第二步是返回被移             除的元素值。</span><br><span class="line">rpop key    从列表右边弹出一个元素</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">llen key    获取列表中元素的个数,当键不存在时LLEN会返回0：</span><br><span class="line">lrange key start stop    返回索引从 start到 stop之间的所有元素（包含两端的元素）</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">lrem key count value    删除列表中前count个值为value的元素，返回值是实际删除的元素个数。</span><br><span class="line">（1）当 count &gt; 0时 LREM 命令会从列表左边开始删除前 count 个值为 value的元素。</span><br><span class="line">（2）当 count &lt; 0时 LREM 命令会从列表右边开始删除前|count|个值为 value 的元素。</span><br><span class="line">（3）当 count = 0是 LREM命令会删除所有值为 value的元素。</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">lindex key index          返回指定索引的元素，索引从0开始,如果index是负数则表示从右边开始计算的索引，最右边元素的索引是−1</span><br><span class="line">lset key index value  将索引为index的元素赋值为value</span><br><span class="line">ltrim key start end   删除指定索引范围之外的所有元素</span><br><span class="line">linsert key before|after pivot value  在列表中从左到右查找值为 pivot 的元素，然后根据第二个参数是</span><br><span class="line">BEFORE还是AFTER来决定将value插入到该元素的前面还是后面。</span><br><span class="line"></span><br><span class="line">rpoplpush source destination    将元素从一个列表转到另一个列表</span><br></pre></td></tr></table></figure><h3 id="集合类型"><a href="#集合类型" class="headerlink" title="集合类型"></a>集合类型</h3><p>在集合中的每个元素都是不同的，且没有顺序。一个集合类型（set）键可以存储至多232 −1个（相信这个数字对大家来说已经很熟悉了）字符串。</p><p>集合类型的常用操作是向集合中加入或删除元素、判断某个元素是否存在等，由于集合<br>类型在Redis内部是使用值为空的散列表（hash table）实现的所以这些操作的时间复杂度都<br>是O(1)。最方便的是多个集合类型键之间还可以进行并集、交集和差集运算，稍后就会看到<br>灵活运用这一特性带来的便利。</p><h4 id="命令-3"><a href="#命令-3" class="headerlink" title="命令"></a>命令</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sadd key member [member ...]   向集合中增加一个或多个元素，如果键不存在则会自动创建。</span><br><span class="line">srem key member [member ...]   从集合中删除一个或多个元素，并返回删除成功的个数</span><br><span class="line">smembers key                   返回集合中的所有元素</span><br><span class="line">sismember key member     判断一个元素是否在集合中是一个时间复杂度为O(1)的操作</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sdiff key [key ...]            对多个集合执行差集运算</span><br><span class="line">sinter key [key ...]           对多个集合执行交集运算</span><br><span class="line">sunion key [key ...]           对多个集合执行并集运算</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scard key         获得集合中的元素个数</span><br><span class="line">sdiffstore destination key [key ...]   不会直接返回运算结果，</span><br><span class="line">而是将结果存储在destination键中。</span><br><span class="line">sinterstore destination key [key ...]</span><br><span class="line">sunionstore destination key [key ...]</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">srandmember key [count]   随机获得集合中的元素</span><br><span class="line">还可以传递count参数来一次随机获得多个元素，根据count的正负不同，具体表现也不同。</span><br><span class="line">1）当count为正数时，SRANDMEMBER会随机从集合里获得count个不重复的元素。</span><br><span class="line">如果count的值大于集合中的元素个数，则SRANDMEMBER会返回集合中的全部元素。</span><br><span class="line">2）当count为负数时，SRANDMEMBER会随机从集合里获得|count|个的元素，这些元</span><br><span class="line">素有可能相同。</span><br><span class="line">SRANDMEMBER 命令返回的数据似乎并不是非常的随机出现这种情况是由集合类型采用的存储结构（散列表）造成的。散列表使用散列函数将元素映射到不同的存储位置（桶）上以实现O(1)时间复杂度的元素查找，举个例子，当使用散列表存储元素b时，使用散列函数计算出b的散列值是0，所以将b存入编号为0的桶（bucket）中，下次要查找b时就可以用同样的散列函数再次计算b的散列值并直接到相</span><br><span class="line">应的桶中找到 b。当两个不同的元素的散列值相同时会出现冲突，Redis 使用拉链法来解决冲</span><br><span class="line">突，即将散列值冲突的元素以链表的形式存入同一桶中，查找元素时先找到元素对应的桶，</span><br><span class="line">然后再从桶中的链表中找到对应的元素。使用SRANDMEMBER命令从集合中获得一个随机</span><br><span class="line">元素时，Redis首先会从所有桶中随机选择一个桶，然后再从桶中的所有元素中随机选择一个</span><br><span class="line">元素，所以元素所在的桶中的元素数量越少，其被随机选中的可能性就越大，</span><br></pre></td></tr></table></figure><h3 id="有序集合"><a href="#有序集合" class="headerlink" title="有序集合"></a>有序集合</h3><p>在集合类型的基础上有序集合类型为集合中的每个元素都关联了一个分数，这使得我们<br>不仅可以完成插入、删除和判断元素是否存在等集合类型支持的操作，还能够获得分数最高<br>（或最低）的前N个元素、获得指定分数范围内的元素等与分数有关的操作。虽然集合中每<br>个元素都是不同的，但是它们的分数却可以相同。</p><p>有序集合类型在某些方面和列表类型有些相似。<br>（1）二者都是有序的。（2）二者都可以获得某一范围的元素。</p><p>但是二者有着很大的区别，这使得它们的应用场景也是不同的。<br>（1）列表类型是通过链表实现的，获取靠近两端的数据速度极快，而当元素增多后，<br>访问中间数据的速度会较慢，所以它更加适合实现如“新鲜事”或“日志”这样很少访问中间元<br>素的应用。（2）有序集合类型是使用散列表和跳跃表（Skip list）实现的，所以即使读取位于中间<br>部分的数据速度也很快（时间复杂度是O(log(N))）（3）列表中不能简单地调整某个元素的位置，但是有序集合可以（通过更改这个元素的分数）。（4）有序集合要比列表类型更耗费内存。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">zadd key score member [score member ...] 加入一个元素和该元素的分数,如果该元素已经存在则会用新的分数替换原有的分数</span><br><span class="line">zscore key member获得元素的分数</span><br><span class="line">zrange key start stop [withscores]  按照元素分数从小到大的顺序返回索引从 start到stop之间的所有元素,如果需要同时获得元素的分数的话可以在 ZRANGE 命令的尾部加上 WITHSCORES 参数，如果两个元素的分数相同，Redis会按照字典顺序（即&quot;0&quot;&lt;&quot;9&quot;&lt;&quot;A&quot;&lt;&quot;Z&quot;&lt;&quot;a&quot;&lt;&quot;z&quot;这样的顺序）来进行排列。再进一步，如果元素的值是中文怎么处理呢？答案是取决于中文的编码方</span><br><span class="line">式，如使用UTF-8编码</span><br><span class="line">zrevrange key start stop [withscores]  按照元素分数从大到小的顺序给出结果</span><br><span class="line"></span><br><span class="line">zrangebyscore min max [withscores][limit offset count] 该命令按照元素分数从小到大</span><br><span class="line">的顺序返回分数在min和max之间（包含min和max）的元素,</span><br><span class="line">如果希望分数范围不包含端点值，可以在分数前加上“(”符号</span><br><span class="line">min和max还支持无穷大，同ZADD命令一样，-inf和+inf分别表示负无穷和正无穷。比如你希望得到所有分数高于80分（不包含80分）的人的名单，但你却不知道最高分是多少,（虽然有些背离现实，但是为了叙述方便，这里假设可以获得的分数是无上限的），这时就可以用上+inf了</span><br><span class="line"> LIMIT offset count</span><br><span class="line">与 SQL 中的用法基本相同，即在获得的元素列表的基础上向后偏移offset个元素，并且只获</span><br><span class="line">取前count个元素。</span><br><span class="line">ZINCRBY key increment member   命令可以增加一个元素的分数，返回值是更改后的分数。</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">zcard key 获得集合中元素的数量</span><br><span class="line">zcount key min max 获得指定分数范围内的元素个数</span><br><span class="line">zrem key member[member ...] 删除一个或多个元素</span><br><span class="line">zremrangebyrank key start stop 按照元素分数从小到大的顺序（即索引 0表示最小的值）</span><br><span class="line">删除处在指定排名范围内的所有元素，并返回删除的元素数量。</span><br><span class="line">zremrangebyscore key min max  删除指定分数范围内的所有元素</span><br><span class="line">zrank key member  按照元素分数从小到大的顺序获得指定的元素的排名（从0开始，即分数</span><br><span class="line">最小的元素排名为0）。</span><br><span class="line">zinterstore</span><br></pre></td></tr></table></figure><h2 id="进阶"><a href="#进阶" class="headerlink" title="进阶"></a>进阶</h2><h3 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h3><p>Redis中的事务（transaction）是一组命令的集合。事务同命令一样都是 Redis 的最小执<br>行单位，一个事务中的命令要么都执行，要么都不执行。</p><p>事务的原理是先将属于一个事务的命令发送给Redis，然后再让Redis依次执行这些命<br>令。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">redis&gt; multi</span><br><span class="line">ok</span><br><span class="line">redis&gt; sadd &quot;user:1:following&quot; 2</span><br><span class="line">queued</span><br><span class="line">redis&gt; sadd &quot;user:2:followers&quot; 1</span><br><span class="line">queued</span><br><span class="line">redis&gt; exec</span><br><span class="line">1)(integer) 1</span><br><span class="line">2)(integer) 1</span><br><span class="line">首先使用MULTI命令告诉Redis：“下面我发给你的命令属于同一个事务，你先不要执行，而是把它们暂时存起来。”Redis回答：“OK。”</span><br><span class="line">而后我们发送了两个 SADD命令来实现关注和被关注操作，可以看到 Redis 遵守了承诺，没有执行这些命令，而是返回QUEUED表示这两条命令已经进入等待执行的事务队列中了。</span><br><span class="line">当把所有要在同一个事务中执行的命令都发给 Redis 后，我们使用 EXEC 命令告诉Redis</span><br><span class="line">将等待执行的事务队列中的所有命令（即刚才所有返回QUEUED的命令）按照发送顺序依次执行。EXEC 命令的返回值就是这些命令的返回值组成的列表，返回值顺序和命令的顺序相同。</span><br><span class="line"></span><br><span class="line">Redis保证一个事务中的所有命令要么都执行，要么都不执行。如果在发送EXEC命令前客户端断线了，则 Redis 会清空事务队列，事务中的所有命令都不会执行。而一旦客户端发送了EXEC命令，所有的命令就都会被执行，即使此后客户端断线也没关系，因为Redis中已经记录了所有要执行的命令。</span><br><span class="line">除此之外，Redis 的事务还能保证一个事务内的命令依次执行而不被其他命令插入。试想客户端A需要执行几条命令，同时客户端B发送了一条命令，如果不使用事务，则客户端B的命令可能会插入到客户端A的几条命令中执行。如果不希望发生这种情况，也可以使用事务。</span><br></pre></td></tr></table></figure><h3 id="错误处理"><a href="#错误处理" class="headerlink" title="错误处理"></a>错误处理</h3><p>如果一个事务中的某个命令执行出错，Redis 会怎样处理呢？要回答这个问题，首先需要知道什么原因会导致命令执行出错。</p><p>（1）语法错误。语法错误指命令不存在或者命令参数的个数不对。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; multi</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; set name itingyu</span><br><span class="line">QUEUED</span><br><span class="line">127.0.0.1:6379&gt; set age</span><br><span class="line">(error) ERR wrong number of arguments for &#x27;set&#x27; command</span><br><span class="line">127.0.0.1:6379&gt; errorcommand age</span><br><span class="line">(error) ERR unknown command &#x27;errorcommand&#x27;</span><br><span class="line">127.0.0.1:6379&gt; exec</span><br><span class="line">(error) EXECABORT Transaction discarded because of previous errors.</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure><p>跟在MULTI命令后执行了3个命令：一个是正确的命令，成功地加入事务队列；其余两<br>个命令都有语法错误。而只要有一个命令有语法错误，执行 EXEC 命令后 Redis 就会直接返<br>回错误，连语法正确的命令也不会执行。</p><p>（2）运行错误。运行错误指在命令执行时出现的错误，比如使用散列类型的命令操作<br>集合类型的键，这种错误在实际执行之前 Redis 是无法发现的，所以在事务里这样的命令是<br>会被 Redis 接受并执行的。如果事务里的一条命令出现了运行错误，事务里其他的命令依然<br>会继续执行（包括出错命令之后的命令）</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; multi</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; set key 1</span><br><span class="line">QUEUED</span><br><span class="line">127.0.0.1:6379&gt; sadd key 2</span><br><span class="line">QUEUED</span><br><span class="line">127.0.0.1:6379&gt; set key 3</span><br><span class="line">QUEUED</span><br><span class="line">127.0.0.1:6379&gt; exec</span><br><span class="line">1) OK</span><br><span class="line">2) (error) WRONGTYPE Operation against a key holding the wrong kind of value</span><br><span class="line">3) OK</span><br><span class="line">127.0.0.1:6379&gt; get key</span><br><span class="line">&quot;3&quot;</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure><p>可见虽然 SADD key 2出现了错误，但是 SET key 3依然执行了。<br>Redis的事务没有关系数据库事务提供的回滚（rollback）[1] 功能。为此开发者必须在事<br>务执行出错后自己收拾剩下的摊子（将数据库复原回事务执行前的状态等）。</p><p>不过由于 Redis 不支持回滚功能，也使得 Redis 在事务上可以保持简洁和快速。另外回<br>顾刚才提到的会导致事务执行失败的两种错误，其中语法错误完全可以在开发时找出并解<br>决，另外如果能够很好地规划数据库（保证键名规范等）的使用，是不会出现如命令与数据<br>类型不匹配这样的运行错误的。</p><h3 id="watch命令介绍"><a href="#watch命令介绍" class="headerlink" title="watch命令介绍"></a>watch命令介绍</h3><p>我们已经知道在一个事务中只有当所有命令都依次执行完后才能得到每个结果的返回<br>值，可是有些情况下需要先获得一条命令的返回值，然后再根据这个值执行下一条命令。例<br>如介绍INCR命令时曾经说过使用GET和SET命令自己实现incr函数会出现竞态条件，</p><p>肯定会有很多读者想到可以用事务来实现incr函数以防止竞态条件，可是因为事务中的<br>每个命令的执行结果都是最后一起返回的，所以无法将前一条命令的结果作为下一条命令的<br>参数，即在执行SET命令时无法获得GET命令的返回值，也就无法做到增1的功能了。</p><p>我们需要换一种思路。即在GET获得键值后保证该键值不被其他客户端修改，直到函数执行完成后才允许其他客户端修改该键键值，这样也可以防止竞态条件。要实现这一思路需要请出事务家族的另一位成员：WATCH。</p><p>WATCH 命令可以监控一个或多个键，一旦其中有一个键被修改（或删除），之后的事务就不会执行。监控一直持续到EXEC 命令（事务中的命令是在 EXEC 之后才执行的，所以在 MULTI 命令后可以修改WATCH监控的键值）</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; set key 1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; watch key</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; set key 2</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; multi</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; set key 3</span><br><span class="line">QUEUED</span><br><span class="line">127.0.0.1:6379&gt; exec</span><br><span class="line">(nil)</span><br><span class="line">127.0.0.1:6379&gt; get key</span><br><span class="line">&quot;2&quot;</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure><p>上例中在执行 WATCH命令后、事务执行前修改了key的值（即 SET key 2），所以最后<br>事务中的命令 SET key 3没有执行，EXEC命令返回空结果。</p><p>学会了WATCH命令就可以通过事务自己实现incr函数了</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">def incr($key)</span><br><span class="line">WATCH $key</span><br><span class="line">$value = GET $key</span><br><span class="line">if not $value</span><br><span class="line">$value = 0</span><br><span class="line">$value = $value + 1</span><br><span class="line">MULTI</span><br><span class="line">SET $key, $value</span><br><span class="line">result = EXEC</span><br><span class="line">return result[0]</span><br></pre></td></tr></table></figure><p>因为EXEC命令返回值是多行字符串类型，所以代码中使用result[0]来获得其中第一个结<br>果。</p><p>提示 由于WATCH命令的作用只是当被监控的键值被修改后阻止之后一个事务的执行，<br>而不能保证其他客户端不修改这一键值，所以我们需要在EXEC执行失败后重新执行整个函<br>数。</p><p><strong>执行 EXEC 命令后会取消对所有键的监控，如果不想执行事务中的命令也可以使用</strong><br><strong>UNWATCH命令来取消监控。</strong></p><p>在代码中会判断要赋值的字段是否存在，如果字段不存在的话就不执行事务中的命令，<br>但需要使用UNWATCH命令来保证下一个事务的执行不会受到影响。</p><h2 id="过期时间"><a href="#过期时间" class="headerlink" title="过期时间"></a>过期时间</h2><p>在实际的开发中经常会遇到一些有时效的数据，比如限时优惠活动、缓存或验证码等，<br>过了一定的时间就需要删除这些数据。在关系数据库中一般需要额外的一个字段记录到期时<br>间，然后定期检测删除过期数据。而在Redis中可以使用 EXPIRE命令设置一个键的过期时<br>间，到时间后Redis会自动删除它。</p><h3 id="命令介绍"><a href="#命令介绍" class="headerlink" title="命令介绍"></a>命令介绍</h3><p>EXPIRE 命令的使用方法为 <strong>EXPIRE key seconds</strong>，其中 seconds 参数表示键的过期时<br>间，单位是秒。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; keys *</span><br><span class="line">1) &quot;mylist&quot;</span><br><span class="line">127.0.0.1:6379&gt; expire mylist 1</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; keys *</span><br><span class="line">(empty list or set)</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure><p>如果想知道一个键还有多久的时间会被删除，可以使用<strong>TTL命令。返回值是键的剩余时</strong><br><strong>间（单位是秒）,</strong></p><p><strong>当键不存在时TTL命令会返回−2。</strong></p><p>那么<strong>没有为键设置过期时间（即永久存在</strong>，这是建立一个键后的默认情况）的情况下会<br>返回什么呢？答案是<strong>返回−1</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; keys *</span><br><span class="line">(empty list or set)</span><br><span class="line">127.0.0.1:6379&gt; set key 1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; ttl key</span><br><span class="line">(integer) -1</span><br><span class="line">127.0.0.1:6379&gt; expire key 10</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; ttl key</span><br><span class="line">(integer) 7</span><br><span class="line">127.0.0.1:6379&gt; ttl key</span><br><span class="line">(integer) 5</span><br><span class="line">127.0.0.1:6379&gt; ttl key</span><br><span class="line">(integer) 4</span><br><span class="line">127.0.0.1:6379&gt; ttl key</span><br><span class="line">(integer) 3</span><br><span class="line">127.0.0.1:6379&gt; ttl key</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; ttl key</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; ttl key</span><br><span class="line">(integer) -2</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure><p>如果想取消键的过期时间设置（即将键恢复成永久的），则可以使用PERSIST命令。如<br>果过期时间被成功清除则返回1；否则返回0（因为键不存在或键本来就是永久的）：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; set key 1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; expire key 20</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; ttl key</span><br><span class="line">(integer) 17</span><br><span class="line">127.0.0.1:6379&gt; persist key</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; ttl key</span><br><span class="line">(integer) -1</span><br><span class="line">127.0.0.1:6379&gt; persist key</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; persist key1</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure><p>除了PERSIST命令之外，使用SET或GETSET命令为键赋值也会同时清除键的过期时间</p><p>其他只对键值进行操作的命令（如INCR、LPUSH、HSET、ZREM）均不会影响键的过期时间。EXPIRE命令的seconds参数必须是整数，所以最小单位是1秒。如果想要更精确的控制键的过期时间应该使用 PEXPIRE命令，PEXPIRE命令与 EXPIRE的唯一区别是前者的时间单位是毫秒，即 PEXPIRE key 1000 与 EXPIRE key 1 等价。对应地可以用 PTTL命令以毫秒为单位返回键的剩余时间。</p><p><strong>提示 如果使用 WATCH命令监测了一个拥有过期时间的键，该键时间到期自动删除并不</strong><br><strong>会被WATCH命令认为该键被改变。</strong></p><p>另外还有两个相对不太常用的命令：EXPIREAT和PEXPIREAT。EXPIREAT命令与EXPIRE命令的差别在于前者使用Unix时间作为第二个参数表示键的过期时刻。PEXPIREAT命令与EXPIREAT命令的区别是前者的时间单位是毫秒。</p><h3 id="实现访问速率限制"><a href="#实现访问速率限制" class="headerlink" title="实现访问速率限制"></a>实现访问速率限制</h3><p>为了减轻服务器的压力，需要限制每个用户（以IP计）一段时间的最大访问量。与时间有关的操作很容易想到EXPIRE命令。</p><p>例如要限制每分钟每个用户最多只能访问100个页面，思路是对每个用户使用一个名为<br>rate.limiting:用户 IP的字符串类型键，每次用户访问则使用 INCR命令递增该键的键值，如果<br>递增后的值是1（第一次访问页面），则同时还要设置该键的过期时间为1分钟。这样每次用<br>户访问页面时都读取该键的键值，如果超过了100就表明该用户的访问频率超过了限制，需<br>要提示用户稍后访问。该键每分钟会自动被删除，所以下一分钟用户的访问次数又会重新计<br>算，也就达到了限制访问频率的目的。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$isKeyExists = EXISTS rate.limiting:$IP</span><br><span class="line">if $isKeyExists is 1</span><br><span class="line">$times = INCR rate.limiting:$IP</span><br><span class="line">if $times &gt; 100</span><br><span class="line">print 访问频率超过了限制，请稍后再试。</span><br><span class="line">exit</span><br><span class="line">else</span><br><span class="line">MULTI</span><br><span class="line">INCR rate.limiting:$IP</span><br><span class="line">EXPIRE $keyName, 60</span><br><span class="line">EXEC</span><br></pre></td></tr></table></figure><p>事实上，4.2.2节中的代码仍然有个问题：如果一个用户在一分钟的第一秒访问了一次博<br>客，在同一分钟的最后一秒访问了9次，又在下一分钟的第一秒访问了10次，这样的访问是<br>可以通过现在的访问频率限制的，但实际上该用户在2秒内访问了19次博客，这与每个用户<br>每分钟只能访问10次的限制差距较大。尽管这种情况比较极端，但是在一些场合中还是需要<br>粒度更小的控制方案。如果要精确地保证每分钟最多访问10次，需要记录下用户每次访问的<br>时间。因此对每个用户，我们使用一个列表类型的键来记录他最近10次访问博客的时间。一<br>旦键中的元素超过 10 个，就判断时间最早的元素距现在的时间是否小于 1分钟。如果是则表<br>示用户最近1分钟的访问次数超过了10次；如果不是就将现在的时间加入到列表中，同时把<br>最早的元素删除。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$listLength = LLEN rate.limiting:$IP</span><br><span class="line">if $listLength &lt; 10</span><br><span class="line">LPUSH rate.limiting:$IP, now()</span><br><span class="line">else</span><br><span class="line">$time = LINDEX rate.limiting:$IP, -1</span><br><span class="line">if now() - $time &lt; 60</span><br><span class="line">print 访问频率超过了限制，请稍后再试。</span><br><span class="line">else</span><br><span class="line">LPUSH rate.limiting:$IP, now()</span><br><span class="line">LTRIM rate.limiting:$IP, 0, 9</span><br></pre></td></tr></table></figure><p>代码中 now()的功能是获得当前的 Unix 时间。由于需要记录每次访问的时间，所以当要<br>限制“A时间最多访问B次”时，如果“B”的数值较大，此方法会占用较多的存储空间，实际使<br>用时还需要开发者自己去权衡。除此之外该方法也会出现竞态条件，同样可以通过脚本功能<br>避免，具体在第6章会介绍到。</p><h3 id="实现缓存"><a href="#实现缓存" class="headerlink" title="实现缓存"></a>实现缓存</h3><p>为了提高网站的负载能力，常常需要将一些访问频率较高但是对CPU或IO资源消耗较大的操作的结果缓存起来，并希望让这些缓存过一段时间自动过期。</p><p>比如教务网站要对全校所有学生的各个科目的成绩汇总排名，并在首页上显示前10名的学生姓名，由于计算过程较耗资源，所以可以将结果使用一个 Redis 的字符串键缓存起来。由于学生成绩总在不断地变化，需要每隔两个小时就重新计算一次排名，这可以通过给键设置过期时间的方式实现。每次用户访问首页时程序先查询缓存键是否存在，如果存在则直接使用缓存的值；否则重新计算排名并将计算结果赋值给该键并同时设置该键的过期时间为两个小时。</p><p>当服务器内存有限时，如果大量地使用缓存键且过期时间设置得过长就会导致 Redis 占满内存；另一方面如果为了防止 Redis 占用内存过大而将缓存键的过期时间设得太短，就可能导致缓存命中率过低并且大量内存白白地闲置。实际开发中会发现很难为缓存键设置合理的过期时间，为此可以限制 Redis 能够使用的最大内存，并让Redis按照一定的规则淘汰不需要的缓存键，这种方式在只将Redis用作缓存系统时非常实用。</p><p>具体的设置方法为：修改配置文件的maxmemory参数，限制Redis最大可用内存大小（单位是字节），当超出了这个限制时Redis会依据maxmemory-policy参数指定的策略来删除不需要的键直到Redis占用的内存小于指定内存。maxmemory-policy支持的规则如表4-1所示。其中的LRU（Least Recently Used）算法即“最近最少使用”，其认为最近最少使用的键在未来一段时间内也不会被用到，即当需要空间时这些键是可以被删除的。如当maxmemory-policy设为allkeys-lru时，一旦Redis占用的内存超过了限制值，Redis会不断地删除数据库中最近最少使用的键[2] ，直到占用的内存小于限制值。</p><h2 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h2><p>有序集合常见的使用场景是大数据排序，如游戏的玩家排行榜，所以很少会需要获得键中的全部数据。同样 Redis 认为开发者在做完交集、并集运算后不需要直接获得全部结果，而是会希望将结果存入新的键中以便后续处理。这解释了为什么有序集合只有ZINTERSTORE和ZUNIONSTORE命令而没有ZINTER和ZUNION命令。</p><h3 id="SORT命令"><a href="#SORT命令" class="headerlink" title="SORT命令"></a>SORT命令</h3><p>SORT命令可以对列表类型、集合类型和有序集合类型键进行排序，并且可以完成与关系数据库中的连接查询相类似的任务。除了集合类型，SORT 命令还可以对列表类型和有序集合类型进行排序，在对有序集合类型排序时会忽略元素的分数，只针对元素自身的值进行排序。</p><p>SORT 命令默认是按照从小到大的顺序排列，SORT命令的DESC参数可以实现<br>将元素按照从大到小的顺序排列。</p><p>SORT命令还支持LIMIT参数来返回指定范围的结果。用法和 SQL 语句一样，LIMIT offset count，表示跳过前 offset 个元素并获取之后的count个元素。</p><h3 id="by参数"><a href="#by参数" class="headerlink" title="by参数"></a>by参数</h3><p>BY参数的语法为BY参考键。其中参考键可以是字符串类型键或者是散列类型键的某个<br>字段（表示为键名-&gt;字段名）。如果提供了 BY 参数，SORT 命令将不再依据元素自身的值<br>进行排序，而是对每个元素使用元素的值替换参考键中的第一个“*”并获取其值，然后依据<br>该值对元素排序。</p><h3 id="Get参数"><a href="#Get参数" class="headerlink" title="Get参数"></a>Get参数</h3><p>GET参数不影响排序，它的作用是使 SORT命令的返回结果不再是元素自身的值，而是<br>GET参数中指定的键值。</p><p>GET参数的规则和BY参数一样，GET参数也支持字符串类型和散列<br>类型的键，并使用“*”作为占位符。</p><p>在一个SORT命令中可以有多个GET参数（而BY参数只能有一个）</p><p>可见有N个GET参数，每个元素返回的结果就有N行。这时有个问题：如果还需要返回<br>文章ID 该怎么办？答案是使用 GET #。也就是说，GET #会返回元素本身的值。</p><h3 id="store参数"><a href="#store参数" class="headerlink" title="store参数"></a>store参数</h3><p>默认情况下SORT会直接返回排序结果，如果希望保存排序结果，可以使用STORE参<br>数。</p><p>保存后的键的类型为列表类型，如果键已经存在则会覆盖它。加上STORE参数后SORT<br>命令的返回值为结果的个数。</p><p>STORE参数常用来结合EXPIRE命令缓存排序结果</p><h3 id="性能优化"><a href="#性能优化" class="headerlink" title="性能优化"></a>性能优化</h3><p>SORT是Redis中最强大最复杂的命令之一，如果使用不好很容易成为性能瓶颈。SORT命<br>令的时间复杂度是O(n+mlog(m))，其中n表示要排序的列表（集合或有序集合）中的元素个<br>数，m表示要返回的元素个数。当n较大的时候SORT命令的性能相对较低，并且Redis在排序<br>前会建立一个长度为n[4] 的容器来存储待排序的元素，虽然是一个临时的过程，但如果同时<br>进行较多的大数据量排序操作则会严重影响性能。</p><p>所以开发中使用SORT命令时需要注意以下几点。<br>（1）尽可能减少待排序键中元素的数量（使N尽可能小）。<br>（2）使用LIMIT参数只获取需要的数据（使M尽可能小）。<br>（3）如果要排序的数据数量较大，尽可能使用STORE参数将结果缓存。</p><h2 id="消息通知"><a href="#消息通知" class="headerlink" title="消息通知"></a>消息通知</h2><h3 id="任务队列"><a href="#任务队列" class="headerlink" title="任务队列"></a>任务队列</h3><p>当页面需要进行如发送邮件、复杂数据运算等耗时较长的操作时会阻塞页面的渲染。为了避免用户等待太久，应该使用独立的线程来完成这类操作。不过一些编程语言或框架不易实现多线程，这时很容易就会想到通过其他进程来实现。就小白的例子来说，设想有一个进程能够完成发邮件的功能，那么在页面中只需要想办法通知这个进程向指定的地址发送邮件就可以了。</p><p>通知的过程可以借助任务队列来实现。任务队列顾名思义，就是“传递任务的队列”。与<br>任务队列进行交互的实体有两类，一类是生产者（producer），另一类是消费者<br>（consumer）。生产者会将需要处理的任务放入任务队列中，而消费者则不断地从任务队列<br>中读入任务信息并执行。</p><p>对于发邮件这个操作来说页面程序就是生产者，而发邮件的进程就是消费者。当需要发<br>送邮件时，页面程序会将收件地址、邮件主题和邮件正文组装成一个任务后存入任务队列<br>中。同时发邮件的进程会不断检查任务队列，一旦发现有新的任务便会将其从队列中取出并<br>执行。由此实现了进程间的通信。</p><p>使用任务队列有如下好处。</p><p>1．松耦合<br>        生产者和消费者无需知道彼此的实现细节，只需要约定好任务的描述格式。这使得生产<br>者和消费者可以由不同的团队使用不同的编程语言编写。</p><p>2．易于扩展<br>        消费者可以有多个，而且可以分布在不同的服务器中，如图4-1所示。借此可以轻易地降低单台服务器的负载。</p><h3 id="使用redis实现任务队列"><a href="#使用redis实现任务队列" class="headerlink" title="使用redis实现任务队列"></a>使用redis实现任务队列</h3><p>说到队列很自然就能想到Redis的列表类型，如果要实现任务队列，只需要让生产者将任务使用LPUSH命令加入到某个键中，另一边让消费者不断地使用RPOP命令从该键中取出任务即可。</p><p>BRPOP命令和RPOP命令相似，唯一的区别是当列表中没有元素时BRPOP命令会一直阻<br>塞住连接，直到有新元素加入。</p><p>BRPOP命令接收两个参数，第一个是键名，第二个是超时时间，单位是秒。当超过了此<br>时间仍然没有获得新元素的话就会返回 nil。上例中超时时间为”0”，表示不限制等待的时<br>间，即如果没有新元素加入列表就会永远阻塞下去。</p><p>除了 BRPOP命令外，Redis 还提供了 BLPOP，和 BRPOP的区别在与从队列取元素时<br>BLPOP会从队列左边取。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;redis入门指南&quot;&gt;&lt;a href=&quot;#redis入门指南&quot; class=&quot;headerlink&quot; title=&quot;redis入门指南&quot;&gt;&lt;/a&gt;redis入门指南&lt;/h1&gt;&lt;h2 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; </summary>
      
    
    
    
    <category term="读书笔记" scheme="https://itingyu.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    <category term="redis入门指南" scheme="https://itingyu.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/redis%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97/"/>
    
    
    <category term="读书笔记" scheme="https://itingyu.github.io/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    <category term="redis入门指南" scheme="https://itingyu.github.io/tags/redis%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97/"/>
    
  </entry>
  
  <entry>
    <title>Nocas配置注册中心和Sentinel分布式流量防卫兵相关知识总结</title>
    <link href="https://itingyu.github.io/posts/53802/"/>
    <id>https://itingyu.github.io/posts/53802/</id>
    <published>2023-06-17T12:12:54.000Z</published>
    <updated>2023-06-17T12:13:35.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、Nocas配置注册中心"><a href="#一、Nocas配置注册中心" class="headerlink" title="一、Nocas配置注册中心"></a><strong>一、Nocas配置注册中心</strong></h2><p>Nacos是阿里巴巴开源的⼀个针对微服务架构中服务发现、配置管理和服务管理平台，Nacos&#x3D;Eureka+Config+Bus。</p><p>Nacos功能特性</p><p>1）服务发现与健康检查</p><p>2）动态配置管理</p><p>3）动态DNS服务</p><p>4）服务和元数据管理，动态的服务权重调整、动态服务优雅下线</p><p><img src="https://pic1.zhimg.com/80/v2-14b927289c9701aa2968f120934ce6b4_720w.webp" alt="img"></p><p><img src="/posts/53802/assets/8e0a65ebe0302c533bc726851a15aa2a.webp" alt="img"></p><p>保护阈值：可以设置为0-1之间的浮点数，它其实是⼀个⽐例值，防止多数服务都处于不可用，少数可用，在流量洪峰到来的时候，引起少量可用服务承受不住导致雪崩效应。</p><p><strong>数据模型</strong></p><p><img src="https://pic3.zhimg.com/80/v2-ff7814adc958693e7d4ac668709c0eda_720w.webp" alt="img"></p><p>Namespace命名空间、Group分组、集群这些都是为了进⾏归类管理，把服务和配置⽂件进行归类，归类之后就可以实现⼀定的效果，⽐如隔离。</p><p>Namespace：命名空间，对不同的环境进⾏隔离，⽐如隔离开发环境、测试环境和生成环境</p><p>Group：分组，将若干个服务或者若干个配置集归为⼀组，通常习惯⼀个系统归为⼀个组</p><p>Service：某⼀个服务，比如简历微服务DataId：配置集或者可以认为是⼀个配置文件</p><p>Namespace + Group + Service 如同 Maven 中的GAV坐标，GAV坐标是为了锁定 Jar，二这里是为了锁定服务</p><p><strong>配置中心</strong></p><p>通过 Namespace + Group + dataId 来锁定配置⽂件，Namespace不指定就默认public，Group不指定就默认 DEFAULT_GROUP，生成dataId：${prefix}-${spring.profile.active}.${file-extension}。</p><p><img src="https://pic3.zhimg.com/80/v2-d98d2f57c915754e99e915cddacb9cde_720w.webp" alt="img"></p><p>通过 Spring Cloud 原⽣注解 @RefreshScope 实现配置⾃动更新，并且可以实现多个配置文件扩展。</p><p><img src="/posts/53802/assets/fb71e96b7ac047d7bac95fd9b1703d2c.webp" alt="img"></p><h2 id="二、Sentinel分布式流量防卫兵"><a href="#二、Sentinel分布式流量防卫兵" class="headerlink" title="二、Sentinel分布式流量防卫兵"></a>二、Sentinel分布式流量防卫兵</h2><p>Sentinel是一个面向云原⽣微服务的流量控制、熔断降级组件。 替代Hystrix，针对问题：服务雪崩、服务降级、服务熔断、服务限流。</p><p><strong>Hystrix：</strong></p><p>1）自己搭建监控平台dashboard。</p><p>2）没有提供UI界⾯进⾏服务熔断、服务降级等配置（而是写代码，入侵了我们源程序环境）。</p><p><strong>Sentinel：</strong></p><p>1）独立可部署Dashboard&#x2F;控制台组件。</p><p>2）减少代码开发，通过UI界⾯配置即可完成细粒度控制（⾃动投递微服务。</p><p><img src="https://pic4.zhimg.com/80/v2-244ec3cfcdd87d8fd0d469efcd12b517_720w.webp" alt="img"></p><p>Sentinel两部分：</p><p>核心库：（Java 客户端）不依赖任何框架&#x2F;库，能够运行于所有 Java 运行时环境，同时对 Dubbo &#x2F; Spring Cloud 等框架也有较好的⽀持。</p><p>控制台：（Dashboard）基于 Spring Boot 开发，打包后可以直接运行，不需要额外的 Tomcat 等应用容器。</p><p>Sentinel特征:</p><p>1）丰富的应用场景：Sentinel 承接了阿里巴巴近10年的双十一大促流量的核心场景，例如秒杀（即突发流量控制在系统容量可以承受的范围）、消息削峰填谷、集群流量控制、实时熔断下游不可⽤应⽤等。</p><p>2）完备的实时监控：Sentinel 同时提供实时的监控功能。您可以在控制台中看到 接入应用的单台机器秒级数据，甚⾄ 500 台以下规模的集群的汇总运行情况。</p><p>3）广泛的开源⽣态：Sentinel 提供开箱即用的与其它开源框架&#x2F;库的整合模块，例如与 Spring Cloud、Dubbo的整合。您只需要引入相应的依赖并进⾏简单的配 置即可快速地接入Sentinel。</p><p>4）完善的 SPI 扩展点：Sentinel 提供简单易⽤、完善的 SPI 扩展接⼝。您可以通过 实现扩展接⼝来快速地定制逻辑。例如定制规则管理、适配动态数据源等。</p><p><img src="/posts/53802/assets/149c0fcd63ff6fc547bf1ba4aa3def46.webp" alt="img"></p><p><strong>流量规则模块</strong></p><p>资源名：默认请求路径针对来源：Sentinel可以针对调用者进行限流，填写微服务名称，默default（不区分来源）</p><p>阈值类型&#x2F;单机阈值</p><p>QPS：（每秒钟请求数量）当调用该资源的QPS达到阈值时进行限流</p><p>线程数：当调用该资源的线程数达到阈值的时候进行限流（线程处理请求的时候，如果说业务逻辑执行时间很长，流量洪峰来临时，会耗费很多线程资源，这些线程资源会堆积，最终可能造成服务不可用，进⼀步上游服务不可用，最终可能服务雪崩）</p><p>是否集群：是否集群限流</p><p>流控模式：</p><p>直接：资源调用达到限流条件时，直接限流</p><p>关联：关联的资源调用达到阈值时候限流自己</p><p>链路：只记录指定链路上的流量</p><p>流控效果：</p><p>快速失败：直接失败，抛出异常</p><p>排队等待：匀速排队，让请求匀速通过，阈值类型必须设置为QPS，否则无效</p><p>流控模式之关联限流：</p><p>关联的资源调用达到阈值时候限流自己，比如用户注册接口，需要调⽤身份证校验接口（往往身份证校验接口），如果身份证校验接口请求达到阈值，使用关联，可 以对用户注册接口进行限流。</p><p><img src="https://pic2.zhimg.com/80/v2-dd6bdc1e82bc3d01e64317519333b415_720w.webp" alt="img"></p><p>Sentinel流量控制：</p><p>关联模式、链路模式、预热、排队等待</p><p>Sentinel降级规则（等于Hystrix中的熔断）：</p><p>RT策略</p><p><img src="/posts/53802/assets/2be33f25208e702d327577d36a93bd9c.webp" alt="img"></p><p>异常比例策略</p><p><img src="/posts/53802/assets/bcbfb337e3442c0931d19181b57d3f0c.webp" alt="img"></p><p>异常策略</p><p><img src="/posts/53802/assets/f3a15ee0ec2b7399d00052c296834af9.webp" alt="img"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、Nocas配置注册中心&quot;&gt;&lt;a href=&quot;#一、Nocas配置注册中心&quot; class=&quot;headerlink&quot; title=&quot;一、Nocas配置注册中心&quot;&gt;&lt;/a&gt;&lt;strong&gt;一、Nocas配置注册中心&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Nacos是阿里巴</summary>
      
    
    
    
    <category term="基础知识" scheme="https://itingyu.github.io/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    <category term="spring cloud" scheme="https://itingyu.github.io/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/spring-cloud/"/>
    
    
    <category term="基础知识" scheme="https://itingyu.github.io/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    <category term="spring cloud" scheme="https://itingyu.github.io/tags/spring-cloud/"/>
    
  </entry>
  
  <entry>
    <title>Sleuth+Zipkin链路追踪和OAuth2统一认证相关知识</title>
    <link href="https://itingyu.github.io/posts/24605/"/>
    <id>https://itingyu.github.io/posts/24605/</id>
    <published>2023-06-17T12:11:23.000Z</published>
    <updated>2023-06-17T12:12:26.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Sleuth-Zipkin链路追踪"><a href="#Sleuth-Zipkin链路追踪" class="headerlink" title="Sleuth+Zipkin链路追踪"></a>Sleuth+Zipkin链路追踪</h2><p><img src="/posts/24605/assets/7f0eb4d52e7e23d678e09b281a679873.webp" alt="img"></p><p>Trace：服务追踪的追踪单元是从客户发起请求（request）抵达被追踪系统的边界开始，到被追踪系统向客户返回响应（response）为止的过程。</p><p>Trace ID：实现请求跟踪，⼀个Trace由⼀个或者多个Span组成，每⼀个Span都有⼀个SpanId，Span中会记录 TraceId，同时还有⼀个叫做ParentId，指向了另外⼀个Span的SpanId，表明父子关系，其实本质表达了依赖关系。</p><p>Span ID：统计各处理单元的时间延迟，除了时间戳记录之外，它还可以包含⼀些其他元数据，比如时间名称、请求信息等。每⼀个Span都会有⼀个唯⼀跟踪标识 Span ID,若干个有序的 span 就组成了⼀个trace。</p><p>分析方式：</p><p>耗时分析：通过 Sleuth 了解采样请求的耗时，分析服务性能问题（哪些服务调用比较耗时）。</p><p>链路优化：发现频繁调⽤的服务，针对性优化等，Sleuth就是通过记录日志的方式来记录踪迹数据的。</p><p>Spring Cloud Sleuth 和 Zipkin ⼀起使用，把 Sleuth 的数据信息发送给 Zipkin 进行聚合，利用 Zipkin 存储并展示数据。</p><h2 id="OAuth2统一认证"><a href="#OAuth2统一认证" class="headerlink" title="OAuth2统一认证"></a>OAuth2统一认证</h2><p>认证：验证用户的合法身份，比如输⼊用户名和密码，系统会在后台验证用户名和密码是否合法，合法的前提下，才能够进行后续的操作，访问受保护的资源，微服务下解决多个服务之间单点登录问题。</p><p><strong>微服务架构下统⼀认证思路</strong></p><p>1）基于Session的认证方式：在分布式的环境下，基于session的认证会出现⼀个问题，每个应用服务都需要 在session中存储用户身份信息，通过负载均衡将本地的请求分配到另⼀个应用服务需要将session信息带过去，否则会重新认证。我们可以使用Session共享、Session黏贴等⽅案。 Session方案也有缺点，比如基于cookie，移动端不能有效使用等</p><p>2）基于token的认证方式：基于token的认证方式，服务端不用存储认证数据，易维护扩展性强，客户端可以把token存在任意地方，并且可以实现web和app统⼀认证机制。其缺点也很明显，token由于自包含信息，因此⼀般数据量较⼤，而且每次请求都需要传递，因此比较占带宽。另外，token的签名验签操作也会给cpu带来额外的处理负担。</p><p><strong>OAuth2开放授权协议</strong></p><p>允许用户授权第三方应用访问他们存储在另外的服务提供者上的信息，而不需要将用户名和密码提供给第三方应用或分享他们数据的所有内容，比如通过QQ登录其他平台。</p><p>OAuth2的颁发Token授权方式</p><p>1）授权码（authorization-code）</p><p>2）密码式（password）提供用户名+密码换取token令牌</p><p>3）隐藏式（implicit）</p><p>4）客户端凭证（client credentials</p><p>使用OAuth2解决问题的本质是，引入了⼀个认证授权层，认证授权层连接了资源的拥有者，在授权层里面，资源的拥有者可以给第三方应用授权去访问我们的某些受保护资源。统⼀认证的场景中，Resource Server其实就是我们的各种受保护的微服务，微服务中的各种API访问接口就是资源，发起http请求的浏览器就是Client 客户端。</p><p><img src="/posts/24605/assets/8c4715675f211c20b7e7d83ccfe72e61.webp" alt="img"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Sleuth-Zipkin链路追踪&quot;&gt;&lt;a href=&quot;#Sleuth-Zipkin链路追踪&quot; class=&quot;headerlink&quot; title=&quot;Sleuth+Zipkin链路追踪&quot;&gt;&lt;/a&gt;Sleuth+Zipkin链路追踪&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;</summary>
      
    
    
    
    <category term="基础知识" scheme="https://itingyu.github.io/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    <category term="spring cloud" scheme="https://itingyu.github.io/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/spring-cloud/"/>
    
    
    <category term="基础知识" scheme="https://itingyu.github.io/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    <category term="spring cloud" scheme="https://itingyu.github.io/tags/spring-cloud/"/>
    
  </entry>
  
  <entry>
    <title>spring如何解决循环依赖</title>
    <link href="https://itingyu.github.io/posts/42455/"/>
    <id>https://itingyu.github.io/posts/42455/</id>
    <published>2023-06-17T12:01:37.000Z</published>
    <updated>2023-06-17T12:07:59.000Z</updated>
    
    <content type="html"><![CDATA[<p>Spring通过三级缓存和提前暴露的方式来解决了循环依赖这个问题，举个例，A对象和B对象互相依</p><p>赖，Spring解决循环依赖过程如下：</p><p>1.通过反射实例化创建A对象并把A对象的工厂对象放入三级缓存；</p><p>2.按照Bean对象生命周期，下一步进行属性注入，A对象依赖B对象，B对象实例化并把B对象的工厂对象放入三级缓存；</p><p>3.B对象属性注入又依赖A对象，但是三级缓存中已存在A对象的工厂对象，通过工厂生产代理对象返回并放入二级缓存后删除三级缓存工厂对象；</p><p>4.B对象拿到返回的A代理对象就可以直接完成装配，放入一级缓存并删除三级缓存B对象工厂；</p><p>5.B对象完成实例化并返回，就可以把二级缓存中A对象同步到一级缓存销毁二级缓存对象解决循环依赖。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Spring通过三级缓存和提前暴露的方式来解决了循环依赖这个问题，举个例，A对象和B对象互相依&lt;/p&gt;
&lt;p&gt;赖，Spring解决循环依赖过程如下：&lt;/p&gt;
&lt;p&gt;1.通过反射实例化创建A对象并把A对象的工厂对象放入三级缓存；&lt;/p&gt;
&lt;p&gt;2.按照Bean对象生命周期，下</summary>
      
    
    
    
    <category term="基础知识" scheme="https://itingyu.github.io/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    <category term="spring" scheme="https://itingyu.github.io/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/spring/"/>
    
    
    <category term="基础知识" scheme="https://itingyu.github.io/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    <category term="spring" scheme="https://itingyu.github.io/tags/spring/"/>
    
  </entry>
  
  <entry>
    <title>kafaka相关知识</title>
    <link href="https://itingyu.github.io/posts/4542/"/>
    <id>https://itingyu.github.io/posts/4542/</id>
    <published>2023-06-17T11:59:07.000Z</published>
    <updated>2023-06-17T12:00:46.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="一、kafka架构"><a href="#一、kafka架构" class="headerlink" title="一、kafka架构"></a><strong>一、kafka架构</strong></h3><h3 id="Kafka基础知识"><a href="#Kafka基础知识" class="headerlink" title="Kafka基础知识"></a><strong>Kafka基础知识</strong></h3><p>Kafka是最初由Linkedin公司开发，是一个分布式、分区的、多副本的、多生产者、多订阅者，基于zookeeper协 调的分布式日志系统(也可以当做MQ系统)，常见可以用于webynginx日志、访问日志，消息服务等等，Linkedin于 2010年贡献给了Apache基金会并成为顶级开源项目。主要应用场景是:日志收集系统和消息系统。</p><p>Kafka主要设计目标如下:</p><p>以时间复杂度为O(1)的方式提供消息持久化能力，即使对TB级以上数据也能保证常数时间的访问性能。</p><p>高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒100K条消息的传输。支持KafkaServer间的消息分区，及分布式消费，同时保证每个partition内的消息顺序传输。同时支持离线数据处理和实时数据处理。支持在线水平扩展</p><p><img src="/posts/4542/assets/cc1aaa51b0a53692dada0398fe357bb3.webp" alt="img"></p><p>kafka是一种发布-订阅模式, 对于消息中间件，消息分推拉两种模式。Kafka只有消息的拉取，没有推送，可以通过轮询实现消息的推送。1.Kafka在一个或多个可以跨越多个数据中心的服务器上作为集群运行。</p><p>2.Kafka集群中按照主题分类管理，一个主题可以有多个分区，一个分区可以有多个副本分区。</p><p>3.每个记录由一个键，一个值和一个时间戳组成。</p><p>Kafka具有四个核心API:</p><p>1.ProducerAPI:允许应用程序将记录流发布到一个或多个Kafka主题。2.ConsumerAPI:允许应用程序订阅一个或多个主题并处理为其生成的记录流。3.StreamsAPI:允许应用程序充当流处理器，使用一个或多个主题的输入流，并生成一个或多个输出主题的 输出流，从而有效地将输入流转换为输出流。4.ConnectorAPI:允许构建和运行将Kafka主题连接到现有应用程序或数据系统的可重用生产者或使用者。例如，关系数据库的连接器可能会捕获对表的所有更改。</p><p><strong>Kafka优势</strong></p><p>1.高吞吐量:单机每秒处理几十上百万的消息量。即使存储了许多TB的消息，它也保持稳定的性能。2.高性能:单节点支持上千个客户端，并保证零停机和零数据丢失。3.持久化数据存储:将消息持久化到磁盘。通过将数据持久化到硬盘以及replication防止数据丢失。</p><p>4.分布式系统，无需停机就可扩展机器。</p><p>5.可靠性-kafka是分布式，分区，复制和容错的。</p><p>6.客户端状态维护：消息被处理的状态是在Consumer端维护，而不是由server端维护。当失败时能自动平衡。</p><p>7.支持online和offline的场景。</p><p>8.支持多种客户端语言。Kafka支持Java、.NET、PHP、Python等多种语言。</p><p><strong>Kafka应用场景</strong></p><p>日志收集：一个公司可以用Kafka可以收集各种服务的Log，通过Kafka以统一接口服务的方式开放给各种Consumer。</p><p>消息系统：解耦生产者和消费者、缓存消息等。</p><p>用户活动跟踪：用来记录web用户或者APP用户的各种活动，如网页搜索、搜索、点击，用户数据收集然后进行用户行为分析。</p><p>运营指标：Kafka也经常用来记录运营监控数据。包括收集各种分布式应用的数据，生产各种操作的集中反馈，比</p><p>如报警和报告；</p><p>流式处理：比如Spark Streaming和Storm。</p><h3 id="Kafka基本架构"><a href="#Kafka基本架构" class="headerlink" title="Kafka基本架构"></a><strong>Kafka基本架构</strong></h3><p><strong>消息和批次</strong></p><p>Kafka的数据单元称为消息。可以把消息看成是数据库里的一个“数据行”或一条“记录”，消息由字节数组组成。批次就是一组消息，这些消息属于同一个主题和分区。</p><p><strong>模式</strong></p><p>消息模式（schema）有许多可用的选项，以便于理解。如JSON和XML，但是它们缺乏强类型处理能力。Kafka的</p><p>许多开发者喜欢使用Apache Avro。Avro提供了一种紧凑的序列化格式，模式和消息体分开。当模式发生变化时，不需要重新生成代码，它还支持强类型和模式进化，其版本既向前兼容，也向后兼容。</p><p><strong>主题和分区</strong></p><p>Kafka的消息通过主题进行分类。主题可比是数据库的表或者文件系统里的文件夹。主题可以被分为若干分区，一</p><p>个主题通过分区分布于Kafka集群中，提供了横向扩展的能力。</p><p><strong>生产者和消费者</strong></p><p>生产者创建消息。消费者消费消息。消息被发布到一个特定的主题上。、</p><p><strong>Borker和集群</strong></p><p>一个独立的Kafka服务器称为broker。broker接收来自生产者的消息，为消息设置偏移量，并提交消息到磁盘保</p><p>存。broker为消费者提供服务，对读取分区的请求做出响应，返回已经提交到磁盘上的消息。单个broker可以轻松处理数千个分区以及每秒百万级的消息量。每个集群都有一个broker是集群控制器。</p><h3 id="Kafka核心概念"><a href="#Kafka核心概念" class="headerlink" title="Kafka核心概念"></a><strong>Kafka核心概念</strong></h3><p><strong>Producer</strong></p><p>生产者创建消息。</p><p><strong>Consumer</strong></p><p>消费者读取消息</p><p><strong>Broker</strong></p><p>一个独立的Kafka 服务器被称为broker，是集群的组成部分。</p><p><strong>Topic</strong></p><p>每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。</p><p><strong>Partition</strong></p><p>\1. 主题可以被分为若干个分区，一个分区就是一个提交日志。</p><p>\2. 消息以追加的方式写入分区，然后以先入先出的顺序读取。</p><p>\3. 无法在整个主题范围内保证消息的顺序，但可以保证消息在单个分区内的顺序。</p><p>\4. Kafka 通过分区来实现数据冗余和伸缩性。</p><p>\5. 在需要严格保证消息的消费顺序的场景下，需要将partition数目设为1。</p><p><strong>Replicas</strong></p><p>kafka 使用主题来组织数据，每个主题被分为若干个分区，每个分区有多个副本。</p><p><strong>Offset</strong></p><p>生产者Offset：消息写入的时候，每一个分区都有一个offset，这个offset就是生产者的offset，同时也是这个分区的最新最大的offset。</p><p>消费者Offset：某个分区的offset情况，生产者写入的offset是最新最大的值是12，而当Consumer A进行消费时，从0开始消费，一直消费到了9，消费者的offset就记录在9，Consumer B就纪录在了11。</p><p><strong>副本</strong></p><p>Kafka通过副本保证高可用。副本分为首领副本(Leader)和跟随者副本(Follower)。</p><p><strong>AR</strong></p><p>分区中的所有副本统称为AR（Assigned Repllicas），AR&#x3D;ISR+OSR。</p><p><strong>ISR</strong></p><p>所有与leader副本保持一定程度同步的副本（包括Leader）组成ISR（In-Sync Replicas），ISR集合是AR集合中</p><p>的一个子集。</p><p><strong>OSR</strong></p><p>与leader副本同步滞后过多的副本（不包括leader）副本，组成OSR(Out-Sync Relipcas)。</p><h3 id="Kafka的安装和配置"><a href="#Kafka的安装和配置" class="headerlink" title="Kafka的安装和配置"></a><strong>Kafka的安装和配置</strong></h3><p>第一步：jdk安装，上传jdk-8u261-linux-x64.rpm到服务器并安装。</p><p>rpm -ivh jdk-8u261-linux-x64.rpm</p><p>第二步：配置java环境变量</p><p>vim &#x2F;etc&#x2F;profile</p><p># 生效</p><p>source &#x2F;etc&#x2F;profile</p><p># 验证</p><p>java -version</p><p><img src="/posts/4542/assets/4d062ed58aa402f9883c24e0e27f2907.webp" alt="img"></p><p>第三步：上传zookeeper安装包并解压。</p><p>tar -zxf zookeeper-3.4.14.tar.gz</p><p>cd &#x2F;zookeeper-3.4.14&#x2F;conf</p><p># 复制zoo_sample.cfg命名为zoo.cfg</p><p>cp zoo_sample.cfg zoo.cfg</p><p># 编辑zoo.cfg文件</p><p>vim zoo.cfg</p><p>dataDir&#x3D;&#x2F;usr&#x2F;local&#x2F;zookeeper&#x2F;zookeeper-3.4.14&#x2F;data</p><p>第四步：配置zookeeper环境变量</p><p>vim &#x2F;etc&#x2F;profile</p><p><img src="/posts/4542/assets/4b61960f2c48867862a652ca458a9417.webp" alt="img"></p><p>启动命令：zkServer.sh start 查看状态命令：zkServer.sh status</p><p><img src="https://pic3.zhimg.com/80/v2-d3c7336fb5b73794a3493068980613de_720w.webp" alt="img"></p><p>第五步：上传kafka_2.12-1.0.2.tgz到服务器并解压</p><p>tar -zxf kafka_2.12-1.0.2.tgz</p><p>第六步：配置kafka环境变量</p><p>vim &#x2F;etc&#x2F;profile</p><p><img src="/posts/4542/assets/5a6309bc2717c746978669bf8d10cadf.webp" alt="img"></p><p>第七步：修改kafka配置文件，连接zookeeper</p><p># 进入配置文件夹修改server.properties文件</p><p>cd config&#x2F;</p><p>vim server.properties</p><p><img src="/posts/4542/assets/bab307aa465bb4ec96f5720ac62e30ea.webp" alt="img"></p><p><img src="/posts/4542/assets/b5d7fa59f17ea5ff8b5640ce45f10fa1.webp" alt="img"></p><p><img src="https://pic3.zhimg.com/80/v2-6109289979f2ec0bf92ed756f643478a_720w.webp" alt="img"></p><p>第七步：启动kafka</p><p>kafka-server-start.sh -daemon ..&#x2F;config&#x2F;server.properties</p><p><img src="/posts/4542/assets/aed5b47230a4c0c26040fdd361502d72.webp" alt="img"></p><p><strong>消费和主题</strong></p><p># 列出现有的主题</p><p>[root@node1 ~]# kafka-topics.sh –list –zookeeper localhost:2181&#x2F;myKafka</p><p># 创建主题，该主题包含一个分区，该分区为Leader分区，它没有Follower分区副本。</p><p>[root@node1 ~]# kafka-topics.sh –zookeeper localhost:2181&#x2F;myKafka –create –topic topic_1 –partitions 1 –replication-factor 1</p><p># 查看分区信息</p><p>[root@node1 ~]# kafka-topics.sh –zookeeper localhost:2181&#x2F;myKafka –list</p><p># 查看指定主题的详细信息</p><p>[root@node1 ~]# kafka-topics.sh –zookeeper localhost:2181&#x2F;myKafka –describe –topic topic_1</p><p># 删除指定主题</p><p>[root@node1 ~]# kafka-topics.sh –zookeeper localhost:2181&#x2F;myKafka –delete –topic topic_1</p><p># 开启生产者</p><p>[root@node1 ~]# kafka-console-producer.sh –topic topic_1 –broker-list localhost:9020</p><p># 开启消费者</p><p>[root@node1 ~]# kafka-console-consumer.sh –bootstrap-server localhost:9092 –topic topic_1</p><p># 开启消费者方式二，从头消费，不按照偏移量消费</p><p>[root@node1 ~]# kafka-console-consumer.sh –bootstrap-server localhost:9092 –topic topic_1 –from-beginning</p><h3 id="Kafka消息接收和发送"><a href="#Kafka消息接收和发送" class="headerlink" title="Kafka消息接收和发送"></a><strong>Kafka消息接收和发送</strong></h3><p><img src="https://pic1.zhimg.com/80/v2-33ee6ba7eb215adc92ab28ae7737f630_720w.webp" alt="img"></p><p>生产者主要的对象有：KafkaProducer ，ProducerRecord 。</p><p>其中KafkaProducer 是用于发送消息的类，ProducerRecord 类用于封装Kafka的消息。</p><p>KafkaProducer 的创建需要指定的参数和含义：</p><p><img src="/posts/4542/assets/ee42dd917a669ae46f334ce8f23e434d.webp" alt="img"></p><h3 id="二、Kafka高级特性"><a href="#二、Kafka高级特性" class="headerlink" title="二、Kafka高级特性"></a><strong>二、Kafka高级特性</strong></h3><h3 id="生产者"><a href="#生产者" class="headerlink" title="生产者"></a><strong>生产者</strong></h3><p><strong>消息发送</strong></p><p>流程图：</p><p><img src="https://pic4.zhimg.com/80/v2-3d763983e0e8dee638fb3310c45d76d3_720w.webp" alt="img"></p><p>\1. Producer创建时，会创建一个Sender线程并设置为守护线程。</p><p>\2. 生产消息时，内部其实是异步流程；生产的消息先经过拦截器-&gt;序列化器-&gt;分区器，然后将消息缓存在缓冲</p><p>区（该缓冲区也是在Producer创建时创建）。</p><p>\3. 批次发送的条件为：缓冲区数据大小达到batch.size或者linger.ms达到上限，哪个先达到就算哪个。</p><p>\4. 批次发送后，发往指定分区，然后落盘到broker；如果生产者配置了retrires参数大于0并且失败原因允许重</p><p>试，那么客户端内部会对该消息进行重试。</p><p>\5. 落盘到broker成功，返回生产元数据给生产者。</p><p>\6. 元数据返回有两种方式：一种是通过阻塞直接返回，另一种是通过回调返回。</p><p>配置参数：</p><p><img src="/posts/4542/assets/13657215c8cb5c9235c52ffdd5235f47.webp" alt="img"></p><p><strong>序列化器</strong></p><p><img src="/posts/4542/assets/8db474e8e01a4c6206d9c961d3909566.webp" alt="img"></p><p>Kafka中的数据都是字节数组，将消息发送到Kafka之前需要先将数据序列化为字节数组，序列化器的作用就是用于序列化要发送的消息。</p><p><strong>分区器</strong></p><p>默认分区计算：</p><p>\1. 如果record提供了分区号，则使用record提供的分区号</p><p>\2. 如果record没有提供分区号，则使用key的序列化后的值的hash值对分区数量取模</p><p>\3. 如果record没有提供分区号，也没有提供key，则使用轮询的方式分配分区号。</p><p><strong>拦截器</strong></p><p>Producer拦截器（interceptor）和Consumer端Interceptor是在Kafka 0.10版本被引入的，主要用于实现Client</p><p>端的定制化控制逻辑。</p><p>Intercetpor的实现接口是org.apache.kafka.clients.producer.ProducerInterceptor，其定义的方法包括：</p><p>onSend(ProducerRecord)：该方法封装进KafkaProducer.send方法中，即运行在用户主线程中。Producer</p><p>确保在消息被序列化以计算分区前调用该方法。用户可以在该方法中对消息做任何操作，但最好保证不要修</p><p>改消息所属的topic和分区，否则会影响目标分区的计算。</p><p>onAcknowledgement(RecordMetadata, Exception)：该方法会在消息被应答之前或消息发送失败时调用，</p><p>并且通常都是在Producer回调逻辑触发之前。onAcknowledgement运行在Producer的IO线程中，因此不</p><p>要在该方法中放入很重的逻辑，否则会拖慢Producer的消息发送效率。</p><p>close：关闭Interceptor，主要用于执行一些资源清理工作。</p><p><strong>原理</strong></p><p><img src="/posts/4542/assets/e4d54fc2e0af1ce3366d96066cf372bb.webp" alt="img"></p><p>主线程：负责消息创建，拦截器，序列化器，分区器等操作，并将消息追加到消息收集器。</p><p>Sender线程：</p><p>该线程从消息收集器获取缓存的消息，将其处理为 &lt;Node, List<ProducerBatch> 的形式，表示集群的broker节点。</p><p>进一步将&lt;Node, List<ProducerBatch>转化为&lt;Node, Request&gt;形式，此时才可以向服务端发送数据。在发送之前，Sender线程将消息以 Map&lt;NodeId, Deque<Request>&gt; 的形式保存到InFlightRequests 中进行缓存，可以通过其获取 leastLoadedNode ,即当前Node中负载压力最小的一个，以实现消息的尽快发出。</p><p><img src="/posts/4542/assets/6efd6bb04e2626b238adcec0aeff6a96.webp" alt="img"></p><p><img src="/posts/4542/assets/eb45e88a0df01f7e6a542afc5c8938c8.webp" alt="img"></p><h3 id="消费者"><a href="#消费者" class="headerlink" title="消费者"></a><strong>消费者</strong></h3><p><strong>消费组</strong></p><p>消费者从订阅的主题消费消息，消费消息的偏移量保存在Kafka的名字是 __consumer_offsets 的主题中，消费者还可以将自己的偏移量存储到Zookeeper，需要设置offset.storage&#x3D;zookeeper。推荐使用Kafka存储消费者的偏移量。因为Zookeeper不适合高并发。多个从同一个主题消费的消费者可以加入到一个消费组中。消费组中的消费者共享group_id。</p><p>消费者四种情况：</p><p>\1. 消费组均衡地给消费者分配分区，每个分区只由消费组中一个消费者消费。</p><p>\2. 消费组均衡地给消费者分配分区，每个分区只由消费组中一个消费者消费。</p><p>\3. 如果在消费组中添加一个消费者2，则每个消费者分别从两个分区接收消息。</p><p>\4. 如果消费组有四个消费者，则每个消费者可以分配到一个分区。</p><p>\5. 如果向消费组中添加更多的消费者，超过主题分区数量，则有一部分消费者就会闲置，不会接收任何消息。</p><p><img src="https://pic4.zhimg.com/80/v2-8cf187a8f07b9762195b08b5dd907acb_720w.webp" alt="img"></p><p><strong>心跳机制</strong></p><p>消费者宕机，退出消费组，触发再平衡，重新给消费组中的消费者分配分区。</p><p>Kafka 的心跳是 Kafka Consumer 和 Broker 之间的健康检查，只有当 Broker Coordinator 正常时，Consumer</p><p>才会发送心跳。broker 处理心跳的逻辑在 GroupCoordinator 类中：如果心跳超期， broker coordinator 会把消费者从 group中移除，并触发 rebalance。</p><p><img src="/posts/4542/assets/2a39c4dea565309abc8a65ac99bc4b4f.webp" alt="img"></p><p><strong>订阅</strong></p><p>Topic，Kafka用于分类管理消息的逻辑单元，类似与MySQL的数据库。</p><p>Partition，是Kafka下数据存储的基本单元，这个是物理上的概念。同一个topic的数据，会被分散的存储到多个partition中，这些partition可以在同一台机器上，也可以是在多台机器上。优势在于：有利于水平扩展，避免单台机器在磁盘空间和性能上的限制，同时可以通过复制来增加数据冗余性，提高容灾能力。为了做到均匀分布，通常partition的数量通常是Broker Server数量的整数倍。</p><p>Consumer Group，同样是逻辑上的概念，是Kafka实现单播和广播两种消息模型的手段。保证一个消费组获取到特定主题的全部的消息。在消费组内部，若干个消费者消费主题分区的消息，消费组可以保证一个主题的每个分区只被消费组中的一个消费者消费。</p><p>consumer 采用 pull 模式从 broker 中读取数据。</p><p>采用 pull 模式，consumer 可自主控制消费消息的速率，可以自己控制消费方式（批量消费&#x2F;逐条消费)，还可以选择不同的提交方式从而实现不同的传输语义。</p><p><strong>反序列化</strong></p><p>Kafka的broker中所有的消息都是字节数组，消费者获取到消息之后，需要先对消息进行反序列化处理，然后才能</p><p>交给用户程序消费处理。消费者的反序列化器包括key的和value的反序列化器。</p><p>key.deserializer</p><p>value.deserializer</p><p>IntegerDeserializer</p><p>StringDeserializer</p><p>需要实现 org.apache.kafka.common.serialization.Deserializer<T> 接口。</p><p><strong>位移提交</strong></p><p>\1. Consumer需要向Kafka记录自己的位移数据，这个汇报过程称为提交位移(Committing Offsets)</p><p>\2. Consumer 需要为分配给它的每个分区提交各自的位移数据</p><p>3.位移提交的由Consumer端负责的，Kafka只负责保管。</p><p>4.位移提交分为自动提交和手动提交</p><p>5.位移提交分为同步提交和异步提交</p><p><strong>消费位移管理</strong></p><p>Kafka中，消费者根据消息的位移顺序消费消息。消费者的位移由消费者管理，可以存储于zookeeper中，也可以存储于Kafka主题__consumer_offsets中。Kafka提供了消费者API，让消费者可以管理自己的位移。</p><p><strong>再均衡</strong></p><p>重平衡其实就是一个协议，它规定了如何让消费者组下的所有消费者来分配topic中的每一个分区。比如一个topic</p><p>有100个分区，一个消费者组内有20个消费者，在协调者的控制下让组内每一个消费者分配到5个分区，这个分配的过程就是重平衡，是kafka为人诟病最多的一个点。</p><p>重平衡的触发条件主要有三个：</p><p>\1. 消费者组内成员发生变更，这个变更包括了增加和减少消费者，比如消费者宕机退出消费组。</p><p>\2. 主题的分区数发生变更，kafka目前只支持增加分区，当增加的时候就会触发重平衡。</p><p>\3. 订阅的主题发生变化，当消费者组使用正则表达式订阅主题，而恰好又新建了对应的主题，就会触发重平衡。</p><p>重平衡过程中，消费者无法从kafka消费消息，这对kafka的TPS影响极大，而如果kafka集内节点较多，比如数百个，那重平衡可能会耗时极多。数分钟到数小时都有可能，而这段时间kafka基本处于不可用状态。所以在实际环境中，应该尽量避免重平衡发生。避免重平衡，是不可能，因为你无法完全保证消费者不会故障。而消费者故障是最常见引发重平衡的地方，需要尽力避免消费者故障，比如合理利用心跳来维持。控制发送心跳的频率，频率越高越不容易被误判。</p><p><strong>消费者管理</strong></p><p>消费组：consumer group是kafka提供的可扩展且具有容错性的消费者机制。</p><p>三个特性：</p><p>\1. 消费组有一个或多个消费者，消费者可以是一个进程，也可以是一个线程</p><p>\2. group.id是一个字符串，唯一标识一个消费组</p><p>\3. 消费组订阅的主题每个分区只能分配给消费组一个消费者。</p><p>消费者位移：消费者在消费的过程中记录已消费的数据，即消费位移（offset）信息。</p><p>kafka提供了5个协议来处理与消费组协调相关的问题：</p><p>Heartbeat请求：consumer需要定期给组协调器发送心跳来表明自己还活着</p><p>LeaveGroup请求：主动告诉组协调器我要离开消费组</p><p>SyncGroup请求：消费组Leader把分配方案告诉组内所有成员</p><p>JoinGroup请求：成员请求加入组</p><p>DescribeGroup请求：显示组的所有信息，包括成员信息，协议名称，分配方案，订阅信息等。通常该请求</p><p>是给管理员使用</p><p>组协调器在再均衡的时候主要用到了前面4种请求。</p><p>消费组组协调器根据状态机对消费组做不同处理：</p><p>\1. Dead：组内已经没有任何成员的最终状态，组的元数据也已经被组协调器移除了。这种状态响应各种请求都</p><p>是一个response：UNKNOWN_MEMBER_ID</p><p>\2. Empty：组内无成员，但是位移信息还没有过期。这种状态只能响应JoinGroup请求</p><p>\3. PreparingRebalance：组准备开启新的rebalance，等待成员加入</p><p>\4. AwaitingSync：正在等待leader consumer将分配方案传给各个成员</p><p>\5. Stable：再均衡完成，可以开始消费。</p><h3 id="主题"><a href="#主题" class="headerlink" title="主题"></a><strong>主题</strong></h3><p><strong>创建主题</strong></p><p>kafka-topics.sh –zookeeper localhost:2181&#x2F;myKafka –create –topic topic_x – partitions 1 –replication-factor 1 kafka-topics.sh –zookeeper localhost:2181&#x2F;myKafka –create –topic topic_test_02 – partitions 3 –replication-factor 1 –config max.message.bytes&#x3D;1048576 –config segment.bytes&#x3D;10485760</p><p><strong>查看主题</strong></p><p>kafka-topics.sh –zookeeper localhost:2181&#x2F;myKafka –list</p><p>kafka-topics.sh –zookeeper localhost:2181&#x2F;myKafka –describe –topic topic_x</p><p>kafka-topics.sh –zookeeper localhost:2181&#x2F;myKafka –topics-with-overrides –describe</p><p><strong>修改主题</strong></p><p>kafka-topics.sh –zookeeper localhost:2181&#x2F;myKafka –create –topic topic_test_01 – partitions 2 –replication-factor 1</p><p>kafka-topics.sh –zookeeper localhost:2181&#x2F;myKafka –alter –topic topic_test_01 – config max.message.bytes&#x3D;1048576</p><p>kafka-topics.sh –zookeeper localhost:2181&#x2F;myKafka –describe –topic topic_test_01</p><p>kafka-topics.sh –zookeeper localhost:2181&#x2F;myKafka –alter –topic topic_test_01 – config segment.bytes&#x3D;10485760</p><p>kafka-topics.sh –zookeeper localhost:2181&#x2F;myKafka –alter –delete-config max.message.bytes –topic topic_test_01</p><p><strong>删除主题</strong></p><p>kafka-topics.sh –zookeeper localhost:2181&#x2F;myKafka –delete –topic topic_</p><p><strong>增加分区</strong></p><p>kafka-topics.sh –zookeeper localhost&#x2F;myKafka –alter –topic myTop1 –partitions 2</p><p><strong>分区副本的分配</strong></p><p>副本分配的三个目标：</p><p>\1. 均衡的将副本分散各个broker上</p><p>\2. 对于某个broker上分配的分区，他的其他副本在其他broker上</p><p>\3. 如果所有的broker都有机架信息，尽量将分区的各个副本分配到不同机架的broker上</p><p>不考虑机架信息的情况：</p><p>\1. 第一个副本通过轮询方式挑选一个broker，进行分配，该轮询是从broker列表随机轮询</p><p>\2. 其余副本是通过增加偏移进行分配</p><p><strong>偏移量管理</strong></p><p>__consumer_offsets主题中保存了各个消费组的偏移量。早期由zookeeper管理。</p><h3 id="KafkaAdminClient应用"><a href="#KafkaAdminClient应用" class="headerlink" title="KafkaAdminClient应用"></a><strong>KafkaAdminClient应用</strong></h3><p>除了使用kafka的bin目录脚本工具来管理kafka之外，还可以通过kafkaAdminClient来将kafka的api将管理功能继承到此客户端中方便调用。其内部原理是使用kafka自定义的一套二进制协议来实现。</p><p>\1. 创建主题：createTopics(final Collection newTopics, final CreateTopicsOptions options)</p><p>\2. 删除主题：deleteTopics(final Collection topicNames, DeleteTopicsOptions options)</p><p>\3. 列出所有主题：listTopics(final ListTopicsOptions options)</p><p>\4. 查询主题：describeTopics(final Collection topicNames, DescribeTopicsOptions options)</p><p>\5. 查询集群信息：describeCluster(DescribeClusterOptions options)</p><p>\6. 查询配置信息：describeConfigs(Collection configResources, final DescribeConfigsOptions options)</p><p>\7. 修改配置信息：alterConfigs(Map configs, final AlterConfigsOptions options)</p><p>\8. 修改副本的日志目录：alterReplicaLogDirs(Map replicaAssignment, final AlterReplicaLogDirsOptions options)</p><p>\9. 查询节点的日志目录信息：describeLogDirs(Collection brokers, DescribeLogDirsOptions options)</p><p>\10. 增加分区：createPartitions(Map newPartitions, final CreatePartitionsOptions options)</p><p>主要操作步骤：</p><p>\1. 客户端根据方法的调用创建相应协议请求。</p><p>\2. 客户端发送请求到kafka broker。</p><p>\3. Kafka broker 处理相应请求并回执，比如CreateTopicRequest对应的是CreateTopicResponse</p><p>\4. 客户端接收相应回执并解析处理。</p><h3 id="分区"><a href="#分区" class="headerlink" title="分区"></a><strong>分区</strong></h3><p><strong>副本机制</strong></p><p>Kafka在一定数量上的服务器上对主题分区进行复制，当集群中某个broker宕机后系统可以自动故障转移到其他可用副本上，不会造成数据丢失。</p><p><img src="/posts/4542/assets/1ab790818a3bc53d891fb5d2c630be00.webp" alt="img"></p><p>同步节点定义：</p><p>\1. 节点必须能够维持与zookeeper会话，心跳机制。</p><p>\2. 对于Follower副本分区，他复制在leader分区的写入，延迟不能太高。</p><p>宕机恢复：</p><p>\1. 少部分副本宕机，从follower从选择一个leader，若宕机恢复，清空commit。重新从leader上pull</p><p>\2. 全部副本宕机，等待ISR其中一个恢复作为leader 或者选择第一个恢复的副本作为leader，前者等待时间长，后者可能丢失数据。</p><p><strong>Leader选举</strong></p><p>Kafka中的leader分区选举，通过维护一个动态变化的ISR集合来实现，一旦Leader分区丢掉，则从ISR中随机挑选一个副本来做新的Leader分区，没有使用过半原则。如果ISR中的副本都丢失了，则要么等待ISR中某个副本恢复成为Leader或者选择第一个恢复的副本做为Leader，两种方式利弊如上。</p><p><strong>分区重新分配</strong></p><p>向已经部署好的kafka集群添加机器，需要从已部署好的kafka节点中复制相应配置文件，然后把里面的broker id修改成全局唯一，最后启动这个节点将他加入到现有的kafka集群中。但是新添加的kafka节点不会自动分配数据，因此无法分担集群负载，因此需要手动将部分分区移动到新添加的kafka节点上，kafka内部自带有相应工具。</p><p><strong>自动再均衡</strong></p><p>当我们分好区运行一段时间后，broker的宕机重启，会引发leader分区和follower分区的角色转化，最后可能导致leader大部分都集中在少数几台broker上，由于leader负责客户端的读写操作，因此集中leader分区的少数服务器I&#x2F;O、CPU、内存都会很紧张，针对这种不平衡情况就需要让leader的分区重新恢复到均衡状态，kafka提供了自动再均衡脚本：kafka-preferred-replica-election.sh，该工具会让每个分区的leader副本分配在合适位置，让leader分区和follower分区在服务器之间均衡分配。</p><p><strong>修改副本因子</strong></p><p>一开始集群较小，因此副本因子较小，现在需要扩容，就要修改副本因子，通过kafka-reassign-partitions.sh修改副本因子。</p><p><strong>分区分配策略</strong></p><p>在kafka中，每个Topic会包含多个分区，默认情况下一个分区只能被一个消费组下面的一个消费者消费，因此会产生分区分配问题，kafka针对这个问题提供了三种分区分配算法：RangeAssignor、RoundRobinAssignor、StickyAssignor。</p><p>RangeAssignor：消费组的成员订阅他们感兴趣的Topic并将这种订阅关系传递给作为订阅组协调者的broker，协调者选择其中一个消费者来执行这个消费组的分区分配并将分配结果转发给消费组内所有的消费者，他是kafka默认采用的分配算法。</p><p>RoundRobinAssignor：将消费组内订阅的所有Topic的分区及所有消费者进行排序后尽量均衡的分配。如果消费组内，消费者订阅的Topic列表是相同的，那分配结果尽量均衡，如果订阅的topic列表是不同的，那么分配结果不保证均衡，因为某些消费者不参与一些topic分配。</p><p>StickyAssignor：虽然RoundRobinAssignor在RangeAssignor上做了一些优化来更均衡的分配分区，但是在一些情况依旧会出现分配偏差，因为以上两种算法没有考虑上一次的分配结果，如果在新一次分配之前考虑上一次的分配结果，尽量少的调整分区分配变动，能节省不少开销，StickyAssignor因此而诞生，他保证分区的分配尽量均衡，并且每一次重新分配的结果尽量与上一次分配结果保持一致。</p><h3 id="物理存储"><a href="#物理存储" class="headerlink" title="物理存储"></a><strong>物理存储</strong></h3><p><strong>日志存储</strong></p><p>Kafka消息是以主题为单位进行归类，各个主题之间又相互独立，互不影响，每个主题可以分一个或多个分区，每个分区各自存在一个记录消息数据的日志文件。</p><p><img src="https://pic1.zhimg.com/80/v2-486f1237aea933b27f3e62c637e14f5c_720w.webp" alt="img"></p><p>偏移量索引文件用于记录消息偏移量与物理地址之间的映射地址之间的映射关系，时间戳索引文件根据时间戳查找对应偏移量。消息内容保存在log日志文件中，新内容追加末尾，采用顺序写的方式。如果需要找到对应偏移量的文件，因为kafka中存在一个ConcurrentSkipListMap保存每个日志分段，可以通过跳跃表方式定位到00000000000000000000.index，再通过二分法在偏移量索引文件中找对应偏移量范围最大内的索引文件，缩小范围之后再顺序找对应偏移量的消息。</p><p><img src="/posts/4542/assets/0e99987ceff30bf32f67d1052dda5aaa.webp" alt="img"></p><p>Kafka提供了两种日志清理策略：</p><p>\1. 日志删除，按照一定删除策略，将不满足条件数据进行数据删除。Kafka通过设定日志保留时间节点进行执行日志删除任务，默认七天，超过就删除，删除是通过跳跃表找到待删除的日志分段，在文件加.delete后缀，然后交给一个延迟删除任务来删除这些指定后缀文件。</p><p>\2. 日志压缩，针对每个消息的key进行整合，对于有相同key不同的value的值，只保留最后一个版本。日志压缩和key有关，确保每个消息的key不为null。</p><h3 id="磁盘存储"><a href="#磁盘存储" class="headerlink" title="磁盘存储"></a><strong>磁盘存储</strong></h3><p><strong>零拷贝</strong></p><p>Kafka性能非常高，但是他却把数据存储在磁盘中，需要对数据进行落盘，因此kafka是多方面协同的结果，包括宏观架构、分布式partition存储，ISR数据同步、以及各种高效利用磁盘的特性。零拷贝不是不需要拷贝，而且减少不必要的拷贝次数，nginx高性能中也有零拷贝应用。</p><p>传统IO：先读取，再发送，经过1-4次复制，第一次将磁盘文件读取到操作系统内核缓存区，第二次copy到application应用程序的缓存，第三次再copy到socket网络发送到缓冲区，最后copy到网络协议栈，由网卡进行网络传输。</p><p>Kafka：网络数据持久化到磁盘，磁盘文件通过网络发送，不需要第二和第三个副本。</p><p><strong>页缓存</strong></p><p>页缓存就是操作系统实现的一种主要磁盘缓存，用来减少对磁盘的IO操作，也就是把磁盘中的数据缓存在内存中，把对磁盘的访问变成对内存的访问，提高效率。</p><p><strong>mmap和senfile</strong></p><p>\1. linux内核提供实现零拷贝的api</p><p>\2. sendfile是将读到内核空间的数据，转到socket buffer，进行网络发送。</p><p>\3. mmap将磁盘文件映射到内存，支持读和写，对内存的操作会反应在磁盘文件上。</p><p>\4. rocketmq在消费消息使用了mmap，kafka使用了sendfile。</p><p>Kafka速度快的原因：</p><p>\1. partition顺序读写，充分利用磁盘特性。</p><p>\2. producer生产的数据持久化到broker，采用mmap文件映射，实现顺序的快速写入。</p><p>\3. customer从broker读取消息，采用sendfile，将磁盘文件读到OS内核缓存区，然后直接转到socket buffer进行网络发送。</p><h3 id="事务"><a href="#事务" class="headerlink" title="事务"></a><strong>事务</strong></h3><p>Kafka的producer发送消息可能是分布式事务，引入2PC，有事务协调者Transaction Coordinator。而且事务管理中日志不可缺，kafka通过内部一个topic来保存事务日志，事务具有commit和abort两种操作，因此也具有对应的两种隔离级别，而且事务ID一定要设置，幂等性也要开启，幂等性的实现通过一个唯一ID。</p><p><img src="https://pic4.zhimg.com/80/v2-5021de3c7f9a2908c84388c5f5bd3463_720w.webp" alt="img"></p><p>在kafka事务中，一个原子性操作，根据操作类型分为3种情况：</p><p>1． 只有producer生产消息，需要事务介入</p><p>2． 消费消息和生产消息并存，需要事务介入，最常见模式。</p><p>3． 只有consumer消费消息，可以手动commit，意义不大。</p><h3 id="控制器"><a href="#控制器" class="headerlink" title="控制器"></a><strong>控制器</strong></h3><p>控制器就是一个broker，控制器还负责leader分区的选举。</p><p>Kafka集群包含若干个broker，集群上创建的主题，包含若干个分区，每个分区包含若干个副本，副本因子包括leader副本和follower副本，副本又分为ISR同步副本分区和OSR非同步副本分区。</p><p><strong>borker选举</strong></p><p>\1. kafka使用zookeeper的分布式锁选举控制器，并在节点加入集群或退出集群时通知控制器。</p><p>\2. 控制器负责在节点加入或离开集群时进行分区leader选举。</p><p>\3. 控制器使用epoch来避免脑裂，脑裂是指两个节点同时认为自己是当前控制器。</p><h3 id="可靠性保证和一致性保证"><a href="#可靠性保证和一致性保证" class="headerlink" title="可靠性保证和一致性保证"></a><strong>可靠性保证和一致性保证</strong></h3><p><strong>可靠性保证</strong></p><p>创建topic主题时可以指定副本因子和分区的副本数，leader负责读写的节点，其他是follower，producer只把消息发送到leader上，follower定期从leader上pull数据，因此就会存在一定的延时性，为了保证可靠性，可以设置ack&#x3D;all。Follower收到消息后，会像leader发送ack，一旦leader收到ISR中所有replica中的ACK，leader就会commit，那么leader就会像producer发送ack，保存消息可靠性。</p><p><strong>一致性保证</strong></p><p>水位或者水印表示位置信息，即位移，kafka源码中使用的是高水位HW。</p><p>每个分区副本对象都有两个重要属性：LEO和HW</p><p>LEO：日志末端位移，记录了该副本日志中下一条消息的位移值。</p><p>HW：水位值，即水淹到这里，对于同一个副本对象而言，其HW值不会大于LEO值。</p><p><img src="https://pic2.zhimg.com/80/v2-1151083cf8c45dd7c69fe5a84e4ec945_720w.webp" alt="img"></p><p>上图HW值就是7，表示位移0-7的所有消息已经提交，LEO值是14，指下一条消息来得时候位移。</p><p>Follower副本的LEO值就是日志的LEO值，新写入一条消息就更新LEO。</p><p>Follower更新HW发生在更新LEO之后，一旦follower向log写入数据，就更新自己的hw值。</p><p>和follower更新LEO相同，leader写log时候自动更新自己的LEO值。</p><p>Leader的HW值就是分区的HW值，当尝试确定分区HW时，他会选出所有满足条件的副本，比较他们的LEO，并选择最小的LEO值作为HW值。</p><h3 id="消息重复的场景及解决方案"><a href="#消息重复的场景及解决方案" class="headerlink" title="消息重复的场景及解决方案"></a><strong>消息重复的场景及解决方案</strong></h3><p>消息重复发送在三个阶段：生产者阶段、broke阶段、消费者阶段</p><p>根本原因：生产者发送的消息没有收到正确的broke响应，导致producer重试，producer发出一条消息，broke落盘以后因为网络等种种原因发送端得到一个发送失败的响应或网络中断，然后producer收到一个可恢复的exception重试消息导致消息重复。</p><p><strong>生产者发送重复解决方案</strong></p><p>\1. 启动kafka幂等性</p><p>\2. Ack&#x3D;0,不重试，但是可能丢失消息。</p><p><strong>生产者和broke阶段消息丢失场景</strong></p><p>\1. ack&#x3D;0,不重试，发送完不管结果，发送失败就丢失了。</p><p>\2. ack&#x3D;1 leader crash 生产者发送消息完，等待leader写入成功就返回了，leader分区丢失了，此时follower还没同步，消息丢失。</p><p><strong>解决生产者和broke阶段消息丢失</strong></p><p>\1. 禁用unclean选举，ack&#x3D;all</p><p>\2. 失败的offset单独记录</p><p><strong>消费者数据重复场景及解决方案</strong></p><p>数据消费完没有及时提交offset到broke</p><p>解决方案：取消自动提交，通过手动提交或者下游做幂等，保证每次一致。</p><h3 id="consumer-offsets"><a href="#consumer-offsets" class="headerlink" title="__consumer_offsets"></a><strong>__consumer_offsets</strong></h3><p>Kafka内部的一个主题。Zookeeper不适合大批量的频繁写入操作，而通过这个主题来实现这个功能。</p><h3 id="延时队列"><a href="#延时队列" class="headerlink" title="延时队列"></a><strong>延时队列</strong></h3><p>两个follower副本已经拉取到了leader副本的最新位置，此时又向leader副本发送拉取请求，而leader副本并没有新的消息写入，就会导致follower副本一直发送拉取请求，而且总拉取空的结果，导致空转消耗资源。</p><p>Kafka通过延迟操作的概念，在处理拉取请求时，先读取一次日志文件，如果收集不到足够多的消息，就会创建一个延时拉取操作以等待拉取到足够数量的消息，当延时拉取操作执行时，会在读取一次日志文件，然后将拉取结果返回给follower副本。Kafka中还有延时数据删除、延时生产等等。</p><h3 id="重试队列"><a href="#重试队列" class="headerlink" title="重试队列"></a><strong>重试队列</strong></h3><p>Kafka没有重试机制，也没有死信队列，需要自己来实现消息重试功能。</p><p>实现逻辑：</p><p>\1. 创建一个topic作为重试topic，用去接收等待重试消息。</p><p>\2. 普通topic消费者设置待重试消息的下一个重试topic。</p><p>\3. 从重试topic获取待重试消息储存到redis的zset中，并以下一次消费时间排序。</p><p>\4. 定时任务从redis获取到达消费事件的消息，并把消息发送到对应的topic</p><p>\5. 同一个消息重试次数过多则不再重试。</p><h3 id="ngx-kafka-module安装与配置"><a href="#ngx-kafka-module安装与配置" class="headerlink" title="ngx_kafka_module安装与配置"></a><strong>ngx_kafka_module安装与配置</strong></h3><p><strong>1. Install librdkafka</strong></p><p>#安装git</p><p>yum -y install git</p><p>#安装c++环境</p><p>yum install gcc-c++</p><p>#git librdkafka并编译</p><p>git clone <a href="https://link.zhihu.com/?target=https://github.com/edenhill/librdkafka">https://github.com/edenhill/librdkafka</a></p><p>cd librdkafka</p><p>.&#x2F;configure</p><p>make</p><p>sudo make install</p><p><strong>2. Install ngx_kafka_module</strong></p><p>git clone <a href="https://link.zhihu.com/?target=https://github.com/brg-liuwei/ngx_kafka_module">https://github.com/brg-liuwei/ngx_kafka_module</a></p><p># cd &#x2F;opt&#x2F;nginx-1.19.8</p><p>.&#x2F;configure –add-module&#x3D;&#x2F;opt&#x2F;nginx_extra&#x2F;ngx_kafka_module</p><p>make</p><p>sudo make install</p><p># or, use <code>sudo make upgrade</code> instead of <code>sudo make install</code></p><p><strong>3.</strong> <strong>配置nginx</strong></p><p>http {</p><p># some other configs</p><p>kafka;</p><p>kafka_broker_list 127.0.0.1:9092; # host:port …</p><p>server {</p><p># some other configs</p><p>location &#x3D; &#x2F;ozdemo&#x2F;kafka {</p><p># optional directive: kafka_partition [<partition-num> | auto]</p><p>#</p><p># kafka_partition auto; # default value</p><p># kafka_partition 0;</p><p># kafka_partition 1;</p><p>kafka_topic topic_ozdemo;</p><p>}</p><p>}</p><p>}</p><p><strong>4.重启nginx</strong></p><p>.&#x2F;nginx -s reload</p><p><strong>5.测试ngx_kafka_module</strong></p><p># 列出现有的主题</p><p>kafka-topics.sh –list –zookeeper localhost:2181&#x2F;kafka</p><p># 创建主题，该主题包含一个分区，该分区为Leader分区，它没有Follower分区副本。</p><p>kafka-topics.sh –zookeeper localhost:2181&#x2F;kafka –create –topic topic_ozdemo –partitions 1 –replication-factor 1</p><p># 查看分区信息</p><p>kafka-topics.sh –zookeeper localhost:2181&#x2F;kafka –list</p><p># 查看指定主题的详细信息</p><p>kafka-topics.sh –zookeeper localhost:2181&#x2F;kafka –describe –topic topic_ozdemo</p><p># 删除指定主题</p><p>kafka-topics.sh –zookeeper localhost:2181&#x2F;kafka –delete –topic topic_ozdemo</p><p>kafka-topics.sh –zookeeper localhost:2181&#x2F;kafka –create –topic topic_ozdemo –partitions 1 –replication-factor 1</p><p># 开启消费者</p><p>kafka-console-consumer.sh –bootstrap-server localhost:9092 –topic topic_ozdemo</p><p># 开启消费者方式二，从头消费，不按照偏移量消费</p><p>kafka-console-consumer.sh –bootstrap-server localhost:9092 –topic topic_ozdemo –from-beginning</p><p># 测试</p><p>curl <a href="http://127.0.0.1/ozdemo/kafka">http://127.0.0.1/ozdemo/kafka</a> -d “message send to kafka topic”</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;一、kafka架构&quot;&gt;&lt;a href=&quot;#一、kafka架构&quot; class=&quot;headerlink&quot; title=&quot;一、kafka架构&quot;&gt;&lt;/a&gt;&lt;strong&gt;一、kafka架构&lt;/strong&gt;&lt;/h3&gt;&lt;h3 id=&quot;Kafka基础知识&quot;&gt;&lt;a href=&quot;</summary>
      
    
    
    
    <category term="基础知识" scheme="https://itingyu.github.io/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    <category term="kafaka" scheme="https://itingyu.github.io/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/kafaka/"/>
    
    
    <category term="基础知识" scheme="https://itingyu.github.io/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    <category term="kafaka" scheme="https://itingyu.github.io/tags/kafaka/"/>
    
  </entry>
  
  <entry>
    <title>rabbitmq相关知识</title>
    <link href="https://itingyu.github.io/posts/16292/"/>
    <id>https://itingyu.github.io/posts/16292/</id>
    <published>2023-06-17T11:48:04.000Z</published>
    <updated>2023-06-17T11:58:51.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="一、消息中间件基础知识"><a href="#一、消息中间件基础知识" class="headerlink" title="一、消息中间件基础知识"></a><strong>一、消息中间件基础知识</strong></h3><h3 id="两种常见分布式架构"><a href="#两种常见分布式架构" class="headerlink" title="两种常见分布式架构"></a><strong>两种常见分布式架构</strong></h3><p>SOA架构：用Dubbo和Zookeeper进行服务间的远程通信。根据实际业务，把系统拆分成合适的、独立部署的模块，模块之间相互独立。根据实际业务，把系统拆分成合适的、独立部署的模块，模块之间相互独立。Dubbo使用自定义的TCP协议，可以让请求报文体积更小，或者使用HTTP2协议，也可以减少报文 的体积，提高传输效率。</p><p><img src="https://pic3.zhimg.com/80/v2-6da1de1fa7158d241200e8417e00e3a2_720w.webp" alt="img"></p><p>微服务架构：SpringCloud中使用Feign解决服务之间远程通信的问题，Feign是轻量级RESTful的HTTP服务客户端，广泛应用于Spring Cloud中。符合面向接口化的编程习惯。</p><p>本质：封装了HTTP调用流程，类似Dubbo的服务调用。RPC主要基于TCP&#x2F;UDP协议，HTTP协议是应用层协议，是构建在传输层协议TCP之上的，RPC效率更高，RPC长连接：不必每次通信都像HTTP一样三次握手，减少网络开销； HTTP服务开发迭代更快：在接口不多，系统与系统之间交互比较少的情况下，HTTP就显得更加方便；相反，在接口比较多，系统与系统之间交互比较多的情况下，HTTP就没有RPC有优势。</p><p><img src="/posts/16292/assets/7bed1f40f9df9c119ed49bd87968d44e.webp" alt="img"></p><h3 id="分布式通信存在的问题及解决办法"><a href="#分布式通信存在的问题及解决办法" class="headerlink" title="分布式通信存在的问题及解决办法"></a><strong>分布式通信存在的问题及解决办法</strong></h3><p>电商项目中，如果后台添加商品信息，该信息放到数据库，我们同时，需要更新搜索引擎的倒排索引。</p><p>解决办法一：在后台添加商品的方法中，如果数据插入数据库成功，就调用更新倒排索引的方法， 接着调用更新静态化页面的方法，如果更新失败重试，（不推荐，更新失败容易出现死循环且高并发场景不适用）</p><p>解决办法二：先执行添加商品的方法，商品添加成功，将更新索引和更新静态页面的任务缓存到一 个公共的位置，然后由相应的服务从该位置获取任务来执行。比如使用redis，使用阻塞队列轮询异步执行。（单使用redis，不使用消息队列，无法确认消息，不推荐）</p><p>解决办法三：分布式异步通信模式，如下图。</p><p><img src="https://pic4.zhimg.com/80/v2-a3dc4b23d71394a6ab19538569deb6c7_720w.webp" alt="img"></p><p>优点：系统间解耦，并具有一定的可恢复性，支持异构系统，下游通常可并发执行，系统具备弹性。服务解耦、流量削峰填谷等</p><p>缺点：消息中间件存在一些瓶颈和一致性问题，对于开发来讲不直观且不易调试，有额外成本。</p><p>使用异步消息模式需要注意的问题： 1. 哪些业务需要同步处理，哪些业务可以异步处理？ 2. 如何保证消息的安全？消息是否会丢失，是否会重复？ 3. 请求的延迟如何能够减少？ 4. 消息接收的顺序是否会影响到业务流程的正常执行？ 5. 消息处理失败后是否需要重发？如果重发如何保证幂等性？</p><p>幂等性：不管重发多少次，都要保证结果的一致性。</p><h3 id="消息中间件概念"><a href="#消息中间件概念" class="headerlink" title="消息中间件概念"></a><strong>消息中间件概念</strong></h3><p>消息中间件也可以称消息队列，是指用高效可靠的消息传递机制进行与平台无关的数据交流，并基于数据通信来进行分布式系统的集成。通过提供消息传递和消息队列模型，可以在分布式环境下扩展进程的通信。</p><p>消息中间件就是在通信的上下游之间截断：break it，Broker，然后利用中间件解耦、异步的特性，构建弹性、可靠、稳定的系统。异步处理、流量削峰、限流、缓冲、排队、最终一致性、消息驱动等需求的场景都可以使用消息中间件。</p><p><img src="https://pic2.zhimg.com/80/v2-8dd708e98c3b8a43404655a3805c7db9_720w.webp" alt="img"></p><h3 id="常用主流消息中间件介绍"><a href="#常用主流消息中间件介绍" class="headerlink" title="常用主流消息中间件介绍"></a><strong>常用主流消息中间件介绍</strong></h3><p>使用最为广泛的三款消息中间件：RabbitMQ、RocketMQ、Kafka。</p><p><strong>RabbitMQ</strong></p><p>RabbitMQ开始是用在电信业务的可靠通信的，也是少有的几款支持AMQP协议的产品之一。</p><p>优点： 1. 轻量级，快速，部署使用方便 2. 支持灵活的路由配置。RabbitMQ中，在生产者和队列之间有一个交换器模块。根据配置的路 由规则，生产者发送的消息可以发送到不同的队列中。路由规则很灵活，还可以自己实现。 3. RabbitMQ的客户端支持大多数的编程语言。</p><p>缺点： 1. 如果有大量消息堆积在队列中，性能会急剧下降 2. RabbitMQ的性能在Kafka和RocketMQ中是最差的，每秒处理几万到几十万的消息。如果应用要求高的性能，不要选择RabbitMQ。 3. RabbitMQ是Erlang开发的，功能扩展和二次开发代价很高。</p><p><strong>RocketMQ</strong></p><p>RocketMQ是一个开源的消息队列，使用java实现。借鉴了Kafka的设计并做了很多改进。 RocketMQ主要用于有序，事务，流计算，消息推送，日志流处理，binlog分发等场景。</p><p>RocketMQ几乎具备了消息队列应该具备的所有特性和功能。 java开发，阅读源代码、扩展、二次开发很方便。 对电商领域的响应延迟做了很多优化。在大多数情况下，响应在毫秒级。如果应用很关注响应时间，可以使用RocketMQ。 性能比RabbitMQ高一个数量级，每秒处理几十万的消息。</p><p>缺点： 跟周边系统的整合和兼容不是很好。</p><p><strong>Kafka</strong></p><p>Kafka的可靠性，稳定性和功能特性基本满足大多数的应用场景。 跟周边系统的兼容性是数一数二的，尤其是大数据和流计算领域，几乎所有相关的开源软件都支持 Kafka，Kafka高效，可伸缩，消息持久化。支持分区、副本和容错。Kafka是Scala和Java开发的，对批处理和异步处理做了大量的设计，因此Kafka可以得到非常高的性能。它的异步消息的发送和接收是三个中最好的，但是跟RocketMQ拉不开数量级，每秒处理几十万的消息。 如果是异步消息，并且开启了压缩，Kafka最终可以达到每秒处理2000w消息的级别。 但是由于是异步的和批处理的，延迟也会高，不适合电商场景。</p><p><img src="/posts/16292/assets/57d7e0f4928e5d90295ea78524029526.webp" alt="img"></p><h3 id="消息中间件应用场景"><a href="#消息中间件应用场景" class="headerlink" title="消息中间件应用场景"></a><strong>消息中间件应用场景</strong></h3><p><strong>电商秒杀场景</strong></p><p>当秒杀开始前，用户在不断的刷新页面，系统应该如何应对高并发的读请求呢？</p><p>在秒杀开始时，大量并发用户瞬间向系统请求生成订单，扣减库存，系统应该如何应对高并发的写请求呢？</p><p>系统应该如何应对高并发的读请求：</p><p>使用缓存策略将请求挡在上层中的缓存中</p><p>能静态化的数据尽量做到静态化</p><p>加入限流（比如对短时间之内来自某一个用户，某一个IP、某个设备的重复请求做丢弃处理）</p><p>系统应该如何应对高并发的写请求：</p><p>生成订单，扣减库存，用户这些操作不经过缓存直达数据库。如果在 1s内，有 1 万个数据连接同时到达，系统的数据库会濒临崩溃。如何解决这个问题呢？我们可以使用消息队列。</p><p>消息队列的作用：</p><p>削去秒杀场景下的峰值写流量——流量削峰（削去秒杀场景下的峰值写流量，将秒杀请求暂存于消息队列，业务服务器响应用户“秒杀结果正在处理中。。。”，释放系统资源去 处理其它用户的请求）</p><p>通过异步处理简化秒杀请求中的业务流程——异步处理（先处理主要的业务，异步处理次要的业务。 如主要流程是生成订单、扣减库存；次要流程比如购买成功之后会给用户发优惠券，增加用户的积分）</p><p>解耦，实现秒杀系统模块之间松耦合——解耦（实现秒杀系统模块之间松耦合，将数据全部发送给消息队列，然后数据服务订阅这个消息队列，接收数据进行处理）</p><p><strong>B端C端数据同步场景</strong></p><p>B端面向企业用户，C端面向求职者。这两个模块业务处理逻辑不同，数据库表结构不同，实际上是处于解耦的状态。但是各自又需要对方的数据，需要共享：如 1. 当C端求职者在更新简历之后，B端企业用户如何尽早看到该简历更新？ 2. 当B端企业用户发布新的职位需求后，C端用户如何尽早看到该职位信息？</p><p>如何解决B端C端数据共享的问题？</p><p>\1. 同步方式：B端和C端通过RPC或WebService的方式发布服务，让对方来调用，以获取对方的信息。求职者每更新一次简历，就调用一次B端的服务，进行数据的同步；B端企业用户每更新职位需求，就调用C端的服务，进行数据的同步。</p><p>\2. 异步方式：使用消息队列，B端将更新的数据发布到消息队列，C端将更新的数据发布到消息队列，B端订阅C端的消息队列，C端订阅B端的消息队列。</p><p>使用同步方式，B端和C端耦合比较紧密，如果其中一个服务有问题，可能会导致另一个服务不可用。使用消息队列的异步方式，对B端C端进行解耦，只要消息队列可用，双方都可以将需要同步的信息 发送到消息队列，对方在收到消息队列推送来的消息的时候，各自更新自己的搜索引擎，更新自己的缓存数据。</p><h3 id="JMS规范"><a href="#JMS规范" class="headerlink" title="JMS规范"></a><strong>JMS规范</strong></h3><p>JMS即Java消息服务（Java Message Service）应用程序接口，是一个Java平台中关于面向消息中间件（MOM，Message oriented Middleware）的API，用于在两个应用程序之间，或分布式系统中发送 消息，进行异步通信。与具体平台无关的API，绝大多数MOM提供商都支持。 它类似于JDBC(Java Database Connectivity)。消息是JMS中的一种类型对象，由两部分组成：报文头和消息主体。</p><p>根据有效负载的类型来划分，可以将消息分为几种类型： 1. 简单文本(TextMessage) 2. 可序列化的对象(ObjectMessage) 3. 属性集合(MapMessage) 4. 字节流(BytesMessage) 5. 原始值流(StreamMessage) 6. 无有效负载的消息(Message)。</p><p>对象模型：ConnectionFactory 接口（连接工厂）、Connection 接口（连接）、Destination 接口（目标）、Session 接口（会话）、MessageConsumer 接口（消息消费者）、MessageProducer 接口（消息生产者）、Message 接口（消息）</p><p><img src="/posts/16292/assets/15b1f814580acbc06e04b7f3f838f5a3.webp" alt="img"></p><p><strong>点对点模式</strong></p><p>一个生产者向一个特定的队列发布消息，一个消费者从该队列中读取消息。这里，生产者知道消费 者的队列，并直接将消息发送到消费者的队列，概括为： 一条消息只有一个消费者获得 生产者无需在接收者消费该消息期间处于运行状态，接收者也同样无需在消息发送时处于运行 状态。 每一个成功处理的消息要么自动确认，要么由接收者手动确认。</p><p><strong>发布&#x2F;订阅模式</strong></p><p>支持向一个特定的主题发布消息。0或多个订阅者可能对接收特定消息主题的消息感兴趣。发布者和订阅者彼此不知道对方。多个消费者可以获得消息。</p><p>在发布者和订阅者之间存在时间依赖性。 发布者需要建立一个主题，以便客户能够订阅。 订阅者必须保持持续的活动状态以接收消息，否则会丢失未上线时的消息。 对于持久订阅，订阅者未连接时发布的消息将在订阅者重连时重发。</p><p><strong>JMS在应用集群中的问题</strong></p><p>点对点和发布订阅模式在集群下都存在问题，点对点浪费空间，发布订阅对业务侵入较大，ActiveMQ通过“虚拟主题”解决了这个问题。</p><p>JMS规范文档(jms-1_1-fr-spec.pdf)下载地址： <a href="https://link.zhihu.com/?target=https://download.oracle.com/otndocs/jcp/7195-jms-1.1-fr-spec-oth-JSpec/">https://download.oracle.com/otndocs/jcp/7195-jms-1.1-fr-spec-oth-JSpec/</a></p><h3 id="AMQP协议"><a href="#AMQP协议" class="headerlink" title="AMQP协议"></a><strong>AMQP协议</strong></h3><p>AMQP全称高级消息队列协议（Advanced Message Queuing Protocol），是一种标准，类似于 JMS，兼容JMS协议。目前RabbitMQ主流支持AMQP 0-9-1，3.8.4版本支持AMQP 1.0，AMQP是一个二进制的协议，信息被组织成数据帧，有很多类型。。所有数据帧都拥有基本相同的格式：帧头，负载，帧尾。数据帧负载的格式依赖于数据帧的类型。</p><p><img src="/posts/16292/assets/ed1f657caa6730e850ec03ffc9b89873.webp" alt="img"></p><p>Publisher：消息发送者，将消息发送到Exchange并指定RoutingKey，以便queue可以接收到指定的消息。</p><p>Consumer：消息消费者，从queue获取消息，一个Consumer可以订阅多个queue以从多个 queue中接收消息。 Server：一个具体的MQ服务实例，也称为Broker。</p><p>Virtual host：虚拟主机，一个Server下可以有多个虚拟主机，用于隔离不同项目，一个Virtual host通常包含多个Exchange、Message Queue。</p><p>Exchange：交换器，接收Producer发送来的消息，把消息转发到对应的Message Queue中。</p><p>Routing key：路由键，用于指定消息路由规则（Exchange将消息路由到具体的queue中），通 常需要和具体的Exchange类型、Binding的Routing key结合起来使用</p><p>Message Queue：实际存储消息的容器，并把消息传递给最终的Consumer。</p><p>AMQP 使用的数据类型如下：</p><p>Integers（数值范围1-8的十进制数字）：用于表示大小，数量，限制等，整数类型无符号的，可以在帧内不对齐。 Bits（统一为8个字节）：用于表示开&#x2F;关值。</p><p>Short strings：用于保存简短的文本属性，字符串个数限制为255，8个字节</p><p>Long strings：用于保存二进制数据块。</p><p>Field tables：包含键值对，字段值一般为字符串，整数等。</p><p>AMQP协议文档下载地址： <a href="https://link.zhihu.com/?target=https://www.amqp.org/sites/amqp.org/files/amqp0-9-1.zip">https://www.amqp.org/sites/amqp.org/files/amqp0-9-1.zip</a></p><h3 id="二、RabbitMQ架构"><a href="#二、RabbitMQ架构" class="headerlink" title="二、RabbitMQ架构"></a><strong>二、RabbitMQ架构</strong></h3><h3 id="RabbitMQ概念及基本架构"><a href="#RabbitMQ概念及基本架构" class="headerlink" title="RabbitMQ概念及基本架构"></a><strong>RabbitMQ概念及基本架构</strong></h3><p>RabbitMQ，俗称“兔子MQ”（可见其轻巧，敏捷），是目前非常热门的一款开源消息中间件。RabbitMQ具有很强大的插件扩展能力，并具备以下特点：</p><p>\1. 高可靠性、易扩展、高可用、功能丰富等</p><p>\2. 支持大多数（甚至冷门）的编程语言客户端。</p><p>\3. RabbitMQ遵循AMQP协议，自身采用Erlang</p><p>\4. RabbitMQ也支持MQTT等其他协议。</p><p>RabbitMQ常用的交换器类型有： fanout 、 direct 、 topic 、 headers 四种。</p><p>Fanout 会把所有发送到该交换器的消息路由到所有与该交换器绑定的队列中。</p><p>Direct direct类型的交换器路由规则很简单，它会把消息路由到那些BindingKey和RoutingKey完全匹配的队列中。</p><p>Topic topic类型的交换器在direct匹配规则上进行了扩展，可以存在两种特殊字符“*”和 “#”，用于模糊匹配。</p><p>Headers headers类型的交换器不依赖于路由键的匹配规则来路由信息，而是根据发送的消息内容中的 headers属性进行匹配。</p><p>RabbitMQ消息有两种类型： 1. 持久化消息和非持久化消息。 2. 这两种消息都会被写入磁盘。</p><p>持久化消息在到达队列时写入磁盘，同时会内存中保存一份备份，当内存吃紧时，消息从内存中清除。</p><p>非持久化消息一般只存于内存中，当内存压力大时数据刷盘处理，以节省内存空间。</p><p>RabbitMQ存储层包含两个部分：队列索引和消息存储。</p><p>队列索引：rabbit_queue_index 索引维护队列的落盘消息的信息，如存储地点、是否已被给消费者接收、是否已被消费者ack等。</p><p>消息存储：rabbit_msg_store 消息以键值对的形式存储到文件中，一个虚拟主机上的所有队列使用同一块存储，每个节点只有一 个。存储分为持久化存储（msg_store_persistent）和短暂存储（msg_store_transient）。持久化存 储的内容在broker重启后不会丢失，短暂存储的内容在broker重启后丢失。</p><p>队列结构 通常队列由rabbit_amqqueue_process和backing_queue这两部分组成， rabbit_amqqueue_process负责协议相关的消息处理，即接收生产者发布的消息、向消费者交付消 息、处理消息的确认（包括生产端的confirm和消费端的ack）等。backing_queue是消息存储的具体形 式和引擎，并向rabbit_amqqueue_process提供相关的接口以供调用。</p><p>为什么消息的堆积导致性能下降？</p><p>在系统负载较高时，消息若不能很快被消费掉，这些消息就会进入到很深的队列中去，这样会增加处理每个消息的平均开销。因为要花更多的时间和资源处理“堆积”的消息，如此用来处理新流入的消息 的能力就会降低，使得后流入的消息又被积压到很深的队列中，继续增大处理每个消息的平均开销，继 而情况变得越来越恶化，使得系统的处理能力大大降低。</p><h3 id="安装和配置RabbitMQ"><a href="#安装和配置RabbitMQ" class="headerlink" title="安装和配置RabbitMQ"></a><strong>安装和配置RabbitMQ</strong></h3><p>第一步：安装依赖</p><p>yum install socat -y</p><p>第二步：安装Erlang</p><p>rpm -ivh erlang-23.0.2-1.el7.x86_64.rpm –force –nodeps</p><p>第三步：安装RabbitMQ</p><p>rpm -ivh rabbitmq-server-3.8.4-1.el7.noarch.rpm –force –nodeps</p><p>第四步：启用RabbitMQ的管理插件</p><p>cd ..&#x2F;usr&#x2F;lib&#x2F;rabbitmq</p><p>rabbitmq-plugins enable rabbitmq_management</p><p><img src="/posts/16292/assets/20776ccaa871ee636970eaf452030220.webp" alt="img"></p><p>第五步：启动RabbitMQ</p><p>systemctl start rabbitmq-server 前台启动</p><p>rabbitmq-server -detached 后台启动</p><p>第六步：添加用户</p><p>rabbitmqctl add_user root 123456</p><p>第七步：给用户添加权限</p><p>rabbitmqctl set_permissions root -p &#x2F; “.<em>“ “.</em>“ “.*”</p><p>第八步: 给用户设置标签</p><p>rabbitmqctl set_user_tags root administrator</p><p>第九步：打开浏览器，登录客户端</p><p><img src="/posts/16292/assets/7d4d1ea04ec166d0db7d92d01413a54b.webp" alt="img"></p><h3 id="RabbitMQ常用操作命令"><a href="#RabbitMQ常用操作命令" class="headerlink" title="RabbitMQ常用操作命令"></a><strong>RabbitMQ常用操作命令</strong></h3><p># 前台启动Erlang VM和RabbitMQ</p><p>rabbitmq-server</p><p># 后台启动</p><p>rabbitmq-server -detached</p><p># 停止RabbitMQ和Erlang VM</p><p>rabbitmqctl stop</p><p># 查看所有队列</p><p>rabbitmqctl list_queues</p><p># 查看所有虚拟主机</p><p>rabbitmqctl list_vhosts</p><p># 在Erlang VM运行的情况下启动RabbitMQ应用</p><p>rabbitmqctl start_app rabbitmqctl stop_app</p><p># 查看节点状态</p><p>rabbitmqctl status</p><p># 查看所有可用的插件</p><p>rabbitmq-plugins list</p><p># 启用插件</p><p>rabbitmq-plugins enable</p><p># 停用插件</p><p>rabbitmq-plugins disable</p><p># 添加用户</p><p>rabbitmqctl add_user username password</p><p># 列出所有用户：</p><p>rabbitmqctl list_users</p><p># 删除用户：</p><p>rabbitmqctl delete_user username</p><p># 清除用户权限： r</p><p>abbitmqctl clear_permissions -p vhostpath username</p><p># 列出用户权限：</p><p>rabbitmqctl list_user_permissions username</p><p># 修改密码：</p><p>rabbitmqctl change_password username newpassword</p><p># 设置用户权限：</p><p>rabbitmqctl set_permissions -p vhostpath username “.<em>“ “.</em>“ “.*”</p><p># 创建虚拟主机:</p><p>rabbitmqctl add_vhost vhostpath</p><p># 列出所以虚拟主机:</p><p>rabbitmqctl list_vhosts</p><p># 列出虚拟主机上的所有权限:</p><p>rabbitmqctl list_permissions -p vhostpath</p><p># 删除虚拟主机:</p><p>rabbitmqctl delete_vhost vhost vhostpath</p><p># 移除所有数据，要在 rabbitmqctl stop_app 之后使用:</p><p>rabbitmqctl reset</p><h3 id="RabbitMQ工作流程详解"><a href="#RabbitMQ工作流程详解" class="headerlink" title="RabbitMQ工作流程详解"></a><strong>RabbitMQ工作流程详解</strong></h3><p><strong>生产者发送消息的流程</strong></p><p>\1. 生产者连接RabbitMQ，建立TCP连接( Connection)，开启信道（Channel）</p><p>\2. 生产者声明一个Exchange（交换器），并设置相关属性，比如交换器类型、是否持久化等</p><p>\3. 生产者声明一个队列井设置相关属性，比如是否排他、是否持久化、是否自动删除等</p><p>\4. 生产者通过 bindingKey （绑定Key）将交换器和队列绑定（ binding ）起来</p><p>\5. 生产者发送消息至RabbitMQ Broker，其中包含 routingKey （路由键）、交换器等信息</p><p>\6. 相应的交换器根据接收到的 routingKey 查找相匹配的队列。</p><p>\7. 如果找到，则将从生产者发送过来的消息存入相应的队列中。</p><p>\8. 如果没有找到，则根据生产者配置的属性选择丢弃还是回退给生产者</p><p>\9. 关闭信道。</p><p>\10. 关闭连接。</p><p><strong>消费者接收消息的过程</strong></p><p>\1. 消费者连接到RabbitMQ Broker ，建立一个连接(Connection ) ，开启一个信道(Channel) 。</p><p>\2. 消费者向RabbitMQ Broker 请求消费相应队列中的消息，可能会设置相应的回调函数， 以及 做一些准备工作 3. 等待RabbitMQ Broker 回应并投递相应队列中的消息， 消费者接收消息。</p><p>\4. 消费者确认( ack) 接收到的消息。</p><p>\5. RabbitMQ 从队列中删除相应己经被确认的消息。</p><p>\6. 关闭信道。</p><p>\7. 关闭连接。</p><h3 id="Connection-和Channel关系"><a href="#Connection-和Channel关系" class="headerlink" title="Connection 和Channel关系"></a><strong>Connection 和Channel关系</strong></h3><p>生产者和消费者，需要与RabbitMQ Broker 建立TCP连接，也就是Connection 。一旦TCP 连接建立起来，客户端紧接着创建一个AMQP 信道（Channel），每个信道都会被指派一个唯一的ID。信道是建立在Connection 之上的虚拟连接， RabbitMQ 处理的每条AMQP 指令都是通过信道完成的。</p><p>为什么不直接使用TCP连接，而是使用信道？</p><p>RabbitMQ 采用类似NIO的做法，复用TCP 连接，减少性能开销，便于管理。 当每个信道的流量不是很大时，复用单一的Connection 可以在产生性能瓶颈的情况下有效地节省 TCP 连接资源。当信道本身的流量很大时，一个Connection 就会产生性能瓶颈，流量被限制。需要建立多个 Connection ，分摊信道。</p><p><img src="https://pic2.zhimg.com/80/v2-0dfb0279d8b9f2ed2ffee47c08222769_720w.webp" alt="img"></p><h3 id="RabbitMQ工作模式详解"><a href="#RabbitMQ工作模式详解" class="headerlink" title="RabbitMQ工作模式详解"></a><strong>RabbitMQ工作模式详解</strong></h3><p><strong>工作队列模式Work Queue</strong></p><p>生产者发消息，启动多个消费者实例来消费消息，每个消费者仅消费部分信息，可达到负载均衡的效果。</p><p>结果：生产者生产消息发送给交换器，交换器向绑定他的消费者分发消息，负载均衡。</p><p><img src="https://pic2.zhimg.com/80/v2-5ac27fc15144c2206bf1533f9af48bb1_720w.webp" alt="img"></p><p><strong>发布订阅模式fanout</strong></p><p>使用fanout类型交换器，routingKey忽略。每个消费者定义生成一个队列并绑定到同一个Exchange，每个消费者都可以消费到完整的消息。消息广播给所有订阅该消息的消费者。生产者将消息发送给交换器。交换器非常简单，从生产者接收消息，将消息推送给消息队列。交换器的类型： direct 、 topic 、 headers 和 fanout 四种类型。发布订阅使 用fanout。不指定交换器会使用默认交换器default。</p><p>实现RabbitMQ的消费者有两种模式，推模式（Push）和拉模式（Pull）。 实现推模式推荐的方式 是继承 DefaultConsumer 基类，也可以使用Spring AMQP的 SimpleMessageListenerContainer 。</p><p>结果：生产者往交换器发送消息，消费者会声明一个临时队列，绑定到交换器，当消息过来，交换器会复制N份发送给订阅的消费者。实现将消息广播到很多接收者。</p><p><img src="/posts/16292/assets/e2053b263aff24f722bd59104ff841c4.webp" alt="img"></p><p><strong>路由模式direct</strong></p><p>使用 direct 类型的Exchange，发N条消费并使用不同的 routingKey ，消费者定义队列并将队列、 routingKey 、Exchange绑定。此时使用 direct 模式Exchagne必须要 routingKey 完全匹配的情况下消息才会转发到对应的队列中被消费，通过路由模式实现让接收者只接收部分消息。</p><p>结果：生产者往交换器发送消息，消费者根据key绑定交换器，交换器根据匹配路由和key推送消息。实现通过 direct 类型的交换器做到了根据日志级别的不同，将消息发送给了不同队列的。</p><p><img src="https://pic4.zhimg.com/80/v2-9b4b22356224076ab4c6c26eafb8f2b7_720w.webp" alt="img"></p><p><strong>主题模式topic</strong></p><p>使用 topic 类型的交换器，队列绑定到交换器、 bindingKey 时使用通配符，交换器将消息路由转发到具体队列时会根据消息 routingKey 模糊匹配，比较灵活。</p><p>结果：生产者往交换器发送消息，消费者根据key绑定交换器，通过绑定器里面的通配符让交换器发送消息时进行分类发送，最后达到定制分发效果。</p><p><img src="/posts/16292/assets/4de1502cc2ada9a1a2b8bc4e95f8a39a.webp" alt="img"></p><h3 id="SpringBoot整合RabbitMQ"><a href="#SpringBoot整合RabbitMQ" class="headerlink" title="SpringBoot整合RabbitMQ"></a><strong>SpringBoot整合RabbitMQ</strong></h3><p>\1. 添加starter依赖</p><dependency><groupId>org.springframework.boot</groupId><artifactId>spring-boot-starter-amqp</artifactId></dependency><p>\2. application.properties中添加连接信息</p><p>spring.application.name&#x3D;springboot_rabbit<br>spring.rabbitmq.host&#x3D;127.0.0.1<br>spring.rabbitmq.virtual-host&#x3D;&#x2F;<br>spring.rabbitmq.username&#x3D;root<br>spring.rabbitmq.password&#x3D;123456<br>spring.rabbitmq.port&#x3D;5672</p><p>\3. 主入口类</p><p><img src="/posts/16292/assets/33df0951152d0de7049571c1822eb4bb.webp" alt="img"></p><p>4.RabbitConfig类</p><p><img src="https://pic3.zhimg.com/80/v2-9847b960b61754f1e7fff21a317cd6d6_720w.webp" alt="img"></p><p>5.使用RestController发送消息</p><p><img src="/posts/16292/assets/6fc09bcf242fd27ad8fbefae4eb9e306.webp" alt="img"></p><p>6.使用监听器，用于推消息</p><p><img src="/posts/16292/assets/a90504f013654f607d4d6951c6032b40.webp" alt="img"></p><h3 id="三、RabbitMQ特性"><a href="#三、RabbitMQ特性" class="headerlink" title="三、RabbitMQ特性"></a><strong>三、RabbitMQ特性</strong></h3><h3 id="消息可靠性问题"><a href="#消息可靠性问题" class="headerlink" title="消息可靠性问题"></a><strong>消息可靠性问题</strong></h3><p>支付平台必须保证数据正确性，保证数据并发安全性，保证数据最终一致性。 支付平台通过如下几种方式保证数据一致性：</p><p>\1. 分布式锁，用redis或zookeeper等常用框架来实现。 比如我们在修改账单时，先锁定该账单，如果该账单有并发操作，后面的操作只能等 待上一个操作的锁释放后再依次执行。</p><p>优点：能够保证数据强一致性。 缺点：高并发场景下可能有性能问题。</p><p>\2. 消息队列，保证最终一致性，我们需要确保消息队列有ack机制 客户端收到消 息并消费处理完成后，客户端发送ack消息给消息中间件 如果消息中间件超过指定时间还没收 到ack消息，则定时去重发消息。</p><p>优点：异步、高并发 缺点：有一定延时、数据弱一致性，并且必须能够确保该业务操作肯定能够成 功完成，不可能失败。</p><h3 id="消息可靠性解决之异常捕获机制"><a href="#消息可靠性解决之异常捕获机制" class="headerlink" title="消息可靠性解决之异常捕获机制"></a><strong>消息可靠性解决之异常捕获机制</strong></h3><p>先执行业务操作，业务操作成功后执行消息发送，消息发送过程通过try catch 方式捕获异常， 在异常处理理的代码块中执行回滚业务操作或者执行重发操作等。这是一种最大努力确保的方式，并无法保证100%绝对可靠，因为这里没有异常并不代表消息就一定投递成功。</p><p><img src="/posts/16292/assets/aa82b0116c838067501a65f320469d10.webp" alt="img"></p><h3 id="消息可靠性解决之AMQP-x2F-RabbitMQ的事务机制"><a href="#消息可靠性解决之AMQP-x2F-RabbitMQ的事务机制" class="headerlink" title="消息可靠性解决之AMQP&#x2F;RabbitMQ的事务机制"></a><strong>消息可靠性解决之AMQP&#x2F;RabbitMQ的事务机制</strong></h3><p>没有捕获到异常并不能代表消息就一定投递成功了。一直到事务提交后都没有异常，确实就说明消息是投递成功了。这种方式在性能方面的开销比较大，不推荐使用。</p><p><img src="/posts/16292/assets/4ef595e6a9186822b921caaa1a76e3af.webp" alt="img"></p><h3 id="消息可靠性解决之发送端确认机制"><a href="#消息可靠性解决之发送端确认机制" class="headerlink" title="消息可靠性解决之发送端确认机制"></a><strong>消息可靠性解决之发送端确认机制</strong></h3><p>RabbitMQ后来引入了一种轻量量级的方式，叫发送方确认(publisher confirm)机制。生产者将信道设置成confirm(确认)模式，一旦信道进入confirm 模式，所有在该信道上⾯面发布的消息都会被指派 一个唯一的ID(从1 开始)，一旦消息被投递到所有匹配的队列之后（如果消息和队列是持久化的，那么确认消息会在消息持久化后发出），RabbitMQ 就会发送一个确认(Basic.Ack)给生产者(包含消息的唯一 ID)，这样生产者就知道消息已经正确送达了。</p><p><img src="/posts/16292/assets/5ae4734aba0f08820126b51dc5d9ecb7.webp" alt="img"></p><h3 id="消息可靠性解决之持久化存储机制"><a href="#消息可靠性解决之持久化存储机制" class="headerlink" title="消息可靠性解决之持久化存储机制"></a><strong>消息可靠性解决之持久化存储机制</strong></h3><p>持久化是提高RabbitMQ可靠性的基础，否则当RabbitMQ遇到异常时（如：重启、断电、停机 等）数据将会丢失。主要从以下几个方面来保障消息的持久性：</p><p>\1. Exchange的持久化。通过定义时设置durable 参数为ture来保证Exchange相关的元数据不丢失。</p><p>\2. Queue的持久化。也是通过定义时设置durable 参数为ture来保证Queue相关的元数据不丢失。</p><p>3.消息的持久化。通过将消息的投递模式 (BasicProperties 中的 deliveryMode 属性)设置为 2 即可实现消息的持久化，保证消息自身不丢失。</p><p>RabbitMQ中的持久化消息都需要写入磁盘（当系统内存不足时，非持久化的消息也会被刷盘处理），这些处理动作都是在“持久层”中完成的。</p><p>\1. 队列索引(rabbit_queue_index)，rabbit_queue_index 负责维护Queue中消息的信息，包括 消息的存储位置、是否已交给消费者、是否已被消费及Ack确认等，每个Queue都有与之对应 的rabbit_queue_index。</p><p>\2. 消息存储(rabbit_msg_store)，rabbit_msg_store 以键值对的形式存储消息，它被所有队列列 共享，在每个节点中有且只有一个。</p><h3 id="消息可靠性解决之Consumer-ACK"><a href="#消息可靠性解决之Consumer-ACK" class="headerlink" title="消息可靠性解决之Consumer ACK"></a><strong>消息可靠性解决之Consumer ACK</strong></h3><p>如何保证消息被消费者成功消费？</p><p>生产者发送确认机制和消息的持久化存储机制，然而这依然无法完全保证整个过程的可靠性，因为如果消息被消费过程中业务处理失败了但是消息却已经出列了（被标记为已消费了），我 们又没有任何重试，那结果跟消息丢失没什么分别。 因此RabbitMQ在消费端会有Ack机制，即消费端消费消息后需要发送Ack确认报文给Broker端，告知自己是否已消费完成，否则可能会一直重发消息直到消息过期（AUTO模式）。</p><p>\1. 采用NONE模式，消费的过程中自行捕获异常，引发异常后直接记录日志并落到异常恢复表， 再通过后台定时任务扫描异常恢复表尝试做重试动作。如果业务不自行处理则有丢失数据的风险</p><p>\2. 采用AUTO（自动Ack）模式，不主动捕获异常，当消费过程中出现异常时会将消息放回 Queue中，然后消息会被重新分配到其他消费者节点（如果没有则还是选择当前节点）重新 被消费，默认会一直重发消息并直到消费完成返回Ack或者一直到过期</p><p>\3. 采用MANUAL（手动Ack）模式，消费者自行控制流程并手动调用channel相关的方法返回 Ack</p><p>SpringBoot项目中支持如下的一些配置：</p><p>#最大重试次数</p><p>spring.rabbitmq.listener.simple.retry.max-attempts&#x3D;5</p><p>#是否开启消费者重试（为false时关闭消费者重试，意思不是“不重试”，而是一直收到消息直到jack 确认或者一直到超时）</p><p>spring.rabbitmq.listener.simple.retry.enabled&#x3D;true</p><p>#重试间隔时间（单位毫秒）</p><p>spring.rabbitmq.listener.simple.retry.initial-interval&#x3D;5000</p><p>#重试超过最大次数后是否拒绝</p><p>spring.rabbitmq.listener.simple.default-requeue-rejected&#x3D;false</p><p>#ack模式</p><p>spring.rabbitmq.listener.simple.acknowledge-mode&#x3D;manual</p><h3 id="消息可靠性解决之消费端限流"><a href="#消息可靠性解决之消费端限流" class="headerlink" title="消息可靠性解决之消费端限流"></a><strong>消息可靠性解决之消费端限流</strong></h3><p>在电商的秒杀活动中，活动一开始会有大量并发写请求到达服务端，需要对消息进行削峰处理，如何削峰？</p><p>当消息投递速度远快于消费速度时，随着时间积累就会出现“消息积压”。消息中间件本身是具备一 定的缓冲能力的，但这个能力是有容量限制的，如果长期运行并没有任何处理，最终会导致Broker崩 溃，而分布式系统的故障往往会发生上下游传递，产生连锁反应。</p><p>\1. RabbitMQ 可以对内存和磁盘使用量设置阈值，当达到阈值后，生产者将被阻塞(block)，直 到对应项指标恢复正常。全局上可以防止超大流量、消息积压等导致的Broker被压垮。</p><p>\2. RabbitMQ 还默认提供了一种基于credit flow 的流控机制，面向每一个连接进行流控。当单个队列达到最大流速时，或者多个队列达到总流速时，都会触发流控。</p><p>\3. RabbitMQ中有一种QoS保证机制，可以限制Channel上接收到的未被Ack的消息数量，如果 超过这个数量限制RabbitMQ将不会再往消费端推送消息。这是一种流控手段，可以防止大量消息瞬时从Broker送达消费端造成消费端巨大压力（甚至压垮消费端）。比较值得注意的是 QoS机制仅对于消费端推模式有效，对拉模式无效。</p><p>提升下游应用的吞吐量和缩短消费过程的耗时，优化主要以下几种方式：</p><p>\1. 优化应用程序的性能，缩短响应时间（需要时间）</p><p>\2. 增加消费者节点实例（成本增加，而且底层数据库操作这些也可能是瓶颈）</p><p>\3. 调整并发消费的线程数（线程数并非越大越好，需要大量压测调优至合理值）</p><h3 id="消息可靠性保障"><a href="#消息可靠性保障" class="headerlink" title="消息可靠性保障"></a><strong>消息可靠性保障</strong></h3><p>消息可靠传输一般是业务系统接入消息中间件时首要考虑的问题，一般消息中间件的消息传输保障 分为三个层级：</p><p>\1. At most once：最多一次。消息可能会丢失，但绝不会重复传输</p><p>\2. At least once：最少一次。消息绝不会丢失，但可能会重复传输</p><p>\3. Exactly once：恰好一次。每条消息肯定会被传输一次且仅传输一次</p><p>RabbitMQ 支持其中的“最多一次”和“最少一次”。</p><p>其中“最少一次”投递实现需要考虑以下这个几个方面的内容：</p><p>\1. 消息生产者需要开启事务机制或者publisher confirm 机制，以确保消息可以可靠地传输到 RabbitMQ 中。</p><p>\2. 消息生产者需要配合使用 mandatory 参数或者备份交换器来确保消息能够从交换器路由到队列中，进而能够保存下来而不会被丢弃。</p><p>\3. 消息和队列都需要进行持久化处理，以确保RabbitMQ 服务器在遇到异常情况时不会造成消息丢失。</p><p>\4. 消费者在消费消息的同时需要将autoAck 设置为false，然后通过手动确认的方式去确认已经正确消费的消息，以避免在消费端引起不必要的消息丢失。</p><p>“最多一次”的方式就无须考虑以上那些方面，生产者随意发送，消费者随意消费，不过这样很难确 保消息不会丢失。</p><h3 id="消息幂等性处理"><a href="#消息幂等性处理" class="headerlink" title="消息幂等性处理"></a><strong>消息幂等性处理</strong></h3><p>一个幂等操作的特点是，其任意多次执行所产生的影响均与一次执行的影响相同。一个幂等的方 法，使用同样的参数，对它进行多次调用和一次调用，对系统产生的影响是一样的。 对于幂等的方法，不用担心重复执行会对系统造成任何改变。</p><p>对于幂等性的一些常见做法：</p><p>\1. 借助数据库唯一索引，重复插入直接报错，事务回滚。</p><p>\2. 前置检查机制。为了防止并发问题，我们通常需要借助“排他锁”来完成。在支付宝有一条铁律叫：一锁、二判、三操作。当然，我们也可以使用乐观锁或CAS机制，乐观锁一般会使用扩展一个版本号字段做判断条件。</p><p>\3. 唯一Id机制，比较通用的方式。</p><h3 id="消息可靠性分析"><a href="#消息可靠性分析" class="headerlink" title="消息可靠性分析"></a><strong>消息可靠性分析</strong></h3><p>在使用任何消息中间件的过程中，难免会出现消息丢失等异常情况，这个时候就需要有一个良好的机制来跟踪记录消息的过程（轨迹溯源），帮助我们排查问题。 在RabbitMQ 中可以使用Firehose 功能来实现消息追踪，Firehose 可以记录每一次发送或者消费 消息的记录，方便RabbitMQ 的使用者进行调试、排错等。Firehose 的原理是将生产者投递给RabbitMQ 的消息，或者RabbitMQ 投递给消费者的消息按照指定的格式发送到默认的交换器上。</p><p>开启Firehose命令： rabbitmqctl trace_on [-p vhost]</p><p>关闭命令为：rabbitmqctl trace_off [-p vhost]</p><p>Firehose 默认情况下处于关闭状态，并且Firehose 的状态是非持久化的，会在RabbitMQ服务重启的时候还原成默认的状态。Firehose 开启之后多少会影响RabbitMQ 整体服务性能，因为它会引起额 外的消息生成、路由和存储。</p><h3 id="TTL机制"><a href="#TTL机制" class="headerlink" title="TTL机制"></a><strong>TTL机制</strong></h3><p>在京东下单，订单创建成功，等待支付，一般会给30分钟的时间，开始倒计时。如果在这段时间内 用户没有支付，则默认订单取消。</p><p>常用实现办法：</p><p>\1. 定期轮询检查（数据库等）</p><p>\2. Timer定时器</p><p>\3. ScheduledExecutorService多线程</p><p>\4. RabbitMQ消息队列</p><p>TTL，Time to Live 的简称，即过期时间。 RabbitMQ 可以对消息和队列两个维度来设置TTL。</p><p>两种方法可以设置消息的TTL：</p><p>\1. 通过Queue属性设置，队列中所有消息都有相同的过期时间。</p><p>\2. 对消息自身进行单独设置，每条消息的TTL可以不同。</p><p>默认规则：</p><p>\1. 如果不设置TTL，则表示此消息不会过期；</p><p>\2. 如果TTL设置为0，则表示除非此时可以直接将消息投递到消费者，否则该消息会被立即丢弃；</p><p>通过命令行方式设置全局TTL，执行如下命令：</p><p>rabbitmqctl set_policy TTL “.*” ‘{“message-ttl”:30000}’ –apply-to queues</p><h3 id="死信队列"><a href="#死信队列" class="headerlink" title="死信队列"></a><strong>死信队列</strong></h3><p>用户下单，调用订单服务，然后订单服务调用派单系统通知外卖人员送单，这时候订单系统与派单系统采用 MQ异步通讯。在定义业务队列时可以考虑指定一个 死信交换机，并绑定一个死信队列。当消息变成死信时，该消 息就会被发送到该死信队列上，这样方便我们查看消息失败的原因。 DLX，全称为Dead-Letter-Exchange，死信交换器。消息在一个队列中变成死信（Dead Letter） 之后，被重新发送到一个特殊的交换器（DLX）中，同时，绑定DLX的队列就称为“死信队列”。</p><p>以下几种情况导致消息变为死信：</p><p>\1. 消息被拒绝（Basic.Reject&#x2F;Basic.Nack），并且设置requeue参数为false；</p><p>\2. 消息过期；</p><p>\3. 队列达到最大长度。</p><h3 id="延迟队列"><a href="#延迟队列" class="headerlink" title="延迟队列"></a><strong>延迟队列</strong></h3><p>延迟消息是指的消息发送出去后并不想立即就被消费，而是需要等（指定的）一段时间后才触发消费。</p><p>\1. 生产者将消息(msg)和路由键(routekey)发送指定的延时交换机(exchange)上</p><p>\2. 延时交换机(exchange)存储消息等待消息到期根据路由键(routekey)找到绑定自己的队列 (queue)并把消息给它 3. 队列(queue)再把消息发送给监听它的消费者(customer）</p><p><img src="/posts/16292/assets/7bb79d1fe470f3686f3200e5d571c30e.webp" alt="img"></p><h3 id="一、RocketMQ架构"><a href="#一、RocketMQ架构" class="headerlink" title="一、RocketMQ架构"></a><strong>一、RocketMQ架构</strong></h3><h3 id="RocketMQ使用场景"><a href="#RocketMQ使用场景" class="headerlink" title="RocketMQ使用场景"></a><strong>RocketMQ使用场景</strong></h3><p>\1. 应用解耦：系统的耦合性越高，容错性就越低。以电商应用为例，用户创建订单后，如果耦合调用库存系统、 物流系统、支付系统，任何一个子系统出了故障或者因为升级等原因暂时不可用，都会造成下单操作异常，影响用户使用体验。</p><p>\2. 流量削峰：缓存起来，分散到很长一段时间处理，这样可以大大提到系统的稳定性和用户体验。</p><p>\3. 数据分发：通过消息队列可以让数据在多个系统之间进行流通。数据的产生方不需要关心谁来使用数据，只需 要将数据发送到消息队列，数据使用方直接在消息队列中直接获取数据即可</p><h3 id="RocketMQ-部署架构"><a href="#RocketMQ-部署架构" class="headerlink" title="RocketMQ 部署架构"></a><strong>RocketMQ 部署架构</strong></h3><p>RocketMQ的角色：</p><p>Producer：消息的发送者；举例：发信者</p><p>Consumer：消息接收者；举例：收信者</p><p>Broker：暂存和传输消息；举例：邮局</p><p>NameServer：管理Broker；举例：各个邮局的管理机构</p><p>Topic：区分消息的种类；一个发送者可以发送消息给一个或者多个Topic；一个消息的接收者 可以订阅一个或者多个Topic消息</p><p>Message Queue：相当于是Topic的分区；用于并行发送和接收消息</p><p><img src="https://pic2.zhimg.com/80/v2-185f773fac81200291b702b45f8678dd_720w.webp" alt="img"></p><p>执行流程:</p><p>\1. 启动NameServer，NameServer起来后监听端口，等待Broker、Producer、Consumer连上来，相当于一个路由控制中心。</p><p>\2. Broker启动，跟所有的NameServer保持长连接，定时发送心跳包。心跳包中包含当前 Broker信息(IP+端口等)以及存储所有Topic信息。注册成功后，NameServer集群中就有Topic 跟Broker的映射关系。</p><p>\3. 收发消息前，先创建Topic，创建Topic时需要指定该Topic要存储在哪些Broker上，也可以在发送消息时自动创建Topic。</p><p>\4. Producer发送消息，启动时先跟NameServer集群中的其中一台建立长连接，并从 NameServer中获取当前发送的Topic存在哪些Broker上，轮询从队列列表中选择一个队列， 然后与队列所在的Broker建立长连接从而向Broker发消息。</p><p>\5. Consumer跟Producer类似，跟其中一台NameServer建立长连接，获取当前订阅Topic存在 哪些Broker上，然后直接跟Broker建立连接通道，开始消费消息。</p><h3 id="RocketMQ特性"><a href="#RocketMQ特性" class="headerlink" title="RocketMQ特性"></a><strong>RocketMQ特性</strong></h3><p>\1. 订阅与发布：消息的发布是指某个生产者向某个topic发送消息；消息的订阅是指某个消费者关注了某个topic中带有某些tag的消息。</p><p>\2. 消息顺序：消息有序指的是一类消息消费时，能按照发送的顺序来消费。RocketMQ可以严格的保证消息有序。</p><p>\3. 消息过滤：RocketMQ的消费者可以根据Tag进行消息过滤，也支持自定义属性过滤。</p><p>\4. 消息可靠性：RocketMQ支持消息的高可靠，影响消息可靠性的几种情况： 1)Broker非正常关闭 2)Broker异常 Crash 3)OS Crash 4)机器掉电，但是能立即恢复供电情况 5)机器无法开机（可能是cpu、主板、内存等 关键设备损坏） 6)磁盘设备损坏，RocketMQ通过异步复制，可保证99%的消息不丢，但是仍然会有极少量的消息可能丢失。通过同步双写技术可以完全避免单点，但是性能会下降。</p><p>\5. 至少一次：指每个消息必须投递一次。Consumer先Pull消息到本地，消费完成后，才向服务器返回ack，如果没有消费一定不会ack消息，所以RocketMQ可以很好的支持此特性。</p><p>\6. 回溯消费：回溯消费是指Consumer已经消费成功的消息，由于业务上需求需要重新消费，要支持此功能， Broker在向Consumer投递成功消息后，消息仍然需要保留。</p><p>\7. 事务消息：RocketMQ事务消息是指应用本地事务和发送消息操作可以被定义到全局事务中，要么同时成功，要么同时失败。</p><p>\8. 定时消息：定时消息（延迟队列）是指消息发送到broker后，不会立即被消费，等待特定时间投递给真正的 topic。</p><p>\9. 消息重试：Consumer消费消息失败后，要提供一种重试机制，令消息再消费一次。</p><p>\10. 消息重投：消息重投保证消息尽可能发送成功、不丢失，但可能会造成消息重复，消息重复在RocketMQ中是 无法避免的问题。</p><p>\11. 流量控制：生产者流控，因为broker处理能力达到瓶颈，不会尝试消息重投；消费者流控，因为消费能力达到瓶颈。</p><p>\12. 死信队列：死信队列用于处理无法被正常消费的消息。 当一条消息初次消费失败，消息队列会自动进行消息重试；达到最大重试次数后，若消费依然失败，则表明消费者在正常情况下无法正确地消费该消息，此时，消息队列不会立刻将消息丢弃，而是将其发送到该消费者对应的特殊队列中。</p><h3 id="消费模式Push-or-Pull"><a href="#消费模式Push-or-Pull" class="headerlink" title="消费模式Push or Pull"></a><strong>消费模式Push or Pull</strong></h3><p>RocketMQ消息订阅有两种模式，一种是Push模式，即MQServer主动向消费端推送；另外一种是Pull模式，即消费端在需要时，主动到MQ Server拉取。但在具体实现时，Push和Pull模式本质都是采用消费端主动拉取的方式，即consumer轮询从 broker拉取消息。RocketMQ使用长轮询机制来模拟Push效果，算是兼顾了二者的优点。</p><p><strong>Push模式</strong></p><p>实时性高，但是消费端的处理能力有限，当瞬间推送很多消息给消费端时，容易造成消费端的消息积压，严重时会压垮客户端，Push方式里，consumer把长轮询的动作封装了，并注册MessageListener监听器，取到消息后，唤醒MessageListener的consumeMessage()来消费，对用户而言，感觉消息是被推送过来的。</p><p><strong>Pull模式</strong></p><p>主动权掌握在消费端自己手中，根据自己的处理能力量力而行。但是Pull的频率，定时间隔太久担心影响时效性，间隔太短担心做太多“无用功”浪费资源。比较折中的办法就是长轮询。Pull方式里，取消息的过程需要用户自己主动调用，首先通过打算消费的Topic拿到 MessageQueue的集合，遍历MessageQueue集合，然后针对每个MessageQueue批量取消息，一次取完后，记录该队列下一次要取的开始offset，直到取完了，再换另一个MessageQueue。</p><h3 id="RocketMQ核心概念"><a href="#RocketMQ核心概念" class="headerlink" title="RocketMQ核心概念"></a><strong>RocketMQ核心概念</strong></h3><p>\1. 消息模型：RocketMQ主要由Producer、Broker、Consumer 三部分组成，其中Producer 负责生产消息， Consumer 负责消费消息，Broker 负责存储消息。</p><p>\2. Producer：消息生产者，负责产生消息，一般由业务系统负责产生消息。</p><p>\3. Consumer：消息消费者，负责消费消息，一般是后台系统负责异步消费。</p><p>\4. PushConsumer：Consumer消费的一种类型，该模式下Broker收到数据后会主动推送给消费端。应用通常向 Consumer对象注册一个Listener接口，一旦收到消息，Consumer对象立刻回调Listener接口方法。该 消费模式一般实时性较高。</p><p>\5. PullConsumer：Consumer消费的一种类型，应用通常主动调用Consumer的拉消息方法从Broker服务器拉消息、 主动权由应用控制。一旦获取了批量消息，应用就会启动消费过程。</p><p>\6. ProducerGroup：同一类Producer的集合，这类Producer发送同一类消息且发送逻辑一致。如果发送的是事务消息 且原始生产者在发送之后崩溃，则Broker服务器会联系同一生产者组的其他生产者实例以提交或回溯消 费。</p><p>\7. ConsumerGroup：同一类Consumer的集合，这类Consumer通常消费同一类消息且消费逻辑一致。消费者组使得在 消息消费方面，实现负载均衡和容错的目标变得非常容易。要注意的是，消费者组的消费者实例必须订 阅完全相同的Topic。RocketMQ 支持两种消息模式：集群消费和广播消费。</p><p>\8. Broker：消息中转角色，负责存储消息，转发消息，一般也称为 Server。</p><p>\9. 一条消息被多个 Consumer 消费，即使这些 Consumer 属于同一个 Consumer Group，消息也会被 Consumer Group 中的每个 Consumer 都消费一次，广播消费中的 Consumer Group 概念可以认为在消息划分方面无意义。</p><p>\10. 集群消费：一个 Consumer Group 中的 Consumer 实例平均分摊消费消息。例如某个 Topic 有 9 条消息，其 中一个 Consumer Group 有 3 个实例，那举每个实例只消费其中的 3 条消息。</p><p>\11. 顺序消息：消费消息的顺序要同发送消息的顺序一致，在RocketMQ 中主要指的是局部顺序，即一类消息为满足顺序性，必须Producer单线程顺序发送，且发送到同一个队列，这样Consumer 就可以按照 Producer发送的顺序去消费消息</p><p>\12. 普通顺序消息：顺序消息的一种，正常情况下可以保证完全的顺序消息，但是一旦发生通信异常，Broker 重启， 由于队列总数发生发化，哈希取模后定位的队列会发化，产生短暂的消息顺序不一致。</p><p>\13. 严格顺序消息：顺序消息的一种，无论正常异常情况都能保证顺序，但是牺牲了分布式 Failover特性，即Broker集 群中只要有一台机器不可用，则整个集群都不可用，服务可用性大大降低。</p><p>\14. Message Queue：在 RocketMQ 中，所有消息队列都是持久化的，长度无限的数据结构，所谓长度无限是指队列中 的每个存储单元都是定长，访问其中的存储单元使用Offset来访问，offset 为 java long 类型，64 位， 理论上在 100 年内不会溢出，所以认为为是长度无限，另外队列中只保存最近几天的数据，之前的数据会按照过期时间来删除。</p><p>\15. 标签（Tag）：为消息设置的标志，用于同一主题下区分不同类型的消息。来自同一业务单元的消息，可以根据不 同业务目的在同一主题下设置不同标签。</p><h3 id="RocketMQ环境搭建"><a href="#RocketMQ环境搭建" class="headerlink" title="RocketMQ环境搭建"></a><strong>RocketMQ环境搭建</strong></h3><p>第一步：安装unzip，解压zip</p><p>yum install -y unzip zip</p><p>第二步：下载rocket包并解压</p><p>wget <a href="https://link.zhihu.com/?target=https://archive.apache.org/dist/rocketmq/4.5.1/rocketmq-all4.5.1-bin-release.zip">https://archive.apache.org/dist/rocketmq/4.5.1/rocketmq-all4.5.1-bin-release.zip</a></p><p>unzip unzip rocketmq-all-4.5.1-bin-release.zip</p><p>第三步：环境变量配置，配套jdk8以上</p><p>vim &#x2F;etc&#x2F;profile #修改配置</p><p>export ROCKET_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;rocketmq&#x2F;rocket</p><p>export PATH&#x3D;$PATH:$ROCKET_HOME&#x2F;bin</p><p>source &#x2F;etc&#x2F;profile #生效</p><p>第四步：修改启动、关闭配置文件，更改占用内存 64m 128m</p><p>vim bin&#x2F;runserver.sh</p><p>vim bin&#x2F;runbroker.sh</p><p>vim conf&#x2F;broker.conf</p><p>第五步：启动NameServer</p><p>sh bin&#x2F;mqnamesrv -n 117.50.5.252:9876 &amp;</p><p>第六步：启动Broker</p><p>sh bin&#x2F;mqbroker -n 117.50.5.252:9876 autoCreateTopicEnable&#x3D;true -c &#x2F;usr&#x2F;local&#x2F;rocketmq&#x2F;rocket&#x2F;conf&#x2F;broker.conf &amp;</p><p>第七步：停止命令</p><p>mqshutdown borker</p><p>mqshutdown namesrv</p><p><img src="/posts/16292/assets/2f0b76cc7df065c69fbb4dccdb2138f0.webp" alt="img"></p><h3 id="二、RocketMQ特性"><a href="#二、RocketMQ特性" class="headerlink" title="二、RocketMQ特性"></a><strong>二、RocketMQ特性</strong></h3><h3 id="消息发送机制"><a href="#消息发送机制" class="headerlink" title="消息发送机制"></a><strong>消息发送机制</strong></h3><p>生产者向消息队列里写入消息，不同的业务场景需要生产者采用不同的写入策略。比如同步发送、异步发送、OneWay发送、延迟发送、发送事务消息等。 默认使用的是DefaultMQProducer类，发送消息要经过五个步骤：</p><p>1）设置Producer的GroupName。</p><p>2）设置InstanceName，当一个Jvm需要启动多个Producer的时候，通过设置不同的 InstanceName来区分，不设置的话系统使用默认名称“DEFAULT”。</p><p>3）设置发送失败重试次数，当网络出现异常的时候，这个次数影响消息的重复投递次数。想保证不丢消息，可以设置多重试几次。</p><p>4）设置NameServer地址</p><p>5）组装消息并发送。</p><p>提升写入的性能 发送一条消息出去要经过三步：</p><p>\1. 客户端发送请求到服务器。 2. 服务器处理该请求。 3. 服务器向客户端返回应答</p><p>Oneway方式只发送请求不等待应答，即将数据写入客户端的Socket缓冲区就返回，不等待对方返回结果。</p><p>另一种提高发送速度的方法是增加Producer的并发量，使用多个Producer同时发送，RocketMQ引入了一个并发窗口，在窗口内消息可以并发地写入DirectMem中，然后异步地将连续一段无空洞的数据刷入文件系统当中，写入性能达到90万+的TPS。</p><h3 id="消息消费机制"><a href="#消息消费机制" class="headerlink" title="消息消费机制"></a><strong>消息消费机制</strong></h3><p>消费的几个要点：</p><p>\1. 消息消费方式（Pull和Push）</p><p>\2. 消息消费的模式（广播模式和集群模式）</p><p>\3. 流量控制（可以结合sentinel来实现）</p><p>\4. 并发线程数设置</p><p>\5. 消息的过滤（Tag、Key） TagA||TagB||TagC * null</p><p>三种提高Consumer的处理能力的方法：</p><p>\1. 提高消费并行度，在同一个ConsumerGroup下（Clustering方式），可以通过增加Consumer实例的数量来提 高并行度。 通过加机器，或者在已有机器中启动多个Consumer进程都可以增加Consumer实例数。</p><p>\2. 以批量方式进行消费，某些业务场景下，多条消息同时处理的时间会大大小于逐个处理的时间总和，比如消费消息中，涉及update某个数据库，一次update10条的时间会大大小于十次update1条数据的时间。</p><p>\3. 检测延时情况，跳过非重要消息，Consumer在消费的过程中，如果发现由于某种原因发生严重的消息堆积，短时间无法消除堆 积，这个时候可以选择丢弃不重要的消息，使Consumer尽快追上Producer的进度。</p><h3 id="消息存储机制"><a href="#消息存储机制" class="headerlink" title="消息存储机制"></a><strong>消息存储机制</strong></h3><p><strong>消息存储</strong></p><p>目前的高性能磁盘，顺序写速度可以达到600MB&#x2F;s， 超过了一般网卡的传输速度。 但是磁盘随机写的速度只有大概100KB&#x2F;s，和顺序写的性能相差6000倍！ 因为有如此巨大的速度差别，好的消息队列系统会比普通的消息队列系统速度快多个数量级。 RocketMQ的消息用顺序写,保证了消息存储的速度。</p><p><strong>存储结构</strong></p><p>RocketMQ消息的存储是由ConsumeQueue和CommitLog配合完成 的，消息真正的物理存储文件 是CommitLog，ConsumeQueue是消息的逻辑队列，类似数据库的索引文件，存储的是指向物理存储 的地址。每 个Topic下的每个Message Queue都有一个对应的ConsumeQueue文件。</p><p>1） CommitLog：消息主体以及元数据的存储主体，存储Producer端写入的消息主体内容,消 息内容不是定长的。</p><p>2） ConsumeQueue：消息消费队列，引入的目的主要是提高消息消费的性能。</p><p>3） IndexFile：IndexFile（索引文件）提供了一种可以通过key或时间区间来查询消息的方法。</p><h3 id="消息过滤机制"><a href="#消息过滤机制" class="headerlink" title="消息过滤机制"></a><strong>消息过滤机制</strong></h3><p>RocketMQ分布式消息队列的消息过滤方式有别于其它MQ中间件，是在Consumer端订阅消息时再做消息过滤的。 RocketMQ这么做是在于其Producer端写入消息和Consumer端订阅消息采用分离存储的机制来实现的，Consumer端订阅消息是需要通过ConsumeQueue这个消息消费的逻辑队列拿到一个索引，然后再从CommitLog里面读取真正的消息实体内容。</p><p><strong>Tag过滤方式：</strong></p><p>Consumer端在订阅消息时除了指定Topic还可以指定TAG，如果一个消息有多 个TAG，可以用||分隔。</p><p>\1. Consumer端会将这个订阅请求构建成一个 SubscriptionData，发送一个Pull消息的请求给 Broker端。</p><p>\2. Broker端从RocketMQ的文件存储层—Store读取数据之前，会用这些数据先构建一个 MessageFilter，然后传给Store。</p><p>\3. Store从 ConsumeQueue读取到一条记录后，会用它记录的消息tag hash值去做过滤。</p><p>\4. 在服务端只是根据hashcode进行判断，无法精确对tag原始字符串进行过滤，在消息消费端拉 取到消息后，还需要对消息的原始tag字符串进行比对，如果不同，则丢弃该消息，不进行消 息消费。</p><p><strong>SQL92的过滤方式：</strong></p><p>仅对push的消费者起作用。 Tag方式虽然效率高，但是支持的过滤逻辑比较简单。 SQL表达式可以更加灵活的支持复杂过滤逻辑。</p><p>\1. 数字比较： &gt;, &gt;&#x3D;, &lt;&#x3D;, BETWEEN, &#x3D;</p><p>\2. 字符串比较： &#x3D;, &lt;&gt;, IN; IS NULL或者IS NOT NULL;</p><p>\3. 逻辑比较： AND, OR, NOT;</p><p>\4. Constant types are: 数字如：123, 3.1415; 字符串如：’abc’，必须是单引号引起来 NULL,特 殊常量 布尔型如：TRUE or FALSE;</p><h3 id="零拷贝原理"><a href="#零拷贝原理" class="headerlink" title="零拷贝原理"></a><strong>零拷贝原理</strong></h3><p><strong>cache和buffer的区别</strong></p><p>Cache：缓存区，是高速缓存，是位于CPU和主内存之间的容量较小但速度很快的存储器，因 为CPU的速度远远高于主内存的速度，CPU从内存中读取数据需等待很长的时间，而 Cache 保存着CPU刚用过的数据或循环使用的部分数据，这时从Cache中读取数据会更快，减少了 CPU等待的时间，提高了系统的性能。</p><p>Buffer：缓冲区，用于存储速度不同步的设备或优先级不同的设备之间传输数据；通过buffer 可以减少进程间通信需要等待的时间，当存储速度快的设备与存储速度慢的设备进行通信时， 存储慢的数据先把数据存放到buffer，达到一定程度存储快的设备再读取buffer的数据，在此 期间存储快的设备CPU可以干其他的事情。</p><p><strong>HeapByteBuffer和DirectByteBuffer</strong></p><p>HeapByteBuffer，是在jvm堆上面一个buffer，底层的本质是一个数组，用类封装维护了很多的 索引（limit&#x2F;position&#x2F;capacity等）。</p><p>DirectByteBuffer，底层的数据是维护在操作系统的内存中，而不是jvm里，DirectByteBuffer里维 护了一个引用address指向数据，进而操作数据。</p><p>HeapByteBuffer优点：内容维护在jvm里，把内容写进buffer里速度快；更容易回收。</p><p>DirectByteBuffer优点：跟外设（IO设备）打交道时会快很多，因为外设读取jvm堆里的数据时， 不是直接读取的，而是把jvm里的数据读到一个内存块里，再在这个块里读取的，如果使用 DirectByteBuffer，则可以省去这一步，实现zero copy（零拷贝）</p><p><strong>缓冲IO和直接IO</strong></p><p>缓存I&#x2F;O又被称作标准I&#x2F;O，大多数文件系统的默认I&#x2F;O操作都是缓存I&#x2F;O。</p><p>\1. 在一定程度上分离了内核空间和用户空间，保护系统本身的运行安全；</p><p>\2. 可以减少读盘的次数，从而提高性能。</p><p>缓存I&#x2F;O数据在传输过程中就需要在应用程序地址空间（用户空间）和缓存（内核空间）之间进行多次数据拷贝操作， 这些数据拷贝操作所带来的CPU以及内存开销是非常大的。</p><p>直接IO就是应用程序直接访问磁盘数据，而不经过内核缓冲区，这样做的目的是减少一次从内核缓 冲区到用户程序缓存的数据复制。</p><p>如果访问的数据不在应用程序缓存中，那么每次数据都会直接从磁盘加载，这种直接加载会非常缓慢。通常直接IO与异步IO结合使用，会得到比较好的性能。</p><p><strong>总结</strong></p><p>\1. 虽然叫零拷贝，实际上sendfile有2次数据拷贝的。第1次是从磁盘拷贝到内核缓冲区，第二次是从内核缓冲区拷贝到网卡（协议引擎）。如果网卡支持 SG-DMA技术，就无需从PageCache拷贝至 Socket 缓冲区；</p><p>\2. 之所以叫零拷贝，是从内存角度来看的，数据在内存中没有发生过拷贝，只是在内存和I&#x2F;O设备之间传输。很多时候我们认为sendfile才是零拷贝，mmap严格来说不算；</p><p>\3. Linux中的API为sendfile、mmap，Java中的API为FileChanel.transferTo()、 FileChannel.map()等；</p><p>\4. Netty、Kafka(sendfile)、Rocketmq（mmap）、Nginx等高性能中间件中，都有大量利用操作系统零拷贝特性。</p><h3 id="同步复制和异步复制"><a href="#同步复制和异步复制" class="headerlink" title="同步复制和异步复制"></a><strong>同步复制和异步复制</strong></h3><p>如果一个Broker组有Master和Slave，消息需要从Master复制到Slave 上，有同步和异步两种复制方式。</p><p>同步复制：</p><p>同步复制方式是等Master和Slave均写 成功后才反馈给客户端写成功状态； 在同步复制方式下，如果Master出故障，Slave上有全部的备份数据，容易恢复，但是同步复制会 增大数据写入延迟，降低系统吞吐量。</p><p>异步复制：</p><p>异步复制方式是只要Master写成功 即可反馈给客户端写成功状态。 在异步复制方式下，系统拥有较低的延迟和较高的吞吐量，但是如果Master出了故障，有些数据因 为没有被写 入Slave，有可能会丢失；</p><p>同步复制和异步复制是通过broker.conf 配置文件里的brokerRole参数进行设置的，这个参数可以被设置成ASYNC_MASTER、 SYNC_MASTER、SLAVE三个值中的一个。</p><p>通常情况下，应该把Master和Save配置成ASYNC_FLUSH的 刷盘 方式，主从之间配置成SYNC_MASTER的复制方式，这样即使有一台机器出故障，仍然能保证数据不丢。</p><p><img src="/posts/16292/assets/2cd9ab4fb64bb5756dc83395c055d7f1.webp" alt="img"></p><p><img src="/posts/16292/assets/0c9a83efec51bba6553e5429315cc6c4.webp" alt="img"></p><h3 id="高可用机制"><a href="#高可用机制" class="headerlink" title="高可用机制"></a><strong>高可用机制</strong></h3><p>RocketMQ分布式集群是通过Master和Slave的配合达到高可用性的。</p><p><img src="/posts/16292/assets/6096e76a21b88d51388b1372c12c2482.webp" alt="img"></p><p>消息消费高可用：在Consumer的配置文件中，并不需要设置是从Master读还是从Slave 读，当Master不可用或者繁忙的时候，Consumer会被自动切换到从Slave 读。</p><p>消息发送高可用：在创建Topic的时候，把Topic的多个Message Queue创建在多个Broker组上，这样既可以在性能方面具有扩展性，也可以降低主节点故障 对整体上带来的影响，而且当一个Broker组的Master不可用后，其他组的Master仍然可用，Producer 仍然可以发送消息的。</p><p><img src="/posts/16292/assets/802a95b49a69f93fd415fe491385f298.webp" alt="img"></p><p>在需要保证消息严格顺序的场景下，由于在主题层面无法保证严格顺序，所以必须指定队列来发送消息，对于任何一个队列，它一定是落在一组特定的主从节点上，如果这个主节点宕机，其他的主节点是无法替代这个主节点的，否则就无法保证严格顺序。 在这种复制模式下，严格顺序和高可用只能选择一个。RocketMQ 在 2018 年底迎来了一次重大的更新，引入 Dledger，增加了一种全新的复制方式解决了这个问题。</p><h3 id="刷盘机制"><a href="#刷盘机制" class="headerlink" title="刷盘机制"></a><strong>刷盘机制</strong></h3><p>RocketMQ 的所有消息都是持久化的，先写入系统 PageCache，然后刷盘，可以保证内存与磁盘 都有一份数据， 访问时，直接从内存读取。消息在通过Producer写入RocketMQ的时候，有两种写磁盘方式，分布式同步刷盘和异步刷盘。</p><p>同步刷盘和异步刷盘差异：</p><p>同步刷盘与异步刷盘的唯一区别是异步刷盘写完 PageCache直接返回，而同步刷盘需要等待刷盘完成才返回， 同步刷盘流程如下： (1). 写入 PageCache后，线程等待，通知刷盘线程刷盘。 (2). 刷盘线程刷盘后，唤醒前端等待线程，可能是一批线程。 (3). 前端等待线程向用户返回成功</p><h3 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a><strong>负载均衡</strong></h3><p>RocketMQ中的负载均衡都在Client端完成，具体来说的话，主要可以分为Producer端发送消息时候的负载均衡和Consumer端订阅消息的负载均衡。</p><p>Producer的负载均衡：</p><p><img src="https://pic1.zhimg.com/80/v2-8b4d46acf987359a14d5f0689f28b080_720w.webp" alt="img"></p><p>Consumer的负载均衡：</p><p><img src="/posts/16292/assets/5dfb6a9226a3110499ae6dec034b3423.webp" alt="img"></p><p>在RocketMQ中，负载均衡或者消息分配是在Consumer端代码中完成的，Consumer从Broker处 获得全局信息，然后自己做负载均衡，只处理分给自己的那部分消息。 Pull Consumer可以看到所有的Message Queue，而且从哪个Message Queue读取消息，读消息 时的Offset都由使用者控制，使用者可以实现任何特殊方式的负载均衡。 DefaultMQPullConsumer有两个辅助方法可以帮助实现负载均衡，一个是 registerMessageQueueListener函数，一个是MQPullConsumerScheduleService。</p><p>DefaultMQPushConsumer的负载均衡过程不需要使用者操心，客户端程序会自动处理，每个 DefaultMQPushConsumer启动后，会马上会触发一个doRebalance动作；而且在同一个 ConsumerGroup里加入新的DefaultMQPush-Consumer时，各个Consumer都会被触发 doRebalance动作。</p><p>消息消费队列在同一消费组不同消费者之间的负载均衡，其核心设计理念是在一个消息消费队列在 同一时间只允许被同一消费组内的一个消费者消费，一个消息消费者能同时消费多个消息队列。</p><h3 id="消息重试"><a href="#消息重试" class="headerlink" title="消息重试"></a><strong>消息重试</strong></h3><p><strong>顺序消息的重试</strong></p><p>对于顺序消息，当消费者消费消息失败后，消息队列 RocketMQ 会自动不断进行消息重试（每次间隔时间为 1 秒），这时，应用会出现消息消费被阻塞的情况。因此，在使用顺序消息时，务必保证应 用能够及时监控并处理消费失败的情况，避免阻塞现象的发生。</p><p><strong>无序消息的重试</strong></p><p>对于无序消息（普通、定时、延时、事务消息），当消费者消费消息失败时，您可以通过设置返回 状态达到消息重试的结果。无序消息的重试只针对集群消费方式生效；广播方式不提供失败重试特性，即消费失败后，失败消 息不再重试，继续消费新的消息。</p><p>消息队列 RocketMQ 默认允许每条消息最多重试 16 次，每次重试的间隔时间如下：</p><p><img src="https://pic1.zhimg.com/80/v2-f6d62f8e582cd6fcc109233881ca7508_720w.webp" alt="img"></p><p>如果消息重试 16 次后仍然失败，消息将不再投递。</p><p>注意：</p><p>1） 消息最大重试次数的设置对相同 Group ID 下的所有 Consumer 实例有效。</p><p>2） 如果只对相同 Group ID 下两个 Consumer 实例中的其中一个设置了 MaxReconsumeTimes，那么该配置对两个 Consumer 实例均生效。</p><p>3） 配置采用覆盖的方式生效，即最后启动的 Consumer 实例会覆盖之前的启动实例的配置</p><h3 id="死信队列-1"><a href="#死信队列-1" class="headerlink" title="死信队列"></a><strong>死信队列</strong></h3><p>RocketMQ中消息重试超过一定次数后（默认16次）就会被放到死信队列中，在消息队列 RocketMQ 中，这种正常情况下无法被消费的消息称为死信消息（Dead-Letter Message），存储死信 消息的特殊队列称为死信队列（Dead-Letter Queue）。</p><p>可视化工具：rocketmq-console下载地址：</p><p><a href="https://link.zhihu.com/?target=https://github.com/apache/rocketmq-externals/archive/rocketmq-console-1.0.0.zip">https://github.com/apache/rocketmq-externals/archive/rocketmq-console-1.0.0.zip</a></p><p>死信消息特性：</p><p>1） 不会再被消费者正常消费。</p><p>2） 有效期与正常消息相同，均为 3 天，3 天后会被自动删除。因此，请在死信消息产生后的 3 天内及时处理。</p><p>死信队列特征：</p><p>1） 一个死信队列对应一个 Group ID， 而不是对应单个消费者实例。</p><p>2） 如果一个 Group ID 未产生死信消息，消息队列 RocketMQ 不会为其创建相应的死信队列。</p><p>3） 一个死信队列包含了对应 Group ID 产生的所有死信消息，不论该消息属于哪个 Topic。</p><p>一条消息进入死信队列，意味着某些因素导致消费者无法正常消费该消息，因此，通常需要您对其进行特殊处理。排查可疑因素并解决问题后，可以在消息队列 RocketMQ 控制台重新发送该消息，让消费者重新消费一次。</p><h3 id="延迟消息"><a href="#延迟消息" class="headerlink" title="延迟消息"></a><strong>延迟消息</strong></h3><p>定时消息（延迟队列）是指消息发送到broker后，不会立即被消费，等待特定时间投递给真正的 topic。 broker有配置项messageDelayLevel，默认值为“1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h”，18个level。可以配置自定义messageDelayLevel。</p><p>level有以下三种情况：</p><p>level &#x3D;&#x3D; 0，消息为非延迟消息</p><p>1&lt;&#x3D;level&lt;&#x3D;maxLevel，消息延迟特定时间，例如level&#x3D;&#x3D;1，延迟1s</p><p>level &gt; maxLevel，则level&#x3D;&#x3D; maxLevel，例如level&#x3D;&#x3D;20，延迟2h</p><p>发消息时，设置delayLevel等级即可： msg.setDelayLevel(level)。</p><h3 id="顺序消息"><a href="#顺序消息" class="headerlink" title="顺序消息"></a><strong>顺序消息</strong></h3><p>顺序消息是指消息的消费顺序和产生顺序相同，在有些业务逻辑下，必须保证顺序。比如订单的生 成、付款、发货，这3个消息必须按顺序处理才行。</p><p>顺序消息分为全局顺序消息和部分顺序消息：</p><p>\1. 全局顺序消息指某个Topic下的所有消息都要保证顺序；</p><p>\2. 部分顺序消息只要保证每一组消息被顺序消费即可，比如上面订单消息的例子，只要保证同一个订单ID的三个消息能按顺序消费即可。</p><p>要保证部分消息有序，需要发送端和消费端配合处理。在发送端，要做到把同一业务ID的消息发送 到同一个Message Queue；在消费过程中，要做到从同一个Message Queue读取的消息不被并发处理，这样才能达到部分有序。消费端通过使用MessageListenerOrderly类来解决单Message Queue的消息被并发处理的问题。</p><p>要保证全局顺序消息，需要先把Topic的读写队列数设置为一，然后Producer和Consumer的并发设置也要是一。简单来说，为了保证整个Topic的全局消息有序，只能消除所有的并发处理，各部分都设置成单线程处理。</p><h3 id="事务消息"><a href="#事务消息" class="headerlink" title="事务消息"></a><strong>事务消息</strong></h3><p>RocketMQ的事务消息，是指发送消息事件和其他事件需要同时成功或同时失败。比如银行转账， A银行的某账户要转一万元到B银行的某账户。A银行发送“B银行账户增加一万元”这个消息，要和“从A银 行账户扣除一万元”这个操作同时成功或者同时失败。RocketMQ采用两阶段提交的方式实现事务消息。</p><p>具体流程如下：</p><p>1）发送方向RocketMQ发送“待确认”消息。</p><p>2）RocketMQ将收到的“待确认”消息持久化成功后，向发送方回复消息已经发送成功，此时第一阶段消息发送完成。</p><p>3）发送方开始执行本地事件逻辑。</p><p>4）发送方根据本地事件执行结果向RocketMQ发送二次确认（Commit或是Rollback）消息， RocketMQ收到Commit状态则将第一阶段消息标记为可投递，订阅方将能够收到该消息；收到 Rollback状态则删除第一阶段的消息，订阅方接收不到该消息。</p><p>5）如果出现异常情况，步骤4）提交的二次确认最终未到达RocketMQ，服务器在经过固定时间段 后将对“待确认”消息发起回查请求。</p><p>6）发送方收到消息回查请求后（如果发送一阶段消息的Producer不能工作，回查请求将被发送到 和Producer在同一个Group里的其他Producer），通过检查对应消息的本地事件执行结果返回Commit 或Roolback状态。</p><p>7）RocketMQ收到回查请求后，按照步骤4）的逻辑处理。</p><p><strong>RocketMQ事务消息流程概要</strong></p><p>事务消息发送及提交：(1) 发送消息（half消息）。 (2) 服务端响应消息写入结果。 (3) 根据发送结果执行本地事务（如果写入失败，此时half消息对业务不可见，本地逻辑不执行）。 (4) 根据本地事务状态执行Commit或者Rollback（Commit操作生成消息索引，消息对消费者可 见）</p><p>事务消息的补偿流程：(1) 对没有Commit&#x2F;Rollback的事务消息（pending状态的消息），从服务端发起一次“回查” (2) Producer收到回查消息，检查回查消息对应的本地事务的状态 (3) 根据本地事务状态，重新Commit或者Rollback</p><p>补偿阶段用于解决消息Commit或者Rollback发生超时或者失败的情况。</p><p><strong>RocketMQ事务消息设计</strong></p><p>\1. 事务消息在一阶段对用户不可见</p><p>\2. Commit和Rollback操作以及Op消息的引入</p><p>\3. Op消息的存储和对应关系，Op消息的内容为对应的Half消息的存储的Offset，这样通过Op消息能索引到 Half消息进行后续的回查操作。</p><p>\4. Half消息的索引构建，在执行二阶段Commit操作时，需要构建出Half消息的索引。</p><p>\5. 处理二阶段失败的消息，如果在RocketMQ事务消息的二阶段过程中失败了，例如在做Commit操作时，出现网络问题导致 Commit失败，那么需要通过一定的策略使这条消息最终被Commit。RocketMQ采用了一种补偿机制， 称为“回查”。</p><p><img src="/posts/16292/assets/a0078a528de0b624f5a54179bdf44d82.webp" alt="img"></p><h3 id="消息查询及优先级"><a href="#消息查询及优先级" class="headerlink" title="消息查询及优先级"></a><strong>消息查询及优先级</strong></h3><p><strong>消息查询</strong></p><p>RocketMQ支持按照下面两种维度（“按照Message Id查询消息”、“按照Message Key查询消息”）进行消息查询。</p><p>按照MessageId查询消息：MsgId 总共 16 字节，包含消息存储主机地址（ip&#x2F;port），消息 Commit Log offset。</p><p>按照Message Key查询消息：主要是基于RocketMQ的IndexFile索引文件来实现的。</p><p><img src="https://pic4.zhimg.com/80/v2-888d9d04eedcacc78d8e4286571789fb_720w.webp" alt="img"></p><p><strong>消息优先级</strong></p><p>有些场景，需要应用程序处理几种类型的消息，不同消息的优先级不同。RocketMQ是个先入先出的队列，不支持消息级别或者Topic级别的优先级。</p><p>1） 多个不同的消息类型使用同一个topic时，由于某一个种消息流量非常大，导致其他类型的消息无法及时消费，造成不公平，所以把流量大的类型消息在一个单独的 Topic，其他类型消息在另外一个 Topic，应用程序创建两个 Consumer，分别订阅不同的 Topic。创建一个 Topic， 设置Topic的 MessageQueue 数量超过 100 个，Producer根据订 单的门店号，把每个门店的订单写人 一 个 MessageQueue。 DefaultMQPushConsumer默认是采用 循环的方式逐个读取一个 Topic 的所有 MessageQueue，这样如果某家门店订单量大增，这家门店对 应的 MessageQueue 消息数增多，等待时间增长，但不会造成其他家门店等待时间增长。</p><p>2） 情况和第一种情况类似，但是不用创建大量的Topic。</p><p>3） 强制优先级 TypeA、 TypeB、 TypeC 三类消息 。TypeA 处于第一优先级，要确保只要有TypeA消息，必须优先处理; TypeB处于第二优先 级; TypeC 处于第三优先级 。</p><h3 id="底层网络通信-–-Netty"><a href="#底层网络通信-–-Netty" class="headerlink" title="底层网络通信 – Netty"></a><strong>底层网络通信</strong> <strong>– Netty</strong></h3><p>RocketMQ底层通信的实现是在Remoting模块里，因为借助了Netty而没有重复造轮子， RocketMQ的通信部分没有很多的代码，就是用Netty实现了一个自定义协议的客户端&#x2F;服务器程序。</p><p>\1. 自定义ByteBuf可以从底层解决ByteBuffer的一些问题，并且通过“内存池”的设计来提升性能</p><p>\2. Reactor主从多线程模型</p><p>\3. 充分利用了零拷贝，CAS&#x2F;volatite高效并发编程特性</p><p>\4. 无锁串行化设计</p><p>\5. 管道责任链的编程模型</p><p>\6. 高性能序列化框架的支持</p><p>\7. 灵活配置TCP协议参数</p><p><img src="/posts/16292/assets/ceec4897b8c94ea50ac99e34724b4f3a.webp" alt="img"></p><p>RocketMQ消息队列中支持通信的方式主要有同步(sync)、异步(async)、单向(oneway) 三种。</p><p>RocketMQ的RPC通信采用Netty组件作为底层通信库，同样也遵循了Reactor多线程模型，同时又在这之上做了一些扩展和优化。</p><p><img src="https://pic4.zhimg.com/80/v2-9b9d39012f16ba92f739797784c2c32f_720w.webp" alt="img"></p><h3 id="限流机制"><a href="#限流机制" class="headerlink" title="限流机制"></a><strong>限流机制</strong></h3><p>RocketMQ消费端中我们可以：</p><p>\1. 设置最大消费线程数 2. 每次拉取消息条数等</p><p>同时：</p><p>\1. PushConsumer会判断获取但还未处理的消息个数、消息总大小、Offset的跨度， 2. 任何一个值超过设定的大小就隔一段时间再拉取消息，从而达到流量控制的目的。</p><p>Sentinel 专门为这种场景提供了匀速器的特性，可以把突然到来的大量请求以匀速的形式均摊，以 固定的间隔时间让请求通过，以稳定的速度逐步处理这些请求，起到“削峰填谷”的效果，从而避免流量突刺造成系统负载过高。同时堆积的请求将会排队，逐步进行处理；当请求排队预计超过最大超时时长 的时候则直接拒绝，而不是拒绝全部请求。比如在 RocketMQ 的场景下配置了匀速模式下请求 QPS 为 5，则会每 200 ms 处理一条消息，多 余的处理任务将排队；同时设置了超时时间为 5 s，预计排队时长超过 5s 的处理任务将会直接被拒绝。</p><h3 id="三、RocketMQ高级实战"><a href="#三、RocketMQ高级实战" class="headerlink" title="三、RocketMQ高级实战"></a><strong>三、RocketMQ高级实战</strong></h3><h3 id="生产者"><a href="#生产者" class="headerlink" title="生产者"></a><strong>生产者</strong></h3><p>Tags的使用：一个应用尽可能用一个Topic，而消息子类型则可以用tags来标识。tags可以由应用自由设置，只 有生产者在发送消息设置了tags，消费方在订阅消息时才可以利用tags通过broker做消息过滤： message.setTags(“TagA”)。</p><p>Keys的使用：每个消息在业务层面的唯一标识码要设置到keys字段，方便将来定位消息丢失问题。服务器会为每 个消息创建索引（哈希索引），应用可以通过topic、key来查询这条消息内容，以及消息被谁消费。由 于是哈希索引，请务必保证key尽可能唯一，这样可以避免潜在的哈希冲突。</p><p>日志的打印：</p><p>1） SEND_OK：消息发送成功。</p><p>2） FLUSH_DISK_TIMEOUT：消息发送成功但是服务器刷盘超时。</p><p>3） FLUSH_SLAVE_TIMEOUT：消息发送成功，但是服务器同步到Slave时超时。</p><p>4） SLAVE_NOT_AVAILABLE：消息发送成功，但是此时Slave不可用。</p><p>消息发送失败处理方式：Producer的send方法本身支持内部重试，至多重试2次，如果发送失败，则轮转到下一个Broker，如果本身向broker发送消息产生超时异常，就不会再重试。</p><p>选择oneway形式发送：oneway形式只发送请求 不等待应答，而发送请求在客户端实现层面仅仅是一个操作系统系统调用的开销，即将数据写入客户端 的socket缓冲区，此过程耗时通常在微秒级。</p><h3 id="消费者"><a href="#消费者" class="headerlink" title="消费者"></a><strong>消费者</strong></h3><p>消费过程幂等：RocketMQ无法避免消息重复，所以如果业务对消费重复非常敏感，务必要在业务层面进行去重处理，可以借助关系数据库进行去重。</p><p>消费速度慢的处理方：1. 提高消费并行度，2. 批量方式消费，3. 跳过非重要消息。</p><p>优化每条消息消费过程：把循环多次处理变为批量单次处理，减少IO次数。</p><p>消费打印日志：在消费入口方法打印消息，消费耗时等，方便后续排查问题。</p><p>其他消费建议：1. 确保同一组内的每个消费者订阅信息保持一致。2.使用有序消息，消费者将锁定每个消息队列，以确保他们被逐个消费。3. 并发消费不建议抛出异常，直接返回状态码。4. 不建议阻塞监听器，因为它会阻塞线程池，并最终可能会终止消费进程。</p><h3 id="Broker"><a href="#Broker" class="headerlink" title="Broker"></a><strong>Broker</strong></h3><p>Broker 角色分为 ASYNC_MASTER（异步主机）、SYNC_MASTER（同步主机）以及SLAVE（从 机）。SYNC_FLUSH（同步刷新）相比于ASYNC_FLUSH（异步处理）会损失很多性能，但是也更可靠， 所以需要根据实际的业务场景做好权衡。</p><p><img src="/posts/16292/assets/7e87ed125a2d2ef40d0d19d1643f9130.webp" alt="img"></p><h3 id="NameServer"><a href="#NameServer" class="headerlink" title="NameServer"></a><strong>NameServer</strong></h3><p>NameServer的设计：</p><p>\1. NameServer互相独立，彼此没有通信关系，单台NameServer挂掉，不影响其他 NameServer。</p><p>\2. NameServer不去连接别的机器，不主动推消息。</p><p>\3. 单个Broker（Master、Slave）与所有NameServer进行定时注册，以便告知NameServer自 己还活着。</p><p>\4. Consumer随机与一个NameServer建立长连接，如果该NameServer断开，则从 NameServer列表中查找下一个进行连接。</p><p>\5. Producer随机与一个NameServer建立长连接，每隔30秒（此处时间可配置）从 NameServer获取Topic的最新队列情况，如果某个Broker Master宕机，Producer最多30秒 才能感知，在这个期间，发往该broker master的消息失败。Producer向提供Topic服务的 Master建立长连接，且定时向Master发送心跳。</p><p>RocketMQ为什么不使用ZooKeeper而自己开发NameServer？</p><p>zookeeper在粗粒度分布式锁，分布式选主，主备高可用切换等不需要高TPS支持的场景下有不可替代的作用，而这些需求往往多集中在大数据、离线任务等相关的业务领域，因为大数据领域，讲究分割数据集，并且大部分时间分任务多进程&#x2F;线程并行处理这些数据集，但是总是有一些点上需要将这些任务和进程统一协调，这时候就是ZooKeeper发挥巨大作用的用武之地。 但是在交易场景交易链路上，在主业务数据存取，大规模服务发现、大规模健康监测等方面有天然 的短板，应该竭力避免在这些场景下引入ZooKeeper，在阿里巴巴的生产实践中，应用对ZooKeeper申 请使用的时候要进行严格的场景、容量、SLA需求的评估。</p><h3 id="系统配置"><a href="#系统配置" class="headerlink" title="系统配置"></a><strong>系统配置</strong></h3><p>设置Xms和Xmx一样大，防止JVM重新调整堆空间大小影响性能。</p><p>-server -Xms8g -Xmx8g -Xmn4g</p><p>设置DirectByteBuffer内存大小。当DirectByteBuffer占用达到这个值，就会触发Full GC。</p><p>-XX:MaxDirectMemorySize&#x3D;15g</p><p>如果不太关心RocketMQ的启动时间，可以设置pre-touch，这样在JVM启动的时候就会分配完整的页空间。</p><p>-XX:+AlwaysPreTouch</p><p>禁用偏向锁可能减少JVM的停顿，在并发小的时候使用偏向锁有利于提升JVM效率，在高并发场合禁用掉。</p><p>-XX:-UseBiasedLocking</p><p>推荐使用JDK1.8的G1垃圾回收器。</p><h3 id="RocketMQ集群"><a href="#RocketMQ集群" class="headerlink" title="RocketMQ集群"></a><strong>RocketMQ集群</strong></h3><p>Producer与NameServer集群中的其中一个节点（随机选择）建立长连接，定期从 NameServer取Topic路由信息，并向提供Topic服务的Master建立长连接，且定时向Master 发送心跳。Consumer与NameServer集群中的其中一个节点（随机选择）建立长连接，定期从 NameServer取Topic路由信息，并向提供Topic服务的Master、Slave建立长连接，且定时向 Master、Slave发送心跳。</p><p><strong>单Master模式</strong></p><p>这种方式风险较大，一旦Broker重启或者宕机时，会导致整个服务不可用。</p><p><strong>多Master模式</strong></p><p>一个集群无Slave，全是Master，例如2个Master或者3个Master，单台机器宕机期间，这台机器上未被消费的消息在机器恢复之前不可订阅，消息实时性 会受到影响。</p><p><strong>多Master多Slave模式（异步）</strong></p><p>每个Master配置一个Slave，有多对Master-Slave，HA采用异步复制方式，主备有短暂消息延迟 （毫秒级），即使磁盘损坏，消息丢失的非常少，且消息实时性不会受影响，但是会丢失少量消息。</p><p><strong>多Master多Slave模式（异步）</strong></p><p>每个Master配置一个Slave，有多对Master-Slave，HA采用同步双写方式，即只有主备都写成功， 才向应用返回成功，消息无延迟，服务可用性与数据可用 性都非常高；但是性能比异步复制模式略低（大约低10%左右），发送单个消息的RT会略高，且目前版 本在主节点宕机后，备机不能自动切换为主机。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;一、消息中间件基础知识&quot;&gt;&lt;a href=&quot;#一、消息中间件基础知识&quot; class=&quot;headerlink&quot; title=&quot;一、消息中间件基础知识&quot;&gt;&lt;/a&gt;&lt;strong&gt;一、消息中间件基础知识&lt;/strong&gt;&lt;/h3&gt;&lt;h3 id=&quot;两种常见分布式架构&quot;&gt;&lt;</summary>
      
    
    
    
    <category term="基础知识" scheme="https://itingyu.github.io/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    <category term="rabbitmq" scheme="https://itingyu.github.io/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/rabbitmq/"/>
    
    
    <category term="基础知识" scheme="https://itingyu.github.io/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    <category term="rabbitmq" scheme="https://itingyu.github.io/tags/rabbitmq/"/>
    
  </entry>
  
  <entry>
    <title>redis数据库知识</title>
    <link href="https://itingyu.github.io/posts/40341/"/>
    <id>https://itingyu.github.io/posts/40341/</id>
    <published>2023-06-17T11:44:43.000Z</published>
    <updated>2023-06-20T08:57:56.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="一、-Redis基础知识"><a href="#一、-Redis基础知识" class="headerlink" title="一、 Redis基础知识"></a><strong>一、</strong> <strong>Redis基础知识</strong></h3><h3 id="Redis应用场景"><a href="#Redis应用场景" class="headerlink" title="Redis应用场景"></a><strong>Redis应用场景</strong></h3><p>\1. 缓存使用，减轻DB压力</p><p>\2. DB使用，用于临时存储数据（字典表，购买记录）</p><p>\3. 解决分布式场景下Session分离问题（登录信息）</p><p>\4. 任务队列（秒杀、抢红包等等）</p><p>\5. 乐观锁</p><p>\6. 应用排行榜 zset</p><p>\7. 签到 bitmap</p><p>\8. 分布式锁</p><p>\9. 冷热数据交换</p><h3 id="缓存的使用场景"><a href="#缓存的使用场景" class="headerlink" title="缓存的使用场景"></a><strong>缓存的使用场景</strong></h3><p>缓存原指CPU上的一种高速存储器，它先于内存与CPU交换数据，速度很快，现在泛指存储在计算机上的原始数据的复制集，便于快速访问，以空间换时间的一种技术。</p><p>\1. DB缓存，减轻DB服务器压力，将已经访问过的内容或数据存储起来，当再次访问时先找缓存，缓存命中返回数据，不命中再找数据库，并回填缓存。</p><p>\2. 提高系统响应能力，在大量瞬间访问时（高并发）MySQL单机会因为频繁IO而造成无法响应，MySQL的InnoDB是有行锁，将数据缓存在Redis中，也就是存在了内存中。</p><p>\3. 做Session分离，将登录成功后的Session信息，存放在Redis中，这样多个服务器(Tomcat)可以共享Session信息。</p><p>\4. 做分布式锁（Redis），多个进程（JVM）在并发时也会产生问题，也要控制时序性，可以采用分布式锁。使用Redis实现setNX。</p><p>\5. 做乐观锁(Redis），同步锁和数据库中的行锁、表锁都是悲观锁，悲观锁的性能是比较低的，响应性比较差，高性能、高响应（秒杀）采用乐观锁 Redis可以实现乐观锁 watch + incr。</p><h3 id="常见缓存的分类"><a href="#常见缓存的分类" class="headerlink" title="常见缓存的分类"></a><strong>常见缓存的分类</strong></h3><p>\1. 客户端缓存（页面缓存和浏览器缓存、APP缓存）</p><p>\2. 网络端缓存（Web代理缓存Nginx、边缘缓存CDN）</p><p>\3. 服务端缓存（数据库级缓存Mysql、平台级缓存EhCache、应用级缓存Redis）</p><h3 id="缓存的优缺点"><a href="#缓存的优缺点" class="headerlink" title="缓存的优缺点"></a><strong>缓存的优缺点</strong></h3><p>优点：</p><p>\1. 缓存的使用可以提升系统的响应能力，大大提升了用户体验。</p><p>\2. 减轻服务器压力</p><p>\3. 提升系统性能，缩短系统的响应时间，减少网络传输时间和应用延迟时间，提高系统的吞吐量，增加系统的并发用户数，提高了数据库资源的利用率</p><p>缺点：</p><p>\1. 额外的硬件支出，空间换时间</p><p>\2. 在高并发场景下会出现缓存失效（缓存穿透、缓存雪崩、缓存击穿）</p><p>\3. 缓存与数据库数据同步，Redis无法做到主从时时数据同步</p><p>\4. 缓存并发竞争，多个redis的客户端同时对一个key进行set值得时候由于执行顺序引起的并发问题</p><h3 id="缓存的读写模式"><a href="#缓存的读写模式" class="headerlink" title="缓存的读写模式"></a><strong>缓存的读写模式</strong></h3><p>\1. Cache Aside Pattern（读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应，更新的时候，先更新数据库，然后再删除缓存）</p><p><img src="/posts/40341/assets/a2da426ddcbb8ddda78af075f0ad2436.webp" alt="img"></p><p><img src="/posts/40341/assets/5dd7db4e77c0f59cac24e976aa2e2b40.webp" alt="img"></p><p>直接删除缓存而不是更新缓存，因为缓存是一个hash、list结构，更新需要遍历，代价大，懒加载的时候才需要更新缓存，也就是使用的时候。也可以采用异步的方式填充缓存，开启一个线程，定时将DB的数据刷到缓存中。</p><p>\2. Read&#x2F;Write Through Pattern（应用程序只操作缓存，缓存操作数据库）</p><p>Read-Through（穿透读模式&#x2F;直读模式）：应用程序读缓存，缓存没有，由缓存回源到数据库，并写入 缓存。 Write-Through（穿透写模式&#x2F;直写模式）：应用程序写缓存，缓存写数据库。</p><p>\3. Write Behind Caching Pattern（应用程序只更新缓存）</p><p>缓存通过异步的方式将数据批量或合并后更新到DB中 不能时时同步，甚至会丢数据。</p><h3 id="缓存高并发脏读的三种情况"><a href="#缓存高并发脏读的三种情况" class="headerlink" title="缓存高并发脏读的三种情况"></a><strong>缓存高并发脏读的三种情况</strong></h3><p>\1. 先更新数据库，再更新缓存，导致update与commit之间，更新缓存，commit失败 则DB与缓存数据不一致。</p><p>\2. 先删除缓存，再更新数据库，导致update与commit之间，有新的读，缓存空，读DB数据到缓存数据是旧的数据。</p><p>\3. 先更新数据库，再删除缓存(<strong>推荐</strong>)，update与commit之间，有新的读，缓存空，读DB数据到缓存 数据是旧的数据 commit后 DB为新数据 则DB与缓存数据不一致 采用延时双删策略，也就是先更新数据库，再删除缓存，再设定一个定时时间，大概是300ms以内，再删除一次缓存，就算第一次读到了脏数据，第二次再读就能保证缓存与数据库一致。</p><h3 id="缓存的架构设计"><a href="#缓存的架构设计" class="headerlink" title="缓存的架构设计"></a><strong>缓存的架构设计</strong></h3><p>\1. 多层次，分布式缓存宕机，本地缓存还可以使用</p><p>\2. 数据类型，简单类型用Memcached，复杂类型用Redis</p><p>\3. 做集群</p><p>\4. 缓存的数据结构设计，缓存的字段会比数据库表少一些，缓存的数据是经常访问的</p><p><img src="/posts/40341/assets/4d1151cf3667989974bec07079dc1997.webp" alt="img"></p><h3 id="Redis安装"><a href="#Redis安装" class="headerlink" title="Redis安装"></a><strong>Redis安装</strong></h3><p>第一步：安装 C 语言需要的 GCC 环境</p><p>yum install -y gcc-c++</p><p><img src="/posts/40341/assets/a854706ef89b6016d7d21c2aad04c660.webp" alt="img"></p><p>yum install -y wget</p><p><img src="/posts/40341/assets/38fd573137fee50daf73fbae026ae3a5.webp" alt="img"></p><p>第二步：下载并解压缩 Redis 源码压缩包</p><p>wget <a href="https://link.zhihu.com/?target=http://download.redis.io/releases/redis-5.0.5.tar.gz">http://download.redis.io/releases/redis-5.0.5.tar.gz</a></p><p><img src="https://pic4.zhimg.com/80/v2-54d62739390d30ea03e1fa8d2eaa8ecb_720w.webp" alt="img"></p><p>tar -zxf redis-5.0.5.tar.gz</p><p><img src="/posts/40341/assets/62d443321ad3973daf4aac1cc97cd3d4.webp" alt="img"></p><p>第三步：编译 Redis 源码，进入 redis-5.0.5 目录，执行编译命令</p><p>cd redis-5.0.5&#x2F;src</p><p>make</p><p><img src="https://pic4.zhimg.com/80/v2-3cd6fbc096f2c72906646794a68fbf2f_720w.webp" alt="img"></p><p>第四步：安装 Redis ，需要通过 PREFIX 指定安装路径</p><p>mkdir &#x2F;usr&#x2F;redis -p</p><p>make install PREFIX&#x3D;&#x2F;usr&#x2F;redis</p><p><img src="/posts/40341/assets/2a113d55789df541514bd4f31c9bf336.webp" alt="img"></p><h3 id="Redis启动命令"><a href="#Redis启动命令" class="headerlink" title="Redis启动命令"></a><strong>Redis启动命令</strong></h3><p><strong>前端启动</strong></p><p>启动命令： .&#x2F;redis-server</p><p>关闭命令： ctrl+c</p><p>客户端窗口关闭则 redis-server 程序结束</p><p><strong>后台启动(守护进程启动)</strong></p><p>第一步：拷贝 redis-5.0.5&#x2F;redis.conf 配置文件到 Redis 安装目录的 bin 目录</p><p>cd redis-5.0.5&#x2F;</p><p><img src="/posts/40341/assets/72e00c51ac14ef8c6269a95ac03574bb.webp" alt="img"></p><p>cp redis.conf &#x2F;usr&#x2F;redis&#x2F;bin&#x2F;</p><p>第二步：修改 redis.conf</p><p>vim redis.conf</p><p># 将<code>daemonize</code>由<code>no</code>改为<code>yes</code></p><p>daemonize yes</p><p># 默认绑定的是回环地址，默认不能被其他机器访问</p><p># bind 127.0.0.1</p><p># 是否开启保护模式，由yes该为no</p><p>protected-mode no</p><p>第三步：启动服务</p><p>.&#x2F;redis-server redis.conf</p><p>第四步：后端启动的关闭方式</p><p>.&#x2F;redis-cli shutdown</p><p><img src="/posts/40341/assets/847cb35fa42ace9e6760f330e4450f2a.webp" alt="img"></p><p>第五步：关闭RedisServer端的防火墙</p><p>systemctl stop firewalld（默认）</p><p>systemctl disable firewalld.service（设置开启不启动）</p><p>systemctl status firewalld.service（查看防火墙是否关闭）</p><p><img src="/posts/40341/assets/30d0028f73a71dbe94b664b84f985ea3.webp" alt="img"></p><p>Redis云服务器端口开放访问不到解决办法</p><p>1.开启防火墙：systemctl start firewalld.service<br>2.添加端口：firewall-cmd –zone&#x3D;public –add-port&#x3D;6379&#x2F;tcp –permanent<br>3.重启防火墙：firewall-cmd –reload</p><h3 id="Redis数据类型"><a href="#Redis数据类型" class="headerlink" title="Redis数据类型"></a><strong>Redis数据类型</strong></h3><p>Redis是一个Key-Value的存储系统，使用ANSI C语言编写。</p><p>key的类型是字符串。</p><p>value的数据类型有： 常用的：string字符串类型、list列表类型、set集合类型、sortedset（zset）有序集合类型、hash类 型。 不常见的：bitmap位图类型、geo地理位置类型，Redis5.0新增：stream类型。</p><p>Redis中命令是忽略大小写，key是不忽略大小写的</p><p>Redis中Key的设计：1. 用:分割 2. 把表名转换为key前缀, 比如: user: 3. 第二段放置主键值 4. 第三段放置列名</p><p>比如：username 的 key：user:9:username对应{userid:9,username:zhangf}</p><p><strong>string字符串类型</strong></p><p>Redis的String能表达3种值的类型：字符串、整数、浮点数 100.01 是个六位的串</p><p><img src="/posts/40341/assets/f5a68d2da1fe9bff3706279eadf5ffdd.webp" alt="img"></p><p>1、key和命令是字符串</p><p>2、普通的赋值</p><p>3、incr用于乐观锁 incr：递增数字，可用于实现乐观锁 watch(事务)</p><p>4、setnx用于分布式锁</p><p><strong>list列表类型</strong></p><p>list列表类型可以存储有序、可重复的元素</p><p><img src="/posts/40341/assets/1a95706fd60114d28b2c35250e19b723.webp" alt="img"></p><p><img src="/posts/40341/assets/bc6736aeafd7adc21c2b3c071ec09a1e.webp" alt="img"></p><p>1、作为栈或队列使用 列表有序可以作为栈和队列使用</p><p>2、可用于各种列表，比如用户列表、商品列表、评论列表等。</p><p><strong>set集合类型</strong></p><p>Set：无序、唯一元素，适用于不能重复的且不需要顺序的数据结构</p><p><img src="https://pic1.zhimg.com/80/v2-2223eaaa645aff786ff46ff377dbdcf8_720w.webp" alt="img"></p><p><strong>sortedset有序集合类型</strong></p><p>SortedSet(ZSet) 有序集合： 元素本身是无序不重复的 每个元素关联一个分数(score) 可按分数排序，分数可重复</p><p><img src="https://pic1.zhimg.com/80/v2-b345d0b59464120e7f75d1632dabec74_720w.webp" alt="img"></p><p><img src="https://pic2.zhimg.com/80/v2-52fcf10e48a69f6dcbf405d9d94a0ca1_720w.webp" alt="img"></p><p><strong>hash类型（散列表）</strong></p><p>Redis hash 是一个 string 类型的 field 和 value 的映射表，它提供了字段和字段值的映射。</p><p><img src="/posts/40341/assets/f7c1ca80c5e4f30cd74c7ec0613bb401.webp" alt="img"></p><p><strong>bitmap位图类型</strong></p><p>bitmap是进行位操作的 通过一个bit位来表示某个元素对应的值或者状态,其中的key就是对应元素本身。</p><p><img src="https://pic3.zhimg.com/80/v2-6ca1f7571d53d41f1eb67c7bead0038e_720w.webp" alt="img"></p><p>1、用户每月签到，用户id为key ， 日期作为偏移量 1表示签到</p><p>2、统计活跃用户, 日期为key，用户id为偏移量 1表示活跃</p><p>3、查询用户在线状态， 日期为key，用户id为偏移量 1表示在线</p><p><strong>geo地理位置类型</strong></p><p>geo是Redis用来处理位置信息的。在Redis3.2中正式使用。主要是利用了Z阶曲线、Base32编码和 geohash算法。</p><p>1、记录地理位置</p><p>2、计算距离</p><p>3、查找”附近的人”</p><p><img src="https://pic1.zhimg.com/80/v2-57fcaa24948169e55cf471ceef792f48_720w.webp" alt="img"></p><p><strong>stream数据流类型</strong></p><p>stream是Redis5.0后新增的数据结构，用于可持久化的消息队列。</p><p><img src="/posts/40341/assets/277d1ad6ee5ba09f5d3077acc482ffca.webp" alt="img"></p><h3 id="二、Redis扩展功能"><a href="#二、Redis扩展功能" class="headerlink" title="二、Redis扩展功能"></a><strong>二、Redis扩展功能</strong></h3><h3 id="发布与订阅"><a href="#发布与订阅" class="headerlink" title="发布与订阅"></a><strong>发布与订阅</strong></h3><p>Redis提供了发布订阅功能，可以用于消息的传输，包括三个部分，publisher，subscriber和Channel</p><p>发布者和订阅者都是Redis客户端，Channel则为Redis服务器端。</p><p>发布者将消息发送到某个的频道，订阅了这个频道的订阅者就能接收到这条消息。</p><p><img src="https://pic1.zhimg.com/80/v2-46b0c3716d28aae266d73f0f70857818_720w.webp" alt="img"></p><p>在Redis哨兵模式中，哨兵通过发布与订阅的方式与Redis主服务器和Redis从服务器进行通信。</p><h3 id="事务特性"><a href="#事务特性" class="headerlink" title="事务特性"></a><strong>事务特性</strong></h3><p><strong>ACID特性与redis事务比较</strong></p><p>1.Atomicity（原子性）：构成事务的的所有操作必须是一个逻辑单元，要么全部执行，要么全部不执行。</p><p>Redis:一个队列中的命令 执行或不执行</p><p>2.Consistency（一致性）：数据库在事务执行前后状态都必须是稳定的或者是一致的。</p><p>Redis: 集群中不能保证时时的一致性，只能是最终一致性</p><p>3.Isolation（隔离性）：事务之间不会相互影响。</p><p>Redis: 命令是顺序执行的，在一个事务中，有可能被执行其他客户端的命令的</p><p>4.Durability（持久性）：事务执行成功后必须全部写入磁盘。</p><p>Redis有持久化但不保证数据的完整性</p><p><strong>Redis事务</strong></p><p>Redis的事务是通过multi、exec、discard和watch这四个命令来完成的。</p><p>Redis的单个命令都是原子性的，所以这里需要确保事务性的对象是命令集合。</p><p>Redis将命令集合序列化并确保处于同一事务的命令集合连续且不被打断的执行</p><p>Redis不支持回滚操作</p><p><strong>事务命令</strong></p><p>multi：用于标记事务块的开始,Redis会将后续的命令逐个放入队列中，然后使用exec原子化地执行这个命令队列</p><p>exec：执行命令队列</p><p>discard：清除命令队列</p><p>watch：监视key，如果监视中发现key变值了清空队列</p><p>unwatch：清除监视key</p><p><img src="https://pic1.zhimg.com/80/v2-dae8e4f177927937d005a89c9a120750_720w.webp" alt="img"></p><h3 id="事务机制"><a href="#事务机制" class="headerlink" title="事务机制"></a><strong>事务机制</strong></h3><p><strong>事务的执行</strong></p><p>\1. 事务开始 在RedisClient中，有属性flags，用来表示是否在事务中 flags&#x3D;REDIS_MULTI</p><p>\2. 命令入队 RedisClient将命令存放在事务队列中 （EXEC,DISCARD,WATCH,MULTI除外）</p><p>\3. 事务队列 multiCmd *commands 用于存放命令</p><p>\4. 执行事务 RedisClient向服务器端发送exec命令，RedisServer会遍历事务队列,执行队列中的命令,最后将执 行的结果一次性返回给客户端。</p><p>\5. 如果某条命令在入队过程中发生错误，redisClient将flags置为REDIS_DIRTY_EXEC，EXEC命令将会失败 返回。</p><p><strong>Watch的执行</strong></p><p>redisDb有一个watched_keys字典,key是某个被监视的数据的key,值是一个链表.记录了所有监视这个数 据的客户端。</p><p>监视机制的触发</p><p>当修改数据后，监视这个数据的客户端的flags置为REDIS_DIRTY_CAS事务执行 RedisClient向服务器端发送exec命令，服务器判断RedisClient的flags，如果为REDIS_DIRTY_CAS，则清空事务队列。</p><p>Redis不支持事务回滚的原因</p><p>1、大多数事务失败是因为语法错误或者类型错误，这两种错误，在开发阶段都是可以预见的</p><p>2、Redis为了性能方面就忽略了事务回滚。</p><h3 id="Lua脚本"><a href="#Lua脚本" class="headerlink" title="Lua脚本"></a><strong>Lua脚本</strong></h3><p>从Redis2.6.0版本开始，通过内置的lua编译&#x2F;解释器，可以使用EVAL命令对lua脚本进行求值。</p><p>脚本的命令是原子的，RedisServer在执行脚本命令中，不允许插入新的命令</p><p>脚本的命令可以复制，RedisServer在获得脚本后不执行，生成标识返回，Client根据标识就可以随时执行</p><p><strong>EVAL命令</strong></p><p>命令说明：</p><p>script参数：是一段Lua脚本程序，它会被运行在Redis服务器上下文中，这段脚本不必(也不应该) 定义为一个Lua函数。</p><p>numkeys参数：用于指定键名参数的个数。</p><p>key [key …]参数： 从EVAL的第三个参数开始算起，使用了numkeys个键（key），表示在脚本中 所用到的那些Redis键(key)，这些键名参数可以在Lua中通过全局变量KEYS数组，用1为基址的形 式访问( KEYS[1] ， KEYS[2] ，以此类推)。</p><p>arg [arg …]参数：可以在Lua中通过全局变量ARGV数组访问，访问的形式和KEYS变量类似( ARGV[1] 、 ARGV[2] ，诸如此类)。</p><p>举例：eval “return {KEYS[1],KEYS[2],ARGV[1],ARGV[2]}” 2 key1 key2 first second</p><p>lua脚本中调用Redis命令：eval “return redis.call(‘set’,KEYS[1],ARGV[1])” 1 n1 zhaoyun</p><p><strong>EVALSHA命令</strong></p><p>EVAL 命令要求你在每次执行脚本的时候都发送一次脚本主体，为了减少带宽的消耗， Redis 实现了 EVALSHA 命令，它的作用和 EVAL 一样，都用于对脚本求值，但 它接受的第一个参数不是脚本，而是脚本的 SHA1 校验和(sum)。</p><p>SCRIPT FLUSH ：清除所有脚本缓存</p><p>SCRIPT EXISTS ：根据给定的脚本校验和，检查指定的脚本是否存在于脚本缓存</p><p>SCRIPT LOAD ：将一个脚本装入脚本缓存，返回SHA1摘要，但并不立即运行它</p><p>SCRIPT KILL ：杀死当前正在运行的脚本</p><p>举例:</p><p>script load “return redis.call(‘set’,KEYS[1],ARGV[1])”-&gt; “c686f316aaf1eb01d5a4de1b0b63cd233010e63d”</p><p>-&gt;evalsha c686f316aaf1eb01d5a4de1b0b63cd233010e63d 1 n2 zhangfei</p><p>其实就是把LUA命令进行缓存并返回一段唯一的sha码，通过码来调用脚本执行命令</p><p><strong>脚本复制</strong></p><p>Redis 传播 Lua 脚本，在使用主从模式和开启AOF持久化的前提下，当执行lua脚本时，Redis 服务器有两种模式：脚本传播模式和命令传播模式。</p><p>脚本传播模式是 Redis 复制脚本时默认使用的模式 Redis会将被执行的脚本及其参数复制到 AOF 文件以及从服务器里面。</p><p>命令传播模式的主服务器会将执行脚本产生的所有写命令用事务包裹起来，然后将事务复制到 AOF 文件以及从服务器里面。</p><p><strong>管道（pipeline）,事务和脚本(lua)三者的区别</strong></p><p>三者都可以批量执行命令</p><p>管道无原子性，命令都是独立的，属于无状态的操作</p><p>事务和脚本是有原子性的，其区别在于脚本可借助Lua语言可在服务器端存储的便利性定制和简化操作</p><p>脚本的原子性要强于事务，脚本执行期间，另外的客户端 其它任何脚本或者命令都无法执行，脚本的执行时间应该尽量短，不能太耗时的脚本。</p><h3 id="慢查询日志和监视器"><a href="#慢查询日志和监视器" class="headerlink" title="慢查询日志和监视器"></a><strong>慢查询日志和监视器</strong></h3><p><strong>Redis慢查询日志用于监视和优化查询</strong></p><p>1、尽量使用短的key，对于value有些也可精简，能使用int就int。</p><p>2、避免使用keys *、hgetall等全量操作。</p><p>3、减少大key的存取，打散为小key 100K以上</p><p>4、将rdb改为aof模式 rdb fork 子进程 数据量过大 主进程阻塞 redis性能大幅下降 关闭持久化 ， （适合于数据量较小，有固定数据源）</p><p>5、想要一次添加多条数据的时候可以使用管道</p><p>6、尽可能地使用哈希存储</p><p>7、尽量限制下redis使用的内存大小，这样可以避免redis使用swap分区或者出现OOM错误 内存与硬盘的swap</p><p><strong>监视器</strong></p><p>Redis客户端通过执行MONITOR命令可以将自己变为一个监视器，实时地接受并打印出服务器当前处理的命令请求的相关信息。</p><h3 id="三、Redis核心原理"><a href="#三、Redis核心原理" class="headerlink" title="三、Redis核心原理"></a><strong>三、Redis核心原理</strong></h3><h3 id="Redis持久化"><a href="#Redis持久化" class="headerlink" title="Redis持久化"></a><strong>Redis持久化</strong></h3><p>Redis是内存数据库，宕机后数据会消失。Redis重启后快速恢复数据，要提供持久化机制，Redis持久化是为了快速的恢复数据而不是为了存储数据，Redis有两种持久化方式：RDB和AOF。</p><h3 id="RDB特性"><a href="#RDB特性" class="headerlink" title="RDB特性"></a><strong>RDB特性</strong></h3><p>RDB（Redis DataBase），是redis默认的存储方式，RDB方式是通过快照（ snapshotting ）完成的。关注的是这一刻的数据，也就是跟拍照一样，抓拍这一刻，不管前后。</p><p>在redis.conf中配置：save 多少秒内 数据变了多少，采用漏洞设计，提升性能。</p><p><img src="/posts/40341/assets/0109e84944c9ef05042e605c96c62129.webp" alt="img"></p><p><img src="https://pic2.zhimg.com/80/v2-f7c80e91a300ab811cd8aeec687f15e5_720w.webp" alt="img"></p><p>\1. Redis父进程首先判断：当前是否在执行save，或bgsave&#x2F;bgrewriteaof（aof文件重写命令）的子进程，如果在执行则bgsave命令直接返回。</p><p>\2. 父进程执行fork（调用OS函数复制主进程）操作创建子进程，这个复制过程中父进程是阻塞的，Redis不能执行来自客户端的任何命令。</p><p>\3. 父进程fork后，bgsave命令返回”Background saving started”信息并不再阻塞父进程，并可以响应其他命令。</p><p>\4. 子进程创建RDB文件，根据父进程内存快照生成临时快照文件，完成后对原有文件进行原子替换。 （RDB始终完整）</p><p>\5. 子进程发送信号给父进程表示完成，父进程更新统计信息。</p><p>\6. 父进程fork子进程后，继续工作。</p><p><strong>优点</strong></p><p>RDB是二进制压缩文件，占用空间小，便于传输（传给slaver）</p><p>主进程fork子进程，可以最大化Redis性能，主进程不能太大，Redis的数据量不能太大，复制过程中主进程阻塞</p><p><strong>缺点</strong></p><p>不保证数据完整性，会丢失最后一次快照以后更改的所有数据</p><h3 id="AOF特性"><a href="#AOF特性" class="headerlink" title="AOF特性"></a><strong>AOF特性</strong></h3><p>AOF（append only file）是Redis的另一种持久化方式。Redis默认情况下是不开启的。开启AOF持久化后 Redis 将所有对数据库进行过写入的命令（及其参数）记录到 AOF文件， 以此达到记录数据库状态的目的，这样当Redis重启后只要按顺序回放这些命令就会恢复到原始状态了。 AOF会记录过程，RDB只管结果。</p><p>在redis.conf中配置</p><p><img src="https://pic4.zhimg.com/80/v2-99acb4dcd40a6dea003db87dbfa7e61b_720w.webp" alt="img"></p><p><strong>AOF原理</strong></p><p>AOF文件中存储的是redis的命令，同步命令到 AOF 文件的整个过程可以分为三个阶段：</p><p>命令传播：Redis 将执行完的命令、命令的参数、命令的参数个数等信息发送到 AOF 程序中。</p><p>缓存追加：AOF 程序根据接收到的命令数据，将命令转换为网络通讯协议的格式，然后将协议内容追加 到服务器的 AOF 缓存中。</p><p>文件写入和保存：AOF 缓存中的内容被写入到 AOF 文件末尾，如果设定的 AOF 保存条件被满足的话， fsync 函数或者 fdatasync 函数会被调用，将写入的内容真正地保存到磁盘中。</p><p><strong>AOF 保存模式</strong></p><p>Redis 目前支持三种 AOF 保存模式，它们分别是：</p><p>AOF_FSYNC_NO ：不保存。</p><p>AOF_FSYNC_EVERYSEC ：每一秒钟保存一次。（默认）</p><p>AOF_FSYNC_ALWAYS ：每执行一个命令保存一次。（不推荐）</p><p><img src="https://pic2.zhimg.com/80/v2-57c7573883534b5b0ed9ef66ce4a145d_720w.webp" alt="img"></p><p>Redis可以在 AOF体积变得过大时，自动地在后台（Fork子进程）对 AOF进行重写，Redis 不希望 AOF 重写造成服务器无法处理请求，所以 Redis 决定将 AOF 重写程序放到（后台）子进程里执行，子进程在进行 AOF重写期间，主进程还需要继续处理命令，而新的命令可能对现有的数据进行修改，因此Redis 增加了一个 AOF 重写缓存。</p><p><img src="https://pic1.zhimg.com/80/v2-e54243fcf92fc4ff89fc90ce8fe433ac_720w.webp" alt="img"></p><h3 id="混合持久化"><a href="#混合持久化" class="headerlink" title="混合持久化"></a><strong>混合持久化</strong></h3><p>RDB和AOF各有优缺点，Redis 4.0 开始支持 rdb 和 aof 的混合持久化。如果把混合持久化打开，aof rewrite 的时候就直接把 rdb 的内容写到 aof 文件开头。在加载时，首先会识别AOF文件是否以 REDIS字符串开头，如果是就按RDB格式加载，加载完RDB后继续按AOF格式加载剩余部分。</p><p><strong>RDB与AOF对比</strong></p><p>1、RDB存某个时刻的数据快照，采用二进制压缩存储，AOF存操作命令，采用文本存储(混合)</p><p>2、RDB性能高、AOF性能较低</p><p>3、RDB在配置触发状态会丢失最后一次快照以后更改的所有数据，AOF设置为每秒保存一次，则最多 丢2秒的数据</p><p>4、Redis以主服务器模式运行，RDB不会保存过期键值对数据，Redis以从服务器模式运行，RDB会保 存过期键值对，当主服务器向从服务器同步时，再清空过期键值对。</p><p><strong>应用场景</strong></p><p>内存数据库 rdb+aof 数据不容易丢</p><p>有原始数据源：每次启动时都从原始数据源中初始化 ，则不用开启持久化</p><p>缓存服务器 rdb 一般性能高</p><p>在数据还原时 有rdb+aof 则还原aof，因为RDB会造成文件的丢失，AOF相对数据要完整。</p><h3 id="底层数据结构"><a href="#底层数据结构" class="headerlink" title="底层数据结构"></a><strong>底层数据结构</strong></h3><p>Redis没有表的概念，Redis实例所对应的db以编号区分，db本身就是key的命名空间。</p><p><img src="https://pic1.zhimg.com/80/v2-4611506e2a8984baba58502dc3818a88_720w.webp" alt="img"></p><p>RedisDB结构体源码：</p><p><img src="https://pic1.zhimg.com/80/v2-77d54e308eb1eb6699a83ed64884c8a8_720w.webp" alt="img"></p><p>RedisObject结构：</p><p><img src="https://pic2.zhimg.com/80/v2-2ea3572924182e7acd7e3055a9de3f05_720w.webp" alt="img"></p><h3 id="字符串对象"><a href="#字符串对象" class="headerlink" title="字符串对象"></a><strong>字符串对象</strong></h3><p>Redis 使用了 SDS(Simple Dynamic String)。用于存储字符串和整型数据。SDS 在 C 字符串的基础上加入了 free 和 len 字段，SDS 由于记录了长度，在可能造成缓冲区溢出时会自动重新分配内存，杜绝了缓冲区溢出。</p><h3 id="跳跃表"><a href="#跳跃表" class="headerlink" title="跳跃表"></a><strong>跳跃表</strong></h3><p>跳跃表是有序集合（sorted-set）的底层实现，效率高，实现简单。</p><p><img src="https://pic1.zhimg.com/80/v2-bd150892784506adceed144122f271cc_720w.webp" alt="img"></p><h3 id="字典（核心）"><a href="#字典（核心）" class="headerlink" title="字典（核心）"></a><strong>字典（核心）</strong></h3><p>字典dict又称散列表（hash），是用来存储键值对的一种数据结构。 Redis整个数据库是用字典来存储的。（K-V结构） 对Redis进行CURD操作其实就是对字典中的数据进行CURD操作。</p><p><strong>数组</strong></p><p>数组：用来存储数据的容器，采用头指针+偏移量的方式能够以O(1)的时间复杂度定位到数据所在的内存地址，海量存储效率高的缘由。</p><p><strong>Hash函数</strong></p><p>Hash（散列），作用是把任意长度的输入通过散列算法转换成固定类型、固定长度的散列值。 hash函数可以把Redis里的key：包括字符串、整数、浮点数统一转换成整数，算出数组下标进行存储。</p><p><img src="/posts/40341/assets/9dc613df0f0c0122fd09435a7b3be430.webp" alt="img"></p><p>Redis字典实现包括：字典(dict)、Hash表(dictht)、Hash表节点(dictEntry)。</p><p>字典达到存储上限（阈值 0.75），需要rehash（扩容）</p><p>\1. 初次申请默认容量为4个dictEntry，非初次申请为当前hash表容量的一倍。</p><p>\2. rehashidx&#x3D;0表示要进行rehash操作。</p><p>\3. 新增加的数据在新的hash表h[1]</p><p>\4. 修改、删除、查询在老hash表h[0]、新hash表h[1]中（rehash中）</p><p>\5. 将老的hash表h[0]的数据重新计算索引值后全部迁移到新的hash表h[1]中，这个过程称为 rehash。</p><p><strong>应用场景：</strong></p><p>1、主数据库的K-V数据存储</p><p>2、散列表对象（hash）</p><p>3、哨兵模式中的主从节点管理</p><p><strong>压缩列表</strong></p><p>压缩列表（ziplist）是由一系列特殊编码的连续内存块组成的顺序型数据结构，节省内存，是一个字节数组，可以包含多个节点（entry）。每个节点可以保存一个字节数组或一个整数。</p><p>应用场景：</p><p>sorted-set和hash元素个数少且是小整数或短字符串（直接使用）</p><p>list用快速链表(quicklist)数据结构存储，而快速链表是双向列表与压缩列表的组合。（间接使用）</p><p><strong>整数集合</strong></p><p>整数集合(intset)是一个有序的（整数升序）、存储整数的连续存储结构。</p><h3 id="快速列表"><a href="#快速列表" class="headerlink" title="快速列表"></a><strong>快速列表</strong></h3><p>快速列表（quicklist）是Redis底层重要的数据结构。是列表的底层实现。（在Redis3.2之前，Redis采用双向链表（adlist）和压缩列表（ziplist）实现。）在Redis3.2以后结合adlist和ziplist的优势Redis设计出了quicklist。</p><p><strong>双向列表（adlist）</strong>：</p><p><img src="https://pic3.zhimg.com/80/v2-9bff2fceff71badd0f99c7a3a5981e26_720w.webp" alt="img"></p><p>\1. 双向：链表具有前置节点和后置节点的引用，获取这两个节点时间复杂度都为O(1)。</p><p>\2. 普通链表（单链表）：节点类保留下一节点的引用。链表类只保留头节点的引用，只能从头节点插 入删除</p><p>\3. 无环：表头节点的 prev 指针和表尾节点的 next 指针都指向 NULL,对链表的访问都是以 NULL 结 束。 环状：头的前一个节点指向尾节点</p><p>\4. 带链表长度计数器：通过 len 属性获取链表长度的时间复杂度为 O(1)。</p><p>\5. 多态：链表节点使用 void* 指针来保存节点值，可以保存各种不同类型的值。</p><p>快速列表quicklist是一个双向链表，链表中的每个节点时一个ziplist结构。quicklist中的每个节点ziplist都能够存 储多个数据元素。</p><p><strong>数据压缩（ziplist）:</strong></p><p>quicklist每个节点的实际数据存储结构为ziplist，这种结构的优势在于节省存储空间。为了进一步降低 ziplist的存储空间，还可以对ziplist进行压缩。Redis采用的压缩算法是LZF。其基本思想是：数据与前 面重复的记录重复位置及长度，不重复的记录原始数据。</p><h3 id="stream流对象"><a href="#stream流对象" class="headerlink" title="stream流对象"></a><strong>stream流对象</strong></h3><p>stream主要由：消息、生产者、消费者和消费组构成。</p><p>Redis Stream的底层主要使用了listpack（紧凑列表）和Rax树（基数树）。</p><p>listpack表示一个字符串列表的序列化，listpack可用于存储字符串或整数。用于存储stream的消息内容。</p><p>Rax 是一个有序字典树 (基数树 Radix Tree)，按照 key 的字典序排列，支持快速地定位、插入和删除操作。</p><h3 id="缓存过期和淘汰策略"><a href="#缓存过期和淘汰策略" class="headerlink" title="缓存过期和淘汰策略"></a><strong>缓存过期和淘汰策略</strong></h3><p>Redis长期使用，key会不断增加，Redis作为缓存使用，物理内存也会满 内存与硬盘交换（swap）虚拟内存 ，频繁IO 性能急剧下降。</p><p>Redis默认缓存淘汰策略：禁止驱逐</p><p><strong>Maxmemory最大内存</strong></p><p>不设置场景</p><p>Redis作为DB使用，保证数据的完整性，不能淘汰 ，可以做集群，横向扩展</p><p>设置的场景</p><p>Redis是作为缓存使用，不断增加Key maxmemory ： 默认为0 不限制</p><p>设置maxmemory后，当趋近maxmemory时，通过缓存淘汰策略，从内存中删除对象，一般是物理内存的3&#x2F;4</p><p><strong>expire数据结构</strong></p><p>在Redis中可以使用expire命令设置一个键的存活时间(ttl: time to live)，过了这段时间，该键就会自动被删除。</p><h3 id="删除策略之定时删除"><a href="#删除策略之定时删除" class="headerlink" title="删除策略之定时删除"></a><strong>删除策略之定时删除</strong></h3><p>在设置键的过期时间的同时，创建一个定时器，让定时器在键的过期时间来临时，立即执行对键的删除操作。 需要创建定时器，而且消耗CPU，一般不推荐使用。</p><h3 id="删除策略之惰性删除"><a href="#删除策略之惰性删除" class="headerlink" title="删除策略之惰性删除"></a><strong>删除策略之惰性删除</strong></h3><p>在key被访问时如果发现它已经失效，那么就删除它。</p><h3 id="删除策略之主动删除"><a href="#删除策略之主动删除" class="headerlink" title="删除策略之主动删除"></a><strong>删除策略之主动删除</strong></h3><p>在redis.conf文件中可以配置主动删除策略,默认是no-enviction（不删除）</p><p>maxmemory-policy allkeys-lru</p><p><strong>LRU算法</strong></p><p>最近最少使用，算法根据数据的历史访问记录来进行淘汰数据，其核心思想 是“如果数据最近被访问过，那么将来被访问的几率也更高”。</p><p>\1. 新数据插入到链表头部；</p><p>\2. 每当缓存命中（即缓存数据被访问），则将数据移到链表头部；</p><p>\3. 当链表满的时候，将链表尾部的数据丢弃。</p><p>\4. 在Java中可以使用LinkHashMap（哈希链表）去实现LRU</p><p>volatile-lru 从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰</p><p>allkeys-lru 从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰</p><p><strong>LFU算法</strong></p><p>LFU (Least frequently used) 最不经常使用，如果一个数据在最近一段时间内使用次数很少，那么在将来一段时间内被使用的可能性也很小。</p><p><strong>Random</strong></p><p>volatile-random 从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰</p><p>allkeys-random 从数据集（server.db[i].dict）中任意选择数据淘汰</p><p><strong>ttl</strong></p><p>从过期时间的表中随机挑选几个键值对，取出其中 ttl 最小的键值对淘汰。</p><p>volatile-ttl 从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰</p><p><strong>缓存淘汰策略的选择</strong></p><p>allkeys-lru ： 在不确定时一般采用策略。 冷热数据交换</p><p>volatile-lru ： 比allkeys-lru性能差 存 : 过期时间</p><p>allkeys-random ： 希望请求符合平均分布(每个元素以相同的概率被访问)</p><p>自己控制：volatile-ttl 缓存穿透</p><h3 id="通信协议之请求协议响应"><a href="#通信协议之请求协议响应" class="headerlink" title="通信协议之请求协议响应"></a><strong>通信协议之请求协议响应</strong></h3><p>Redis是单进程单线程的。 应用系统和Redis通过Redis协议（RESP）进行交互。</p><p>Redis协议位于TCP层之上，即客户端和Redis实例保持双工的连接。</p><p><strong>串行的请求响应模式（ping-pong）</strong></p><p>串行化是最简单模式，客户端与服务器端建立长连接 连接通过心跳机制检测（ping-pong） ack应答 客户端发送请求，服务端响应，客户端收到响应后，再发起第二个请求，服务器端再响应。telnet和redis-cli 发出的命令 都属于该种模式，性能较低。</p><p><strong>双工的请求响应模式(pipeline)</strong></p><p>批量请求，批量响应 请求响应交叉进行，不会混淆(TCP双工)</p><p>pipeline的作用是将一批命令进行打包，然后发送给服务器，服务器执行完按顺序打包返回。</p><p>通过pipeline，一次pipeline（n条命令）&#x3D;一次网络时间 + n次命令时间</p><p><strong>原子化的批量请求响应模式（事务）</strong></p><p>Redis可以利用事务机制批量执行命令。</p><p><strong>发布订阅模式(pub&#x2F;sub)</strong></p><p>发布订阅模式是：一个客户端触发，多个客户端被动接收，通过服务器中转。</p><p><strong>脚本化的批量执行（lua）</strong></p><p>客户端向服务器端提交一个lua脚本，服务器端执行该脚本。</p><p><strong>请求数据格式</strong></p><p>内联格式：可以使用telnet给Redis发送命令，首字符为Redis命令名的字符，格式为 str1 str2 str3…</p><p>规范格式(redis-cli) RESP：</p><p>1、间隔符号，在Linux下是\r\n，在Windows下是\n</p><p>2、简单字符串 Simple Strings, 以 “+”加号 开头</p><p>3、错误 Errors, 以”-“减号 开头</p><p>4、整数型 Integer， 以 “:” 冒号开头</p><p>5、大字符串类型 Bulk Strings, 以 “$”美元符号开头，长度限制512M</p><p>6、数组类型 Arrays，以 “*”星号开头</p><h3 id="通信协议之命令处理流程"><a href="#通信协议之命令处理流程" class="headerlink" title="通信协议之命令处理流程"></a><strong>通信协议之命令处理流程</strong></h3><p>整个流程包括：服务器启动监听、接收命令请求并解析、执行命令请求、返回命令回复等。</p><p><img src="https://pic3.zhimg.com/80/v2-818aef511ccf7c5427130840354e5aba_720w.webp" alt="img"></p><h3 id="事件处理机制之文件事件"><a href="#事件处理机制之文件事件" class="headerlink" title="事件处理机制之文件事件"></a><strong>事件处理机制之文件事件</strong></h3><p>Redis服务器是典型的事件驱动系统。</p><p>文件事件即Socket的读写事件，也就是IO事件。客户端的连接、命令请求、数据回复、连接断开。</p><p>socket 套接字（socket）是一个抽象层，应用程序可以通过它发送或接收数据。</p><p>Reactor Redis事件处理机制采用单线程的Reactor模式，属于I&#x2F;O多路复用的一种常见模式。</p><p>IO多路复用( I&#x2F;O multiplexing ）指的通过单个线程管理多个Socket。</p><p>Reactor pattern(反应器设计模式)是一种为处理并发服务请求，并将请求提交到一个或者多个服务处理程序的事件设计模式。</p><p>Reactor模式是事件驱动的，也就是文件事件。</p><p>有一个Service Handler，有多个Request Handlers，这个Service Handler会同步的将输入的请求（Event）多路复用的分发给相应的Request Handler。</p><p><img src="/posts/40341/assets/5b48e7d73619b8a0c8e466b4501a63f0.webp" alt="img"></p><h3 id="4种IO多路复用模型"><a href="#4种IO多路复用模型" class="headerlink" title="4种IO多路复用模型"></a><strong>4种IO多路复用模型</strong></h3><p>select，poll，epoll、kqueue都是IO多路复用的机制。 I&#x2F;O多路复用就是通过一种机制，一个进程可以监视多个描述符（socket），一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。</p><p><strong>Select</strong></p><p>调用后select函数会阻塞，直到有描述符就绪（有数据 可读、可写、或者有except），或者超时 （timeout指定等待时间，如果立即返回设为null即可），函数返回。当select函数返回后，可以通过遍历fd列表，来找到就绪的描述符，最大监听1024，采用的是线性扫描的方法，即不管这些socket是不是活 跃的，都轮询一遍，效率比较低。</p><p><strong>Poll</strong></p><p>poll使用一个 pollfd的指针实现，pollfd结构包含了要监视的event和发生的event，不再使用select“参 数-值”传递的方式，没有1024限制，但是仍然采用的是线性扫描的方法，即不管这些socket是不是活跃的，都轮询一遍，效率比较低。。</p><p><strong>Epoll</strong></p><p>epoll是在linux2.6内核中提出的，是之前的select和poll的增强版本。相对于select和poll来说，epoll更 加灵活，没有描述符限制，并且不会采用线性扫描，只扫描活跃的。</p><p><strong>Kqueue</strong></p><p>kqueue 是 unix 下的一个IO多路复用库。最初是2000年Jonathan Lemon在FreeBSD系统上开发的一个 高性能的事件通知接口。注册一批socket描述符到 kqueue 以后，当其中的描述符状态发生变化时，kqueue 将一次性通知应用程序哪些描述符可读、可写或出错了。能处理大量数据，性能较高。</p><h3 id="事件处理机制之时间事件"><a href="#事件处理机制之时间事件" class="headerlink" title="事件处理机制之时间事件"></a><strong>事件处理机制之时间事件</strong></h3><p>时间事件分为定时事件与周期事件：</p><p>id(全局唯一id)</p><p>when (毫秒时间戳，记录了时间事件的到达时间)</p><p><strong>serverCron</strong></p><p>时间事件的最主要的应用是在redis服务器需要对自身的资源与配置进行定期的调整，从而确保服务器的 长久运行，这些操作由redis.c中的serverCron函数实现。该时间事件主要进行以下操作：</p><p>1）更新redis服务器各类统计信息，包括时间、内存占用、数据库占用等情况。</p><p>2）清理数据库中的过期键值对。</p><p>3）关闭和清理连接失败的客户端。</p><p>4）尝试进行aof和rdb持久化操作。</p><p>5）如果服务器是主服务器，会定期将数据向从服务器做同步操作。</p><p>6）如果处于集群模式，对集群定期进行同步与连接测试操作。</p><p>timeProc（时间事件处理器，当时间到达时，Redis就会调用相应的处理器来处理事件）</p><p><strong>定时事件</strong></p><p>定时事件：让一段程序在指定的时间之后执行一次 aeTimeProc（时间处理器）的返回值是AE_NOMORE 该事件在达到后删除，之后不会再重复。</p><p><strong>周期性事件</strong></p><p>周期性事件：让一段程序每隔指定时间就执行一次 aeTimeProc（时间处理器）的返回值不是AE_NOMORE 当一个时间事件到达后，服务器会根据时间处理器的返回值，对时间事件的 when 属性进行更新，让这 个事件在一段时间后再次达到。 serverCron就是一个典型的周期性事件。</p><p><strong>aeEventLoop</strong></p><p>aeEventLoop 是整个事件驱动的核心，Redis自己的事件处理机制 它管理着文件事件表和时间事件列表， 不断地循环处理着就绪的文件事件和到期的时间事件。</p><p><img src="/posts/40341/assets/8a3a30a01a4c4eaecc1000aecb2a4f8d.webp" alt="img"></p><p><strong>aeProcessEvent</strong></p><p>首先计算距离当前时间最近的时间事件，以此计算一个超时时间；然后调用 aeApiPoll 函数去等待底层的I&#x2F;O多路复用事件就绪；aeApiPoll 函数返回之后，会处理所有已经产生文件事件和已经达到的时间事件。</p><h3 id="四、Redis企业应用"><a href="#四、Redis企业应用" class="headerlink" title="四、Redis企业应用"></a><strong>四、Redis企业应用</strong></h3><h3 id="JVM缓存"><a href="#JVM缓存" class="headerlink" title="JVM缓存"></a><strong>JVM缓存</strong></h3><p>JVM缓存就是本地缓存，设计在应用服务器中（tomcat）。 通常可以采用Ehcache和Guava Cache，在互联网应用中，由于要处理高并发，通常选择Guava Cache。</p><p>适用本地（JVM）缓存的场景：</p><p>1、对性能有非常高的要求。</p><p>2、不经常变化</p><p>3、占用内存不大</p><p>4、有访问整个集合的需求</p><p>5、数据允许不时时一致</p><h3 id="文件缓存"><a href="#文件缓存" class="headerlink" title="文件缓存"></a><strong>文件缓存</strong></h3><p>这里的文件缓存是基于http协议的文件缓存，一般放在nginx中。</p><p>静态文件（比如css，js， 图片）中，很多都是不经常更新的。nginx使用proxy_cache将用户的请 求缓存到本地一个目录。下一个相同请求可以直接调取缓存文件，就不用去请求服务器了。</p><h3 id="Redis缓存"><a href="#Redis缓存" class="headerlink" title="Redis缓存"></a><strong>Redis缓存</strong></h3><p>Redis采用的是基于内存的采用的是单进程单线程模型的 KV 数据库，由C语言编写，官方提供的数据是可以达到110000+的QPS（每秒内查询次数）。80000的写</p><p>分布式缓存，采用主从+哨兵或RedisCluster的方式缓存数据库的数据。 在实际开发中作为数据库使用，数据要完整 作为缓存使用，作为Mybatis的二级缓存使用</p><p><strong>缓存大小设置</strong></p><p>GuavaCache的缓存设置方式:</p><p>CacheBuilder.newBuilder().maximumSize(num) &#x2F;&#x2F; 超过num会按照LRU算法来移除缓存</p><p>Nginx的缓存设置方式：</p><p>http { …</p><p>proxy_cache_path &#x2F;path&#x2F;to&#x2F;cache levels&#x3D;1:2 keys_zone&#x3D;my_cache:10m max_size&#x3D;10g inactive&#x3D;60m use_temp_path&#x3D;off;</p><p>server { proxy_cache mycache;</p><p>location &#x2F; { proxy_pass <a href="http://localhost:8000/">http://localhost:8000</a>; }</p><p>}</p><p>}</p><p>Redis缓存设置：</p><p>maxmemory&#x3D;num # 最大缓存量 一般为内存的3&#x2F;4</p><p>maxmemory-policy allkeys lru #</p><p>key数量：一个key或是value大小最大是512M</p><p><strong>命中率</strong></p><p>1、缓存的数量越少命中率越高，比如缓存单个对象的命中率要高于缓存集合</p><p>2、过期时间越长命中率越高</p><p>3、缓存越大缓存的对象越多，则命中的越多</p><p><strong>过期策略</strong></p><p>Redis的过期策略是定时删除+惰性删除</p><p><strong>缓存预热</strong></p><p>缓存预热就是系统启动前,提前将相关的缓存数据直接加载到缓存系统。避免在用户请求的时候,先查询 数据库,然后再将数据缓存的问题!用户直接查询实现被预热的缓存数据。</p><p>加载缓存思路： 数据量不大，可以在项目启动的时候自动进行加载 利用定时任务刷新缓存，将数据库的数据刷新到缓存中</p><h3 id="缓存问题之缓存穿透"><a href="#缓存问题之缓存穿透" class="headerlink" title="缓存问题之缓存穿透"></a><strong>缓存问题之缓存穿透</strong></h3><p>一般的缓存系统，都是按照key去缓存查询，如果不存在对应的value，就应该去后端系统查找（比如 DB）。 缓存穿透是指在高并发下查询key不存在的数据（不存在的key），会穿过缓存查询数据库。导致数据库 压力过大而宕机。</p><p>解决方案：</p><p>对查询结果为空的情况也进行缓存，缓存时间（ttl）设置短一点，或者该key对应的数据insert了之后清理缓存。 问题：缓存太多空值占用了更多的空间</p><p>使用布隆过滤器。在缓存之前在加一层布隆过滤器，在查询的时候先去布隆过滤器查询 key 是否存在，如果不存在就直接返回，存在再查缓存和DB。</p><p>布隆过滤器的原理：当一个元素被加入集合时，通过K个Hash函数将这个元素映射成一个数组中的K 个点，把它们置为1。检索时，我们只要看看这些点是不是都是1就（大约）知道集合中有没有它了：如果这些点有任何一个0，则被检元素一定不在；如果都是1，则被检元素很可能在。多个K是为了避免hash碰撞。</p><h3 id="缓存问题之缓存雪崩"><a href="#缓存问题之缓存雪崩" class="headerlink" title="缓存问题之缓存雪崩"></a><strong>缓存问题之缓存雪崩</strong></h3><p>当缓存服务器重启或者大量缓存集中在某一个时间段失效，这样在失效的时候，也会给后端系统(比如 DB)带来很大压力。 突然间大量的key失效了或redis重启，大量访问数据库，数据库崩溃</p><p>解决方案:</p><p>1、key的失效期分散开不同的key设置不同的有效期</p><p>2、设置二级缓存（数据不一定一致）</p><p>3、高可用（脏读）</p><h3 id="缓存问题之缓存击穿"><a href="#缓存问题之缓存击穿" class="headerlink" title="缓存问题之缓存击穿"></a><strong>缓存问题之缓存击穿</strong></h3><p>对于一些设置了过期时间的key，如果这些key可能会在某些时间点被超高并发地访问，是一种非常“热 点”的数据。</p><p>缓存在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，这些请求发现缓 存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。</p><p>解决方案：</p><p>1、用分布式锁控制访问的线程 使用redis的setnx互斥锁先进行判断，这样其他线程就处于等待状态，保证不会有大并发操作去操作数 据库。</p><p>2、不设超时时间，volatile-lru 但会造成写一致问题</p><p>当数据库数据发生更新时，缓存中的数据不会及时更新，这样会造成数据库中的数据与缓存中的数据的 不一致，应用会从缓存中读取到脏数据。可采用延时双删策略处理。</p><h3 id="缓存问题之数据不一致"><a href="#缓存问题之数据不一致" class="headerlink" title="缓存问题之数据不一致"></a><strong>缓存问题之数据不一致</strong></h3><p>缓存和DB的数据不一致的根源 ： 数据源不一样，强一致性很难，追求最终一致性（时间）。</p><p>保证数据的最终一致性(延时双删)</p><p>1、先更新数据库同时删除缓存项(key)，等读的时候再填充缓存</p><p>2、2秒后再删除一次缓存项(key)</p><p>3、设置缓存过期时间 Expired Time 比如 10秒 或1小时</p><p>4、将缓存删除失败记录到日志中，利用脚本提取失败记录再次删除（缓存失效期过长 7*24）</p><h3 id="缓存问题之数据并发竞争"><a href="#缓存问题之数据并发竞争" class="headerlink" title="缓存问题之数据并发竞争"></a><strong>缓存问题之数据并发竞争</strong></h3><p>这里的并发指的是多个redis的client同时set 同一个key引起的并发问题。多客户端（Jedis）同时并发写一个key，一个key的值是1，本来按顺序修改为2,3,4，最后是4，但是顺序变成了4,3,2，最后变成了2。</p><p><strong>第一种方案：分布式锁+时间戳</strong></p><p>准备一个分布式锁，大家去抢锁，抢到锁就做set操作。加锁的目的实际上就是把并行读写改成串行读写的方式，从而来避免资源竞争。</p><p>.Redis分布式锁的实现：主要用到的redis函数是setnx() ，通过SETNX实现分布式锁</p><p><img src="/posts/40341/assets/f537196a9fbc2c2731b5af86c832f1b6.webp" alt="img"></p><p><strong>第二种方案：利用消息队列</strong></p><p>在并发量过大的情况下,可以通过消息中间件进行处理,把并行读写进行串行化。 把Redis的set操作放在队列中使其串行化,必须的一个一个执行。</p><p><strong>Hot Key</strong></p><p>当有大量的请求(几十万)访问某个Redis某个key时，由于流量集中达到网络上限，从而导致这个redis的 服务器宕机。造成缓存击穿，接下来对这个key的访问将直接访问数据库造成数据库崩溃，或者访问数 据库回填Redis再访问Redis，继续崩溃。</p><p>如何发现热key</p><p>1、预估热key，比如秒杀的商品、火爆的新闻等</p><p>2、在客户端进行统计，实现简单，加一行代码即可</p><p>3、如果是Proxy，比如Codis，可以在Proxy端收集</p><p>4、利用Redis自带的命令，monitor、hotkeys。但是执行缓慢（不要用）</p><p>5、利用基于大数据领域的流式计算技术来进行实时数据访问次数的统计，比如 Storm、Spark Streaming、Flink，这些技术都是可以的。发现热点数据后可以写到zookeeper中。</p><p>如何处理热Key：</p><p>1、变分布式缓存为本地缓存 发现热key后，把缓存数据取出后，直接加载到本地缓存中。可以采用Ehcache、Guava Cache都可以，这样系统在访问热key数据时就可以直接访问自己的缓存了。（数据不要求时时一致）</p><p>2、在每个Redis主节点上备份热key数据，这样在读取时可以采用随机读取的方式，将访问压力负载到 每个Redis上。</p><p>3、利用对热点数据访问的限流熔断保护措施，每个系统实例每秒最多请求缓存集群读操作不超过 400 次，一超过就可以熔断掉，不让请求缓存集群，直接返回一个空白信息，然后用户稍后会自行再次重新刷新页面之类的。</p><p><strong>Big Key</strong></p><p>大key指的是存储的值（Value）非常大，比如热门话题下的讨论 大V的粉丝列表 序列化后的图片等等</p><p>造成的问题：</p><p>大key会大量占用内存，在集群中无法均衡</p><p>Redis的性能下降，主从复制异常</p><p>在主动删除或过期删除时会操作时间过长而引起服务阻塞</p><p>解决办法</p><p>1、 string类型的big key，尽量不要存入Redis中，可以使用文档型数据库MongoDB或缓存到CDN上。</p><p>2、 hash， set，zset，list 中存储过多的元素，可以将这些元素分拆。</p><p>3、 使用 lazy delete(unlink命令)删除，该命令会在另一个线程中 回收内存，因此它是非阻塞的。</p><h3 id="缓存与数据库的一致性"><a href="#缓存与数据库的一致性" class="headerlink" title="缓存与数据库的一致性"></a><strong>缓存与数据库的一致性</strong></h3><p><strong>缓存更新策略</strong></p><p>利用Redis的缓存淘汰策略被动更新 LRU 、LFU</p><p>利用TTL被动更新</p><p>在更新数据库时主动更新 （先更数据库再删缓存—-延时双删）</p><p>异步更新 定时任务 数据不保证时时一致 不穿DB</p><p><img src="/posts/40341/assets/abd4d56a47b3ad150330524c74e42675.webp" alt="img"></p><h3 id="Redis乐观锁"><a href="#Redis乐观锁" class="headerlink" title="Redis乐观锁"></a><strong>Redis乐观锁</strong></h3><p><strong>利用Watch实现Redis乐观锁</strong></p><p>乐观锁基于CAS（Compare And Swap）思想（比较并替换），是不具有互斥性，不会产生锁等待而消 耗资源，但是需要反复的重试，但也是因为重试的机制，能比较快的响应。</p><p>1、利用redis的watch功能，监控这个redisKey的状态值</p><p>2、获取redisKey的值</p><p>3、创建redis事务</p><p>4、给这个key的值+1</p><p>5、然后去执行这个事务，如果key的值被修改过则回滚，key不加1</p><h3 id="Redis分布式锁"><a href="#Redis分布式锁" class="headerlink" title="Redis分布式锁"></a><strong>Redis分布式锁</strong></h3><p><strong>Setnx</strong></p><p>共享资源互斥</p><p>共享资源串行化</p><p>单应用中使用锁：（单进程多线程） synchronized、ReentrantLock</p><p>分布式应用中使用锁：（多进程多线程）。 利用Redis的单线程特性对共享资源进行串行化处理。</p><p>方式1（使用set命令实现）–推荐</p><p><img src="/posts/40341/assets/4a2efe8e5547d492bac752e1ee30841a.webp" alt="img"></p><p>方式2（使用setnx命令实现） – 并发会产生问题</p><p><img src="/posts/40341/assets/1cd0a5fdacb0a8040e4b2d8e72e593fe.webp" alt="img"></p><p>释放锁 方式1（del命令实现） – 并发</p><p><img src="/posts/40341/assets/2e2393aa5611249fc2bb6b3cdba437ad.webp" alt="img"></p><p>释放锁 方式2（redis+lua脚本实现）–推荐</p><p><img src="/posts/40341/assets/14ebce26185daf9a69de82c1b01af9c4.webp" alt="img"></p><p>分布式锁是CP模型，Redis集群是AP模型。 (base) Redis集群不能保证数据的随时一致性，只能保证数据的最终一致性。</p><p>为什么还可以用Redis实现分布式锁？</p><p>与业务有关 当业务不需要数据强一致性时，比如：社交场景，就可以使用Redis实现分布式锁 当业务必须要数据的强一致性，即不允许重复获得锁，比如金融场景（重复下单，重复转账）就不要使用 可以使用CP模型实现，比如：zookeeper和etcd。</p><p><strong>Redisson分布式锁的实现原理</strong></p><p>如果该客户端面对的是一个redis cluster集群，他首先会根据hash节点选择一台机器。 发送lua脚本到redis服务器上。</p><p>那么在这个时候，如果客户端2来尝试加锁，第一个if判断会执行“exists myLock”，发现myLock这个锁key已经存在了。 接着第二个if判断，判断一下，myLock锁key的hash数据结构中，是否包含客户端2的ID，但是明显不 是的，因为那里包含的是客户端1的ID。此时客户端2会进入一个while循环，不停的尝试加锁。只要客户端1一旦加锁成功，就会启动一个watch dog看门狗，他是一个后台线程，会每隔10秒检查一 下，如果客户端1还持有锁key，那么就会不断的延长锁key的生存时间。</p><p><img src="https://pic1.zhimg.com/80/v2-11bf38cb188d27ace6d32cf6d3d3e13c_720w.webp" alt="img"></p><p><strong>分布式锁特性</strong></p><p>互斥性</p><p>任意时刻，只能有一个客户端获取锁，不能同时有两个客户端获取到锁。</p><p>同一性</p><p>锁只能被持有该锁的客户端删除，不能由其它客户端删除。</p><p>可重入性</p><p>持有某个锁的客户端可继续对该锁加锁，实现锁的续租 容错性 锁失效后（超过生命周期）自动释放锁（key失效），其他客户端可以继续获得该锁，防止死锁</p><p><strong>Zookeeper分布式锁的对比</strong></p><p><img src="/posts/40341/assets/1985b7c69e60da93863d104ae6631c97.webp" alt="img"></p><h3 id="五、Redis高可用方案"><a href="#五、Redis高可用方案" class="headerlink" title="五、Redis高可用方案"></a><strong>五、Redis高可用方案</strong></h3><h3 id="主从复制及实战"><a href="#主从复制及实战" class="headerlink" title="主从复制及实战"></a><strong>主从复制及实战</strong></h3><p>“高可用性”（High Availability）通常来描述一个系统经过专门的设计，从而减少停工时间，而保持其服 务的高度可用性。CAP的A AP模型 单机的Redis是无法保证高可用性的，当Redis服务器宕机后，即使在有持久化的机制下也无法保证不丢失数据。所以我们采用Redis多机和集群的方式来保证Redis的高可用性。</p><p><img src="https://pic3.zhimg.com/80/v2-767852afa61c17958e81baeec19b045a_720w.webp" alt="img"></p><p><strong>主从配置</strong></p><p>主Redis配置无需配置</p><p>从Redis配置修改从服务器上的 redis.conf 文件：</p><p><img src="/posts/40341/assets/47642f744a26dbefbdaa74bd3590a632.webp" alt="img"></p><p>作用：读写分离、数据容灾</p><p>原理与实现：</p><p>保存主节点信息，然后slaver与master建立socket连接，slaver关联文件事件处理器，该处理器接收RDB文件（全量复制）、接收Master传播来的写命令（增量复制），Slaver向Master发送ping命令，Master的响应：发送“pong” , 说明正常，主从正常连接后，进行权限验证，在身份验证步骤之后，从服务器将执行命令REPLCONF listening-port ，向主服务器发送从服务器的监听端口号，然后开始同步数据，当同步数据完成后，主从服务器就会进入命令传播阶段，主服务器只要将自己执行的写命令发送给从服务器，而从服务器只要一直执行并接收主服务器发来的写命令。</p><p><strong>同步数据集</strong></p><p>在Redis 2.8之后使用PSYNC命令，具备完整重同步和部分重同步模式。 Redis 的主从同步，分为全量同步和增量同步。 只有从机第一次连接上主机是全量同步。断线重连有可能触发全量同步也有可能是增量同步（ master 判断 runid 是否一致）。除此之外的情况都是增量同步。</p><p>Redis 的全量同步过程主要分三个阶段：同步快照阶段、同步写缓冲阶段、同步增量阶段</p><p>增量同步：Redis增量同步主要指Slave完成初始化后开始正常工作时， Master 发生的写操作同步到 Slave 的 过程。 通常情况下，Master 每执行一个写命令就会向 Slave 发送相同的写命令，然后 Slave 接收并执行。</p><p><strong>心跳检测</strong></p><p>在命令传播阶段，从服务器默认会以每秒一次的频率向主服务器发送命令，进行心跳检测。</p><p>\1. 检测主从的连接状态</p><p>\2. 辅助实现min-slaves</p><p>\3. 检测命令丢失</p><p><strong>主从配置实战</strong></p><p>第一步：创建master主、salver从文件夹</p><p>mkdir redis-master</p><p>mkdir redis-slaver1</p><p>mkdir redis-slaver2</p><p><img src="/posts/40341/assets/cbe08bef3d70fb1adbd0f181d25fa7bb.webp" alt="img"></p><p>第二步：进入redis安装目录安装redis</p><p>cd &#x2F;usr&#x2F;local&#x2F;redis-5.0.5&#x2F;src&#x2F;</p><p>make install PREFIX&#x3D;&#x2F;var&#x2F;redis-ms&#x2F;redis-master</p><p><img src="/posts/40341/assets/8adcffe8a16608af6fc320a65cdcbe7d.webp" alt="img"></p><p>第三步：拷贝redis.conf到master</p><p>cp &#x2F;usr&#x2F;local&#x2F;redis-5.0.5&#x2F;redis.conf &#x2F;var&#x2F;redis-ms&#x2F;redis-master&#x2F;bin</p><p><img src="https://pic3.zhimg.com/80/v2-506ecc88e8fa5f2d35ceda09390f0c62_720w.webp" alt="img"></p><p>第四步：编辑redis.conf</p><p>vim redis.conf</p><p># 将<code>daemonize</code>由<code>no</code>改为<code>yes</code> daemonize yes</p><p># bind 127.0.0.1</p><p># 是否开启保护模式，由yes该为no protected-mode no</p><p>第五步：把所有内容拷贝到从salver文件夹</p><p>cp -r &#x2F;var&#x2F;redis-ms&#x2F;redis-master&#x2F;* &#x2F;var&#x2F;redis-ms&#x2F;redis-slaver1cp -r &#x2F;var&#x2F;redis-ms&#x2F;redis-master&#x2F;* &#x2F;var&#x2F;redis-ms&#x2F;redis-slaver2</p><p>第六步：修改两从的redis.conf配置文件</p><p>cd &#x2F;var&#x2F;redis-ms&#x2F;redis-slaver1&#x2F;bin</p><p>vim redis.conf</p><p>#端口改为6380 6381</p><p>replicaof 127.0.0.1 6379 #添加这段配置，指定主服务器</p><p>第七步：启动所有主从节点</p><p>.&#x2F;redis-server redis.conf</p><p><img src="/posts/40341/assets/ca6ff6892082e648db893dda28230740.webp" alt="img"></p><p><img src="/posts/40341/assets/01ba2e3c1bc66b847435d8bbbd810d46.webp" alt="img"></p><p><img src="https://pic1.zhimg.com/80/v2-0eea50a9bfb4302dc70b6aa961e926b0_720w.webp" alt="img"></p><h3 id="哨兵模式及实战"><a href="#哨兵模式及实战" class="headerlink" title="哨兵模式及实战"></a><strong>哨兵模式及实战</strong></h3><p>哨兵（sentinel）是Redis的高可用性(High Availability)的解决方案： 由一个或多个sentinel实例组成sentinel集群可以监视一个或多个主服务器和多个从服务器。 当主服务器进入下线状态时，sentinel可以将该主服务器下的某一从服务器升级为主服务器继续提供服 务，从而保证redis的高可用性。</p><p><img src="https://pic3.zhimg.com/80/v2-ad84385c36c092d929f009c17d99d37e_720w.webp" alt="img"></p><p><strong>哨兵模式实战</strong></p><p>第一步：创建哨兵sentinel节点文件夹</p><p>mkdir redis-sentinel1</p><p>mkdir redis-sentinel2</p><p>mkdir redis-sentinel3</p><p><img src="https://pic1.zhimg.com/80/v2-952a042ed7eaefe765f884af71719544_720w.webp" alt="img"></p><p>第二步：拷贝redis到sentinel文件夹</p><p>cp -r &#x2F;var&#x2F;redis-ms&#x2F;redis-master&#x2F;* &#x2F;var&#x2F;redis-ms&#x2F;redis-sentinel1</p><p>cp -r &#x2F;var&#x2F;redis-ms&#x2F;redis-master&#x2F;* &#x2F;var&#x2F;redis-ms&#x2F;redis-sentinel2</p><p>cp -r &#x2F;var&#x2F;redis-ms&#x2F;redis-master&#x2F;* &#x2F;var&#x2F;redis-ms&#x2F;redis-sentinel2</p><p>第三步：拷贝sentinel.conf 配置文件并修改</p><p>cp &#x2F;usr&#x2F;local&#x2F;redis-5.0.5&#x2F;sentinel.conf &#x2F;var&#x2F;redis-ms&#x2F;redis-sentinel1&#x2F;bin&#x2F;</p><p>cp &#x2F;usr&#x2F;local&#x2F;redis-5.0.5&#x2F;sentinel.conf &#x2F;var&#x2F;redis-ms&#x2F;redis-sentinel2&#x2F;bin&#x2F;</p><p>cp &#x2F;usr&#x2F;local&#x2F;redis-5.0.5&#x2F;sentinel.conf &#x2F;var&#x2F;redis-ms&#x2F;redis-sentinel3&#x2F;bin&#x2F;</p><p><img src="/posts/40341/assets/a4f611c6abae6c3a533f5371e61f226f.webp" alt="img"></p><p>vim sentinel.conf</p><p># 哨兵sentinel实例运行的端口 默认26379</p><p># 将<code>daemonize</code>由<code>no</code>改为<code>yes</code></p><p># 哨兵sentinel监控的redis主节点的 ip port</p><p># master-name 可以自己命名的主节点名字 只能由字母A-z、数字0-9 、这三个字符”.-_”组成。</p><p># quorum 当这些quorum个数sentinel哨兵认为master主节点失联 那么这时 客观上认为主节点失联了</p><p># sentinel monitor</p><p>sentinel monitor mymaster 127.0.0.1 6379 2</p><p># 当在Redis实例中开启了requirepass foobared 授权密码 这样所有连接Redis实例的客户端都要提 供密码</p><p># 设置哨兵sentinel 连接主从的密码 注意必须为主从设置一样的验证密码</p><p># sentinel auth-pass</p><p>sentinel auth-pass mymaster MySUPER–secret-0123passw0rd</p><p># 指定多少毫秒之后 主节点没有应答哨兵sentinel 此时 哨兵主观上认为主节点下线 默认30秒，改成3 秒</p><p># sentinel down-after-milliseconds</p><p>sentinel down-after-milliseconds mymaster 3000</p><p>第四步：依次启动redis主从客户端和哨兵sentinel客户端</p><p>Redis主从启动：.&#x2F;redis-server redis.conf</p><p>Sentinel哨兵服务启动：.&#x2F;redis-sentinel sentinel.conf</p><p><img src="/posts/40341/assets/43f8f032338c597002c652ef1d7d187c.webp" alt="img"></p><p><strong>检测原理</strong></p><p>获取主服务器信息：Sentinel默认每10s一次，向被监控的主服务器发送info命令，获取主服务器和其下属从服务器的信息。</p><p>获取从服务器信息：当Sentinel发现主服务器有新的从服务器出现时，Sentinel还会向从服务器建立命令连接和订阅连接。 在命令连接建立之后，Sentinel还是默认10s一次，向从服务器发送info命令，并记录从服务器的信息。</p><p>向主服务器和从服务器发送消息(以订阅的方式)：默认情况下，Sentinel每2s一次，向所有被监视的主服务器和从服务器所订阅的—sentinel—:hello频道 上发送消息，消息中会携带Sentinel自身的信息和主服务器的信息。</p><p>接收来自主服务器和从服务器的频道信息：当Sentinel与主服务器或者从服务器建立起订阅连接之后，Sentinel就会通过订阅连接，向服务器发送命令。</p><p>检测主观下线状态：Sentinel每秒一次向所有与它建立了命令连接的实例(主服务器、从服务器和其他Sentinel)发送PING命 令 实例在down-after-milliseconds毫秒内返回无效回复(除了+PONG、-LOADING、-MASTERDOWN外) 实例在down-after-milliseconds毫秒内无回复（超时） Sentinel就会认为该实例主观下线(SDown)。</p><p>检查客观下线状态：当一个Sentinel将一个主服务器判断为主观下线后 Sentinel会向同时监控这个主服务器的所有其他Sentinel发送查询命令判断它们是否也认为主服务器下线。如果达到Sentinel配置中的quorum数量的Sentinel实例都判断主服 务器为主观下线，则该主服务器就会被判定为客观下线(ODown)。</p><p><strong>故障转移</strong></p><p>选举Leader Sentinel：当一个主服务器被判定为客观下线后，监视这个主服务器的所有Sentinel会通过选举算法（raft），选 出一个Leader Sentinel去执行failover（故障转移）操作。</p><p>Raft协议是用来解决分布式系统一致性问题的协议。 Raft协议描述的节点共有三种状态：Leader, Follower, Candidate。</p><p>选举流程： Raft采用心跳机制触发Leader选举 系统启动后，全部节点初始化为Follower，term为0。节点如果收到了RequestVote或者AppendEntries，就会保持自己的Follower身份，节点如果一段时间内没收到AppendEntries消息，在该节点的超时时间内还没发现Leader，Follower就会转换成Candidate，自己开始竞选Leader。如果在计时器超时前，节点收到多数节点的同意投票，就转换成Leader。同时向所有其他节点发送 AppendEntries，告知自己成为了Leader。</p><p>当选举出Leader Sentinel后，Leader Sentinel会对下线的主服务器执行故障转移操作，主要有三个步骤：</p><p>\1. 它会将失效 Master 的其中一个 Slave 升级为新的 Master , 并让失效 Master 的其他 Slave 改为复制新的 Master ；</p><p>\2. 当客户端试图连接失效的 Master 时，集群也会向客户端返回Master的地址，使得集群可以使用现在的 Master 替换失效 Master 。</p><p>\3. Master和 Slave服务器切换后， Master的redis.conf 、 Slave的redis.conf 和 sentinel.conf 的配置文件的内容都会发生相应的改变，即Master 主服务器的 redis.conf 配置文件中会多一行replicaof的配置， sentinel.conf 的监控目标会随之调换。</p><p><strong>主服务器的选择</strong></p><p>\1. 过滤掉主观下线的节点</p><p>\2. 选择slave-priority最高的节点，如果由则返回没有就继续选择</p><p>\3. 选择出复制偏移量最大的系节点，因为复制偏移量越大则数据复制的越完整，如果由就返回了，没有就继续</p><p>\4. 选择run_id最小的节点，因为run_id越小说明重启次数越少</p><p><img src="https://pic1.zhimg.com/80/v2-6045599d2798ac5defe24c96b1e772b8_720w.webp" alt="img"></p><h3 id="集群和分区特性"><a href="#集群和分区特性" class="headerlink" title="集群和分区特性"></a><strong>集群和分区特性</strong></h3><p>分区是将数据分布在多个Redis实例（Redis主机）上，以至于每个实例只包含一部分数据。</p><p>分区的意义：</p><p>\1. 单机Redis的网络I&#x2F;O能力和计算资源是有限的，将请求分散到多台机器，充分利用多台机器的计算能力 可网络带宽，有助于提高Redis总体的服务能力。</p><p>\2. 即使Redis的服务能力能够满足应用需求，但是随着存储数据的增加，单台机器受限于机器本身的存储 容量，将数据分散到多台机器上存储使得Redis服务可以横向扩展。</p><p><strong>分区方式</strong></p><p>范围分区：实现简单，方便迁移和扩展，但是热点数据分布不均，性能损失</p><p><img src="/posts/40341/assets/bb5aca91e44899ad5b2d25f779bdb3d5.webp" alt="img"></p><p>Hash分区</p><p>利用简单的hash算法，支持任何类型的key 热点分布较均匀，性能较好，但是迁移复杂，需要重新计算，扩展较差，可以使用一致性hash环解决。</p><p><img src="/posts/40341/assets/f04a8d86417a65ff836aaa24631accda.webp" alt="img"></p><h3 id="Client端分区"><a href="#Client端分区" class="headerlink" title="Client端分区"></a><strong>Client端分区</strong></h3><p>对于一个给定的key，客户端直接选择正确的节点来进行读写。许多Redis客户端都实现了客户端分区 (JedisPool)，也可以自行编程实现。</p><p>客户端选择算法：一致性hash</p><p>普通hash是对主机数量取模，而一致性hash是对2^32（4 294 967 296）取模。我们把2^32想象成一 个圆，就像钟表一样，钟表的圆可以理解成由60个点组成的圆，而此处我们把这个圆想象成由2^32个 点组成的圆，将缓存服务器与被缓存对象都映射到hash环上以后，从被缓存对象的位置出发，沿顺时针方向遇到的第 一个服务器，就是当前对象将要缓存于的服务器，由于被缓存对象与服务器hash后的值是固定的，所 以，在服务器不变的情况下，数据必定会被缓存到固定的服务器上，那么，当下次想要访问这个数据 时，只要再次使用相同的算法进行计算，即可算出这个数据被缓存在哪个服务器上，直接去对应的服务 器查找对应的数据即可。</p><p>优点：添加或移除节点时，数据只需要做部分的迁移，比如上图中把C服务器移除，则数据4迁移到服务器A 中，而其他的数据保持不变。并且通过虚拟节点可解决hash偏移量问题。</p><p>缺点 复杂度高 客户端需要自己处理数据路由、高可用、故障转移等问题，且不易扩展</p><h3 id="Proxy端分区"><a href="#Proxy端分区" class="headerlink" title="Proxy端分区"></a><strong>Proxy端分区</strong></h3><p>在客户端和服务器端引入一个代理或代理集群，客户端将命令发送到代理上，由代理根据算法，将命令 路由到相应的服务器上。常见的代理有Codis（豌豆荚）和TwemProxy（Twitter）。</p><p><strong>优点</strong></p><p>对客户端透明,与codis交互方式和redis本身交互一样</p><p>支持在线数据迁移,迁移过程对客户端透明有简单的管理和监控界面</p><p>支持高可用,无论是redis数据存储还是代理节点</p><p>自动进行数据的均衡分配</p><p>最大支持1024个redis实例,存储容量海量</p><p>高性能</p><p><strong>缺点</strong></p><p>采用自有的redis分支,不能与原版的redis保持同步</p><p>如果codis的proxy只有一个的情况下, redis的性能会下降20%左右</p><p>某些命令不支持</p><h3 id="官方RedisCluster分区"><a href="#官方RedisCluster分区" class="headerlink" title="官方RedisCluster分区"></a><strong>官方RedisCluster分区</strong></h3><p>Redis3.0之后，Redis官方提供了完整的集群解决方案。</p><p>方案采用去中心化的方式，包括：sharding（分区）、replication（复制）、failover（故障转移）。 称为RedisCluster。 Redis5.0前采用redis-trib进行集群的创建和管理，需要ruby支持 Redis5.0可以直接使用Redis-cli进行集群的创建和管理.</p><p><img src="/posts/40341/assets/1740c7c3ccda005c0d8808b7e23ea2cd.webp" alt="img"></p><p><strong>去中心化</strong></p><p>RedisCluster由多个Redis节点组构成，是一个P2P无中心节点的集群架构，依靠Gossip协议传播的集群。</p><p><strong>Gossip协议</strong></p><p>Gossip协议是一个通信协议，一种传播消息的方式。</p><p>通过gossip协议，cluster可以提供集群间状态同步更新、选举自助failover等重要的集群功能。</p><p><img src="/posts/40341/assets/d73d3d688fef59493b24963c569834bf.webp" alt="img"></p><p><strong>Slot</strong></p><p>redis-cluster把所有的物理节点映射到[0-16383]个slot上,基本上采用平均分配和连续分配的方式。</p><p><img src="/posts/40341/assets/d499784a03286e9814dc322f4d3d56f8.webp" alt="img"></p><p>当需要在 Redis 集群中放置一个 key-value 时，redis 先对 key 使用 crc16 算法算出一个结果，然后把 结果对 16384 求余数，这样每个 key 都会对应一个编号在 0-16383 之间的哈希槽，redis 会根据节点数 量大致均等的将哈希槽映射到不同的节点。</p><p><strong>RedisCluster的优势</strong></p><p>\1. 高性能 Redis Cluster 的性能与单节点部署是同级别的。 多主节点、负载均衡、读写分离</p><p>\2. 高可用 Redis Cluster 支持标准的 主从复制配置来保障高可用和高可靠。 failover Redis Cluster 也实现了一个类似 Raft 的共识方式，来保障整个集群的可用性。</p><p>\3. 易扩展 向 Redis Cluster 中添加新节点，或者移除节点，都是透明的，不需要停机。 水平、垂直方向都非常容易扩展。 数据分区，海量数据，数据存储</p><p>\4. 原生 部署 Redis Cluster 不需要其他的代理或者工具，而且 Redis Cluster 和单机 Redis 几乎完全兼 容。</p><h3 id="RedisCluster集群搭建实战"><a href="#RedisCluster集群搭建实战" class="headerlink" title="RedisCluster集群搭建实战"></a><strong>RedisCluster集群搭建实战</strong></h3><p>RedisCluster最少需要三台主服务器，三台从服务器。</p><p>第一步：创建相应集群目录文件夹，端口号7001-7006</p><p>mkdir redis-cluster</p><p>mkdir 7001</p><p>mkdir 7002</p><p>mkdir 7003</p><p>mkdir 7004</p><p>mkdir 7005</p><p>mkdir 7006</p><p><img src="/posts/40341/assets/cbd2980bc496a0d9c1d53a1ed71f40b6.webp" alt="img"></p><p>第二步：进入redis安装目录，给所有端口号文件夹安装redis</p><p>cd redis-5.0.5&#x2F;src&#x2F;</p><p>make install PREFIX&#x3D;&#x2F;usr&#x2F;local&#x2F;redis-cluster&#x2F;7001</p><p><img src="/posts/40341/assets/b81e44ee393d1ef8e02e6dce29f46157.webp" alt="img"></p><p>第三步：拷贝redis.conf到7001安装目录下</p><p>cp &#x2F;usr&#x2F;local&#x2F;redis-5.0.5&#x2F;redis.conf &#x2F;usr&#x2F;local&#x2F;redis-cluster&#x2F;7001&#x2F;bin</p><p><img src="https://pic3.zhimg.com/80/v2-5f74eeba3506caf607b1dfc5acb5d0be_720w.webp" alt="img"></p><p>第四步：修改redis.conf</p><p>vim redis.conf</p><p># bind 127.0.0.1 屏蔽127端口</p><p>#将<code>daemonize</code>由<code>no</code>改为<code>yes</code> daemonize yes</p><p>#是否开启保护模式，由yes该为no protected-mode no</p><p>#端口port改为7001</p><p>#打开cluster-enable yes</p><p><img src="/posts/40341/assets/d455a2f15e76706eadcca0e5f94fb695.webp" alt="img"></p><p>第五步：把redis.conf复制到其他节点并更改相应端口号</p><p>cp -r &#x2F;usr&#x2F;local&#x2F;redis-cluster&#x2F;7001&#x2F;* &#x2F;usr&#x2F;local&#x2F;redis-cluster&#x2F;7002</p><p>cp -r &#x2F;usr&#x2F;local&#x2F;redis-cluster&#x2F;7001&#x2F;* &#x2F;usr&#x2F;local&#x2F;redis-cluster&#x2F;7003</p><p>cp -r &#x2F;usr&#x2F;local&#x2F;redis-cluster&#x2F;7001&#x2F;* &#x2F;usr&#x2F;local&#x2F;redis-cluster&#x2F;7004</p><p>cp -r &#x2F;usr&#x2F;local&#x2F;redis-cluster&#x2F;7001&#x2F;* &#x2F;usr&#x2F;local&#x2F;redis-cluster&#x2F;7005</p><p>cp -r &#x2F;usr&#x2F;local&#x2F;redis-cluster&#x2F;7001&#x2F;* &#x2F;usr&#x2F;local&#x2F;redis-cluster&#x2F;7006</p><p>vim 7002&#x2F;bin&#x2F;redis.conf</p><p>第六步：创建start.sh批处理，启动所有的实例</p><p>cd 7001&#x2F;bin</p><p>.&#x2F;redis-server redis.conf</p><p>cd ..</p><p>cd ..</p><p>cd 7002&#x2F;bin</p><p>.&#x2F;redis-server redis.conf</p><p>cd ..</p><p>cd ..</p><p>cd 7003&#x2F;bin</p><p>.&#x2F;redis-server redis.conf</p><p>cd ..</p><p>cd ..</p><p>cd 7004&#x2F;bin</p><p>.&#x2F;redis-server redis.conf</p><p>cd ..</p><p>cd ..</p><p>cd 7005&#x2F;bin</p><p>.&#x2F;redis-server redis.conf</p><p>cd ..</p><p>cd ..</p><p>cd 7006&#x2F;bin</p><p>.&#x2F;redis-server redis.conf</p><p>cd ..</p><p>cd ..</p><p>第七步：执行赋写和执行的权限并启动RedisCluster</p><p>chmod u+x start.sh</p><p><img src="/posts/40341/assets/bab4fde8517641a524b55ad3113c2fa8.webp" alt="img"></p><p>.&#x2F;start.sh</p><p><img src="https://pic3.zhimg.com/80/v2-f64d79a82cf476a0047442bcd1a29682_720w.webp" alt="img"></p><p>第八步：创建Redis集群（创建时Redis里不要有数据）</p><p>.&#x2F;redis-cli –cluster create 47.106.138.46:7001 47.106.138.46:7002 47.106.138.46:7003 47.106.138.46:7004 47.106.138.46:7005 47.106.138.46:7006 –cluster-replicas 1</p><p>#–cluster create 集群创建</p><p>#做三主三从 前面三个ip做主 后面三个ip做从 采用物理IP地址</p><p>#–cluster-replicas 1 说明备份一份 也就是一主一从 如果一主两从则数字为2 三主IP后面要跟六从IP</p><p><img src="/posts/40341/assets/961a15f9488642f90af24cbbc47d202e.webp" alt="img"></p><p>cat nodes.conf #查看集群节点</p><p><img src="/posts/40341/assets/ee993415a094cd91c0664ad87abc2ae3.webp" alt="img"></p><p>第九步：命令客户端连接集</p><p>.&#x2F;redis-cli -h 127.0.0.1 -p 7001 -c</p><p>cluster nodes</p><p><img src="/posts/40341/assets/e901cf57e67f2cf55bdf879e76566a06.webp" alt="img"></p><p><img src="/posts/40341/assets/da2754ac8a8cee72edb84a093017afd3.webp" alt="img"></p><p><img src="https://pic3.zhimg.com/80/v2-5d50b23c0d76a5a2ba4d48ce04c0298a_720w.webp" alt="img"></p><p><strong>Redis集群扩容实战</strong></p><p>第一步：创建新增节点文件夹，并安装redis</p><p>mkdir 7007</p><p>cd redis-5.0.5&#x2F;src&#x2F;</p><p>make install PREFIX&#x3D;&#x2F;usr&#x2F;local&#x2F;redis-cluster&#x2F;7007</p><p>cp &#x2F;usr&#x2F;local&#x2F;redis-5.0.5&#x2F;redis.conf &#x2F;usr&#x2F;local&#x2F;redis-cluster&#x2F;7007&#x2F;bin</p><p>第二步：修改redis.conf配置文件</p><p>vim redis.conf</p><p># bind 127.0.0.1 屏蔽127端口</p><p>#将<code>daemonize</code>由<code>no</code>改为<code>yes</code> daemonize yes</p><p>#是否开启保护模式，由yes该为no protected-mode no</p><p>#端口port改为7007</p><p>#打开cluster-enable yes</p><p>第四步：拷贝至7008修改端口并启动7007客户端</p><p>cp -r 7007 7008</p><p>.&#x2F;redis-server redis.conf</p><p><img src="/posts/40341/assets/466e53594f9b6e77bcc72f44e823d3c5.webp" alt="img"></p><p>第五步：添加7007结点作为新节点</p><p>.&#x2F;redis-cli –cluster add-node 47.106.138.46:7007 47.106.138.46:7001</p><p><img src="/posts/40341/assets/ccfb6cd3e4cc970ece6c6336f292fb98.webp" alt="img"></p><p>第六步：hash槽重新分配（数据迁移）</p><p>.&#x2F;redis-cli –cluster reshard 47.106.138.46:7007</p><p>#输入要分配的槽数量</p><p>How many slots do you want to move (from 1 to 16384)? 2000</p><p>#输入接收槽的结点id</p><p>What is the receiving node ID?</p><p>#输入源结点id 也就是那些节点分槽给新节点</p><p>Please enter all the source node IDs.</p><p>Type ‘all’ to use all the nodes as source nodes for the hash slots. #全部分</p><p>Type ‘done’ once you entered all the source nodes IDs.#指定ID</p><p>第七步：启动7008从节点并添加进集群</p><p>.&#x2F;redis-server redis.conf</p><p>#.&#x2F;redis-cli –cluster add-node 新节点的ip和端口 旧节点ip和端口</p><p>#–cluster-slave – cluster-master-id 主节点id</p><p>.&#x2F;redis-cli –cluster add-node 47.106.138.46:7008 47.106.138.46:7007 –cluster-slave –cluster-master-id f3852ca45a0995b9a02488dbd2672aa1bbe93b55</p><p><img src="https://pic4.zhimg.com/80/v2-a54e5081fa0ebef312b83ca688849d6f_720w.webp" alt="img"></p><h3 id="分区路由"><a href="#分区路由" class="headerlink" title="分区路由"></a><strong>分区路由</strong></h3><p>不同节点分组服务于相互无交集的分片（sharding），Redis Cluster 不存在单独的proxy或配置服务 器，所以需要将客户端路由到目标的分片。</p><p><strong>客户端路由</strong></p><p>Redis Cluster的客户端相比单机Redis 需要具备路由语义的识别能力，且具备一定的路由缓存能力。</p><p><strong>moved重定向</strong></p><p>1.每个节点通过通信都会共享Redis Cluster中槽和集群中对应节点的关系</p><p>2.客户端向Redis Cluster的任意节点发送命令，接收命令的节点会根据CRC16规则进行hash运算与 16384取余，计算自己的槽和对应节点</p><p>3.如果保存数据的槽被分配给当前节点，则去槽中执行命令，并把命令执行结果返回给客户端</p><p>4.如果保存数据的槽不在当前节点的管理范围内，则向客户端返回moved重定向异常</p><p>5.客户端接收到节点返回的结果，如果是moved异常，则从moved异常中获取目标节点的信息</p><p>6.客户端向目标节点发送命令，获取命令执行结果</p><p><img src="/posts/40341/assets/999169200e2ced870f72913e1d76a2ed.webp" alt="img"></p><p><strong>ask重定向</strong></p><p>在对集群进行扩容和缩容时，需要对槽及槽中数据进行迁移 当客户端向某个节点发送命令，节点向客户端返回moved异常，告诉客户端数据对应的槽的节点信息 如果此时正在进行集群扩展或者缩空操作，当客户端向正确的节点发送命令时，槽及槽中数据已经被迁 移到别的节点了，就会返回ask，这就是ask重定向机制</p><p>1.客户端向目标节点发送命令，目标节点中的槽已经迁移支别的节点上了，此时目标节点会返回ask转 向给客户端 2.客户端向新的节点发送Asking命令给新的节点，然后再次向新节点发送命令</p><p>3.新节点执行命令，把命令执行结果返回给客户端</p><p><img src="https://pic4.zhimg.com/80/v2-7d8473b3427aed33888bd2d413d47b0b_720w.webp" alt="img"></p><p><strong>moved和ask的区别</strong></p><p>1、moved：槽已确认转移</p><p>2、ask：槽还在转移过程中</p><h3 id="节点添加"><a href="#节点添加" class="headerlink" title="节点添加"></a><strong>节点添加</strong></h3><p>在RedisCluster中每个slot 对应的节点在初始化后就是确定的。在某些情况下，节点和分片需要变更：</p><p>1.新的节点作为master加入；</p><p>2.某个节点分组需要下线；</p><p>3.负载不均衡需要调整slot 分布。</p><p>此时需要进行分片的迁移，迁移的触发和过程控制由外部系统完成。包含下面 2 种：</p><p>1.节点迁移状态设置：迁移前标记源&#x2F;目标节点。</p><p>2.key迁移的原子化命令：迁移的具体步骤。</p><p><img src="https://pic2.zhimg.com/80/v2-3661a2b06a78368064008a4adbb1a2d1_720w.webp" alt="img"></p><p>1、向节点B发送状态变更命令，将B的对应slot 状态置为importing。</p><p>2、向节点A发送状态变更命令，将A对应的slot 状态置为migrating。</p><p>3、向A 发送migrate 命令，告知A 将要迁移的slot对应的key 迁移到B。</p><p>4、当所有key 迁移完成后，cluster setslot 重新设置槽位。</p><p><strong>扩容实战</strong></p><h3 id="集群容灾"><a href="#集群容灾" class="headerlink" title="集群容灾"></a><strong>集群容灾</strong></h3><p><strong>故障检测</strong></p><p>集群中的每个节点都会定期地（每秒）向集群中的其他节点发送PING消息 如果在一定时间内(cluster-node-timeout)，发送ping的节点A没有收到某节点B的pong回应，则A将B 标识为pfail。 A在后续发送ping时，会带上B的pfail信息， 通知给其他节点。 如果B被标记为pfail的个数大于集群主节点个数的一半（N&#x2F;2 + 1）时，B会被标记为fail，A向整个集群 广播，该节点已经下线。 其他节点收到广播，标记B为fail。</p><p><strong>从节点选举</strong></p><p>raft，每个从节点，都根据自己对master复制数据的offset，来设置一个选举时间，offset越大（复制数据越多）的从节点，选举时间越靠前，优先进行选举。</p><p><strong>变更通知</strong></p><p>当slave 收到过半的master 同意时，会成为新的master。此时会以最新的Epoch 通过PONG 消息广播 自己成为master，让Cluster 的其他节点尽快的更新拓扑结构(node.conf)。</p><p><strong>副本漂移</strong></p><p>在一主一从的情况下，如果主从同时挂了，那整个集群就挂了，Redis提供了一种方法叫副本漂移，这种方法既能提高集群的可靠性又不用增加太多的从机。</p><p><img src="/posts/40341/assets/761b1496563350fcfeb4163a2fd74fb8.webp" alt="img"></p><p>Master1宕机，则Slaver11提升为新的Master1 集群检测到新的Master1是单点的（无从机），集群从拥有最多的从机的节点组（Master3）中，选择节点名称字母顺序最小的从机（Slaver31）漂移 到单点的主从节点组(Master1)。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;一、-Redis基础知识&quot;&gt;&lt;a href=&quot;#一、-Redis基础知识&quot; class=&quot;headerlink&quot; title=&quot;一、 Redis基础知识&quot;&gt;&lt;/a&gt;&lt;strong&gt;一、&lt;/strong&gt; &lt;strong&gt;Redis基础知识&lt;/strong&gt;&lt;/h3</summary>
      
    
    
    
    <category term="基础知识" scheme="https://itingyu.github.io/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    <category term="redis" scheme="https://itingyu.github.io/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/redis/"/>
    
    
    <category term="基础知识" scheme="https://itingyu.github.io/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    <category term="redis" scheme="https://itingyu.github.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>MongoDB</title>
    <link href="https://itingyu.github.io/posts/51937/"/>
    <id>https://itingyu.github.io/posts/51937/</id>
    <published>2023-06-17T11:40:25.000Z</published>
    <updated>2023-06-17T11:42:59.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="一、-MongoDB概念与结构"><a href="#一、-MongoDB概念与结构" class="headerlink" title="一、 MongoDB概念与结构"></a><strong>一、</strong> <strong>MongoDB概念与结构</strong></h3><h3 id="MongoDB体系结构"><a href="#MongoDB体系结构" class="headerlink" title="MongoDB体系结构"></a><strong>MongoDB体系结构</strong></h3><p>MongoDB 由C++编写而成，是一个介于关系数据库和非关系数据库之间的产品，是非关系数据库中功能最丰富、</p><p>最像关系数据库的。在高负载的情况下，通过添加更多的节点，可以保证服务器性能。</p><p><img src="https://pic4.zhimg.com/80/v2-654bbb8652e47f05da55752446e668cb_720w.webp" alt="img"></p><p><img src="/posts/51937/assets/ab957f657fc2259e7b04bf0225fcbb32.webp" alt="img"></p><h3 id="BSON结构"><a href="#BSON结构" class="headerlink" title="BSON结构"></a><strong>BSON结构</strong></h3><p>BSON是一种类json的一种二进制形式的存储格式，简称Binary JSON，它和JSON一样，支持内嵌的文档对象和数组对象，但是BSON有JSON没有的一些数据类型，如Date和Binary Data类型。具备轻量性、可遍历性、高效性三个特征。而MongoDB使用了BSON这种结构来存储数据和网络数据交换，他把这种格式转化成一文档这个概念(Document)，这里的一个Document也可以理解成关系数据库中的一条记录(Record)，并且可以嵌套。</p><p><img src="https://pic4.zhimg.com/80/v2-e8d4bc342d3ff3bfb700f79137e1ac77_720w.webp" alt="img"></p><h3 id="MongoDB的安装和启动"><a href="#MongoDB的安装和启动" class="headerlink" title="MongoDB的安装和启动"></a><strong>MongoDB的安装和启动</strong></h3><p>1） 创建mongodb文件夹：mkdir mongodb</p><p>2） 上传压缩包并解压：tar -zxvf mongodb-linux-x86_64-4.1.3.tgz</p><p><img src="/posts/51937/assets/c4c03ca6fdc03fecf079f3461b398cef.webp" alt="img"></p><p>3） 进入解压出来的目录文件中，建立多级目录db：mkdir -p &#x2F;data&#x2F;db</p><p><img src="/posts/51937/assets/9a8e10c9032b85f2016433dc8e30edff.webp" alt="img"></p><p>4） 启动MongoDB，执行命令：.&#x2F;bin&#x2F;mongod</p><p><img src="https://pic4.zhimg.com/80/v2-4f53bff151d65f87eec81ddf00c1019b_720w.webp" alt="img"></p><p>5） 另一种启动方式，以配置文件方式，先创建mongo.conf文件并设置配置参数：vi mongo.confdbpath&#x3D;&#x2F;data&#x2F;db&#x2F;</p><p>port&#x3D;27017</p><p>bind_ip&#x3D;0.0.0.0</p><p>fork&#x3D;true</p><p>logpath &#x3D; &#x2F;data&#x2F;db&#x2F;mongodb.log</p><p>logappend &#x3D; true</p><p>auth&#x3D;false</p><p>dbpath 数据库目录，默认&#x2F;data&#x2F;db</p><p>port 监听的端口，默认27017</p><p>bind_ip 监听IP地址，默认全部可以访问</p><p>fork 是否已后台启动的方式登陆</p><p>logpath 日志路径</p><p>logappend 是否追加日志</p><p>auth 是开启用户密码登陆</p><p>config 指定配置文件</p><p>6） 创建配置文件对应多级目录：mkdir -p data&#x2F;mongo，启动MongoDB：.&#x2F;bin&#x2F;mongod -f mongo.conf</p><p>7） 修复错误bin&#x2F;mongod –repair</p><h3 id="二、MongoDB命令和索引"><a href="#二、MongoDB命令和索引" class="headerlink" title="二、MongoDB命令和索引"></a><strong>二、MongoDB命令和索引</strong></h3><h3 id="MongoDB基本操作"><a href="#MongoDB基本操作" class="headerlink" title="MongoDB基本操作"></a><strong>MongoDB基本操作</strong></h3><p><strong>基本操作</strong></p><p>查看数据库 show dbs;</p><p>切换数据库 如果没有对应的数据库则创建 use 数据库名;</p><p>创建集合 db.createCollection(“集合名”)</p><p>查看集合 show tables; show collections;</p><p>删除集合 db.集合名.drop();</p><p>删除当前数据库 db.dropDatabase();</p><p><strong>数据添加</strong></p><p>插入单条、多条数据 db.集合名.insert(文档)、db.集合名.insert([文档,文档])</p><p>例如: db.lg_resume_preview.insert({name:”张晓峰”,city:”bj”})</p><p><strong>数据查询</strong></p><p>db.集合名.find(条件)</p><p>And条件 db.集合名.find({key1:value1, key2:value2}).pretty()</p><p>Or条件 db.集合名.find({$or:[{key1:value1}, {key2:value2}]}).pretty()</p><p>Not条件 db.集合名.find({key:{$not:{$操作符:value}}).pretty()</p><p>分页查询 db.集合名.find({条件}).sort({排序字段:排序方式})).skip(跳过的行数).limit(一页显示多少数据)</p><p><img src="/posts/51937/assets/c9d3e6e7cd255e3b23a1ad2619d98fee.webp" alt="img"></p><p><strong>数据更新</strong></p><p>db.集合名.update(</p><p><query>,</p><p><update>,</p><p>{</p><p>upsert: <boolean>,</p><p>multi: <boolean>,</p><p>writeConcern: <document></p><p>}</p><p>)</p><p>参数说明:</p><p>db.集合名.update({条件},{$set:{字段名:值}},{multi:true}</p><p>query : update的查询条件，类似sql update查询内where后面的。</p><p>update : update的对象和一些更新的操作符（如$set,$inc…）等，也可以理解为sql update中set后面的</p><p>upsert : 可选，如果不存在update的记录，是否插入objNew,true为插入，默认是false，不插入。</p><p>multi : 可选，MongoDB 默认是false,只更新找到的第一条记录，如果这个参数为true,就把按条件查出来多条记录全部更新。</p><p>writeConcern :可选，用来指定mongod对写操作的回执行为比如写的行为是否需要确认。</p><p><strong>数据删除</strong></p><p>db.collection.remove(</p><p><query>,</p><p>{</p><p>justOne: <boolean>,</p><p>writeConcern: <document></p><p>}</p><p>)</p><p>参数说明：</p><p>query :（可选）删除的文档的条件。</p><p>justOne : （可选）如果设为 true 或 1，则只删除一个文档，如果不设置该参数，或使用默认值</p><p>false，则删除所有匹配条件的文档。</p><p>writeConcern :（可选）用来指定mongod对写操作的回执行为。</p><h3 id="MongoDB聚合操作"><a href="#MongoDB聚合操作" class="headerlink" title="MongoDB聚合操作"></a><strong>MongoDB聚合操作</strong></h3><p>聚合是MongoDB的高级查询语言，它允许我们通过转化合并由多个文档的数据来生成新的在单个文档</p><p>里不存在的文档信息。一般都是将记录按条件分组之后进行一系列求最大值，最小值，平均值的简单操作，也可以对记录进行复杂数据统计，数据挖掘的操作。</p><p><strong>单目的聚合操作</strong></p><p>单目的聚合常用命令：count() 和 distinct()</p><p><strong>聚合管道</strong></p><p>统计数据(诸如统计平均值,求和等)，并返回计算后的数据结果。</p><p><img src="/posts/51937/assets/bf2f16aac932e1f2d30ad60a14c2879c.webp" alt="img"></p><p>常用操作:</p><p>$group：将集合中的文档分组，可用于统计结果。</p><p>$project：修改输入文档的结构。可以用来重命名、增加或删除域，也可以用于创建计算结果以及</p><p>嵌套文档。</p><p>$match：用于过滤数据，只输出符合条件的文档。$match使用MongoDB的标准查询操作。</p><p>$limit：用来限制MongoDB聚合管道返回的文档数。</p><p>$skip：在聚合管道中跳过指定数量的文档，并返回余下的文档。</p><p>$sort：将输入文档排序后输出。</p><p>$geoNear：输出接近某一地理位置的有序文档。</p><p><strong>MapReduce编程模型</strong></p><p>Pipeline查询速度快于MapReduce，但是MapReduce的强大之处在于能够在多台Server上并行执行复杂的聚合逻辑。MongoDB不允许Pipeline的单个聚合操作占用过多的系统内存，超过20%直接报错。</p><p><img src="/posts/51937/assets/81193c260c8be87afa8470f997e318a9.webp" alt="img"></p><p>参数说明：</p><p>map：是JavaScript 函数，负责将每一个输入文档转换为零或多个文档，生成键值对序列,作为reduce 函数参数</p><p>reduce：是JavaScript 函数，对map操作的输出做合并的化简的操作（将key-value变成keyvalues，也就是把values数组变成一个单一的值value）</p><p>out：统计结果存放集合</p><p>query： 一个筛选条件，只有满足条件的文档才会调用map函数。</p><p>sort： 和limit结合的sort排序参数（也是在发往map函数前给文档排序），可以优化分组机制</p><p>limit： 发往map函数的文档数量的上限（要是没有limit，单独使用sort的用处不大）</p><p>finalize：可以对reduce输出结果再一次修改</p><p>verbose：是否包括结果信息中的时间信息，默认为fasle</p><h3 id="MongoDB索引类型"><a href="#MongoDB索引类型" class="headerlink" title="MongoDB索引类型"></a><strong>MongoDB索引类型</strong></h3><p><strong>单键索引</strong> <strong>(Single Field)</strong></p><p>MongoDB的单键索引也就是我们熟悉的普通索引，可以在任何字段上创建，但是他自带一种TTL索引，也就是过期索引，可以设置时间并过期失效，只支持日期字段。</p><p>db.集合名.createIndex({“字段名”:排序方式})</p><p>db.集合名.createIndex({“日期字段”:排序方式}, {expireAfterSeconds: 秒数})</p><p><strong>复合索引(Compound Index)</strong></p><p>与mysql的复合索引相同，支持基于多个字段的索引。</p><p>db.集合名.createIndex( { “字段名1” : 排序方式, “字段名2” : 排序方式 } )</p><p><strong>多键索引(Multikey indexes)</strong></p><p>针对属性包含数组数据的情况，MongoDB支持针对数组中每一个element创建索引，Multikey</p><p>indexes支持strings，numbers和nested documents</p><p><strong>地理空间索引(Geospatial Index)</strong></p><p>针对地理空间坐标数据创建索引。</p><p>2dsphere索引，用于存储和查找球面上的点</p><p>2d索引，用于存储和查找平面上的点</p><p><img src="https://pic2.zhimg.com/80/v2-a8d35ded711b29784244491e95992325_720w.webp" alt="img"></p><p><strong>全文索引</strong></p><p>MongoDB提供了针对string内容的文本查询，Text Index支持任意属性值为string或string数组元素的 索引查询。注意:一个集合仅支持最多一个Text Index，中文分词推荐ES。</p><p>db.集合.createIndex({“字段”: “text”})</p><p>db.集合.find({“$text”: {“$search”: “coffee”}})</p><p><strong>哈希索引 Hashed Index</strong></p><p>针对属性的哈希值进行索引查询,当要使用Hashed index时，MongoDB能够自动的计算hash值。</p><p>db.集合.createIndex({“字段”: “hashed”})</p><h3 id="Explain参数及慢查询分析"><a href="#Explain参数及慢查询分析" class="headerlink" title="Explain参数及慢查询分析"></a><strong>Explain参数及慢查询分析</strong></h3><p><strong>索引管理</strong></p><p>创建：db.COLLECTION_NAME.createIndex({“字段”:排序方式}, {background: true});</p><p>获取集合所有索引：db.COLLECTION_NAME.getIndexes()</p><p>索引大小：db.COLLECTION_NAME.totalIndexSize()</p><p>重建：db.COLLECTION_NAME.reIndex()</p><p>删除：db.COLLECTION_NAME.dropIndex(“INDEX-NAME”)</p><p><strong>Explain执行计划分析</strong></p><p>设置不同参数可查看不同执行计划分析</p><p>queryPlanner：默认参数</p><p>executionStats：统计信息</p><p>allPlansExecution：所有执行计划信息</p><p><img src="/posts/51937/assets/0080697a7be6a726dda1cd413ad865c5.webp" alt="img"></p><p>1）第一层，executionTimeMillis最为直观explain返回值是executionTimeMillis值，指的是这条语句的执</p><p>行时间，这个值当然是希望越少越好。</p><p>其中有3个executionTimeMillis，分别是：</p><p>executionStats.executionTimeMillis 该query的整体查询时间。</p><p>executionStats.executionStages.executionTimeMillisEstimate 该查询检索document获得数据的时间。</p><p>executionStats.executionStages.inputStage.executionTimeMillisEstimate 该查询扫描文档 index</p><p>所用时间。</p><p>2）第二层，index与document扫描数与查询返回条目数 关注3个返回项 nReturned、</p><p>totalKeysExamined、totalDocsExamined，分别代表该条查询返回的条目、索引扫描条目、文档扫描</p><p>条目。直观的影响到executionTimeMillis耗时，我们需要扫描的越少速度越快。最理想的状态是：nReturned&#x3D;totalKeysExamined&#x3D;totalDocsExamined</p><p>3）第三层，stage状态分析。</p><p>所有类型如下：</p><p>COLLSCAN：全表扫描</p><p>IXSCAN：索引扫描</p><p>FETCH：根据索引去检索指定document</p><p>SHARD_MERGE：将各个分片返回数据进行merge</p><p>SORT：表明在内存中进行了排序</p><p>LIMIT：使用limit限制返回数</p><p>SKIP：使用skip进行跳过</p><p>IDHACK：针对_id进行查询</p><p>SHARDING_FILTER：通过mongos对分片数据进行查询</p><p>COUNT：利用db.coll.explain().count()之类进行count运算</p><p>TEXT：使用全文索引进行查询时候的stage返回</p><p>PROJECTION：限定返回字段时候stage的返回</p><p>优秀stage的组合(查询的时候尽可能用上索引)：</p><p>Fetch+IDHACK</p><p>Fetch+IXSCAN</p><p>Limit+（Fetch+IXSCAN）</p><p>PROJECTION+IXSCAN</p><p>SHARDING_FITER+IXSCAN</p><p>需要优化的组合：</p><p>COLLSCAN(全表扫描)</p><p>SORT(使用sort但是无index)</p><p>COUNT 不使用index进行count)</p><p><strong>慢查询分析</strong></p><p>1）开启内置的查询分析器,记录读写操作效率</p><p>db.setProfilingLevel(n,m),n的取值可选0,1,2</p><p>0表示不记录</p><p>1表示记录慢速操作,如果值为1,m必须赋值单位为ms,用于定义慢速查询时间的阈值</p><p>2表示记录所有的读写操作</p><p>2）查询监控结果</p><p>db.system.profile.find().sort({millis:-1}).limit(3)</p><p>3）分析慢速查询</p><p>应用程序设计不合理、不正确的数据模型、硬件配置问题,缺少索引等</p><p>4）解读explain结果，是否缺少索引</p><h3 id="MongoDB索引底层实现原理"><a href="#MongoDB索引底层实现原理" class="headerlink" title="MongoDB索引底层实现原理"></a><strong>MongoDB索引底层实现原理</strong></h3><p>MongoDB 是文档型的数据库，它使用BSON 格式保存数据，比关系型数据库存储更方便。</p><p><strong>MongoDB底层B-树</strong>：</p><p>1）多路非二叉树</p><p>2）每个节点既保存数据又保存索引</p><p>3）搜索时相当于二分查找</p><p><img src="https://pic2.zhimg.com/80/v2-c345fc430f5c63e7b002939367a014e1_720w.webp" alt="img"></p><p><strong>Mysql Innodb底层B+树：</strong></p><p>1）多路非二叉</p><p>2）只有叶子节点保存数据</p><p>3）搜索时也相当于二分查找</p><p>4）增加了相邻节点指针</p><p><img src="https://pic4.zhimg.com/80/v2-e201a60599e54f545bcc752bdb60046b_720w.webp" alt="img"></p><p><strong>比较差异：</strong></p><p>1）B+树相邻接点的指针可以大大增加区间访问性，可使用在范围查询等，而B-树每个节点 key 和 data 在一起 适合随机读写 ，而区间查找效率很差。</p><p>2）B+树更适合外部存储，也就是磁盘存储，使用B-结构的话，每次磁盘预读中的很多数据是用不上 的数据。因此，它没能利用好磁盘预读的提供的数据。由于节点内无 data 域，每个节点能索引的范围更大更精确。</p><p>3）注意这个区别相当重要，是基于（1）（2）的，B-树每个节点即保存数据又保存索引树的深度小，所以磁盘IO的次数很少，B+树只有叶子节点保存，较B树而言深度大磁盘IO多，但是区间访问比较 好。</p><h3 id="MongoDB的适用场景"><a href="#MongoDB的适用场景" class="headerlink" title="MongoDB的适用场景"></a><strong>MongoDB的适用场景</strong></h3><p><strong>使用场景</strong></p><p>● 网站数据：Mongo 非常适合实时的插入,更新与查询，并具备网站实时数据存储所需的复制及高 度伸缩性。</p><p>● 缓存：由于性能很高，Mongo 也适合作为信息基础设施的缓存层。在系统重启之后，由Mongo 搭建的持久化缓存层可以避免下层的数据源过载。</p><p>● 大尺寸、低价值的数据：使用传统的关系型数据库存储一些大尺寸低价值数据时会比较浪费， 在此之前，很多时候程序员往往会选择传统的文件进行存储。</p><p>● 高伸缩性的场景：Mongo 非常适合由数十或数百台服务器组成的数据库，Mongo 的路线图中 已经包含对MapReduce 引擎的内置支持以及集群高可用的解决方案。</p><p>● 用于对象及JSON 数据的存储：Mongo 的BSON 数据格式非常适合文档化格式的存储及查询。</p><p>1）游戏场景，使用 MongoDB 存储游戏用户信息，用户的装备、积分等直接以内嵌文档的形式存 储，方便查询、更新。</p><p>2）物流场景，使用 MongoDB 存储订单信息，订单状态在运送过程中会不断更新，以 MongoDB 内 嵌数组的形式来存储，一次查询就能将订单所有的变更读取出来。</p><p>3）社交场景，使用 MongoDB 存储存储用户信息，以及用户发表的朋友圈信息，通过地理位置索引 实现附近的人、地点等功能。</p><p>4）物联网场景，使用 MongoDB 存储所有接入的智能设备信息，以及设备汇报的日志信息，并对这 些信息进行多维度的分析。</p><p>5）直播，使用 MongoDB 存储用户信息、礼物信息等。</p><p><strong>使用条件</strong></p><p><img src="https://pic4.zhimg.com/80/v2-9776b06f1067fd9f43649194b61018c7_720w.webp" alt="img"></p><h3 id="三、MongoDB架构及集群高可用"><a href="#三、MongoDB架构及集群高可用" class="headerlink" title="三、MongoDB架构及集群高可用"></a><strong>三、MongoDB架构及集群高可用</strong></h3><h3 id="MongoDB存储引擎和数据模型"><a href="#MongoDB存储引擎和数据模型" class="headerlink" title="MongoDB存储引擎和数据模型"></a><strong>MongoDB存储引擎和数据模型</strong></h3><p><strong>存储引擎</strong></p><p>MongoDB底层使用了可插拔的存储引擎以满足用户的不同需要，与Mysql相同，最新版本使用WiredTiger 作为默认的存储引擎，WiredTiger 提供了不同粒度的并发控制和压缩机制，能够为不同种类的应用提供了最好的性能和存储率。</p><p><img src="https://pic4.zhimg.com/80/v2-d48a798485490aaa8586e4cf168f1457_720w.webp" alt="img"></p><p><strong>数据模型</strong></p><p>内嵌：把相关联的数据保存在同一个文档结构之中。</p><p>1.数据对象之间有包含关系 ,一般是数据对象之间有一对多或者一对一的关系 。</p><p>2.需要经常一起读取的数据。</p><p>3.有 map-reduce&#x2F;aggregation 需求的数据放在一起，这些操作都只能操作单个collection。</p><p>引用：通过存储数据引用信息来实现两个不同文档之间的关联。</p><p>1.当内嵌数据会导致很多数据的重复，并且读性能的优势又不足于覆盖数据重复的弊端 。</p><p>2.需要表达比较复杂的多对多关系的时候 。</p><p>3.大型层次结果数据集嵌套不要太深。</p><h3 id="MongoDB存储引擎"><a href="#MongoDB存储引擎" class="headerlink" title="MongoDB存储引擎"></a><strong>MongoDB存储引擎</strong></h3><p>存储引擎是MongoDB的核心组件，负责管理数据如何存储在硬盘和内存上。mongodb3.2开始默认的存储引擎是WiredTiger，3.2版本之前的默认存储引擎是MMAPv1。</p><p><strong>WiredTiger存储引擎优势</strong></p><p>1）文档空间分配方式： WiredTiger使用的是BTree存储 MMAPV1 线性存储 需要Padding</p><p>2）并发级别： WiredTiger 文档级别锁 MMAPV1引擎使用表级锁</p><p>3）数据压缩： snappy (默认) 和 zlib ,相比MMAPV1(无压缩) 空间节省数倍。</p><p>4）内存使用： WiredTiger 可以指定内存的使用大小。</p><p>5）Cache使用： WT引擎使用了二阶缓存WiredTiger Cache, File System Cache来保证Disk上的数据的最终一致性，而MMAPv1只有journal日志。</p><p><img src="/posts/51937/assets/96391be2f106ce04cece166e14de0878.webp" alt="img"></p><p><strong>WiredTiger存储引擎实现原理</strong></p><p>WiredTiger的写操作会默认写入 Cache ,并持久化到 WAL (Write Ahead Log)，每60s或Log文件达到2G 做一次checkpoint（就是把table中的元数据存储在临时文件中）产生快照文件。WiredTiger初始化时，恢复至最新的快照状态，然后再根据WAL 恢复数据，保证数据的完整性。WiredTiger采用Copy on write的方式管理写操作 （insert、update、delete），写操作会先缓存在cache里，持久化时，写操作不会在原来的leaf page 上进行，而是写入新分配的page，每次checkpoint都会产生一个新的root page。在数据库宕机时 , 为保证 MongoDB 中数据的持久性，MongoDB 使用了 Write Ahead Logging 向磁盘上的 journal 文件预先进行写入。除了journal 日志，MongoDB 还使用检查点（checkpoint）来保证数据的一致性。</p><p><img src="/posts/51937/assets/75ddd8592d652a3dbbff07ceb94f5dc3.webp" alt="img"></p><h3 id="MongoDB集群之复制集实战"><a href="#MongoDB集群之复制集实战" class="headerlink" title="MongoDB集群之复制集实战"></a><strong>MongoDB集群之复制集实战</strong></h3><p>MongoDB主从复制结构没有自动故障转移功能，需要指定master和slave端,存在一定缺陷，因此4.0后不再支持，建议使用复制集或者分片集群。</p><p>1） 建立复制集文件夹并将解压包放入并解压</p><p>mkdir replica-one</p><p>mv mongodb-linux-x86_64-4.1.3.tgz replica-one&#x2F;</p><p>tar -xvf mongodb-linux-x86_64-4.1.3.tgz</p><p>2） 进入解压文件夹，进行配置并创建对应文件夹</p><p>vi mongo_37017.conf</p><p><img src="/posts/51937/assets/65d5831aa0b41a0465b725c361ee1e69.webp" alt="img"></p><p>mkdir &#x2F;data&#x2F;mongo&#x2F;data&#x2F;server1 -p</p><p>mkdir &#x2F;data&#x2F;mongo&#x2F;logs -p</p><p>3）复制配置文件成集群并修改配置</p><p>cp mongo_37017.conf mongo_37018.conf</p><p>vi mongo_37018.conf</p><p>cp mongo_37017.conf mongo_37019conf</p><p>vi mongo_37019.conf</p><p>4）启动三个节点，进入任何一个节点进行配置命令</p><p>.&#x2F;bin&#x2F;mongod -f mongo_37017.conf</p><p>.&#x2F;bin&#x2F;mongod -f mongo_37018.conf</p><p>.&#x2F;bin&#x2F;mongod -f mongo_37019.conf</p><p>.&#x2F;bin&#x2F;mongo –port 37017</p><p>var cfg &#x3D;{“_id”:”lagouCluster”,</p><p>“protocolVersion” : 1,</p><p>“members”:[</p><p>{“_id”:1,”host”:” 47.106.138.46:37017”,”priority”:10},</p><p>{“_id”:2,”host”:” 47.106.138.46:37018”}</p><p>]</p><p>}rs.initiate(cfg)&#x2F;&#x2F;初始化</p><p>rs.reconfig(cfg) &#x2F;&#x2F;重新加载配置并生效</p><p>rs.addArb(“47.106.138.46:37020”)&#x2F;&#x2F;配置仲裁节点</p><p><img src="https://pic3.zhimg.com/80/v2-248db476e8080782d02519f1975f7f5a_720w.webp" alt="img"></p><p>rs.status()&#x2F;&#x2F;状态查看</p><p>rs.add(“47.106.138.46:37019”) &#x2F;&#x2F;增加节点</p><p>rs.remove(“47.106.138.46:37019”)&#x2F;&#x2F;删除slave节点</p><p>rs.slaveOk &#x2F;&#x2F;从节点查询之前同步命令</p><p><img src="https://pic4.zhimg.com/80/v2-cdd125ffdf47977abbf608e23060b0c7_720w.webp" alt="img"></p><h3 id="MongoDB集群之分片集群实战"><a href="#MongoDB集群之分片集群实战" class="headerlink" title="MongoDB集群之分片集群实战"></a><strong>MongoDB集群之分片集群实战</strong></h3><p>分片是MongoDB用来将大型集合水平分割到不同服务器或者复制集上所采用的方法。不需要功能强大的大型计算机就可以存储更多的数据，处理更大的负载。</p><p>工作原理</p><p><img src="https://pic3.zhimg.com/80/v2-3e3e0c1283f1fa32061817d7ab1fd21e_720w.webp" alt="img"></p><p>1） 解压安装包，搭建配置节点集群</p><p>tar -xvf mongodb-linux-x86_64-4.1.3.tgz &#x2F;&#x2F;解压命令</p><p>mv mongodb-linux-x86_64-4.1.3 shard_cluster &#x2F;&#x2F;重命名命令</p><p>2） 进入解压文件夹内，配置集群节点</p><p>mkdir cofig &#x2F;&#x2F;创建配置节点文件夹</p><p>vi config-17017.conf &#x2F;&#x2F;配置节点信息</p><p><img src="https://pic4.zhimg.com/80/v2-893fd535df7de594418b148fb5503bab_720w.webp" alt="img"></p><p>mkdir config1 logs &#x2F;&#x2F;建立配置信息文件夹</p><p>3） 以相同方式配置剩余两个配置节点</p><p>cp config-17017.conf config-17018.conf &#x2F;&#x2F;复制配置节点</p><p>vi config-17018.conf &#x2F;&#x2F;修改配置节点</p><p><img src="https://pic4.zhimg.com/80/v2-d7d86daf8c16a7e1a472ea25ad8e8caf_720w.webp" alt="img"></p><p>mkdir config2 &#x2F;&#x2F;创建对应配置文件夹</p><p>4） 启动配置节点</p><p>.&#x2F;bin&#x2F;mongod -f config&#x2F;config-17017.conf</p><p>.&#x2F;bin&#x2F;mongod -f config&#x2F;config-17018.conf</p><p>.&#x2F;bin&#x2F;mongod -f config&#x2F;config-17019.conf</p><p><img src="https://pic1.zhimg.com/80/v2-8f46bd26ba1e83aee16ea91a76b23904_720w.webp" alt="img"></p><p>5） 进入任意节点的mongo shell 并添加配置节点集群</p><p>.&#x2F;bin&#x2F;mongo –port 17017 &#x2F;&#x2F;进入节点库</p><p>use admin &#x2F;&#x2F;admin权限库配置才能生效</p><p>var cfg &#x3D;{“_id”:”configsvr”,</p><p>“members”:[</p><p>{“_id”:1,”host”:”47.106.138.46:17017”},</p><p>{“_id”:2,”host”:”47.106.138.46:17018”},</p><p>{“_id”:3,”host”:”47.106.138.46:17019”}]</p><p>};&#x2F;&#x2F;集群配置</p><p>rs.initiate(cfg) &#x2F;&#x2F;初始化生效</p><p><img src="/posts/51937/assets/019021e8714e4b1fd33d54ba6d87c1d9.webp" alt="img"></p><p>6） 配置shard集群，解压安装包到对应目录</p><p>tar -xvf mongodb-linux-x86_64-4.1.3.tgz</p><p>mkdir shard1 shard2 &#x2F;&#x2F;创建两个分片集群目录</p><p>mkdir shard1-37017 shard1-37018 shard1-37019 &#x2F;&#x2F;建立第一个集群的各节点目录</p><p>7） 配置集群节点信息</p><p>vi shard1-37017.conf</p><p><img src="https://pic3.zhimg.com/80/v2-63eb366a889c9afe3d173201ea60ee72_720w.webp" alt="img"></p><p>8） 依次配置第二第三个节点信息，然后启动所有节点并配置集群</p><p>.&#x2F;bin&#x2F;mongod -f shard&#x2F;shard1&#x2F;shard1-37017.conf</p><p>.&#x2F;bin&#x2F;mongod -f shard&#x2F;shard1&#x2F;shard1-37018.conf</p><p>.&#x2F;bin&#x2F;mongod -f shard&#x2F;shard1&#x2F;shard1-37019.conf</p><p>.&#x2F;bin&#x2F;mongo –port 37017 &#x2F;&#x2F;进入节点库</p><p>use admin &#x2F;&#x2F;admin权限库配置才能生效</p><p>var cfg &#x3D;{“_id”:”shard1”,</p><p>“protocolVersion” : 1,</p><p>“members”:[</p><p>{“_id”:1,”host”:”49.235.85.246:37017”},</p><p>{“_id”:2,”host”:”49.235.85.246:37018”},</p><p>{“_id”:3,”host”:”49.235.85.246:37019”}]</p><p>};&#x2F;&#x2F;集群配置</p><p>rs.initiate(cfg) &#x2F;&#x2F;初始化生效</p><p><img src="https://pic1.zhimg.com/80/v2-742abddaf64e240f34283e57da2fb394_720w.webp" alt="img"></p><p>9） 以相同方法配置另一个集群并启动所有节点</p><p>.&#x2F;bin&#x2F;mongod -f shard&#x2F;shard2&#x2F;shard2-47017.conf</p><p>.&#x2F;bin&#x2F;mongod -f shard&#x2F;shard2&#x2F;shard2-47018.conf</p><p>.&#x2F;bin&#x2F;mongod -f shard&#x2F;shard2&#x2F;shard2-47019.conf</p><p>.&#x2F;bin&#x2F;mongo –port 47017 &#x2F;&#x2F;进入节点库</p><p>var cfg &#x3D;{“_id”:”shard2”,</p><p>“protocolVersion” : 1,</p><p>“members”:[</p><p>{“_id”:1,”host”:”49.235.85.246:47017”},</p><p>{“_id”:2,”host”:”49.235.85.246:47018”},</p><p>{“_id”:3,”host”:”49.235.85.246:47019”}]</p><p>};&#x2F;&#x2F;集群配置</p><p>rs.initiate(cfg) &#x2F;&#x2F;初始化生效</p><p><img src="https://pic4.zhimg.com/80/v2-640b42edf0df6f311589c2244bdb1917_720w.webp" alt="img"></p><p>10）配置和启动路由节点</p><p>mkdir route logs &#x2F;&#x2F;创建路由配置文件夹及日志文件夹</p><p>vi route-27107.conf&#x2F;&#x2F;创建并配置以下路由配置信息</p><p>port&#x3D;27017</p><p>bind_ip&#x3D;0.0.0.0</p><p>fork&#x3D;true</p><p>logpath&#x3D;route&#x2F;logs&#x2F;route.log</p><p>configdb&#x3D;configsvr&#x2F;47.106.138.46:17017,47.106.138.46:17018,47.106.138.46:1701911）启动路由服务并配置分片集群路由信息</p><p>.&#x2F;bin&#x2F;mongos -f route&#x2F;route-27017.conf &#x2F;&#x2F;启动路由服务 注意是mongos</p><p>.&#x2F;bin&#x2F;mongo –port 27017 &#x2F;&#x2F;进入路由</p><p>sh.status() &#x2F;&#x2F;查看分片集群信息sh.addShard(“shard1&#x2F;49.235.85.246:37017,49.235.85.246:37018,49.235.85.246:37019”); sh.addShard(“shard2&#x2F;49.235.85.246:47017,49.235.85.246:47018,49.235.85.246:47019”);</p><p><img src="https://pic1.zhimg.com/80/v2-1f048418f893a5783facba1028b1ec80_720w.webp" alt="img"></p><p>12）开启数据库和集合分片完成分片集群配置</p><p>sh.enableSharding(“lg_resume”) &#x2F;&#x2F;为数据库开启分片功能sh.shardCollection(“lg_resume.lg_resume_data”,{“name”:”hashed”}) &#x2F;&#x2F;指定对应表的分片规则，语句规则是以字段name哈希分片，也可以范围分片</p><h3 id="四、MongoDB安全认证及数据监控"><a href="#四、MongoDB安全认证及数据监控" class="headerlink" title="四、MongoDB安全认证及数据监控"></a><strong>四、MongoDB安全认证及数据监控</strong></h3><h3 id="MongoDB安全认证实战"><a href="#MongoDB安全认证实战" class="headerlink" title="MongoDB安全认证实战"></a><strong>MongoDB安全认证实战</strong></h3><p>MongoDB默认没有账号的，可以直接连接，无须身份验证，实际项目中，在生产环境需要增加权限验证，保证数据安全。</p><p>1）切换到admin数据库添加用户，创建超级管理员</p><p>use admin;</p><p>db.createUser({</p><p>user: “root”,</p><p>pwd: “123456”,</p><p>roles: [{ role: “root”, db: “admin” }]</p><p>});</p><p>2） 为访问的库创建普通用户</p><p>use lg_resume &#x2F;&#x2F;切换到普通库</p><p>db.createUser({</p><p>user:”fangyf”,</p><p>pwd:”123456”,</p><p>roles:[{role:”readWrite”,db:”lagou_resume”}]</p><p>})3）关闭所有的分片节点和路由节点</p><p>yum install psmisc &#x2F;&#x2F;安装psmisckillall mongod &#x2F;&#x2F;快速关闭所有进程</p><p>4）生成密钥文件并修改权限</p><p>mkdir data&#x2F;mongodb -p &#x2F;&#x2F;创建文件夹</p><p>openssl rand -base64 756 &gt; data&#x2F;mongodb&#x2F;testKeyFile.file &#x2F;&#x2F;创建密钥文件chmod 600 data&#x2F;mongodb&#x2F;testKeyFile.file &#x2F;&#x2F;修改权限</p><p>5）配置节点集群和分片节点集群开启安全认证和指定密钥文件，所有配置文件追加auth&#x3D;true</p><p>keyFile&#x3D;data&#x2F;mongodb&#x2F;testKeyFile.file6）在路由配置文件中 设置密钥文件</p><p>keyFile&#x3D;data&#x2F;mongodb&#x2F;testKeyFile.file</p><p>7）依次启动所有的配置节点分片节点和路由节点使用路由进行权限验证.&#x2F;bin&#x2F;mongod -f config&#x2F;config-17017.conf</p><p>.&#x2F;bin&#x2F;mongod -f config&#x2F;config-17018.conf</p><p>.&#x2F;bin&#x2F;mongod -f config&#x2F;config-17019.conf</p><p>.&#x2F;bin&#x2F;mongod -f shard&#x2F;shard1&#x2F;shard1-37017.conf</p><p>.&#x2F;bin&#x2F;mongod -f shard&#x2F;shard1&#x2F;shard1-37018.conf</p><p>.&#x2F;bin&#x2F;mongod -f shard&#x2F;shard1&#x2F;shard1-37019.conf</p><p>.&#x2F;bin&#x2F;mongod -f shard&#x2F;shard2&#x2F;shard2-47017.conf</p><p>.&#x2F;bin&#x2F;mongod -f shard&#x2F;shard2&#x2F;shard2-47018.conf</p><p>.&#x2F;bin&#x2F;mongod -f shard&#x2F;shard2&#x2F;shard2-47019.conf</p><p>.&#x2F;bin&#x2F;mongos -f route&#x2F;route-27017.conf</p><p><strong>其他操作</strong></p><p>修改密码</p><p>db.changeUserPassword( ‘root’ , ‘rootNew’ );</p><p>用户添加角色</p><p>db.grantRolesToUser( ‘用户名’ , [{ role: ‘角色名’ , db: ‘数据库名’}])</p><p>以auth 方向启动mongod</p><p>.&#x2F;bin&#x2F;mongod -f conf&#x2F;mongo.conf –auth(在mongo.conf中添加auth&#x3D;true参数正常启动也可)</p><p>验证项目</p><p>db.auth(“账号”,”密码”)</p><p>删除项目</p><p>db.dropUser(“用户名”)</p><p>各个角色解析</p><p><img src="https://pic2.zhimg.com/80/v2-8579c1a7c2b11a5b6e1a2fdc933035e9_720w.webp" alt="img"></p><p><img src="https://pic3.zhimg.com/80/v2-0ee4f9af30567a0aa23228c0e7f12586_720w.webp" alt="img"></p><h3 id="MongoDB数据监控"><a href="#MongoDB数据监控" class="headerlink" title="MongoDB数据监控"></a><strong>MongoDB数据监控</strong></h3><p><strong>数据监控</strong></p><p>MongoDB Ops Manager(MMS) 用于监控和备份MongoDB的基础设施服务。</p><p>1)简易的自动化数据库部署、扩展、升级和任务管理;</p><p>2)通过 OPS 平台提供的超过 100 项仪表、图表，可以对 mongodb 进行多种监控;</p><p>3)支持单节点、分片集群的备份和恢复;</p><p><strong>数据备份</strong></p><p>支持定时备份及集群环境下全量加增量的备份和恢复</p><p><img src="https://pic1.zhimg.com/80/v2-93116f2029131707644068cf0e102ff0_720w.webp" alt="img"></p><p>在MongoDB 中我们使用mongodump命令来备份MongoDB数据。</p><p>命令：mongodump -h dbhost -d dbname -o dbdirectory</p><p>-h:ip加端口 -d:备份的实例 -o:备份数据存放位置</p><p>比如：.&#x2F;bin&#x2F;mongodump -h 127.0.0.1:37017 -d lg -o &#x2F;root&#x2F;bdatas</p><p><img src="https://pic2.zhimg.com/80/v2-ee9f4088d5546927cc2bb2a5c7880389_720w.webp" alt="img"></p><p><strong>数据恢复</strong></p><p>mongodb使用 mongorestore 命令来恢复备份的数据。</p><p>命令：mongorestore -h <hostname>&lt;:port&gt; -d dbname <path></p><p>-h:ip加端口 -d:恢复的实例 <path>备份数据所在位置</p><p>比如：.&#x2F;bin&#x2F;mongorestore -h 127.0.0.1:37017 -d lg &#x2F;root&#x2F;bdatas&#x2F;lg</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;一、-MongoDB概念与结构&quot;&gt;&lt;a href=&quot;#一、-MongoDB概念与结构&quot; class=&quot;headerlink&quot; title=&quot;一、 MongoDB概念与结构&quot;&gt;&lt;/a&gt;&lt;strong&gt;一、&lt;/strong&gt; &lt;strong&gt;MongoDB概念与结构&lt;</summary>
      
    
    
    
    <category term="基础知识" scheme="https://itingyu.github.io/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    <category term="mongoDB" scheme="https://itingyu.github.io/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/mongoDB/"/>
    
    
    <category term="基础知识" scheme="https://itingyu.github.io/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    <category term="mongoDB" scheme="https://itingyu.github.io/tags/mongoDB/"/>
    
  </entry>
  
  <entry>
    <title>分库分表</title>
    <link href="https://itingyu.github.io/posts/18707/"/>
    <id>https://itingyu.github.io/posts/18707/</id>
    <published>2023-06-17T11:30:44.000Z</published>
    <updated>2023-06-17T11:32:10.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="分库分表背景及解决方案"><a href="#分库分表背景及解决方案" class="headerlink" title="分库分表背景及解决方案"></a><strong>分库分表背景及解决方案</strong></h3><p><strong>背景及问题</strong></p><p>用户增多单库承受不住使用主从架构分担请求，业务复杂，写入请求增多，提高程序性能，分库分表读写分离。</p><p><strong>解决方案</strong></p><p>垂直拆分：分为垂直分库和垂直分表</p><p>1）垂直分库：比如一个库中保存用户和订单，由于量都非常大，可以分成两个库分别来保存用户和订单信息。</p><p>2）垂直分表：比如一张表保存了用户信息，其中还有用户介绍，可以把用户介绍这种大文本单独设计一张表，进行关联，需要的时候进行关联查询。</p><p>水平拆分：分为水平分库和水平分表</p><p>1）水平分库：单张表的数据切分到多个服务器上去，每个服务器具有相应的库与表，只是表中数据集合不同。</p><p>2）水平分表：针对数据量巨大的单张表（比如订单表），按照规则把一张表的数据切分到多张表里面去。</p><p>水平分表规则：</p><p>1） RANGE（时间、地域、大小）</p><p>2） HASH（ID取模）</p><p>3） 站内信（维度，即自己只能看见自己，单请求在一个库）</p><p>4） 用户表（范围、ID HASH均匀分布）</p><p>5） 流水表（时间维度）</p><p>主键规则：</p><p>1） UUID</p><p>2） 雪花算法</p><p>数据一致性：</p><p>1）强一致性：XA协议</p><p>2）最终一致性：TCC、saga、Seata</p><p>数据库扩容：</p><p>1）成倍增加数据节点，实现平滑扩容</p><p>2）成倍扩容以后，表中的部分数据请求已被路由到其他节点上面，可以清理掉</p><p>业务层改造：</p><p>1）基于代理层方式：Mycat、Sharding-Proxy、MySQL Proxy</p><p>2）基于应用层方式：Sharding-jdbc</p><p>分库后面临的问题：</p><p>1） 事务问题</p><p>2） 跨库跨表的join问题</p><p>3） 数据库扩容、维护成本变高</p><h3 id="ShardingSphere"><a href="#ShardingSphere" class="headerlink" title="ShardingSphere"></a><strong>ShardingSphere</strong></h3><p>Apache ShardingSphere是一款开源的分布式数据库中间件组成的生态圈，它由Sharding-JDBC、Sharding-Proxy和Sharding-Sidecar（规划中）这3款相互独立的产品组成。ShardingSphere定位为关系型数据库中间件，旨在充分合理地在分布式的场景下利用关系型数据库的 计算和存储能力，而并非实现一个全新的关系型数据库。</p><p><img src="/posts/18707/assets/1da5127b26533f6c5edfa51f46cb1e5c.webp" alt="img"></p><p>1） Sharding-JDBC：被定位为轻量级Java框架，在Java的JDBC层提供的额外服务，以jar包形式使用。</p><p>2） Sharding-Proxy：被定位为透明化的数据库代理端，提供封装了数据库二进制协议的服务端版 本，用于完成对异构语言的支持。</p><p>3） Sharding-Sidecar：被定位为Kubernetes或Mesos的云原生数据库代理，以DaemonSet的形式代 理所有对数据库的访问。</p><p><img src="/posts/18707/assets/38a47287c4f8df70c71ec02d8aab2338.webp" alt="img"></p><p><img src="https://pic2.zhimg.com/80/v2-85e6dc040ae2e7cd03c0496b2123aae1_720w.webp" alt="img"></p><h3 id="Sharding-JDBC"><a href="#Sharding-JDBC" class="headerlink" title="Sharding-JDBC"></a><strong>Sharding-JDBC</strong></h3><p>Sharding-JDBC定位为轻量级Java框架，在Java的JDBC层提供的额外服务。可理解为增强版的JDBC驱动，完全兼容JDBC和各种ORM 框架的使用。</p><p>1） 适用于任何基于Java的ORM框架，如：JPA, Hibernate, Mybatis, Spring JDBC Template或直接使 用JDBC。</p><p>2） 基于任何第三方的数据库连接池，如：DBCP, C3P0, BoneCP, Druid, HikariCP等。</p><p>3） 支持任意实现JDBC规范的数据库。目前支持MySQL，Oracle，SQLServer和PostgreSQL。</p><p><strong>Sharding-JDBC主要功能</strong></p><p>1） 数据分片：分库分表、读写分离、分片策略、分布式主键</p><p>2） 分布式事务：标准化事务接口、XA强一致性事务、柔性事务</p><p>3） 数据库治理：配置动态、服务治理、数据脱敏、链路追踪</p><p><strong>Sharding-JDBC 内部结构</strong></p><p><img src="/posts/18707/assets/1908b05ac9694014d2e5aead43cb22dc.webp" alt="img"></p><p>1） 黄色部分表示的是Sharding-JDBC的入口API，采用工厂方法的形式提供。</p><p>2） 蓝色部分表示的是Sharding-JDBC的配置对象，提供灵活多变的配置方式。</p><p>3） 红色部分表示的是内部对象，由Sharding-JDBC内部使用，应用开发者无需关注。</p><p><strong>Sharding-JDBC初始化流程</strong></p><p>1） 根据配置的信息生成Configuration对象</p><p>2） 通过Factory会将Configuration对象转化为Rule对象</p><p>3） 通过Factory会将Rule对象与DataSource对象封装</p><p>4） Sharding-JDBC使用DataSource进行分库分表和读写分离操作</p><p><strong>Sharding-JDBC 使用过程</strong></p><p>1） 引入maven依赖</p><p>2） 规则配置，Java，YAML，Spring命名空间和Spring Boot Starter四种方式配置</p><p>3） 通过ShardingDataSourceFactory工厂和规则配置对象获取ShardingDataSource，创建DataSource。</p><h3 id="数据分片核心概念"><a href="#数据分片核心概念" class="headerlink" title="数据分片核心概念"></a><strong>数据分片核心概念</strong></h3><p><strong>表概念</strong></p><p>1） 真实表 数据库中真实存在的物理表。例如b_order0、b_order1</p><p>2） 逻辑表 在分片之后，同一类表结构的名称（总成）。例如b_order。</p><p>3） 数据节点 在分片之后，由数据源和数据表组成。例如ds0.b_order1 绑定表</p><p>4） 绑定表 指的是分片规则一致的关系表（主表、子表），例如b_order和b_order_item，均按照 order_id分片，则此两个表互为绑定表关系。绑定表之间的多表关联查询不会出现笛卡尔积 关联，可以提升关联查询效率。</p><p>5） 广播表 广播表会在不同的数据节点上进行存储，存储 的表结构和数据完全相同，比如省份，字典表信息</p><p><strong>分片算法</strong></p><p>1） 精确分片算法PreciseShardingAlgorithm</p><p>2） 范围分片算法RangeShardingAlgorithm</p><p>3） 复合分片算法ComplexKeysShardingAlgorithm</p><p>4） Hint分片算法HintShardingAlgorithm</p><p><strong>分片策略</strong></p><p>1） 标准分片策略StandardShardingStrateg</p><p>2） 复合分片策略ComplexShardingStrategy</p><p>3） 行表达式分片策略InlineShardingStrateg</p><p>4） Hint分片策略HintShardingStrategy</p><p>5） 不分片策略NoneShardingStrategy</p><p><strong>分片策略配置</strong></p><p>1） 数据源分片策略</p><p>2） 表分片策略</p><h3 id="数据分片流程"><a href="#数据分片流程" class="headerlink" title="数据分片流程"></a><strong>数据分片流程</strong></h3><p><img src="https://pic4.zhimg.com/80/v2-66649837f5f00d3651792bdfbb73e5c3_720w.webp" alt="img"></p><p>1） SQL解析：SQL解析分为词法解析和语法解析。先通过词法解析器将SQL拆分为一个个不可再分的单词。再使 用语法解析器对SQL进行理解，并最终提炼出解析上下文。</p><p>2） 查询优化：负责合并和优化分片条件，如OR等。</p><p>3） SQL路由：根据解析上下文匹配用户配置的分片策略，并生成路由路径。</p><p>4） SQL改写：将SQL改写为在真实数据库中可以正确执行的语句。</p><p>5） SQL执行：通过多线程执行器异步执行SQL。</p><p>6） 结果归并：将多个执行结果集归并以便于通过统一的JDBC接口输出。</p><h3 id="数据分片SQL使用规范"><a href="#数据分片SQL使用规范" class="headerlink" title="数据分片SQL使用规范"></a><strong>数据分片SQL使用规范</strong></h3><p><strong>SQL使用规范</strong></p><p>1） 支持路由至单数据节点时，目前MySQL数据库100%全兼容，路由至多数据节点时，全面支持DQL、DML、DDL、DCL、TCL。</p><p>2） 路由至多数据节点不支持CASE WHEN、HAVING、UNION (ALL)。</p><p>3） 支持分页子查询，但其他子查询有限支持，无论嵌套多少层，只能解析第一层。</p><p>4） 由于归并的限制，子查询中包含聚合函数目前无法支持。</p><p>5） 不支持包含schema的SQL。</p><p>6） 当分片键处于运算表达式或函数中的SQL时，将采用全路由的形式获取结果。</p><p><strong>不支持的SQL示例</strong></p><p>INSERT INTO tbl_name (col1, col2, …) VALUES(1+2, ?, …) &#x2F;&#x2F;VALUES语句不支持运算表达式</p><p>INSERT INTO tbl_name (col1, col2, …) SELECT col1, col2, … FROM tbl_name WHERE col3 &#x3D; ? &#x2F;&#x2F;INSERT .. SELECT</p><p>SELECT COUNT(col1) as count_alias FROM tbl_name GROUP BY col1 HAVING count_alias &gt; ? &#x2F;&#x2F;HAVING</p><p>SELECT * FROM tbl_name1 UNION SELECT * FROM tbl_name2 &#x2F;&#x2F;UNION</p><p>SELECT * FROM tbl_name1 UNION ALL SELECT * FROM tbl_name2 &#x2F;&#x2F;UNION ALL</p><p>SELECT * FROM ds.tbl_name1 &#x2F;&#x2F;包含schema</p><p>SELECT SUM(DISTINCT col1), SUM(col1) FROM tbl_name &#x2F;&#x2F;同时使用普通聚合函数和DISTINCT</p><p>SELECT * FROM tbl_name WHERE to_date(create_time, ‘yyyy-mm-dd’) &#x3D; ? &#x2F;&#x2F;会导致全路由<strong>分页查询</strong></p><p>完全支持MySQL和Oracle的分页查询，SQLServer由于分页查询较为复杂，仅部分支持</p><h3 id="数据分片Inline行表达式"><a href="#数据分片Inline行表达式" class="headerlink" title="数据分片Inline行表达式"></a><strong>数据分片Inline行表达式</strong></h3><p>前面分片策略说到了行表达式分片策略InlineShardingStrateg，他就是采用Inline行表达式进行分片的配置，简化数据节点和分片算法配置信息。完成配置简化、配置一体化。</p><p><strong>语法格式</strong></p><p>使用${ expression }或$-&gt;{ expression }标识行表达式</p><p>${begin..end} 表示范围区间</p><p>${[unit1, unit2, unit_x]} 表示枚举值</p><p>行表达式中如果出现多个${}或$-&gt;{}表达式，整个表达式结果会将每个子表达式结果进行笛卡尔 (积)组合</p><p>${[‘online’, ‘offline’]}_table${1..3}</p><p>$-&gt;{[‘online’, ‘offline’]}_table$-&gt;{1..3}</p><p>上面语句解析结果-&gt;</p><p>online_table1, online_table2, online_table3,</p><p>offline_table1, offline_table2, offline_table3</p><p>均匀分布的数据节点</p><p><img src="https://pic4.zhimg.com/80/v2-970525f81dcee0eb53abe2a8c6fbf44b_720w.webp" alt="img"></p><p>用行表达式：</p><p>db${0..1}.b_order${1..2} 或者 db$-&gt;{0..1}.b_order$-&gt;{1..2}</p><p>自定义的数据节点</p><p><img src="https://pic3.zhimg.com/80/v2-bc0b721e0719a1089594b92fed97c0a6_720w.webp" alt="img"></p><p>用行表达式：</p><p>db0.b_order${0..1},db1.b_order${2..4}</p><p>分片算法配置，根据分片键进行计算的方式，返回相应的真实数据源或真实表名称。</p><p>ds${id % 10} 或者 ds$-&gt;{id % 10} -&gt;结果为：ds0、ds1、ds2… ds9</p><p>分布式主键</p><p>内置的分布式主键生成器，例如UUID、SNOWFLAKE，还抽离出分布式主键生成器的接口，方便用户自行实现自定义的自增主键生成器。</p><p><img src="/posts/18707/assets/5008b8352d711136af6b2c72d25f6b18.webp" alt="img"></p><h3 id="读写分离及架构设计方案"><a href="#读写分离及架构设计方案" class="headerlink" title="读写分离及架构设计方案"></a><strong>读写分离及架构设计方案</strong></h3><p>读写分离是通过主从的配置方式，将查询请求均匀的分散到多个数据副本，进一步的提升系统的处理能力。</p><p><img src="/posts/18707/assets/3f6e77e7910e69624d773f575bb6b280.webp" alt="img"></p><p>主从架构：读写分离，目的是高可用、读写扩展。主从库内容相同，根据SQL语义进行路由。</p><p>分库分表架构：数据分片，目的读写扩展、存储扩容。库和表内容不同，根据分片配置进行路由。</p><p>读写分离虽然可以提升系统的吞吐量和可用性，但同时也带来了数据不一致的问题，包括多个主库之间的数据一致性，以及主库与从库之间的数据一致性的问题。</p><p><strong>架构设计方案</strong></p><p>方案一（第一阶段-&gt;一主两从）：数据量不是很多的情况下，我们可以将数据库进行读写分离，以应对高并发的需求，通过水平扩展从库，来缓解查询的压力。</p><p><img src="/posts/18707/assets/70512a8c6564c421ee37993b78df04e3.webp" alt="img"></p><p>方案二（第二阶段-&gt;主从加分表）：数据量达到500万的时候，数据量预估千万级别，将数据进行分表存储。</p><p><img src="https://pic4.zhimg.com/80/v2-5652a6faac34d6c8e90b4b99b5e10d23_720w.webp" alt="img"></p><p>方案三（最终阶段-&gt;分库分表加读写分离）：如果方案二不满足需求，数据量继续扩大，这时考虑分库分表，将数据存储在不同数据库的不同表中。</p><p><img src="https://pic2.zhimg.com/80/v2-ae1491e1e88ab8c63cd6644e53fe0f59_720w.webp" alt="img"></p><p>ShardingSphere读写分离模块的主要设计目标是让使用方尽量像使用一个数据库一样使用主从数据库集群，即规则让关联数据在同一个库中，避免跨库调用。</p><p>ShardingSphere核心功能</p><p>1） 提供一主多从的读写分离配置。仅支持单主库，可以支持独立使用，也可以配合分库分表使用</p><p>2） 独立使用读写分离，支持SQL透传。不需要SQL改写流程</p><p>3） 同一线程且同一数据库连接内，能保证数据一致性。如果有写入操作，后续的读操作均从主库读取。</p><p>4） 基于Hint的强制主库路由。可以强制路由走主库查询实时数据，避免主从同步数据延迟。</p><p>ShardingSphere不支持项</p><p>1） 主库和从库的数据同步</p><p>2） 主库和从库的数据同步延迟</p><p>3） 主库双写或多写</p><p>4） 跨主库和从库之间的事务的数据不一致。建议在主从架构中，事务中的读写均用主库操作，使用Hint强制路由。</p><h3 id="强制路由Hint"><a href="#强制路由Hint" class="headerlink" title="强制路由Hint"></a><strong>强制路由Hint</strong></h3><p>分片条件并不存在于SQL，而存在于外部业务逻辑，使用Hint指定了强制分片路由，那么SQL将会无视原有的分片逻辑，直接路由至指定的数据节点操作，比如事务操作，要求读写都在主库。</p><p>使用步骤：</p><p>1） 编写分库或分表路由策略，实现HintShardingAlgorithm接口</p><p>2） 在配置文件指定分库或分表策略</p><p>3） 在代码执行查询前使用HintManager指定执行策略值</p><h3 id="数据脱敏"><a href="#数据脱敏" class="headerlink" title="数据脱敏"></a><strong>数据脱敏</strong></h3><p>数据脱敏是指对某些敏感信息通过脱敏规则进行数据的变形，实现敏感隐私数据的可靠保护，其实就是加密。</p><p><img src="https://pic2.zhimg.com/80/v2-95ef39ead87ec9430908a06c5b3ba09d_720w.webp" alt="img"></p><p>脱敏配置四部分：数据源配置，加密器配置，脱敏表配置以及查询属性配置</p><p><img src="/posts/18707/assets/b13354cfcb0a7e5fda7fb68844bdb413.webp" alt="img"></p><p>数据源配置：指DataSource的配置信息</p><p>加密器配置：指使用什么加密策略进行加解密。目前ShardingSphere内置了两种加解密策略： AES&#x2F;MD5</p><p>脱敏表配置：指定哪个列用于存储密文数据（cipherColumn）、哪个列用于存储明文数据 （plainColumn）以及用户想使用哪个列进行SQL编写（logicColumn）</p><p>查询属性的配置：当底层数据库表里同时存储了明文数据、密文数据后，该属性开关用于决定是直 接查询数据库表里的明文数据进行返回，还是查询密文数据通过Encrypt-JDBC解密后返回。</p><p><strong>加密策略解析</strong></p><p>ShardingSphere提供了两种加密策略用于数据脱敏，该两种策略分别对应ShardingSphere的两种加解 密的接口，即Encryptor和QueryAssistedEncryptor。</p><p>Encryptor：提供encrypt(), decrypt()两种方法对需要脱敏的数据进行加解密。</p><p>QueryAssistedEncryptor：即使是相同的数据，如两个用户的密码相同，它们在数据库里存储的脱敏数据也应当是不一样的。</p><h3 id="分布式事务理论CAP和BASE"><a href="#分布式事务理论CAP和BASE" class="headerlink" title="分布式事务理论CAP和BASE"></a><strong>分布式事务理论CAP和BASE</strong></h3><p><strong>CAP（强一致性）</strong></p><p>布鲁尔定理。对于共享数据系统，最多只能同时拥有CAP其中的两个</p><p><img src="https://pic4.zhimg.com/80/v2-92d88f53b7a320a293599a3e8f4a719b_720w.webp" alt="img"></p><p><strong>BASE（最终一致性）</strong></p><p>基本可用（Basically Available）、软状态（ Soft State）、最终一致性（ Eventual Consistency）。它的核心思想是即使无法做到强一致性（CAP 就是强一致性），但应用可以采用适合的方式达到最终一致性。</p><p>BA指的是基本业务可用性，支持分区失败；</p><p>S表示柔性状态，也就是允许短时间内不同步；</p><p>E表示最终一致性，数据最终是一致的，但是实时是不一致的。</p><h3 id="分布式事务模式2PC和3PC"><a href="#分布式事务模式2PC和3PC" class="headerlink" title="分布式事务模式2PC和3PC"></a><strong>分布式事务模式2PC和3PC</strong></h3><p><strong>2PC模式（强一致性）</strong></p><p>两阶段提交，就是将事务的提交过程分为两个阶段来进行处理。事务的发起者称协调者，事务的执行者称参与者。</p><p>1） 阶段 1：准备阶段 协调者向所有参与者发送事务内容，询问是否可以提交事务，并等待所有参与者答复。 各参与者执行事务操作，但不提交事务，将 undo 和 redo 信息记入事务日志中。 如参与者执行成功，给协调者反馈 yes；如执行失败，给协调者反馈 no。</p><p>2） 阶段 2：提交阶段 如果协调者收到了参与者的失败消息或者超时，直接给每个参与者发送回滚(rollback)消息； 否则，发送提交(commit)消息。</p><p>2PC 方案存在的问题</p><p>1） 性能问题：所有参与者在事务提交阶段处于同步阻塞状态，占用系统资源，容易导致性能瓶颈。</p><p>2） 可靠性问题：如果协调者存在单点故障问题，如果协调者出现故障，参与者将一直处于锁定状态。</p><p>3） 数据一致性问题：在阶段 2 中，如果发生局部网络问题，一部分事务参与者收到了提交消息，另一部分事务参与者没收到提交消息，那么就导致了节点之间数据的不一致。</p><p><strong>3PC模式（强一致性）</strong></p><p>两阶段提交的改进版本，引入超时机制，将两阶段的准备阶段拆分为 2 个阶段，插入了一个 preCommit 阶段。</p><p>1） 阶段1：canCommit 协调者向参与者发送 commit 请求，参与者如果可以提交就返回 yes 响应，否则返回 no 响应。</p><p>2） 阶段2：preCommit 协调者根据阶段 1 canCommit 参与者的反应情况执行预提交事务或中断事务操作。 参与者均反馈 yes：协调者向所有参与者发出 preCommit 请求，参与者收到 preCommit 请求后，执行事务操作，但不提交；将 undo 和 redo 信息记入事务日志 中；各参与者向协调者反馈 ack 响应或 no 响应，并等待最终指令。 任何一个参与者反馈 no或等待超时：协调者向所有参与者发出 abort 请求，无论收到协调者发出的 abort 请求，或者在等待协调者请求过程中出现超时，参与者均会中断事务。</p><p>3） 阶段3：do Commit 该阶段进行真正的事务提交，根据阶段 2 preCommit反馈的结果完成事务提交或中断操作。</p><h3 id="Sharding-JDBC整合XA原理"><a href="#Sharding-JDBC整合XA原理" class="headerlink" title="Sharding-JDBC整合XA原理"></a><strong>Sharding-JDBC整合XA原理</strong></h3><p>ShardingSphere整合XA事务时，分离了XA事务管理和连接池管理，这样接入XA时，可以做到对业务的零侵入，而且ShardingSphere集成后，可保证分片后跨库事务强一致性，XA本身也是强一致性的。</p><p><img src="/posts/18707/assets/71d6f92281887a760d4315815785c90d.webp" alt="img"></p><p>执行步骤：</p><p>1） Begin（开启XA全局事务）：调用具体的XA事务管理器开启XA的全局事务。</p><p>2） 执行物理SQL：将所有SQL操作，标记为XA事务。</p><p>3） Commit&#x2F;rollback（提交XA事务）：收集所有投票，全部收到提交，否则回滚。</p><h3 id="Sharding-JDBC整合Saga原理"><a href="#Sharding-JDBC整合Saga原理" class="headerlink" title="Sharding-JDBC整合Saga原理"></a><strong>Sharding-JDBC整合Saga原理</strong></h3><p>ShardingSphere是基于反向SQL技术实现的反向补偿操作，它将对数据库进行更新操作的SQL自动生成反向SQL，并交由Saga-actuator引擎执行。</p><p><img src="/posts/18707/assets/0a5385d5d250c819e0fecdf8bc3e65e6.webp" alt="img"></p><p>执行步骤：</p><p>1） Init（Saga引擎初始化）</p><p>2） Begin（开启Saga全局事务）：记录了所有子事务的正向SQL和逆向SQL</p><p>3） 执行物理SQL</p><p>4） Commit&#x2F;rollback（提交Saga事务）：生成Saga执行引擎所需的调用链路图，然后进行提交或回滚</p><h3 id="Sharding-JDBC整合Seata原理"><a href="#Sharding-JDBC整合Seata原理" class="headerlink" title="Sharding-JDBC整合Seata原理"></a><strong>Sharding-JDBC整合Seata原理</strong></h3><p>分布式事务的实现目前主要分为两阶段的XA强事务和BASE柔性事务。</p><p><img src="/posts/18707/assets/8b41bdfff12e7250a2047c091bb07fae.webp" alt="img"></p><p>整合Seata AT事务时，需要把TM，RM，TC的模型融入到ShardingSphere 分布式事务的SPI的生态中。在数据库资源上，Seata通过对接DataSource接口，让JDBC操作可以同TC进行RPC通信。</p><p><img src="/posts/18707/assets/a971a98d4aa5946d3347765dbbf84f7b.webp" alt="img"></p><p>执行步骤：</p><p>1） Init（Seata引擎初始化）：包含Seata柔性事务的应用启动时，用户配置的数据源会按seata.conf的配置，适配成Seata事务所 需的DataSourceProxy，并且注册到RM中。</p><p>2） Begin（开启Seata全局事务）：TM控制全局事务的边界，TM通过向TC发送Begin指令，获取全局事务ID，所有分支事务通过此全 局事务ID，参与到全局事务中；全局事务ID的上下文存放在当前线程变量中。</p><p>3） 执行分片物理SQL ：处于Seata全局事务中的分片SQL通过RM生成undo快照，并且发送participate指令到TC，加入到全局事务中。ShardingSphere的分片物理SQL是按多线程方式执行，因此整合Seata AT事务时， 需要在主线程和子线程间进行全局事务ID的上下文传递，这同服务间的上下文传递思路完全相同。</p><p>4） Commit&#x2F;rollback（提交Seata事务）：提交Seata事务时，TM会向TC发送全局事务的commit和rollback指令，TC根据全局事务ID协调所有分支事务进行commit和rollback。</p><h3 id="ShardingSphere-SPI-加载"><a href="#ShardingSphere-SPI-加载" class="headerlink" title="ShardingSphere SPI 加载"></a><strong>ShardingSphere SPI 加载</strong></h3><p>Apache ShardingSphere所有通过SPI方式载入的功能模块：</p><p>1） SQL解析接口：用于规定用于解析SQL的ANTLR语法文件</p><p>2） 数据库协议接口：用于Sharding-Proxy解析与适配访问数据库的协议</p><p>3） 数据脱敏接口：用于规定加解密器的加密、解密、类型获取、属性设置等方式</p><p>4） 分布式主键接口：用于规定如何生成全局性的自增、类型获取、属性设置等。</p><p>5） 分布式事务接口：用于规定如何将分布式事务适配为本地事务接口。</p><p>6） XA事务管理器接口：用于规定如何将XA事务的实现者适配为统一的XA事务接口。</p><p>7） 注册中心接口：用于规定注册中心初始化、存取数据、更新数据、监控等行为。</p><h3 id="ShardingSphere-编排治理"><a href="#ShardingSphere-编排治理" class="headerlink" title="ShardingSphere 编排治理"></a><strong>ShardingSphere 编排治理</strong></h3><p>提供配置中心&#x2F;注册中心（以及规划中的元数据中心）、配置动态化、数据库熔断禁用、 调用链路等治理能力。</p><p>1） 配置中心：将配置集中于配置中心，可以更加有效进行管理，并且支持数据源、表与分片及读写分离策略的动态切换。</p><p>2） 注册中心：存放运行时的动态&#x2F;临时状态数据，比如可用的proxy的实例，需要禁用或熔断的datasource实例。可以提供熔断数据库访问程序对数据库的访问和禁用从库的访问的编排治理能力。</p><p>3） 支持外部配置中心和注册中心扩展，基于SPI机制，比如Zookeeper、Nocas等等。</p><p>4） 应用性能监控：对分布式系统的性能诊断，包含调用链展示，应用拓扑分析等。</p><h3 id="Sharding-Proxy"><a href="#Sharding-Proxy" class="headerlink" title="Sharding-Proxy"></a><strong>Sharding-Proxy</strong></h3><p>Sharding-Proxy是ShardingSphere的第二个产品，定位为透明化的数据库代理端，提供封装了数据库二进制协议的服务端版本，用于完成对异构语言的支持，也就是一个代理组件，可以对其他语言使用，不只是JAVA，便于扩展，不过Sharding-Proxy 默认不支持hint。</p><p><img src="https://pic2.zhimg.com/80/v2-3b4894ab94f32cd419dd4518b6e6223d_720w.webp" alt="img"></p><p>Sharding-Proxy使用过程：</p><p>1） 下载Sharding-Proxy的最新发行版；</p><p>2） 解压缩后修改conf&#x2F;server.yaml和以config-前缀开头的文件，进行分片规则、读写分离规则配置 编辑%SHARDING_PROXY_HOME%\conf\config-xxx.yaml 编辑%SHARDING_PROXY_HOME%\conf\server.yaml</p><p>3） 引入依赖jar 如果后端连接MySQL数据库，需要下载MySQL驱动， 解压缩后将mysql-connector-java5.1.48.jar拷贝到${sharding-proxy}\lib目录。 如果后端连接PostgreSQL数据库，不需要引入额外依赖。</p><p>4） Linux操作系统请运行bin&#x2F;start.sh，Windows操作系统请运行bin&#x2F;start.bat启动Sharding-Proxy。 使用默认配置启动：${sharding-proxy}\bin\start.sh 配置端口启动：${sharding-proxy}\bin\start.sh ${port}</p><p>5） 使用客户端工具连接。如: mysql -h 127.0.0.1 -P 3307 -u root -p root</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;分库分表背景及解决方案&quot;&gt;&lt;a href=&quot;#分库分表背景及解决方案&quot; class=&quot;headerlink&quot; title=&quot;分库分表背景及解决方案&quot;&gt;&lt;/a&gt;&lt;strong&gt;分库分表背景及解决方案&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;背景及问题&lt;/st</summary>
      
    
    
    
    <category term="基础知识" scheme="https://itingyu.github.io/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    <category term="mysql" scheme="https://itingyu.github.io/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/mysql/"/>
    
    
    <category term="基础知识" scheme="https://itingyu.github.io/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    <category term="mysql" scheme="https://itingyu.github.io/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>mysql集群架构</title>
    <link href="https://itingyu.github.io/posts/38076/"/>
    <id>https://itingyu.github.io/posts/38076/</id>
    <published>2023-06-17T11:10:42.000Z</published>
    <updated>2023-06-17T11:13:16.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="集群架构设计"><a href="#集群架构设计" class="headerlink" title="集群架构设计"></a><strong>集群架构设计</strong></h3><p>集群架构设计的三个维度：可用性、扩展性、一致性</p><p><strong>可用性设计</strong></p><p>1） 站点高可用，冗余站点</p><p>2） 服务高可用，冗余服务</p><p>3） 数据高可用，冗余数据</p><p>高可用的方案：主从模式，双主模式（分双主双写和双主单写）</p><p><strong>扩展性设计</strong></p><p>1） 加从库，从库过多会引发主库性能损耗。</p><p>2） 分库分表，分为垂直拆分和水平拆分，垂直拆分可以缓解部分压力，水平拆分可以无限扩展。</p><p><strong>一致性设计</strong></p><p>1） 不使用从库</p><p>2） 增加访问路由层，得到主从同步最长时间t，在数据发生修改后的t时间内，先访问主库，保证数据一致。</p><h3 id="主从模式使用场景"><a href="#主从模式使用场景" class="headerlink" title="主从模式使用场景"></a><strong>主从模式使用场景</strong></h3><p>数据可以从一个MySQL数据库服务器主节点复制到一个或多个从节点，默认采用异步复制方式，这样从节点不用一直访问主服务器来更新自己的数据，从节点可以复制主数据库中的所有数据库，或者特定的数据库，或者特定的表。</p><p><img src="https://pic4.zhimg.com/80/v2-ff30969b4cef1c5705d834f371729f3b_720w.webp" alt="img"></p><p><strong>主从复制用途</strong></p><p>1） 实时灾备，用于故障切换（高可用）</p><p>2） 读写分离，提供查询服务（读扩展）</p><p>3） 数据备份，避免影响业务（高可用）</p><p><strong>主从部署必要条件</strong></p><p>1） 从库服务器能连通主库</p><p>2） 主库开启binlog日志（设置log-bin参数）</p><p>3） 主从server-id不同</p><h3 id="主从模式实现原理"><a href="#主从模式实现原理" class="headerlink" title="主从模式实现原理"></a><strong>主从模式实现原理</strong></h3><p><img src="/posts/38076/assets/a52ebf6d575ee37e63210e54c56eddb5.webp" alt="img"></p><p>实现步骤：</p><p>1） 主库将数据库的变更操作记录到Binlog日志文件中</p><p>2） 从库读取主库中的Binlog日志文件信息写入到从库的Relay Log中继日志中</p><p>3） 从库读取中继日志信息在从库中进行Replay,更新从库数据信息</p><p>具体触发机制如下：</p><p>1） Master服务器对数据库更改操作记录在Binlog中，BinlogDump Thread接到写入请求后，读取 Binlog信息推送给Slave的I&#x2F;O Thread。</p><p>2） Slave的I&#x2F;O Thread将读取到的Binlog信息写入到本地Relay Log中。</p><p>3） Slave的SQL Thread检测到Relay Log的变更请求，解析relay log中内容在从库上执行。</p><p>存在的问题：</p><p>1） 主库宕机后，数据可能丢失</p><p>2） 从库只有一个SQL Thread，主库写压力大，复制很可能延时</p><p>解决的办法：</p><p>1） 半同步复制—解决数据丢失的问题</p><p>2） 并行复制—-解决从库复制延迟的问题</p><h3 id="半同步复制"><a href="#半同步复制" class="headerlink" title="半同步复制"></a><strong>半同步复制</strong></h3><p>从5.5开始，MySQL让Master在某一个时间点等待Slave节点的ACK消息，接收到ACK消息后才进行事务提交，这就是半同步复制。</p><p>主从复制时的完整过程：</p><p>1） InnoDB Redo File Write (Prepare Write)</p><p>2） Binlog File Flush &amp; Sync to Binlog File</p><p>3） InnoDB Redo File Commit（Commit Write）</p><p>4） Send Binlog to Slave</p><p>当Master不需要关注Slave是否接受到Binlog Event时，即为传统的主从复制。</p><p>当Master需要在第三步等待Slave返回ACK时，即为 after-commit，半同步复制（MySQL 5.5引入）。</p><p>当Master需要在第二步等待 Slave 返回 ACK 时，即为 after-sync，增强半同步（MySQL 5.7引入）。</p><p><img src="https://pic3.zhimg.com/80/v2-b40172df22381befa9054e11d3c42776_720w.webp" alt="img"></p><h3 id="并行复制"><a href="#并行复制" class="headerlink" title="并行复制"></a><strong>并行复制</strong></h3><p>MySQL从5.6版本开始追加了并行复制功能，改善复制延迟。</p><p><strong>5.6版本并行复制</strong></p><p>基于库的并行复制，也就是多线程分别执行各自库的操作，互不干扰，单库多表并发效率就不高了。</p><p><img src="https://pic4.zhimg.com/80/v2-756a05662eff8a22e62e0cf5cf1f68eb_720w.webp" alt="img"></p><p><strong>5.7版本并行复制</strong></p><p>基于组提交的并行复制，不再有库的并行复制限制。当事务提交时，通过在主库上的二进制日志中添加组提交信息，并将在单个操作中写入到二进制日志中。如果多个事务能同时提交成功，那么它们意味着没有冲突，因此可以在Slave上并行执行。MySQL 5.7的并行复制基于一个前提，即所有已经处于prepare阶段的事务，都是可以并行提交的。</p><p>InnoDB事务提交采用的是两阶段提交模式。一个阶段是prepare，另一个是commit。</p><p>在MySQL 5.7版本中，其设计方式是将组提交的信息存放在GTID中。为了避免用户没有开启GTID功能，MySQL 5.7又引入了称之为Anonymous_Gtid的二进制日志event类型，即日志中具有相同的last_committed，表示这些事务都在一组内。</p><p><strong>8.0 并行复制</strong></p><p>基于write-set的并行复制。有一个集合变量来存储事务修改的记录信息（主键哈希值），所有已经提交的事务所修改的主键值经过hash后都会与那个变量的集合进行对比，来判断改行是否与其冲突，并以此来确定依赖关系，没有冲突即可并行，row级别的粒度，类似于之前的表锁行锁差异，效率肯定更高。</p><h3 id="MySQL安装"><a href="#MySQL安装" class="headerlink" title="MySQL安装"></a><strong>MySQL安装</strong></h3><ol><li>上传mysql安装包到Linux服务器并进行解压</li></ol><p>tar -xvf mysql-5.7.28-1.el7.x86_64.rpm-bundle.tar</p><p><img src="/posts/38076/assets/9a753dc7069250b7436af6f0aec26529.webp" alt="img"></p><ol start="2"><li>检查是否已有Mysql安装，存在就移除‘</li></ol><p>rpm -qa | grep mariadb</p><p>rpm -e mariadb-libs-5.5.41-2.el7_0.x86_64 –nodeps</p><ol start="3"><li>安装mysql-community-common-5.7.28-1.el7.x86_64.rpm</li></ol><p>rpm -ivh mysql-community-common-5.7.28-1.el7.x86_64.rpm</p><ol start="4"><li>安装mysql-community-libs-5.7.28-1.el7.x86_64.rpm</li></ol><p>rpm -ivh mysql-community-libs-5.7.28-1.el7.x86_64.rpm</p><ol start="5"><li>安装mysql-community-libs-compat-5.7.28-1.el7.x86_64.rpm</li></ol><p>rpm -ivh mysql-community-libs-compat-5.7.28-1.el7.x86_64.rpm</p><p>6）安装客户端 mysql-community-client-5.7.28-1.el7.x86_64.rpm</p><p>rpm -ivh mysql-community-client-5.7.28-1.el7.x86_64.rpm</p><p>7）安装服务端mysql-community-server-5.7.28-1.el7.x86_64.rpm</p><p>rpm -ivh mysql-community-server-5.7.28-1.el7.x86_64.rpm</p><p>8）安装开发包 mysql-community-devel-5.7.28-1.el7.x86_64.rpm</p><p>rpm -ivh mysql-community-devel-5.7.28-1.el7.x86_64.rpm</p><p>9）初始化Mysql</p><p>mysqld –initialize –user&#x3D;mysql</p><p>10）查看root随机生成默认密码</p><p>cat &#x2F;var&#x2F;log&#x2F;mysqld.log #root@localhost: Ajtag.WsR3,J</p><p>11）设置自动启动Mysql</p><p>systemctl start mysqld.service</p><p>12）查看状态</p><p>systemctl status mysqld.service</p><p><img src="/posts/38076/assets/8c37905765e74dc59888501e24bcbf00.webp" alt="img"></p><p>13）登录Mysql</p><p>mysql -uroot -p # 密码：Ajtag.WsR3,J</p><p>14）修改数据库密码</p><p>set password&#x3D;password(‘root’); 修改密码</p><p>exit #退出</p><p>15）关闭服务器防火墙</p><p>systemctl stop iptables</p><p>systemctl stop firewalld</p><p>systemctl disable firewalld.service</p><p>注意1：如果安装执行出现Header V3 DSA&#x2F;SHA1 Signature, key ID 5072e1f5:错误，这是由于yum安装了旧版本的GPG keys造成的，在尾部加上–force –nodeps即可。</p><p><img src="/posts/38076/assets/8d40ffd71b6bf4b7d37095257b0788cc.webp" alt="img"></p><p>注意2：如果初始化mysql失败，执行yum -y install numactl命令</p><p><img src="/posts/38076/assets/845e02cb62de8f6318a16331b61c0c37.webp" alt="img"></p><p>注意3：如果安装完mysql之后，mysql命令登录不成功，使用yum install libncurses*命令</p><p><img src="/posts/38076/assets/75c03225c1e2285cecd00ee8e999578c.webp" alt="img"></p><h3 id="主从同步实战"><a href="#主从同步实战" class="headerlink" title="主从同步实战"></a><strong>主从同步实战</strong></h3><p>1） 修改主库my.cnf配置文件</p><p>执行命令vim &#x2F;etc&#x2F;my.cnf</p><p>log_bin&#x3D;mysql-bin #开启binlog,文件名称为mysql-bin</p><p>server-id&#x3D;1 #指定server-id</p><p>sync-binlog&#x3D;1 #执行几次后进行磁盘同步1就代表次数</p><p>#忽略以下库的同步</p><p>binlog-ignore-db&#x3D;performance_schema</p><p>binlog-ignore-db&#x3D;information_schema</p><p>binlog-ignore-db&#x3D;sys</p><p>#指定同步的库 不设置就是同步所有库</p><p>binlog-do-db&#x3D;test</p><p>2） 完成配置修改重启mysql</p><p>systemctl restart mysqld</p><ol><li>主库授权</li></ol><p>#登录MySQL</p><p>mysql -uroot -p</p><p>#主库授权设置</p><p>grant replication slave on <em>.</em> to ‘root‘@’%’ identified by ‘root’;</p><p>grant all privileges on <em>.</em> to ‘root‘@’%’ identified by ‘root’;</p><p>#刷新权限，立即生效</p><p>flush privileges;</p><p>#查看主库状态</p><p>show master status;</p><ol start="2"><li>从库配置修改</li></ol><p>执行命令 vim &#x2F;etc&#x2F;my.cnf</p><p>server-id&#x3D;2</p><p>relay_log&#x3D;mysql-relay-bin #relay-log名称</p><p>read_only&#x3D;1 #此库只读</p><p>5） 完成配置修改重启mysql</p><p>systemctl restart mysqld</p><p>6） 从库启动授权</p><p>#登陆数据库设置复制的主库</p><p>change master to master_host&#x3D;’47.106.138.46’,master_port&#x3D;3306,master_user&#x3D;’root’,</p><p>master_password&#x3D;’root’,master_log_file&#x3D;’ master-bin.000002’,master_log_pos&#x3D;154;</p><p>#查看从库状态</p><p>show slave status \G;</p><p>#开启从库</p><p>start slave;</p><p>#停止从库</p><p>stop slave;</p><p>#重新绑定主库</p><p>reset master;</p><p>#主库修改配置，从库无法启动，重置</p><p>reset slave;</p><h3 id="半同步复制实战"><a href="#半同步复制实战" class="headerlink" title="半同步复制实战"></a><strong>半同步复制实战</strong></h3><p>1） 主库半同步复制设置</p><p>#是否支持动态加载</p><p>select @@have_dynamic_loading;</p><p><img src="https://pic4.zhimg.com/80/v2-2f4c9903e0bb14cb1fa9c9b59ada08f3_720w.webp" alt="img"></p><p>#查看插件列表</p><p>show plugins;</p><p><img src="/posts/38076/assets/6af9eab6d58960c02dee111429128747.webp" alt="img"></p><p>#安装半同步复制插件并起别名</p><p>install plugin rpl_semi_sync_master soname ‘semisync_master.so’;</p><p><img src="/posts/38076/assets/a796cc2231d264b1f35d1f8282df1f5e.webp" alt="img"></p><p>#查看半同步复制相关参数</p><p>show variables like ‘%semi%’;</p><p><img src="/posts/38076/assets/1664455598527aae2dcf1a5bb18318e3.webp" alt="img"></p><p>#开启半同步复制</p><p>set global rpl_semi_sync_master_enabled&#x3D;1;</p><p>#设置超时时间，默认10秒，设置为1秒</p><p>set global rpl_semi_sync_master_timeout&#x3D;1000;</p><p><img src="/posts/38076/assets/8985461cb49c4205d30ff9fefc557211.webp" alt="img"></p><p>2） 从库半同步复制设置</p><p>#是否支持动态加载</p><p>select @@have_dynamic_loading;</p><p><img src="/posts/38076/assets/f5171dbd1869548e443ad7aa2136551d.webp" alt="img"></p><p>#查看插件列表</p><p>show plugins;</p><p>#安装从库半同步复制插件并起别名</p><p>install plugin rpl_semi_sync_slave soname ‘semisync_slave.so’;</p><p>#查看半同步复制相关参数</p><p>show variables like ‘%semi%’;</p><p><img src="https://pic4.zhimg.com/80/v2-7fc309545852cd827a47aadcdf95daeb_720w.webp" alt="img"></p><p>#开启从库半同步复制</p><p>set global rpl_semi_sync_slave_enabled&#x3D;1;</p><p><img src="https://pic2.zhimg.com/80/v2-b9fa1cb9be50e39bd097d8b9138011b9_720w.webp" alt="img"></p><p>#重新加载从库</p><p>stop slave;</p><p>start slave;</p><p><img src="/posts/38076/assets/05686834676076bf3e853b38e963494a.webp" alt="img"></p><p>切换到&#x2F;var&#x2F;log目录，查看mysqld.log日志文件核验半同步复制是否生效</p><p><img src="/posts/38076/assets/380e8594b08d77dc107d124ae73260ba.webp" alt="img"></p><h3 id="并行复制实战"><a href="#并行复制实战" class="headerlink" title="并行复制实战"></a><strong>并行复制实战</strong></h3><p>1） 主库设置</p><p>#查看数据库组信息</p><p>show variables like ‘%binlog_group%’;</p><p><img src="https://pic4.zhimg.com/80/v2-760f3e043505dec2a37a8a6f26809e03_720w.webp" alt="img"></p><p>#设置延迟时间</p><p>set binlog_group_commit_sync_delay&#x3D;1000;</p><p>#设置组内事务数量</p><p>set binlog_group_commit_sync_no_delay_count&#x3D;100;</p><p>2）从库配置</p><p>#查看从库可设置参数</p><p>show variables like ‘%slave%’;</p><p><img src="/posts/38076/assets/03055b8ccfffb456988eb21cec0d68c7.webp" alt="img"></p><p>#修改并行复制方式，由库改组</p><p>set global slave_parallel_type&#x3D;‘LOGICAL_CLOCK’;</p><p>#设置组内最大线程数</p><p>set global slave_parallel_workers&#x3D;8;</p><p>#查看relay相关参数</p><p>show variables like ‘%relay_log%’;</p><p><img src="/posts/38076/assets/42a72128b348a6cde13865eb3405990b.webp" alt="img"></p><p>#打开relay_log写入权限</p><p>set global relay_log_recovery&#x3D;1;</p><p>#设置日志信息源为table，提高效率</p><p>set global relay_log_info_repository&#x3D;’TAABLE’;</p><p>#重启服务，使配置生效</p><p>systemctl restart mysqld</p><h3 id="读写分离"><a href="#读写分离" class="headerlink" title="读写分离"></a><strong>读写分离</strong></h3><p>大多数互联网业务基本上读多写少，因此读写分离就可以提高读的效率，读写分离首先需要将数据库分为主从库，一个主库用于写数据，多个从库完成读数据的操作，主从库之间通过主从复制机制进行数据的同步，而且这样还可以进行主库主写，不加索引，从库主读，加索引，把两个库的效率提升到最高，不过需要解决主从同步延迟和读写分配机制。</p><p><img src="https://pic4.zhimg.com/80/v2-c6f56a158dfc5fde1a722d607ef62a63_720w.webp" alt="img"></p><p><strong>主从同步延迟</strong></p><p>1） 写后立刻读：在写入数据库后，某个时间段内读操作就去主库，之后读操作访问从库。</p><p>2） 二次查询：先去从库读取数据，找不到时就去主库进行数据读取，注意对恶意攻击限制。</p><p>3） 根据业务特殊处理：根据业务特点和重要程度进行调整，实时性高数据读写都在主库，其他在从库。</p><p><strong>读写分配机制</strong></p><p>控制何时去主库写，何时去从库读。</p><p>1） 基于编程和配置实现：根据操作类型进行路由分配，增删改时操作主库，查询时操作从库。</p><p>2） 基于服务器端代理实现：使用中间件代理，动态分配，常用MySQL Proxy、MyCat以及Shardingsphere等。</p><p><img src="https://pic4.zhimg.com/80/v2-b38def16fb105a6b59a2ffcf5946b24f_720w.webp" alt="img"></p><h3 id="读写分离实战"><a href="#读写分离实战" class="headerlink" title="读写分离实战"></a><strong>读写分离实战</strong></h3><p>1） 代理主机上解压mysql-proxy代理包</p><p>tar -xzvf mysql-proxy-0.8.5-linux-el6-x86-64bit.tar</p><p>2） 创建一个mysql-proxy配置文件</p><p>vim &#x2F;etc&#x2F;mysql-proxy.cnf</p><p>3） 在配置文件内写入相应配置参数</p><p>user&#x3D;root #运行mysql-proxy用户</p><p>admin-username&#x3D;root#主从mysql共有的用户</p><p>admin-password&#x3D;root#用户的密码</p><p>proxy-address&#x3D; 117.50.5.252:4040 #mysql-proxy运行ip和端口，不加端口，默认4040</p><p>proxy-backend-addresses&#x3D; 47.106.138.46 #指定后端主master写入数据</p><p>proxy-read-only-backend-addresses&#x3D; 49.235.85.246 #指定后端从slave读取数据</p><p>proxy-lua-script&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql-proxy&#x2F;lua&#x2F;rw-splitting.lua #指定读写分离配置文件位置</p><p>log-file&#x3D;&#x2F;var&#x2F; logs&#x2F;mysql-proxy.log #日志位置</p><p>log-level&#x3D;debug #定义log日志级别，由高到低分别有(error|warning|info|message|debug)</p><p>daemon&#x3D;true #以守护进程方式运行</p><p>keepalive&#x3D;true #mysql-proxy崩溃时，尝试重启</p><p>#保存退出！并修改文件权限</p><p>chmod 660 &#x2F;etc&#x2F;mysql-porxy.cnf</p><p>4）修改lua脚本配置文件</p><p>vi &#x2F;usr&#x2F;local&#x2F;mysql-proxy&#x2F;lua&#x2F;rw-splitting.lua</p><p>min_idle_connections &#x3D; 1, #最小连接数，默认超过4个连接数时，才开始读写分离，改为1</p><p>max_idle_connections &#x3D; 8, #最大连接数，默认8</p><p>5）运行proxy脚本，在对应bin目录找到mysql-proxy</p><p>.&#x2F;mysql-proxy –defaults-file&#x3D;&#x2F;etc&#x2F;mysql-proxy.cnf</p><h3 id="双主模式"><a href="#双主模式" class="headerlink" title="双主模式"></a><strong>双主模式</strong></h3><p>主从模式，一主多从、读写分离，如果是单主模式，单主故障问题没法避免，是双主或者多主，增加MySQL入口，可以提升了主库的可用性，推荐使用双主单写，因为双主双写存在ID冲突和双主更新覆盖丢失问题。</p><p><img src="/posts/38076/assets/1007be3d6f8ee41b82dce780f872daa6.webp" alt="img"></p><p>双主模式实战</p><p>1） 修改主库1的配置</p><p>执行命令vim &#x2F;etc&#x2F;my.cnf</p><p>relay_log&#x3D;mysql-relay-bin #relay_log名称</p><p>log_slave_updates&#x3D;1</p><p>#双主双写自增主键设置 1，3，5，7… 双主单写不用设置</p><p>auto_increment_offset&#x3D;1 #自动递增</p><p>auto_increment_increment&#x3D;2 #递增量</p><p>2） 完成配置修改重启mysql</p><p>systemctl restart mysqld</p><p>3）修改主库2的配置</p><p>执行命令vim &#x2F;etc&#x2F;my.cnf</p><p>log_bin&#x3D;mysql-bin #开启binlog,文件名称为mysql-bin</p><p>server-id&#x3D;3 #指定server-id</p><p>sync-binlog&#x3D;1 #执行几次后进行磁盘同步 1就代表次数</p><p>#忽略以下库的同步</p><p>binlog-ignore-db&#x3D;performance_schema</p><p>binlog-ignore-db&#x3D;information_schema</p><p>binlog-ignore-db&#x3D;sys</p><p>relay_log&#x3D;mysql-relay-bin #relay_log名称</p><p>log_slave_updates&#x3D;1</p><p>#双主双写自增主键设置 2，4，6，8… 双主单写不用设置</p><p>auto_increment_offset&#x3D;2 #自动递增</p><p>auto_increment_increment&#x3D;2 #递增量</p><p>4）登陆mysql并授权</p><p>#主库授权设置</p><p>grant replication slave on <em>.</em> to ‘root‘@’%’ identified by ‘root’;</p><p>grant all privileges on <em>.</em> to ‘root‘@’%’ identified by ‘root’;</p><p>#刷新权限，立即生效</p><p>flush privileges;</p><p>5）主库1和主库2互复制设置</p><p>#设置复制的master1主库为master2</p><p>change master to master_host&#x3D;’47.106.138.46’,master_port&#x3D;3306,</p><p>master_user&#x3D;’root’,master_password&#x3D;’root’,master_log_file&#x3D;’mysql-bin.000004’,master_log_pos&#x3D;154;</p><p>#设置复制的master2主库为master1</p><p>change master to master_host&#x3D;’49.235.85.246’,master_port&#x3D;3306,</p><p>master_user&#x3D;’root’,master_password&#x3D;’root’,master_log_file&#x3D;’mysql-bin.000001’,master_log_pos&#x3D;867;</p><h3 id="MMM架构"><a href="#MMM架构" class="headerlink" title="MMM架构"></a><strong>MMM架构</strong></h3><p>MMM架构是管理和监控双主复制，支持双主故障切换的第三方软件。</p><p><img src="https://pic2.zhimg.com/80/v2-9d7c5bf386053c97ffeb8960f874199d_720w.webp" alt="img"></p><p><strong>MMM故障处理机制</strong></p><p>MMM 划分writer和reader两类角色，分别对应写节点和读节点。</p><p>1） 当 writer节点出现故障，程序会自动移除该节点上的VIP</p><p>2） 写操作切换到 Master2，并将Master2设置为writer</p><p>3） 将所有Slave节点会指向Master2</p><p>MMM 也会管理 Slave 节点，在出现宕机、复制延迟或复制错误，MMM会移除该节点的VIP，直到节点恢复正常。</p><p><strong>MMM监控机制</strong></p><p>MMM 包含monitor和agent两类程序</p><p>monitor：监控集群内数据库的状态，在出现异常时发布切换命令。</p><p>agent：运行在每个MySQL服务器上的代理进程，monitor 命令的执行者。</p><h3 id="MHA架构"><a href="#MHA架构" class="headerlink" title="MHA架构"></a><strong>MHA架构</strong></h3><p>MHA是一款优秀的故障切换和 主从提升的高可用软件。能30秒之内自动完成数据库的故障切换并最大保证数据一致性，并支持在线快速将Master切换到其他主机，通常只需0.5－2秒。</p><p><img src="https://pic3.zhimg.com/80/v2-35feebfa05d6d1756095095dfa774852_720w.webp" alt="img"></p><p>MHA由两部分组成：MHA Manager（管理节点）和MHA Node（数据节点）</p><p>MHA Manager会定时探测集群中的master节点，当master出现故障时，它可以自动将最新数据的 slave提升为新的master，然后将所有其他的slave重新指向新的master。</p><p><strong>MHA故障处理机制</strong></p><p>1） 把宕机master的binlog保存下来</p><p>2） 根据binlog位置点找到最新的slave</p><p>3） 用最新slave的relay log修复其它slave</p><p>4） 将保存下来的binlog在最新的slave上恢复</p><p>5） 将最新的slave提升为master</p><p>6） 将其它slave重新指向新提升的master，并开启主从复制</p><p><strong>MHA优点</strong></p><p>1） 自动故障转移快</p><p>2） 主库崩溃不存在数据一致性问题</p><p>3） 性能优秀，支持半同步复制和异步复制</p><p>4） 一个Manager监控节点可以监控多个集群</p><h3 id="MHA架构实战"><a href="#MHA架构实战" class="headerlink" title="MHA架构实战"></a><strong>MHA架构实战</strong></h3><p>1） 环境说明</p><p>腾讯云主机作为MHA管理，阿里云作为主服务器，华为云和Ucloud作为从服务器。</p><p>2） 把mha4mysql-node-0.58-0.el7.centos.noarch.rpm节点程序上传到每个服务器，在MHA管理服务器再上传mha4mysql-manager-0.58-0.el7.centos.noarch.rpm管理端程序。</p><p><img src="/posts/38076/assets/126597528f5be2d71df2ee91afea43ce.webp" alt="img"></p><p>3） 修改主库的&#x2F;etc&#x2F;my.cnf配置并重启mysql</p><p><img src="https://pic3.zhimg.com/80/v2-194ca4fdca0a2fbf8e7a289515aa1af6_720w.webp" alt="img"></p><p>4） 修改从库的&#x2F;etc&#x2F;my.cnf配置并重启mysql</p><p>server-id&#x3D;2</p><p>relay-log &#x3D; relay-log #开启中继日志</p><p>log-bin &#x3D; master-log #开启二进制日志</p><p>read_only &#x3D; ON #启用只读属性</p><p>relay_log_purge &#x3D; 0 #是否自动清空不再需要中继日志</p><p>skip_name_resolve #关闭名称解析（非必须）</p><p>log_slave_updates &#x3D; 1 #使得更新的数据写进二进制日志中</p><p>5） 重启修改配置的库，使配置生效</p><p>systemctl restart mysqld</p><p>6） 安装依赖</p><p>yum install perl-DBI -y</p><p>yum install perl-DBD-MySQL -y</p><p>yum install perl-Config-Tiny -y</p><p>yum install <a href="https://link.zhihu.com/?target=https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm">https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm</a></p><p>yum install perl-Log-Dispatch -y</p><p>yum install perl-Parallel-ForkManager -y</p><p>7） 主、从、MHA安装node程序</p><p>rpm -ivh mha4mysql-node-0.58-0.el7.centos.noarch.rpm</p><p>8） MHA安装manager程序</p><p>rpm -ivh mha4mysql-manager-0.58-0.el7.centos.noarch.rpm</p><p>9） 四台服务器之间建立免密设置，输入第一个命令，回车然后再输入各个服务器地址命名并输入登录密码</p><p>#MHA 49.235.99.6</p><p>ssh-keygen -t rsa</p><p>ssh-copy-id -i &#x2F;root&#x2F;.ssh&#x2F;id_rsa <a href="mailto:&#114;&#x6f;&#111;&#116;&#64;&#52;&#x37;&#46;&#x31;&#48;&#54;&#x2e;&#49;&#51;&#56;&#x2e;&#52;&#54;">&#114;&#x6f;&#111;&#116;&#64;&#52;&#x37;&#46;&#x31;&#48;&#54;&#x2e;&#49;&#51;&#56;&#x2e;&#52;&#54;</a></p><p>ssh-copy-id -i &#x2F;root&#x2F;.ssh&#x2F;id_rsa <a href="mailto:&#114;&#111;&#x6f;&#116;&#x40;&#x34;&#57;&#x2e;&#x32;&#51;&#53;&#46;&#56;&#x35;&#46;&#x32;&#52;&#x36;">&#114;&#111;&#x6f;&#116;&#x40;&#x34;&#57;&#x2e;&#x32;&#51;&#53;&#46;&#56;&#x35;&#46;&#x32;&#52;&#x36;</a></p><p>ssh-copy-id -i &#x2F;root&#x2F;.ssh&#x2F;id_rsa <a href="mailto:&#114;&#x6f;&#111;&#x74;&#64;&#49;&#x31;&#x37;&#46;&#53;&#48;&#x2e;&#x35;&#46;&#x32;&#x35;&#50;">&#114;&#x6f;&#111;&#x74;&#64;&#49;&#x31;&#x37;&#46;&#53;&#48;&#x2e;&#x35;&#46;&#x32;&#x35;&#50;</a></p><p>#master 47.106.138.46</p><p>ssh-keygen -t rsa</p><p>ssh-copy-id -i &#x2F;root&#x2F;.ssh&#x2F;id_rsa <a href="mailto:&#114;&#x6f;&#111;&#116;&#64;&#52;&#x39;&#46;&#50;&#51;&#53;&#46;&#x38;&#53;&#x2e;&#50;&#52;&#54;">&#114;&#x6f;&#111;&#116;&#64;&#52;&#x39;&#46;&#50;&#51;&#53;&#46;&#x38;&#53;&#x2e;&#50;&#52;&#54;</a></p><p>ssh-copy-id -i &#x2F;root&#x2F;.ssh&#x2F;id_rsa <a href="mailto:&#x72;&#x6f;&#x6f;&#x74;&#64;&#49;&#x31;&#x37;&#x2e;&#x35;&#48;&#46;&#53;&#x2e;&#x32;&#x35;&#50;">&#x72;&#x6f;&#x6f;&#x74;&#64;&#49;&#x31;&#x37;&#x2e;&#x35;&#48;&#46;&#53;&#x2e;&#x32;&#x35;&#50;</a></p><p>#slave1 49.235.85.246</p><p>ssh-keygen -t rsa</p><p>ssh-copy-id -i &#x2F;root&#x2F;.ssh&#x2F;id_rsa <a href="mailto:&#114;&#111;&#x6f;&#x74;&#x40;&#x34;&#55;&#46;&#x31;&#x30;&#54;&#x2e;&#x31;&#51;&#56;&#x2e;&#x34;&#x36;">&#114;&#111;&#x6f;&#x74;&#x40;&#x34;&#55;&#46;&#x31;&#x30;&#54;&#x2e;&#x31;&#51;&#56;&#x2e;&#x34;&#x36;</a></p><p>ssh-copy-id -i &#x2F;root&#x2F;.ssh&#x2F;id_rsa <a href="mailto:&#x72;&#x6f;&#111;&#x74;&#x40;&#x31;&#49;&#55;&#46;&#x35;&#x30;&#46;&#53;&#x2e;&#x32;&#53;&#50;">&#x72;&#x6f;&#111;&#x74;&#x40;&#x31;&#49;&#55;&#46;&#x35;&#x30;&#46;&#53;&#x2e;&#x32;&#53;&#50;</a></p><p>#slave2 117.50.5.252</p><p>ssh-keygen -t rsa</p><p>ssh-copy-id -i &#x2F;root&#x2F;.ssh&#x2F;id_rsa <a href="mailto:&#x72;&#x6f;&#x6f;&#x74;&#64;&#x34;&#x37;&#x2e;&#49;&#48;&#x36;&#46;&#x31;&#51;&#x38;&#46;&#52;&#x36;">&#x72;&#x6f;&#x6f;&#x74;&#64;&#x34;&#x37;&#x2e;&#49;&#48;&#x36;&#46;&#x31;&#51;&#x38;&#46;&#52;&#x36;</a></p><p>ssh-copy-id -i &#x2F;root&#x2F;.ssh&#x2F;id_rsa <a href="mailto:root@49.235.85.246">root@49.235.85.246</a></p><p><img src="/posts/38076/assets/610fe7b6aaaba3090289e8ff706e14f1.webp" alt="img"></p><p>10）MHA配置</p><p>mkdir -p &#x2F;etc&#x2F;mha</p><p>vim &#x2F;etc&#x2F;mha&#x2F;mha.cnf</p><p>#下载scripts 并放到&#x2F;etc&#x2F;mha&#x2F;scripts路径下，记得给脚本加执行权限</p><p>下载连接：<a href="https://link.zhihu.com/?target=https://github.com/yoshinorim/mha4mysql-manager/samples/scripts">https://github.com/yoshinorim/mha4mysql-manager/samples/scripts</a></p><p>[server default]</p><p>manager_workdir&#x3D;&#x2F;etc&#x2F;mha&#x2F; #manager工作目录</p><p>manager_log&#x3D;&#x2F;etc&#x2F;mha&#x2F;manager.log #mananger日志</p><p>master_binlog_dir&#x3D;&#x2F;var&#x2F;lib&#x2F;mysql #binlog复制目录</p><p>user&#x3D;root</p><p>password&#x3D;root</p><p>ping_interval&#x3D;1</p><p>remote_workdir&#x3D;&#x2F;tmp</p><p>repl_password&#x3D;root</p><p>repl_user&#x3D;root</p><p>secondary_check_script&#x3D; &#x2F;usr&#x2F;bin&#x2F;masterha_secondary_check -s 49.235.85.246 -s 117.50.5.252 –user&#x3D;root –master_host&#x3D;47.106.138.46 –master_ip&#x3D;47.106.138.46 –master_port&#x3D;3306</p><p>master_ip_failover_script&#x3D;&#x2F;etc&#x2F;mha&#x2F;scripts&#x2F;master_ip_failover #切换脚本</p><p>master_ip_online_change_script&#x3D;&#x2F;etc&#x2F;mha&#x2F;scripts&#x2F;master_ip_online_change #手动switchover时候的切换</p><p>#shutdown_script&#x3D;””</p><p>ssh_user&#x3D;root</p><p>[server1]</p><p>hostname&#x3D;47.106.138.46</p><p>port&#x3D;3306</p><p>candidate_master&#x3D;1</p><p>check_repl_delay&#x3D;0</p><p>[server2]</p><p>hostname&#x3D;49.235.85.246</p><p>port&#x3D;3306</p><p>candidate_master&#x3D;1</p><p>check_repl_delay&#x3D;0</p><p>[server3]</p><p>hostname&#x3D;117.50.5.252</p><p>port&#x3D;3306</p><p>10）检查ssh连接和复制状态</p><p>#检查ssh免密连接</p><p>masterha_check_ssh –conf&#x3D;&#x2F;etc&#x2F;mha&#x2F;mha.cnf</p><p>#检查复制</p><p>masterha_check_repl –conf&#x3D;&#x2F;etc&#x2F;mha&#x2F;mha.cnf</p><p>11）启动Manager</p><p>nohup masterha_manager –conf&#x3D;&#x2F;etc&#x2F;mha&#x2F;mha.cnf&lt; &#x2F;dev&#x2F;null &gt; &#x2F;etc&#x2F;mha&#x2F;manager.log 2&gt;&amp;1 &amp;</p><p>12）查看状态</p><p>masterha_check_status –conf&#x3D;&#x2F;etc&#x2F;mha&#x2F;mha.cnf</p><p>13）停止Manager</p><p>masterha_stop –conf&#x3D;&#x2F;etc&#x2F;mha&#x2F;mha.cnf</p><p>rm &#x2F;etc&#x2F;mha&#x2F;&#x2F;mha.failover.complete</p><h3 id="主备切换策略"><a href="#主备切换策略" class="headerlink" title="主备切换策略"></a><strong>主备切换策略</strong></h3><p>主备切换是指将备库变为主库，主库变为备库，有可靠性优先和可用性优先两种策略，可靠性优先为常用。</p><p>主备延迟就是同一个事务，在备库执行完成的时间和主库执行完成的时间之间的差值。</p><p>同步延迟的原因：备库机器性能差、备库执行其他操作消耗CPU，分工问题、大事务耗时长。</p><p><strong>可靠性优先</strong></p><p>主备切换过程一般由专门的HA高可用组件完成，但是切换过程中会存在短时间不可用，为保证数据一致性。</p><p><strong>可用性优先</strong></p><p>不等主从同步完成，直接把业务请求切换至从库B ，并且让从库B可读写。</p><h3 id="分库分表"><a href="#分库分表" class="headerlink" title="分库分表"></a><strong>分库分表</strong></h3><p>分库分表，主要有垂直拆分和水平拆分两种拆分模式，都属于物理空间的拆分。</p><p>分库分表方案：只分库、只分表、分库又分表。</p><p>垂直拆分：由于表数量多导致的单个库大。将表拆分到多个库中。</p><p>水平拆分：由于表记录多导致的单个库大。将表记录拆分到多个表中。<strong>垂直拆分</strong></p><p>垂直拆分又称为纵向拆分，垂直拆分是将表按库进行分离，或者修改表结构按照访问的差异将某些</p><p>列拆分出去。</p><p>垂直分表就是将一张表中不常用的字段拆分到另一张表中，从而保证第一张表中的字段较少，避免 出现数据库跨页存储的问题，从而提升查询效率。</p><p>按业务分表</p><p><img src="/posts/38076/assets/2e4620f96ab00f184602d28375735024.webp" alt="img"></p><p>字段过多分字段</p><p><img src="https://pic4.zhimg.com/80/v2-3ee7ffabb5302403cb9ce88379aea797_720w.webp" alt="img"></p><p>优点：</p><p>1） 拆分后业务清晰，拆分规则明确；</p><p>2） 易于数据的维护和扩展；</p><p>3） 可以使得行数据变小，一个数据块就能存放更多的数据，在查询时就会减少 I&#x2F;O 次 数；</p><p>4） 可以达到最大化利用 Cache 的目的。</p><p>5） 便于实现冷热分离的数据表设计模式。</p><p>缺点：</p><p>1） 主键出现冗余，需要管理冗余列；</p><p>2） 会引起表连接 JOIN 操作，提高了系统的复杂度；</p><p><strong>水平拆分</strong></p><p>水平拆分又称为横向拆分，根据某种规则将数据分散至多个库或表中，每个表仅包含数据的一部分。</p><p><img src="/posts/38076/assets/a5fac8d9023c3ab3d28a1b8f150ce5e1.webp" alt="img"></p><p>水平拆分：解决表中记录过多问题。</p><p>垂直拆分：解决表过多或者是表字段过多问题。</p><p>优点：</p><p>1） 不存在单库大数据，解决高并发的性能瓶颈；</p><p>2） 切分的表的结构相同，应用层改造较少，只需要增加路由规则即可；</p><p>3） 提高了系统的稳定性和负载能力。</p><p>缺点：</p><p>1） 分片事务的一致性难以解决；</p><p>2） 数据扩容的难度和维护量极大。</p><p><strong>主键策略</strong></p><p>1） UUID</p><p>2） SNOWFLAKE(雪花算法)</p><p>3） 数据库ID表</p><p>4） Redis生成ID</p><h3 id="分片策略"><a href="#分片策略" class="headerlink" title="分片策略"></a><strong>分片策略</strong></h3><p>数据分片是根据指定的分片键和分片策略将数据水平拆分，拆分成多个数据片后分散到多个数据存储节点中，其实就是把原本数据打散，存在多个数据库中，他和分库分表的差异就是：分片可以制定规则，相当于逻辑，达到对应目的，而分库分表是最终的物理实现。</p><p><strong>基于范围分片</strong></p><p>根据特定字段的范围进行拆分，比如用户ID、订单时间、产品价格等。</p><p>优点：新的数据可以落在新的存储节点上，如果集群扩容，数据无需迁移。</p><p>缺点：数据热点分布不均，数据冷热不均匀，导致节点负荷不均。</p><p><strong>哈希取模分片</strong></p><p>整型的Key可直接对设备数量取模，其他类型的字段可以先计算Key的哈希值，然后再对设备数量取模。</p><p>优点：实现简单，数据分配比较均匀，不容易出现冷热不均，负荷不均的情况。</p><p>缺点：扩容时会产生大量的数据迁移，比如从n台设备扩容到n+1，绝大部分数据需要重新分配和迁移。</p><p><strong>一致性哈希分片</strong></p><p>一致性Hash是将数据按照特征值映射到一个首尾相接的Hash环上，同时也将节点（按照IP地址或者机器名Hash）映射到这个环上。对于数据，从数据在环上的位置开始，顺时针找到的第一个节 点即为数据的存储节点。</p><p><img src="https://pic4.zhimg.com/80/v2-223ff8107ed392104bce5500f8602897_720w.webp" alt="img"></p><h3 id="扩容方案"><a href="#扩容方案" class="headerlink" title="扩容方案"></a><strong>扩容方案</strong></h3><p>数据库达到承受极限时，就需要增加新服务器节点数量进行横向扩容。</p><p><img src="https://pic4.zhimg.com/80/v2-2b3bad7b01ad32d1e8a203f1efe3498f_720w.webp" alt="img"></p><p>横向扩容需要解决的问题：</p><p>1） 数据迁移问题</p><p>2） 分片规则改变</p><p>3） 数据同步、时间点、数据一致性</p><p><strong>停机扩容</strong></p><p>停止所有对外服务，新增n个数据库，然后写一个数据迁移程序，将原有x个库的数据导入到最新的y个库中，数据迁移完成，修改数据库服务配置，并重启所有服务。</p><p><strong>平滑扩容</strong></p><p>持续对外提供服务，保证服务的可用性，通过配置双主同步、双主双写、检测数据同步等来实现。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;集群架构设计&quot;&gt;&lt;a href=&quot;#集群架构设计&quot; class=&quot;headerlink&quot; title=&quot;集群架构设计&quot;&gt;&lt;/a&gt;&lt;strong&gt;集群架构设计&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;集群架构设计的三个维度：可用性、扩展性、一致性&lt;/p&gt;
&lt;p&gt;&lt;stron</summary>
      
    
    
    
    <category term="基础知识" scheme="https://itingyu.github.io/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    <category term="mysql" scheme="https://itingyu.github.io/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/mysql/"/>
    
    
    <category term="基础知识" scheme="https://itingyu.github.io/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    <category term="mysql" scheme="https://itingyu.github.io/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>mysql事务和锁相关知识</title>
    <link href="https://itingyu.github.io/posts/33988/"/>
    <id>https://itingyu.github.io/posts/33988/</id>
    <published>2023-06-17T11:09:49.000Z</published>
    <updated>2023-06-17T11:10:24.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="ACID特性"><a href="#ACID特性" class="headerlink" title="ACID特性"></a><strong>ACID特性</strong></h3><p>关系型数据库管理系统中，一个逻辑工作单元要成为事务，必须满足这4个特性，即原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）和持久性（Durability）。</p><p>原子性：每一个写事务，都会修改BufferPool，从而产生相应的Redo&#x2F;Undo日志，脏页没有刷成功数据库挂了可以通过 Redo 日志将其恢复出来，脏页刷新成功数据库挂了通过Undo来实现同步。</p><p>持久性：Redo log在系统Crash重启之类的情况时，可以修复数据，从而保障事务的持久性。</p><p>隔离性：InnoDB 支持的隔离性有 4 种，隔离性从低到高分别为：读未提交、读提交、可重复读、可串行化。锁和多版本控制（MVCC）技术就是用于保障隔离性的。</p><p>一致性：数据的完整性是通过原子性、隔离性、持久性来保证的，而这3个特性又是通过 Redo&#x2F;Undo 来保证的。</p><p><img src="https://pic4.zhimg.com/80/v2-71404860e0fc856d6b32c07a85d63973_720w.webp" alt="img"></p><h3 id="并发事务和排队"><a href="#并发事务和排队" class="headerlink" title="并发事务和排队"></a><strong>并发事务和排队</strong></h3><p><strong>事务并发问题</strong></p><p>1） 更新丢失：当两个或多个事务更新同一行记录，会产生更新丢失现象。可以分为回滚覆盖和提交覆盖。</p><p>2） 脏读：一个事务读取到了另一个事务修改但未提交的数据。</p><p>3） 不可重复读：一个事务中多次读取同一行记录不一致，后面读取的跟前面读取的不一致。</p><p>4） 幻读：一个事务中多次按相同条件查询，结果不一致。</p><p><strong>排队</strong></p><p>完全顺序执行所有事务的数据库操作，不需要加锁，简单的说就是全局排队，强一致性，处理性能低。</p><h3 id="排他锁和读写锁"><a href="#排他锁和读写锁" class="headerlink" title="排他锁和读写锁"></a><strong>排他锁和读写锁</strong></h3><p><strong>排他锁</strong></p><p>如果事务之间涉及到相同的数据项时，使用排他锁，或叫互斥锁，先进入的事务独占数据项以后，其他事务被阻塞，等待前面的事务释放锁。</p><p><img src="https://pic2.zhimg.com/80/v2-3da7850b5feff0450d0550d6571afa19_720w.webp" alt="img"></p><p><strong>读写锁</strong></p><p>读写锁就是进一步细化锁的颗粒度，区分读操作和写操作，让读和读之间不加锁，读写锁，可以让读和读并行，而读和写、写和读、写和写这几种之间还是要加排他锁。</p><p><img src="/posts/33988/assets/7975c4777caf188aec2b59efb76c0baa.webp" alt="img"></p><h3 id="MVCC"><a href="#MVCC" class="headerlink" title="MVCC"></a><strong>MVCC</strong></h3><p>多版本控制MVCC，也就是Copy on Write的思想。MVCC除了支持读和读并行，还支持读和写、写和读的并行，但为了保证一致性，写和写是无法并行的，写写并行可以用乐观锁和悲观锁。每次事务修改操作之前，都会在Undo日志中记录修改之前的数据状态和事务号，该备份记录可以用于其他事务的读取，也可以进行必要时的数据回滚。</p><p><img src="/posts/33988/assets/8f328f52741fe0a5dd58cd7a39e809d2.webp" alt="img"></p><p><strong>实现原理</strong></p><p>MVCC最大的好处是读不加锁，读写不冲突。，读操作可以分为两类: 快照读与当前读，支持可重复读和读已提交。</p><p>快照读：读取的是记录的快照版本（有可能是历史版本），不用加锁。</p><p>当前读：读取的是记录的最新版本，并且当前读返回的记录，都会加锁，保证其他事务不会再并发修改这条记录。</p><h3 id="事务隔离级别"><a href="#事务隔离级别" class="headerlink" title="事务隔离级别"></a><strong>事务隔离级别</strong></h3><p>数据库的事务隔离级别越高，并发问题就越小，但是并发处理能力越差。</p><p><img src="/posts/33988/assets/d20761f2109e981b631e6cab738b7419.webp" alt="img"></p><p>读未提交：解决了回滚覆盖类型的更新丢失，但是可能发生脏读现象，也就是可能读取到其他会话中未提交事务修改的数据。</p><p>已提交读：只能读取到其他会话中已经提交的数据，解决了脏读。但可能发生 不可重复读现象，也就是可能在一个事务中两次查询结果不一致。</p><p>可重复度：解决了不可重复读，它确保同一事务的多个实例在并发读取数据时，会看到同样的数据行。不过可能会出现幻读，当用户读取某一范围的数据行时，另一个事务又在该范围插入了新行，当用户在读取该范围的数据时会发现有新的幻影行。</p><p>可串行化：所有的增删改查串行执行。它通过强制事务排序，解决相互冲突，从而解决幻读的问题。</p><p><strong>事务隔离级别和锁的关系</strong></p><p>1）事务隔离级别是SQL92定制的标准，相当于事务并发控制的整体解决方案，本质上是对锁和MVCC使用的封装，隐藏了底层细节。</p><p>2）锁是数据库实现并发控制的基础，事务隔离性是采用锁来实现，对相应操作加不同的锁，就可以防止其他事务同时对数据进行读写操作。</p><p>3）对用户来讲，首先选择使用隔离级别，当选用的隔离级别不能解决并发问题或需求时，才有必要在开发中手动的设置锁。</p><h3 id="锁分类"><a href="#锁分类" class="headerlink" title="锁分类"></a><strong>锁分类</strong></h3><p><strong>操作的粒度可分为表级锁、行级锁和页级锁</strong></p><p>1）表级锁：每次操作锁住整张表。锁定粒度大，发生锁冲突的概率最高，并发度最低。应用在 MyISAM、InnoDB、BDB 等存储引擎中。</p><p>2）行级锁：每次操作锁住一行数据。锁定粒度最小，发生锁冲突的概率最低，并发度最高。应 用在InnoDB 存储引擎中。</p><p>3）页级锁：每次锁定相邻的一组记录，锁定粒度界于表锁和行锁之间，开销和加锁时间界于表锁和行锁之间，并发度一般。应用在BDB 存储引擎中。</p><p><img src="/posts/33988/assets/ed64d9de2e8e13772fa91fb591d76e9b.webp" alt="img"></p><p><strong>操作的类型可分为读锁和写锁</strong></p><p>读锁（S锁）：共享锁，针对同一份数据，多个读操作可以同时进行而不会互相影响。</p><p>写锁（X锁）：排他锁，当前写操作没有完成前，它会阻断其他写锁和读锁。</p><p>IS锁、IX锁：意向读锁、意向写锁，属于表级锁，S和X主要针对行级锁。在对表记录添加S或X锁之前，会先对表添加IS或IX锁。</p><p><strong>操作的性能可分为乐观锁和悲观锁</strong></p><p>乐观锁：一般的实现方式是对记录数据版本进行比对，在数据更新提交的时候才会进行冲突检测，如果发现冲突了，则提示错误信息。</p><p>悲观锁：在对一条数据修改的时候，为了避免同时被其他人修改，在修改数据之前先锁定， 再修改的控制方式。共享锁和排他锁是悲观锁的不同实现，但都属于悲观锁范畴。</p><h3 id="行锁原理"><a href="#行锁原理" class="headerlink" title="行锁原理"></a><strong>行锁原理</strong></h3><p>InnoDB行锁是通过对索引数据页上的记录加锁实现的，主要实现算法有 3 种：Record Lock、Gap Lock 和 Next-key Lock。</p><p>RecordLock锁：锁定单个行记录的锁。（记录锁，RC、RR隔离级别都支持）</p><p>GapLock锁：间隙锁，锁定索引记录间隙，确保索引记录的间隙不变。（范围锁，RR隔离级别支 持）</p><p>Next-key Lock 锁：记录锁和间隙锁组合，同时锁住数据，并且锁住数据前后范围。（记录锁+范围锁，RR隔离级别支持）</p><p><strong>锁的应用</strong></p><p>主键加锁行为：仅在主键索引记录上加X锁。</p><p>唯一键加锁行为：唯一索引上加X锁，然后在主键索引记录上加X锁。</p><p>非唯一键加锁行为：对满足条件的记录和主键分别加X锁，前后范围分别加Gap Lock。</p><p>无索引加锁行为：表里所有行和间隙都会加X锁，当没有索引时，会导致全表锁定，因为InnoDB引擎 锁机制是基于索引实现的记录锁定。</p><p>1） select … from 语句 不加锁</p><p>2） select … from lock in share mode语句 共享锁 Next-Key Lock锁，存在唯一索引可降级为RecordLock锁。</p><p>3） select … from for update语句 排他锁 Next-Key Lock锁，存在唯一索引可降级为RecordLock锁。</p><p>4） update … where 语句 Next-Key Lock锁，存在唯一索引可降级为RecordLock锁。</p><p>5） delete … where 语句 Next-Key Lock锁，存在唯一索引可降级为RecordLock锁。</p><p>6） insert语句 RecordLock锁。</p><h3 id="悲观锁"><a href="#悲观锁" class="headerlink" title="悲观锁"></a><strong>悲观锁</strong></h3><p>数据处理过程，将数据处于锁定状态，一般使用数据库的锁机制实现。从广义上来讲，行锁、表锁、读锁、写锁、共享锁、排他锁等，都属于悲观锁。</p><p>表级锁：每次操作都锁住整张表，并发度最低。</p><p>共享锁（行级锁-读锁）：只能读取，不能修改，修改操作被阻塞。</p><p>排他锁（行级锁-写锁）：当前事务可以读取和修改，其他事务不能修改，也不能获取记录锁。</p><h3 id="乐观锁"><a href="#乐观锁" class="headerlink" title="乐观锁"></a><strong>乐观锁</strong></h3><p>在数据库操作时， 想法很乐观，认为这次的操作不会导致冲突，因此在数据库操作时并不做任何的特殊处理，即不加锁，而是在进行事务提交时再去判断是否有冲突了。</p><p>乐观锁实现：使用版本字段（version）、使用时间戳（Timestamp）</p><p><img src="/posts/33988/assets/2e81b6642ecf30f8803cfbb813f2bba5.webp" alt="img"></p><h3 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a><strong>死锁</strong></h3><p><strong>表锁死锁</strong></p><p>用户A–》A表（表锁）–》B表（表锁）</p><p>用户B–》B表（表锁）–》A表（表锁）</p><p>用户A、B都锁住一张表，又在互相访问且不释放锁住的表资源，因此对于数据库的多表操作时，尽量按照相同的顺序进行处理，尽量避免同时锁定两个资源。</p><p><strong>行级锁死锁</strong></p><p>1）事务中执行了一条没有索引条件的查询，引发全表扫描，把行级锁上升为全表记录锁定，多个这样的事务执行后，就很容易产生死锁和阻塞，因此SQL语句中不要使用太复杂的关联多表的查询。</p><p>2）两个事务分别想拿到对方持有的锁，互相等待，于是产生死锁，因此在同一个事务中，尽可能做到一次锁定所需要的所有资源。</p><p><strong>共享锁转换为排他锁</strong></p><p>事务A查询一条记录，加共享锁，这时候事务B对同一条记录进行更新，事务B 的排他锁要等事务A共享锁释放，而事务A需要继续执行更新需要排他锁，而事务B的排他锁已经在等待队列中，因此可以通过乐观锁控制，或者前端提交按钮做控制，避免用户频繁点击造成这种情况。</p><p><strong>死锁排查</strong></p><p>查看死锁日志及锁状态变量</p><p>1）查看近期死锁日志信息；</p><p>2）使用explain查看下SQL执行计划</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;ACID特性&quot;&gt;&lt;a href=&quot;#ACID特性&quot; class=&quot;headerlink&quot; title=&quot;ACID特性&quot;&gt;&lt;/a&gt;&lt;strong&gt;ACID特性&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;关系型数据库管理系统中，一个逻辑工作单元要成为事务，必须满足这4个特性，即</summary>
      
    
    
    
    <category term="基础知识" scheme="https://itingyu.github.io/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    <category term="mysql" scheme="https://itingyu.github.io/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/mysql/"/>
    
    
    <category term="基础知识" scheme="https://itingyu.github.io/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    <category term="mysql" scheme="https://itingyu.github.io/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>mysql索引原理相关知识</title>
    <link href="https://itingyu.github.io/posts/64993/"/>
    <id>https://itingyu.github.io/posts/64993/</id>
    <published>2023-06-17T11:08:54.000Z</published>
    <updated>2023-06-17T11:09:37.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="索引类型"><a href="#索引类型" class="headerlink" title="索引类型"></a><strong>索引类型</strong></h3><p>索引可以提升查询速度，会影响where查询，以及order by排序，分为B Tree索引、Hash索引、FULLTEXT全文索引、R Tree索引、普通索引、唯一索引、主键索引、复合索引、主键索引、辅助索引、聚集索引（聚簇索引）、非聚集索引（非聚簇索引）</p><p>1） 普通索引：这是最基本的索引类型，基于普通字段建立的索引，没有任何限制。</p><p>ALTER TABLE tablename ADD INDEX [索引的名字] (字段名);</p><p>2） 唯一索引：索引字段的值必须唯一，但允许有空值 。</p><p>ALTER TABLE tablename ADD UNIQUE INDEX [索引的名字] (字段名);</p><p>3） 主键索引：它是一种特殊的唯一索引，不允许有空值。</p><p>ALTER TABLE tablename ADD PRIMARY KEY (字段名);</p><p>4） 复合索引：用户可以在多个列上建立索 引，这种索引叫做组复合索引，分窄索引和宽索引，使用复合索引，要根据where条件建索引。</p><p>ALTER TABLE tablename ADD INDEX [索引的名字] (字段名1，字段名2…);</p><p>5） 全文索引：对于大量的文本数据检索，使用模糊查询效率很低。使用全文索引，查询速度会比like快很多倍。全文索引字段值可以进行切词模糊查询。</p><p>创建方式：ALTER TABLE tablename ADD FULLTEXT [索引的名字] (字段名); CREATE TABLE tablename ( […], FULLTEXT KEY [索引的名字] (字段名</p><h3 id="索引原理"><a href="#索引原理" class="headerlink" title="索引原理"></a><strong>索引原理</strong></h3><p>索引是存储引擎用于快速查找记录的一种数据结构，物理数据页存储。需要额外开辟空间和数据维护工作，索引可以加快检索速度，但是同时也会降低增删改操作速度。</p><p><strong>二分查找法</strong></p><p><img src="/posts/64993/assets/78a49e6672d130a510cc87213887afa5.webp" alt="img"></p><p><img src="/posts/64993/assets/71bd060e19c3088f4808935ab8c0a43a.webp" alt="img"></p><p><img src="/posts/64993/assets/98c59f3c35a83d16d38976377aff400e.webp" alt="img"></p><p><img src="https://pic2.zhimg.com/80/v2-9df413feb67d3705c869d8bfd878b17d_720w.webp" alt="img"></p><p><strong>Hash结构</strong></p><p>Hash底层实现是由Hash表来实现的，是根据键值存储数据的结构。</p><p><img src="/posts/64993/assets/3f8980f1321f3b022555adb949705cc9.webp" alt="img"></p><h3 id="B-Tree结构"><a href="#B-Tree结构" class="headerlink" title="B+Tree结构"></a><strong>B+Tree结构</strong></h3><p>MySQL数据库索引采用的是B+Tree结构，在B-Tree结构上做了优化改造。</p><p><strong>B-Tree结构</strong></p><p><img src="/posts/64993/assets/8b7de0a7f2f4c5eed089dbeed90cbea6.webp" alt="img"></p><p>原理：从根节点开始，对节点内的索引值序列采用二分法查找，如果命中就结束查找。没有命中会进入子节点重复查找过程，直到所对应的的节点指针为空，或已经是叶子节点了才结束。</p><p><strong>B+Tree结构</strong></p><p><img src="/posts/64993/assets/5db2ac84e330d1d2f5e2d02866989ea7.webp" alt="img"></p><p>B+树进行范围查找时，只需要查找定位两个节点的索引值，然后利用叶子节点的指针进行遍历。</p><h3 id="聚簇索引和辅助索引"><a href="#聚簇索引和辅助索引" class="headerlink" title="聚簇索引和辅助索引"></a><strong>聚簇索引和辅助索引</strong></h3><p>B+Tree的叶子节点存放主键索引值和行记录就属于聚簇索引；如果索引值和行记录分开存放就属于非聚簇索引。</p><p>B+Tree的叶子节点存放的是主键字段值就属于主键索引；如果存放的是非主键值 就属于辅助索引。</p><p>聚簇索引：如果表定义了主键，则主键索引就是聚簇索引，否则第一个非空unique列作为聚簇索引，不然自建隐藏索引。</p><p>辅助索引：一个表InnoDB只能创建一个聚簇索引，但可以创建多个辅助索引。</p><p>非聚簇索引： MyISAM数据表的索引文件和数据文件是分开的，被称为非聚簇索引结构。</p><h3 id="Explain分析"><a href="#Explain分析" class="headerlink" title="Explain分析"></a><strong>Explain分析</strong></h3><p>EXPLAIN 命令用于对 SELECT 语句进行分析，并输出 SELECT 执行的详细信息。</p><p><img src="/posts/64993/assets/fd9b9cc140c5e7300cedbd16745c0289.webp" alt="img"></p><p><strong>select_type查询的类型</strong></p><p>SIMPLE ： 表示查询语句不包含子查询或union</p><p>PRIMARY：表示此查询是最外层的查询</p><p>UNION：表示此查询是UNION的第二个或后续的查询</p><p>DEPENDENT UNION：UNION中的第二个或后续的查询语句，使用了外面查询结果</p><p>UNION RESULT：UNION的结果</p><p>SUBQUERY：SELECT子查询语句</p><p>DEPENDENT SUBQUERY：SELECT子查询语句依赖外层查询的结果。</p><p><strong>type</strong></p><p>ALL：表示全表扫描，性能最差。</p><p>index：表示基于索引的全表扫描，先扫描索引再扫描全表数据。</p><p>range：表示使用索引范围查询。使用&gt;、&gt;&#x3D;、&lt;、&lt;&#x3D;、in等等。</p><p>ref：表示使用非唯一索引进行单值查询。</p><p>eq_ref：一般情况下出现在多表join查询，表示前面表的每一个记录，都只能匹配后面表的一 行结果。</p><p>const：表示使用主键或唯一索引做等值查询，常量查询。</p><p>NULL：表示不用访问表，速度最快。</p><p><strong>possible_keys</strong></p><p>表示查询时能够使用到的索引。注意并不一定会真正使用，显示的是索引名称。</p><p><strong>key</strong></p><p>表示查询时真正使用到的索引，显示的是索引名称。</p><p><strong>rows</strong></p><p>MySQL查询优化器会根据统计信息，估算SQL要查询到结果需要扫描多少行记录。</p><p><strong>key_len</strong></p><p>表示查询使用了索引的字节数量。可以判断是否全部使用了组合索引。</p><p><strong>Extra</strong></p><p>Using where: 表示查询需要通过索引回表查询数据。</p><p>Using index: 表示查询需要通过索引，索引就可以满足所需数据。</p><p>Using filesort: 表示查询出来的结果需要额外排序，数据量小在内存，大的话在磁盘，有Using filesort 建议优化。</p><p>Using temprorary: 查询使用到了临时表，一般出现于去重、分组等操作。</p><h3 id="回表查询"><a href="#回表查询" class="headerlink" title="回表查询"></a><strong>回表查询</strong></h3><p>通过辅助索引无法直接定位行记录, 先通过辅助索引定位主键值，然后再通过聚簇索引定位行记录，它的性能比扫一遍索引树低。</p><h3 id="覆盖索引"><a href="#覆盖索引" class="headerlink" title="覆盖索引"></a><strong>覆盖索引</strong></h3><p>只需要在一棵索引树上就能获取SQL所需的所有列数据，无需回表，速度更快，这就叫做索引覆盖。将被查询的字段，建立到组合索引。</p><h3 id="最左前缀原则"><a href="#最左前缀原则" class="headerlink" title="最左前缀原则"></a><strong>最左前缀原则</strong></h3><p>复合索引使用时遵循最左前缀原则，最左前缀顾名思义，就是最左优先，即查询中使用到最左边的列， 那么查询就会使用到索引，如果从索引的第二列开始查找，索引将失效。</p><h3 id="LIKE查询和NULL查询"><a href="#LIKE查询和NULL查询" class="headerlink" title="LIKE查询和NULL查询"></a><strong>LIKE查询和NULL查询</strong></h3><p>select * from user where name like ‘%o%’; &#x2F;&#x2F;不起作用</p><p>select * from user where name like ‘o%’; &#x2F;&#x2F;起作用</p><p>select * from user where name like ‘%o’; &#x2F;&#x2F;不起作用</p><p>可以在含有NULL的列上使用索引，但NULL和其他数据还是有区别的，NULL列需要增加额外空间来记录其值是否为NULL。</p><h3 id="索引与排序"><a href="#索引与排序" class="headerlink" title="索引与排序"></a><strong>索引与排序</strong></h3><p>MySQL查询支持filesort和index两种方式的排序，filesort是先把结果查出，然后在缓存或磁盘进行排序操作，效率较低。使用index是指利用索引自动实现排序，不需另做排序操作，效率会比较高。</p><p>filesort有两种排序算法：双路排序和单路排序。</p><p><strong>index方式的排序</strong></p><ol><li><p>ORDER BY 子句索引列组合满足索引最左前列</p></li><li><p>WHERE子句+ORDER BY子句索引列组合满足索引最左前列</p></li></ol><p><strong>filesort方式的排序</strong></p><ol><li><p>对索引列同时使用了ASC和DESC</p></li><li><p>WHERE子句和ORDER BY子句满足最左前缀，但where子句使用了范围查询（例如&gt;、&lt;、in等）</p></li><li><p>ORDER BY或者WHERE+ORDER BY索引列没有满足索引最左前列</p></li><li><p>使用了不同的索引，MySQL每次只采用一个索引，ORDER BY涉及了两个索引</p></li><li><p>WHERE子句与ORDER BY子句，使用了不同的索引</p></li><li><p>WHERE子句或者ORDER BY子句中索引列使用了表达式，包括函数表达式</p></li></ol><h3 id="慢查询定位"><a href="#慢查询定位" class="headerlink" title="慢查询定位"></a><strong>慢查询定位</strong></h3><p>开启慢查询日志: SHOW VARIABLES LIKE ‘slow_query_log%’</p><p>通过文本编辑器打开slow.log日志</p><p>time：日志记录的时间</p><p>User@Host：执行的用户及主机</p><p>Query_time：执行的时间</p><p>Lock_time：锁表时间</p><p>Rows_sent：发送给请求方的记录数，结果数量</p><p>Rows_examined：语句扫描的记录条数</p><p>SET timestamp：语句执行的时间点</p><p>select….：执行的具体的SQL语句</p><p>也可以通过分析工具查看，比如mysqldumpslow。</p><h3 id="慢查询优化"><a href="#慢查询优化" class="headerlink" title="慢查询优化"></a><strong>慢查询优化</strong></h3><p><strong>如何判断是否为慢查询？</strong></p><p>依据SQL语句的执行时间，它把当前语句的执行时间跟 long_query_time 参数做比较，超出记录日志，long_query_time 参数的默认值是 10s，该参数值可以根据自己的业务需要进行调整。</p><p><strong>如何判断是否应用了索引？</strong></p><p>根据SQL语句执行过程中有没有用到表的索引，可通过 explain 命令分析查看</p><p>查询是否使用索引，只是表示一个SQL语句的执行过程；而是否为慢查询，是由它执行的时间决定，不止要创建索引，还要考虑索引过滤性，过滤性好，执行速度才会快。</p><p><strong>慢查询原因总结</strong></p><p>1） 全表扫描：explain分析type属性all</p><p>2） 全索引扫描：explain分析type属性index</p><p>3） 索引过滤性不好：靠索引字段选型、数据量和状态、表设计</p><p>4） 频繁的回表查询开销：尽量少用select *，使用覆盖索引</p><h3 id="分页查询优化"><a href="#分页查询优化" class="headerlink" title="分页查询优化"></a><strong>分页查询优化</strong></h3><p>一般的分页查询使用简单的 limit 子句就可以实现</p><p>SELECT * FROM 表名 LIMIT [offset,] rows</p><p>如果查询偏移量变化，比如查询万，百万级后面的数据，就不能用简单的直接分页了</p><p>1） 利用覆盖索引优化</p><p>2） 利用子查询优化</p><p>select * from user where id&gt;&#x3D; (select id from user limit 10000,1) limit 100;</p><p>使用了id做主键比较(id&gt;&#x3D;)，并且子查询使用了覆盖索引进行优化。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;索引类型&quot;&gt;&lt;a href=&quot;#索引类型&quot; class=&quot;headerlink&quot; title=&quot;索引类型&quot;&gt;&lt;/a&gt;&lt;strong&gt;索引类型&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;索引可以提升查询速度，会影响where查询，以及order by排序，分为B Tree索引</summary>
      
    
    
    
    <category term="基础知识" scheme="https://itingyu.github.io/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    <category term="mysql" scheme="https://itingyu.github.io/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/mysql/"/>
    
    
    <category term="基础知识" scheme="https://itingyu.github.io/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    <category term="mysql" scheme="https://itingyu.github.io/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>mysql架构原理相关知识</title>
    <link href="https://itingyu.github.io/posts/55736/"/>
    <id>https://itingyu.github.io/posts/55736/</id>
    <published>2023-06-17T11:07:51.000Z</published>
    <updated>2023-06-20T07:39:56.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="体系架构"><a href="#体系架构" class="headerlink" title="体系架构"></a>体系架构</h2><p>MySQL Server架构自顶向下大致可以分网络连接层、服务层、存储引擎层和系统文件层。</p><p><img src="/posts/55736/assets/63c91ba3413830969fd9e89113b66589.webp" alt="img"></p><p><strong>网络连接层</strong></p><p>客户端连接器：提供与MySQL服务器建立的支持。</p><p><strong>服务层</strong></p><p>主要包含系统管理和控制工具、连接池、SQL接口、解析器、查询优化器和缓存六个部分。</p><p>1） 连接池：存储和管理客户端与数据库的连接。</p><p>2） 系统管理和控制工具：集群、备份、安全管理。</p><p>3） SQL接口：接受客户端发送的各种SQL命令并返回查询结果。</p><p>4） 解析器：解析SQL，生成一颗解析树，验证SQL是否合法。</p><p>5） 查询优化器：将解析树转化成执行计划，与存储引擎进行交互。</p><p>6） 缓存：各种缓存，比如表、记录、权限等等，缓存有命中查询结果直接返回。</p><p><strong>存储引擎层</strong></p><p>负责MySQL中数据的存储与提取，与底层系统文件进行交互，可插拔，常见的两类：MyISAM和InnoDB。</p><p><strong>系统文件层</strong></p><p>负责将数据库的数据和日志存储在文件系统之上，并完成与存储引擎的交互，比如日志、配置文件等等。</p><p>错误日志查询：show variables like ‘%log_error%’</p><p>通用查询日志：show variables like ‘%general%’;</p><p>二进制日志(恢复和主从复制)：show binary logs;</p><p>慢查询日志(记录超时，默认10秒)：show variables like ‘%slow_query%’;</p><p>配置文件: 存放MySQL所有的配置信息文件。</p><h2 id="运行机制"><a href="#运行机制" class="headerlink" title="运行机制"></a>运行机制</h2><p><img src="/posts/55736/assets/5fb31418669f8ea6c64b9283a04db98b.webp" alt="img"></p><p>1） 建立连接，通过客户端&#x2F;服务器通信协议与MySQL建立连接。通信方式是半双工，也就是不能同时即发送数据也接收数据，除此之外还有全双工和单工，通过show processlist;可以查看用户正在运行的线程信息。</p><p>2） 查询缓存，开启了查询缓存且在查询缓存过程中查询到完全相同的SQL语句，则将查询结果直接返回给客户端，没有的话则进入下一环节。不过查询的结果大于query_cache_limit设置或者存在不确定参数，比如now()不会走缓存。show variables like ‘%query_cache%’;可查看缓存信息。</p><p>3） 解析器，将客户端发送的SQL进行语法解析，生成”解析树”，并检验SQL是否合法。</p><p>4） 查询优化器，根据“解析树”生成最优的执行计划，其实就是SQL优化，比如in排序，max函数等等。</p><p>5） 查询执行引擎，根据 SQL 语句中表的存储引擎类型，以及对应的API接口与底层存储引擎缓存或者物理文件的交互，得到查询结果并返回给客户端，如果开启了查询缓存，会把结果存入缓存中，并且返回方式是增量返回，不是一次性全部返回。</p><h2 id="存储引擎"><a href="#存储引擎" class="headerlink" title="存储引擎"></a>存储引擎</h2><p>根据MySQL提供的文件访问层抽象接口定制的一种文件访问机制，负责MySQL中的数据的存储和提取。5.5版本之前默认采用MyISAM存储引擎，5.5开始采用InnoDB存储引擎。</p><p><strong>InnoDB和MyISAM对比</strong></p><p>1）事务和外键</p><p>InnoDB支持事务和外键，具有安全性和完整性，适合大量insert或update操作</p><p>MyISAM不支持事务和外键，它提供高速存储和检索，适合大量的select查询操作</p><p>2）锁机制</p><p>InnoDB支持行级锁，锁定指定记录。基于索引来加锁实现。</p><p>MyISAM支持表级锁，锁定整张表。</p><p>3）索引结构</p><p>InnoDB使用聚集索引（聚簇索引），索引和记录在一起存储，既缓存索引，也缓存记录。</p><p>MyISAM使用非聚集索引（非聚簇索引），索引和记录分开。</p><p>4）并发处理能力</p><p>MyISAM使用表锁，会导致写操作并发率低，读之间并不阻塞，读写阻塞。</p><p>InnoDB读写阻塞可以与隔离级别有关，可以采用多版本并发控制（MVCC）来支持高并发</p><p>5）存储文件</p><p>InnoDB表对应两个文件，一个.frm表结构文件，一个.ibd数据文件。InnoDB表最大支持64TB；</p><p>MyISAM表对应三个文件，一个.frm表结构文件，一个MYD表数据文件，一个.MYI索引文件。默认限制是256TB。</p><p>6）MyISAM适用场景</p><p>不需要事务支持（不支持）</p><p>并发相对较低（锁定机制问题）</p><p>数据修改相对较少，以读为主</p><p>数据一致性要求不高</p><p>7）InnoDB适用场景</p><p>需要事务支持（具有较好的事务特性）</p><p>行级锁定对高并发有很好的适应能力</p><p>数据更新较为频繁的场景</p><p>数据一致性要求较高</p><p>硬件设备内存较大，可以利用InnoDB较好的缓存能力来提高内存利用率，减少磁盘IO</p><h2 id="InnoDB存储结构"><a href="#InnoDB存储结构" class="headerlink" title="InnoDB存储结构"></a>InnoDB存储结构</h2><p>MySQL 5.5版本开始默认使用InnoDB作为引擎，它擅长处理事务，具有自动崩溃恢复的特性。</p><p><img src="/posts/55736/assets/5e54f8668d1b9e45733634324fc171df.webp" alt="img"></p><p>内存结构主要包括Buffer Pool、Change Buffer、Adaptive Hash Index和Log Buffer四大组件。</p><p><strong>Buffer Pool</strong></p><p>缓冲池，简称BP。BP以Page页为单位，默认大小16K，BP的底层采用链表数据结构管理Page。通过改进型LRU算法维护，即中间插入，命中往头部移动，未命中往尾部移动，实行末尾淘汰。</p><p>建议：将innodb_buffer_pool_size设置为总内存大小的60%-80%，innodb_buffer_pool_instances可以设置为多个，这样可以避免缓存争夺。</p><p><strong>Change Buffer</strong></p><p>写缓冲区，简称CB。在进行DML操作时，如果BP没有其相应的Page数据，并不会立刻将磁盘页加载到缓冲池，而是在CB记录缓冲变更，等未来数据被读取时，再将数据合并恢复到BP中，默认占BP的25%。</p><p><strong>Adaptive Hash Index</strong></p><p>自适应哈希索引，用于优化对BP数据的查询。InnoDB存储引擎会自动根据访问的频率和模式来为某些页建立哈希索引。</p><p><strong>Log Buffer</strong></p><p>日志缓冲区，保存要写入磁盘上log文件（Redo&#x2F;Undo）的数据，日志缓冲区的内容定期刷新到磁盘log文件中。</p><p>缓冲区满自动刷新到磁盘。</p><h2 id="InnoDB磁盘结构"><a href="#InnoDB磁盘结构" class="headerlink" title="InnoDB磁盘结构"></a>InnoDB磁盘结构</h2><p>InnoDB磁盘主要包含Tablespaces，InnoDB Data Dictionary，Doublewrite Buffer、Redo Log 和Undo Logs。</p><p><strong>表空间（Tablespaces）</strong></p><p>存储表结构和数据。并且分为系统表空间、独立表空间、 通用表空间、临时表空间、Undo表空间等多种类型。</p><p>1） 系统表空间：默认包含任何用户在系统表空间创建的表数据和索引数据，是InnoDB Data Dictionary，Doublewrite Buffer，Change Buffer，Undo Logs的存储区域。</p><p>2） 独立表空间：默认开启，独立表空间是一个单表表空间，该表创建于自己的数据文件中，而非创建于系统表空间中。</p><p>3） 通用表空间：通用表空间为通过create tablespace语法创建的共享表空间。</p><p>4） 撤销表空间：撤销表空间由一个或多个包含Undo日志文件组成。</p><p>5） 临时表空间：分为session temporary tablespaces 和global temporary tablespace两种。session temporary tablespaces 存储的是用户创建的临时表和磁盘内部的临时表。global temporary tablespace储存用户临时表的回滚段。</p><p><strong>数据字典（InnoDB Data Dictionary）</strong></p><p>InnoDB数据字典由内部系统表组成，这些表包含用于查找表、索引和表字段等对象的元数据。</p><p><strong>双写缓冲区（Doublewrite Buffer）</strong></p><p>位于系统表空间，是一个存储区域。在BufferPage的page页刷新到磁盘真正的位置前，会先将数据存在Doublewrite 缓冲区，当出现进程崩溃，从这里获取数据并恢复。</p><p><strong>重做日志（Redo Log）</strong></p><p>重做日志是一种基于磁盘的数据结构，用于在崩溃恢复期间更正不完整事务写入的数据。MySQL以循环方式写入重做日志文件，记录InnoDB中所有对Buffer Pool修改的日志，当出现崩溃从重做日志中把数据更新到数据文件。</p><p><strong>撤销日志（Undo Logs）</strong></p><p>撤消日志是在事务开始之前保存的被修改数据的备份，用于例外情况时回滚事务。撤消日志属于逻辑日志，根据每行记录进行记录。</p><p><strong>版本差异</strong></p><p>5.7版本：Undo日志表空间从共享表空间分离，安装时可自由指定，增加临时表空间，并且可动态修改Buffer Pool</p><p>8.0版本：数据字典和Undo、Doublewrite Buffer都从共享表空间分离，临时表空间可以配置多个物理文件。</p><h2 id="InnoDB线程模型"><a href="#InnoDB线程模型" class="headerlink" title="InnoDB线程模型"></a>InnoDB线程模型</h2><p><img src="/posts/55736/assets/46fb6536b02296f63d9c07827eec58d1.webp" alt="img"></p><p><strong>IO Thread</strong></p><p>使用了大量的AIO（Async IO）来做读写处理，10个IO Thread，分别是write（4），read（4），insert buffer和log thread。</p><p><strong>Purge Thread</strong></p><p>事务提交之后，回收已经分配的undo 页。</p><p><strong>Page Cleaner Thread</strong></p><p>将脏数据刷新到磁盘，脏数据刷盘后相应的redo log也就可以覆盖，即可以同步数据，又能达到redo log循环使用的目的。</p><p><strong>Master Thread</strong></p><p>Master thread是InnoDB的主线程，负责调度其他各线程，优先级最高。作用是将缓冲池中的数据异步刷新到磁盘 ，保证数据的一致性，比如脏页的刷新、undo页回收、redo日志刷新、合并写缓冲等，分1秒和10秒执行。</p><h2 id="InnoDB数据文件"><a href="#InnoDB数据文件" class="headerlink" title="InnoDB数据文件"></a>InnoDB数据文件</h2><p><img src="/posts/55736/assets/b16d631ed851900555ec815f1b005295.webp" alt="img"></p><p>InnoDB数据文件存储结构：分为一个ibd数据文件-&gt;Segment（段）-&gt;Extent（区）-&gt;Page（页）-&gt;Row（行）</p><p>Tablesapce：表空间，用于存储多个ibd数据文件，用于存储表的记录和索引。一个文件包含多个段。</p><p>Segment：段，用于管理多个Extent，分为数据段、索引段、回滚段。</p><p>Extent：区，一个区固定包含64个连续的页，大小为1M。</p><p>Page：页，用于存储多个Row行记录，大小为16K。包含很多种页类型，比如数据页，undo页，系统页等等。</p><p>Row：行，包含了记录的字段值，事务ID、滚动指针、字段指针等信息。</p><p>InnoDB只支持两种文件格式：Antelope 和 Barracuda。</p><p>InnoDB存储引擎支持四种行格式：REDUNDANT、COMPACT、DYNAMIC和COMPRESSED。</p><h2 id="Undo-Log"><a href="#Undo-Log" class="headerlink" title="Undo Log"></a>Undo Log</h2><p>数据库事务开始之前，会将要修改的记录存放到 Undo 日志里，当事务回滚时或者数据库崩溃时，可以利用 Undo 日志，撤销未提交事务对数据库产生的影响。事务提交之后也不会马上删除，而是进入删除队列待删除。Undo Log属于逻辑日志，记录一个变化过程，采用段的方式管理和记录。例如执行一个delete，undolog会记录一个insert；执行一个update，undolog会记录一个相反的update。</p><p>1） 实现事务的原子性</p><p>事务处理过程中，如果出现了错误或者用户执行了 ROLLBACK 语句，MySQL可以利用 Undo Log中的备份将数据恢复到事务开始之前的状态。</p><p>2） 实现多版本并发控制（MVCC）</p><p>事务未提交之前，Undo Log保存了未提交之前的版本数据，Undo Log中的数据可作为数据旧版本快照供其他并发事务进行快照读。</p><p><img src="/posts/55736/assets/37d40ba1af52916eabe38540b8a61696.webp" alt="img"></p><h3 id="Redo-Log"><a href="#Redo-Log" class="headerlink" title="Redo Log"></a>Redo Log</h3><p>指事务中修改的任何数据，将最新的数据备份存储的位置（Redo Log），被称为重做日志。事务操作的执行，就会生成Redo Log，在事务提交时会将产生Redo Log写入Log Buffer。等事务操作的脏页写入到磁盘之后，Redo Log占用的空间会被覆盖写入。</p><p><img src="https://pic3.zhimg.com/80/v2-8032b827a564cb1b085a64cc62d74136_720w.webp" alt="img"></p><p>Redo Log 文件内容是以顺序循环的方式写入文件，写满时则回溯到第一个文件，进行覆盖写。</p><h3 id="Binlog日志"><a href="#Binlog日志" class="headerlink" title="Binlog日志"></a>Binlog日志</h3><p>MySQL Server的日志，即Binary log（二进制日志），简称Binlog。Binlog是记录所有数据库表结构变更以及表数据修改的二进制日志，不会记录SELECT和SHOW这类操作。Binlog日志是以事件形式记录，还包含语句所执行的消耗时间。用于主从复制和数据恢复。</p><p>Binlog文件名默认为“主机名_binlog-序列号”格式，文件记录模式有STATEMENT、ROW和MIXED三种。</p><p><strong>Binlog文件结构</strong></p><p>MySQL的binlog文件中记录的是对数据库的各种修改操作，用来表示修改操作的数据结构是Log event。</p><p><img src="/posts/55736/assets/a0acf9f627cd711383546758f1130361.webp" alt="img"></p><p><strong>Binlog写入机制</strong></p><p>1） 根据记录模式和操作触发event事件生成log event（事件触发执行机制）</p><p>2） 将事务执行过程中产生log event写入缓冲区，每个事务线程都有一个缓冲区，存放两个缓冲区，即支持事务和不支持事务的缓冲区。</p><p>3） 事务在提交阶段会将产生的log event写入到外部binlog文件中，以串行写入，保证连续性。</p><p><strong>Binlog文件操作</strong></p><p>状态查看：show variables like ‘log_bin’;</p><p>开启Binlog功能：set global log_bin&#x3D;mysqllogbin;</p><p>使用 binlog 恢复数据：</p><p>mysqlbinlog–start-datetime&#x3D;”2020-04-25 18:00:00” –stopdatetime&#x3D;”2020-04-26 00:00:00” mysqlbinlog.000002 | mysql -uroot -p1234 &#x2F;&#x2F;按指定时间恢复</p><p>mysqlbinlog –start-position&#x3D;154 –stop-position&#x3D;957 mysqlbinlog.000002 | mysql -uroot -p1234&#x2F;&#x2F;按事件位置号恢复</p><p>删除Binlog文件：purge binary logs to ‘mysqlbinlog.000001’; &#x2F;&#x2F;删除指定文件</p><p>可以通过设置expire_logs_days参数来启动自动清理功能。默认值为0表示没启用。设置为1表示超 出1天binlog文件会自动删除掉。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;体系架构&quot;&gt;&lt;a href=&quot;#体系架构&quot; class=&quot;headerlink&quot; title=&quot;体系架构&quot;&gt;&lt;/a&gt;体系架构&lt;/h2&gt;&lt;p&gt;MySQL Server架构自顶向下大致可以分网络连接层、服务层、存储引擎层和系统文件层。&lt;/p&gt;
&lt;p&gt;&lt;img src=</summary>
      
    
    
    
    <category term="基础知识" scheme="https://itingyu.github.io/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    <category term="mysql" scheme="https://itingyu.github.io/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/mysql/"/>
    
    
    <category term="基础知识" scheme="https://itingyu.github.io/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    <category term="mysql" scheme="https://itingyu.github.io/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>mysql性能优化总结</title>
    <link href="https://itingyu.github.io/posts/48068/"/>
    <id>https://itingyu.github.io/posts/48068/</id>
    <published>2023-06-17T11:07:09.000Z</published>
    <updated>2023-06-17T11:07:25.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="系统配置优化"><a href="#系统配置优化" class="headerlink" title="系统配置优化"></a><strong>系统配置优化</strong></h2><p>1）保证从内存中读取数据，扩大innodb_buffer_pool_size，默认128M，可到3&#x2F;4，修改 my.cnf，降低磁盘操作。</p><p>2）数据预热，通过预热脚本，将磁盘上的全部数据缓存到内存中。</p><p>3）降低磁盘写入次数，增大redolog，减少落盘次数，生产中不开通用查询日志，遇到性能问题开慢查询日志，不要求极高安全性，将写redolog策略 innodb_flush_log_at_trx_commit设置为0或2，不即时写入减少磁盘操作。</p><p>4）提高磁盘读写性能，使用SSD或内存磁盘。</p><h2 id="表结构设计优化"><a href="#表结构设计优化" class="headerlink" title="表结构设计优化"></a><strong>表结构设计优化</strong></h2><p>1）设计中间表，针对于统计或实时性不高需求。</p><p>2）设计冗余字段，减少表之间关联操作，比如用户、订单，也可以在订单表加入一个所属用户姓名。</p><p>3）拆表，字段太多或者字段使用较少进行拆分。</p><p>4）主键优化，每张表一个主键索引，分布式情况下雪花，不然就自增。</p><p>5）字段设计，将表字段长度设计得尽量小，因为越小查询越快，而且最好都为not null避免null值比较，能用数值类型就别用文本，数值类型效率高，如性别。</p><h2 id="SQL索引及优化"><a href="#SQL索引及优化" class="headerlink" title="SQL索引及优化"></a><strong>SQL索引及优化</strong></h2><p>1）使用explain查看索引使用情况，通过慢查询日志找执行时间过程的sql，进行分析，查看索引使用情况，重点关注如下：</p><p>type列，连接类型，最好达到range级别，杜绝出现all级别。</p><p>rows列，扫描行数，预估值。</p><p>extra列，详细说明，建议优化的值如下：Using filesort，Using temporary 。</p><p>2）sql语句中in包含的值不应过多，避免消耗过大。</p><p>3）select语句务必指明字段名称，减少CPU、IO、内存、网络带宽消耗，而且表结构变化用*可能影响前端。</p><p>4）当只需要一条数据的时候，使用limit 1，停止全表扫描。</p><p>5）排序字段加索引提高效率。</p><p>6）限制条件中其他字段没有索引，尽量少用or，否则会造成查询不走索引。</p><p>7）用union all 代替union，因为union将结果合并后还要过滤性操作去重。</p><p>8）order by rand()不走索引，别用。</p><p>9）区分in和exists、not in和not exists，如果是exists，那么以外层表为驱动表，先被访问，如果是in，那么先执行子查询。所以in适合于外表大而内表小的情况；exists适合于外表小而内表大的情况。</p><p>10）使用合理的分页方式以提高分页的效率，降低 limit m,n 中m 的值。</p><p>11）分段查询，当查询范围过大，查询缓慢时，通过程序，分段进行查询，循环遍历，将结果合并处理。</p><p>12）不建议使用%前缀模糊查询，只有’name%’才有走索引。</p><p>13）where子句中对字段少用表达式操作，因为会造成不走索引。</p><p>14）避免隐式转换，传入类型和定义类型不一致触发隐式转换。</p><p>15）联合索引，要遵守最左前缀法则，否则失效。</p><p>16）优化器采取它认为合适的索引来检索sql语句效率不理想可以使用force index来强制查询走某个索引。</p><p>17）存在范围查询，比如between、&gt;、&lt;等条件时，会造成后面的索引字段失效。</p><p>18）使用join优化，尽量使用inner join，避免left join，并且以小表驱动大表，减少嵌套循环 次数。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;系统配置优化&quot;&gt;&lt;a href=&quot;#系统配置优化&quot; class=&quot;headerlink&quot; title=&quot;系统配置优化&quot;&gt;&lt;/a&gt;&lt;strong&gt;系统配置优化&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;1）保证从内存中读取数据，扩大innodb_buffer_pool_siz</summary>
      
    
    
    
    <category term="基础知识" scheme="https://itingyu.github.io/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    <category term="mysql" scheme="https://itingyu.github.io/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/mysql/"/>
    
    
    <category term="基础知识" scheme="https://itingyu.github.io/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    <category term="mysql" scheme="https://itingyu.github.io/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>springcloud组件知识</title>
    <link href="https://itingyu.github.io/posts/30414/"/>
    <id>https://itingyu.github.io/posts/30414/</id>
    <published>2023-06-17T11:01:03.000Z</published>
    <updated>2023-06-17T11:02:10.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="一、Spring-Cloud基础知识"><a href="#一、Spring-Cloud基础知识" class="headerlink" title="一、Spring Cloud基础知识"></a>一、Spring Cloud基础知识</h3><h3 id="微服务架构"><a href="#微服务架构" class="headerlink" title="微服务架构"></a>微服务架构</h3><p>微服务架构可以说是SOA架构的⼀种拓展，这种架构模式下它拆分粒度更⼩、服务更独⽴。把应⽤拆分成为⼀个个微⼩的服务，不同的服务可以使⽤不同的开发语⾔和存储，服务之间往往通过Restful等轻量级通信。微服务架构关键在于微⼩、独⽴、轻量级通信。微服务是在SOA上做的升华粒度更加细致，微服务架构强调的⼀个重点是“业务需要彻底的组件化和服务化。</p><p><img src="/posts/30414/assets/a7b08d8aa29f8dc93f072c4539021b3a.webp" alt="img"></p><p><strong>微服务架构的优点</strong></p><p>1）微服务很⼩，便于特定业务功能的聚焦 A B C D</p><p>2）微服务很⼩，每个微服务都可以被⼀个⼩团队单独实施（开发、测试、部署上线、运维），团队合作⼀定程度解耦，便于实施敏捷开发</p><p>3）微服务很⼩，便于重⽤和模块之间的组装</p><p>4）微服务很独⽴，那么不同的微服务可以使⽤不同的语⾔开发，松耦合</p><p>5）微服务架构下，我们更容易引⼊新技术</p><p>6）微服务架构下，我们可以更好的实现DevOps开发运维⼀体化；</p><p><strong>微服务架构的缺点</strong></p><p>1）微服务架构下，分布式复杂难以管理，当服务数量增加，管理将越加复杂；</p><p>2）微服务架构下，分布式链路跟踪难等；</p><p><strong>微服务架构的概念</strong></p><p>服务注册：服务提供者将所提供服务的信息（服务器IP和端⼝、服务访问协议等） 注册&#x2F;登记到注册中⼼</p><p>服务发现：服务消费者能够从注册中⼼获取到较为实时的服务列表，然后根究⼀定 的策略选择⼀个服务访问</p><p><img src="https://pic2.zhimg.com/80/v2-84bf0900356e0dda3796cf12efa0ac8d_720w.webp" alt="img"></p><p>负载均衡：负载均衡即将请求压⼒分配到多个服务器（应⽤服务器、数据库服务器等），以 此来提⾼服务的性能、可靠性。</p><p><img src="/posts/30414/assets/f012fe4698a40c000fffbbc453e04b5d.webp" alt="img"></p><p>熔断：熔断即断路保护。微服务架构中，如果下游服务因访问压⼒过⼤⽽响应变慢或失 败，上游服务为了保护系统整体可⽤性，可以暂时切断对下游服务的调⽤。这种牺 牲局部，保全整体的措施就叫做熔断。</p><p><img src="https://pic2.zhimg.com/80/v2-278ffbedb72d5df6849da39f49242c0d_720w.webp" alt="img"></p><p>链路追踪：所谓链路追踪，就是对⼀次请求涉及的很多个服务链路进⾏⽇志记 录、性能监控。</p><p><img src="https://pic3.zhimg.com/80/v2-da77b3c5d9931936d55fd851207f109a_720w.webp" alt="img"></p><p>API ⽹关：微服务架构下，不同的微服务往往会有不同的访问地址，客户端可能需要调⽤多个服务的接⼝才能完成⼀个业务需求，API请求调用统⼀接⼊API⽹关层，由⽹关转发请求。API⽹关更专注在安全、路由、流量等问题的处理上。</p><p>1） 统⼀接⼊（路由）</p><p>2） 安全防护</p><p>3） ⿊⽩名单</p><p>4） 协议适配</p><p>5） 流量管控</p><p>6） 容错能⼒</p><p><img src="https://pic4.zhimg.com/80/v2-58400794e0d81907118d3dac831829c7_720w.webp" alt="img"></p><h3 id="体系结构"><a href="#体系结构" class="headerlink" title="体系结构"></a>体系结构</h3><p><img src="/posts/30414/assets/973034bad588f76220538678ccbd9ee9.webp" alt="img"></p><p><img src="https://pic2.zhimg.com/80/v2-2fc134e04511ad56584c71339762ce7d_720w.webp" alt="img"></p><p>Spring Cloud中的各组件协同⼯作，才能够⽀持⼀个完整的微服务架构。</p><p>1） 注册中⼼负责服务的注册与发现，很好将各服务连接起来</p><p>2） API⽹关负责转发所有外来的请求</p><p>3） 断路器负责监控服务之间的调⽤情况，连续多次失败进⾏熔断保护。</p><p>4） 配置中⼼提供了统⼀的配置信息管理服务,可以实时的通知各个服务获取最新的 配置信息</p><h3 id="Spring-Cloud-与-Dubbo"><a href="#Spring-Cloud-与-Dubbo" class="headerlink" title="Spring Cloud 与 Dubbo"></a>Spring Cloud 与 Dubbo</h3><p>Dubbo是阿⾥巴巴公司开源的⼀个⾼性能优秀的服务框架，基于RPC调⽤，对于⽬前使⽤率较⾼的Spring Cloud Netflix来说，它是基于HTTP的，所以效率上没有Dubbo⾼，但问题在于Dubbo体系的组件不全，不能够提供⼀站式解决⽅案。</p><h3 id="Spring-Cloud-与-Spring-Boot"><a href="#Spring-Cloud-与-Spring-Boot" class="headerlink" title="Spring Cloud 与 Spring Boot"></a>Spring Cloud 与 Spring Boot</h3><p>Spring Cloud 只是利⽤了Spring Boot 的特点，让我们能够快速的实现微服务组件开发，否则不使⽤Spring Boot的话，我们在使⽤Spring Cloud时，每⼀个组件的相关Jar包都需要我们⾃⼰导⼊配置以及需要开发⼈员考虑兼容性等各种情况。所以Spring Boot是我们快速把Spring Cloud微服务技术应⽤起来的⼀种⽅式</p><h3 id="二、Spring-Cloud核心组件"><a href="#二、Spring-Cloud核心组件" class="headerlink" title="二、Spring Cloud核心组件"></a>二、Spring Cloud核心组件</h3><h3 id="Eureka注册服务中心"><a href="#Eureka注册服务中心" class="headerlink" title="Eureka注册服务中心"></a>Eureka注册服务中心</h3><p>分布式微服务架构中，服务注册中⼼⽤于存储服务提供者地址信息、服务发布相关的属性信息，消费者通过主动查询和被动通知的⽅式获取服务提供者的地址信息，⽽不再需要通过硬编码⽅式得到提供者的地址信息。</p><p><img src="https://pic2.zhimg.com/80/v2-d5bdb69416eee569f3df31f744b06cf1_720w.webp" alt="img"></p><p>1） 服务提供者启动</p><p>2） 服务提供者将相关信息主动注册到注册中心</p><p>3） 服务消费者获取服务注册信息：</p><p>Pull模式：服务消费者可以主动拉去可用的服务提供者清单</p><p>Push模式：服务消费者可以主动拉去可用的服务提供者清单</p><p>4） 服务消费者直接调用服务提供者</p><p><strong>主流服务中心对比</strong></p><p>Zookeeper: Zookeeper ⽤来做服务注册中⼼，主要是因为它具有节点变更通知功能，只要客户端监听相关服务节点，服务节点的所有变更，都能及时的通知到监听客户端，这样作为调⽤⽅只要使⽤ Zookeeper 的客户端就能实现服务节点的订阅和 变更通知功能了，zookeeper遵循半数集群可用原则。</p><p>Nocas: 注册中⼼ + 配置中⼼的组合，帮助我们解决微服务开发必会涉及到的服务注册与发现，服务配置，服务管理等问题。Nacos 是Spring Cloud Alibaba 核⼼组件之⼀，负责服务注册与发现，还有配置。</p><p><img src="https://pic2.zhimg.com/80/v2-bb252d46c865e2a2714060456ef7fb99_720w.webp" alt="img"></p><p><strong>基础架构</strong></p><p><img src="/posts/30414/assets/09f7fe6733769ae2507d67a437b69eb8.webp" alt="img"></p><p>Eureka 包含两个组件：Eureka Server 和 Eureka Client，也就是服务端，存储该服务的信息以及客户端</p><p>1）图中us-east-1c、us-east-1d，us-east-1e代表不同的区也就是不同的机房</p><p>2）图中每⼀个Eureka Server都是⼀个集群。</p><p>3）图中Application Service作为服务提供者向Eureka Server中注册服务， Eureka Server接受到注册事件会在集群和分区中进⾏数据同步，Application Client作为消费端（服务消费者）可以从Eureka Server中获取到服务注册信息，进⾏服务调⽤。</p><p>4）微服务启动后，会周期性地向Eureka Server发送⼼跳（默认周期为30秒） 以续约⾃⼰的信息</p><p>5）Eureka Server在⼀定时间内没有接收到某个微服务节点的⼼跳，Eureka Server将会注销该微服务节点（默认90秒）</p><p>6）每个Eureka Server同时也是Eureka Client，多个Eureka Server之间通过复制的⽅式完成服务注册列表的同步 7）Eureka Client会缓存Eureka Server中的信息。即使所有的Eureka Server节点都宕掉，服务消费者依然可以使⽤缓存中的信息找到服务提供者</p><p><strong>Euraka客户端详解</strong></p><p>服务提供者（也是Eureka客户端）要向EurekaServer注册服务，并完成服务续约等工作</p><p>服务注册详解：导⼊了eureka-client依赖坐标，配置Eureka服务注册中⼼地址后，服务在启动时会向注册中⼼发起注册请求，携带服务元数据信息，Eureka注册中⼼接收到了之后会把服务的信息保存在Map中。</p><p>服务续约详解：服务每隔30秒会向注册中⼼续约(⼼跳)⼀次（也称为报活），如果没有续约，租约在90秒后到期，然后服务会被失效。</p><p>获取服务列表详解：服务消费者启动时，从 EurekaServer服务列表获取只读备份，缓存到本地，每隔30秒，会重新获取并更新数据。</p><p><strong>Eurake服务端详解</strong></p><p>服务下线：当服务正常关闭操作时，会发送服务下线的REST请求给EurekaServer，服务中⼼接受到请求后，将该服务置为下线状态。</p><p>失效剔除：Eureka Server会定时，默认60S检查发现实例在在⼀定时间，默认90S没有收到心跳，注销此实例。</p><p>自我保护：如果在15分钟内超过85%的客户端节点都没有正常的⼼跳，那么Eureka就认为客户端与注册中⼼出现了⽹络故障，Eureka Server⾃动进⼊⾃我保护机制。</p><p>1） 不会剔除任何服务实例，保证大多数服务可用</p><p>2） Eureka Server仍然能够接受新服务的注册和查询请求，但是不会同步，需要等网络稳定再同步。</p><p>3） 可配置开关：eureka.server.enable-self-preservation</p><h3 id="Ribbon负载均衡"><a href="#Ribbon负载均衡" class="headerlink" title="Ribbon负载均衡"></a>Ribbon负载均衡</h3><p>负载均衡分为服务器端负载均衡和客户端负载均衡</p><p>服务器端负载均衡：Nginx、F5等等，请求到达服务器之后由这些负载均衡器根据⼀定的算法将请求路由到⽬标服务器处理。</p><p>客户端负载均衡：Ribbon，服务消费者客户端会有⼀个服务器地址列表，调用⽅在请求前通过⼀定的负载均衡算法选择⼀个服务器进⾏访问，负载均衡算法的执行是在请求客户端进⾏。</p><p><img src="/posts/30414/assets/b295f5fab6b866747ea9f8ca39f7fbd1.webp" alt="img"></p><p>负载均衡策略，定义在IRule接口</p><p><img src="/posts/30414/assets/e8fffb10a28ce5bef09d35841a4a4d52.webp" alt="img"></p><p><img src="/posts/30414/assets/2fc24d42dfe54a70ddf0c3c55318fcf0.webp" alt="img"></p><p><strong>Ribbon工作原理</strong></p><p><img src="https://pic2.zhimg.com/80/v2-676bfe41dbcc3e95de157d23f67defd1_720w.webp" alt="img"></p><p>Ribbon给restTemplate添加了⼀个拦截器interceptor方法，通过拦截器进行请求拦截，然后通过负载策略实现请求分发。</p><h3 id="Hystrix熔断器"><a href="#Hystrix熔断器" class="headerlink" title="Hystrix熔断器"></a>Hystrix熔断器</h3><p><strong>雪崩效应</strong></p><p><img src="/posts/30414/assets/60bbed5790945a6fe7805f0076bbff1b.webp" alt="img"></p><p>扇⼊：代表着该微服务被调⽤的次数，扇⼊⼤，说明该模块复⽤性好</p><p>扇出：该微服务调⽤其他微服务的个数，扇出⼤，说明业务逻辑复杂</p><p>在微服务架构中，⼀个应用可能会有多个微服务组成，微服务之间的数据交互通过远程过程调⽤完成。这就带来⼀个问题，假设微服务A调用微服务B和微服务C，微服务B和微服务C又调用其它的微服务，这就是所谓的“扇出”。如果扇出的链路上某个微服务的调用响应时间过⻓或者不可⽤，对微服务A的调用就会占⽤越来越多的系统资源，进⽽引起系统崩溃，所谓的“雪崩效应”。</p><p><strong>解决方案</strong></p><p>服务熔断：当扇出链路的某个微服务不可⽤或者响应时间太⻓时，熔断该节点微服务的调⽤，进⾏服务的降级，快速返回错误的响应信息。当检测到该节点微服务调⽤响应正常后，恢复调⽤链路。</p><p>服务降级：先将⼀些不关紧的服务停掉（调⽤我的时候，给你返回⼀个预留的值，也叫做兜底数据），待渡过难关⾼峰过去，再把那些服务打开。</p><p>服务限流：服务降级是当服务出问题或者影响到核⼼流程的性能时，暂时将服务屏蔽掉，待⾼峰或者问题解决后再打开。</p><p><strong>Hystrix基础知识</strong></p><ol><li><p>包裹请求: 使⽤@HystrixCommand注解添加Hystrix控制，包裹对依赖的调用逻辑。⾃动投递微服务方法。</p></li><li><p>跳闸机制：当某服务的错误率超过⼀定的阈值时，Hystrix可以跳闸，停⽌请求 该服务⼀段时间。</p></li><li><p>资源隔离：Hystrix为每个依赖都维护了⼀个⼩型的线程池(舱壁模式)。如果该线程池已满，发往该依赖的请求就被⽴即拒绝，⽽不是排队等待，从而加速失败判定。</p></li><li><p>监控：Hystrix可以近乎实时地监控运⾏指标和配置的变化，如成功、失败、超时等等。</p></li><li><p>回退机制：当请求失败、超时、被拒绝，或当断路器打开时，执⾏回退逻辑，回退逻辑自定义。</p></li><li><p>自我修复：断路器打开⼀段时间后，会⾃动进⼊“半开”状态。</p></li></ol><p><strong>舱壁模式（线程池隔离策略）</strong></p><p>Hystrix线程池默认线程数是10个，当所有服务共用这个线程池，请求数量超过10个，那么一些服务就不可用了，因此诞生了舱壁模式，每一个控制方法创建一个线程池，也就是各自用自己的线程池。</p><p><img src="/posts/30414/assets/a8c34d6e84a81feda03b0e32b5ddfa71.webp" alt="img"></p><p><strong>Hystrix跳闸、自我修复</strong></p><p><img src="/posts/30414/assets/f615a9e06813ddb6473617abd6d9b91f.webp" alt="img"></p><p>1）当调用出现问题时，开启⼀个时间窗（10s）。</p><p>2）在这个时间窗内，统计调用次数是否达到最小请求数？如果没有达到，则重置统计信息，回到第1步 如果达到了，则统计失败的请求数占所有请求数的百分⽐，是否达到阈值？如果达到，则跳闸（不再请求对应服务） 如果没有达到，则重置统计信息，回到第1步 。</p><p>3）如果跳闸，则会开启⼀个活动窗⼝（默认5s），每隔5s，Hystrix会让⼀个请求通过,到达那个问题服务，看是否调用成功，如果成功，重置断路器回到第1步，如果失败，回到第3步。</p><p><strong>Hystrix</strong> <strong>DashBoard健康检查</strong></p><p>Hystrix官方提供了基于图形化的 DashBoard（仪表板）监控平台。通过搭建一个DashBoard项目实现对Hystrix仪表板每个断路器（被 @HystrixCommand注解的⽅法）的状态监控。</p><p><img src="/posts/30414/assets/36d5487ad31e49ace09c57ee28d125a5.webp" alt="img"></p><p><strong>Hystrix Turbine聚合监控</strong></p><p>在集群环境下，结合dashboard仪表盘就需要每次输⼊⼀个监控数据流url进去查看，通过Hystrix Turbine聚合监控，专门新建一个Turbine监控项目可以实现聚合各个实例上的hystrix监控数据。</p><p><img src="/posts/30414/assets/4a0f15c759d1cc644bac5900a0a1b225.webp" alt="img"></p><h3 id="Feign远程调用组件"><a href="#Feign远程调用组件" class="headerlink" title="Feign远程调用组件"></a>Feign远程调用组件</h3><p>服务消费者调⽤服务提供者的时候使⽤RestTemplate技术需要拼接url以及getForObject存在硬编码。</p><p>Feign是Netflix开发的⼀个轻量级RESTful的HTTP服务客户端，以Java接⼝注解的⽅式调⽤Http请求，类似于dubbo，服务消费者拿到服务提供者的接⼝，然后像调用本地接⼝⽅法⼀样去调用，实际发出的是远程的请求。</p><p>本质：封装了Http调用流程，更符合⾯向接口化的编程习惯，类似于Dubbo的服务调用，基于代理实现。</p><p>Feign &#x3D; RestTemplate+Ribbon+Hystrix</p><p><strong>Feign对负载均衡的⽀持</strong></p><p>Feign 本身已经集成了Ribbon依赖和⾃动配置，因此我们不需要额外引⼊依赖，可以通过 ribbon.xx 来进⾏全局配置,也可以通过服务名.ribbon.xx 来对指定服务进⾏ 细节配置配置。</p><p><img src="/posts/30414/assets/fb96b904f8411ad4e8d9e0a1b504ffa5.webp" alt="img"></p><p><strong>Feign对熔断器的支持</strong></p><p>⾃定义FallBack处理类（需要实现FeignClient接⼝）；Feign集成了Hystrix，但是他们的超时是独立的，使用又是一起的，以最小值触发熔断。</p><p><img src="/posts/30414/assets/4d8afa62f85342f113159d9d484f4106.webp" alt="img"></p><p><img src="https://pic3.zhimg.com/80/v2-ae46d85f7b5f786d470b2c240e26fde2_720w.webp" alt="img"></p><p><strong>Feign的日志级别配置</strong></p><p>如果我们想看到Feign请求时的⽇志，首先要创建一个能被扫描到的配置类，通过这个类来加载配置的yml日志级别配置来实现。</p><p><img src="/posts/30414/assets/b62007feaa48da9872799c9d2540bf72.webp" alt="img"></p><p><strong>Feign对请求压缩和响应压缩的⽀持</strong></p><p>Feign ⽀持对请求和响应进⾏GZIP压缩，以减少通信过程中的性能损耗，以配置方式实现。</p><h3 id="GateWay网关组件"><a href="#GateWay网关组件" class="headerlink" title="GateWay网关组件"></a>GateWay网关组件</h3><p>网关是微服务架构中的重要组成部分，基于Spring5.0+SpringBoot2.0+WebFlux等技术开发，性能比Zuul高，为微服务架构提供⼀种简单有效的统⼀的API路由管理⽅式。不仅可以提供统⼀的路由⽅式，还可以做过滤、鉴权、 流量控制、熔断、路径重写、日志监控等等。</p><p><img src="/posts/30414/assets/503654ef3b84ef235fc7c12baa41a4d3.webp" alt="img"></p><p><strong>GateWay核心</strong></p><p>路由（route）：最基础的部分，由⼀个ID、一个目标URL、⼀系列的断⾔（匹配条件判断）和 Filter过滤器（精细化控制）组成。如果断言为true，则匹配该路由。</p><p>断⾔（predicates）：匹配Http请求中的所有内容（包括请求头、请求参数等）</p><p>过滤器（filter）：请求之前或者之后执⾏业务逻辑。</p><p><img src="https://pic3.zhimg.com/80/v2-1e3cdf3beeec9831082f14ab3d9c88b6_720w.webp" alt="img"></p><p>工作流程，核心路由转发+执行过滤链</p><p><img src="https://pic3.zhimg.com/80/v2-29a8c0308049f351313d963b025bab62_720w.webp" alt="img"></p><p>客户端向Spring Cloud GateWay发出请求，然后在GateWay Handler Mapping中 找到与请求相匹配的路由，将其发送到GateWay Web Handler；Handler再通过指 定的过滤器链来将请求发送到我们实际的服务执⾏业务逻辑，然后返回。</p><p><strong>GateWay路由规则</strong></p><p><img src="https://pic3.zhimg.com/80/v2-64d3bfd6116f05ab102fb01f6e0b1f9e_720w.webp" alt="img"></p><p>可以实现时间前后，区间匹配、Cookie正则匹配、Host匹配、Method匹配、远程地址匹配等等。</p><p>GateWay动态路由：GateWay⽀持⾃动从注册中⼼中获取服务列表并访问，即所谓的动态路由。</p><p><strong>GateWay过滤器</strong></p><p>从过滤器⽣命周期分pre和post</p><p><img src="/posts/30414/assets/cdf6d703af76133df8e19c755d25cc57.webp" alt="img"></p><p>从过滤器类型分GateWayFilter和 GlobalFilter，常用GlobalFilter，即全局过滤器。</p><p><img src="/posts/30414/assets/93f4608535382a6409ede93df0c03a59.webp" alt="img"></p><p>GateWay高可用：可以启动多个GateWay实例来实现⾼可⽤，在GateWay 的上游使⽤Nginx等负载均衡设备进⾏负载转发以达到高可用的目的。</p><h3 id="Config分布式配置中心"><a href="#Config分布式配置中心" class="headerlink" title="Config分布式配置中心"></a>Config分布式配置中心</h3><p>Config Server是集中式的配置服务，⽤于集中管理应⽤程序各个环境下的配置。默认使⽤Git存储配置⽂件内容，也可以SVN。</p><p><strong>配置中心的优点</strong></p><p>1） 集中配置管理，多个微服务不同配置统一管控。</p><p>2） 不同环境不同配置，对于测试、生产等环境不同配置。</p><p>3） 实现运⾏期间可动态调整，如更改数据库连接信息，连接池等。</p><p>4） 配置内容发⽣变化，微服务可以⾃动更新配置</p><p><img src="https://pic4.zhimg.com/80/v2-67733eda7b7fdd550ee442d40e6d4ccf_720w.webp" alt="img"></p><p>Server 端：提供配置⽂件的存储、以接口的形式将配置⽂件的内容提供出去，通过使⽤@EnableConfigServer注解在 Spring boot 应⽤中⾮常简单的嵌⼊。</p><p>Client 端：通过接口获取配置数据并初始化自己的应用。</p><p>Config配置手动刷新</p><p>1）Client客户端添加依赖springboot-starter-actuator（已添加）</p><p>2）Client客户端bootstrap.yml中添加配置（暴露通信端点</p><p>3）Client客户端使⽤到配置信息的类上添加@RefreshScope</p><p>4）⼿动向Client客户端发起POST请求，<a href="http://localhost:8080/actuator/refresh%EF%BC%8C">http://localhost:8080/actuator/refresh，</a> 刷新配置信息</p><p><strong>Config配置⾃动更新，结合消息总线BUS，支持（RabbitMq&#x2F;Kafka）</strong></p><p>消息总线Bus，即我们经常会使⽤MQ消息代理构建⼀个共⽤的Topic，通过这个Topic连接各个微服务实例，MQ⼴播的消息会被所有在注册中⼼的微服务实例监听和消费。就是通过⼀个主题连接各个微服务，打通脉络。</p><p><img src="https://pic2.zhimg.com/80/v2-2109d7b215c50acaf9a90e85482278e9_720w.webp" alt="img"></p><ol><li>Config Server服务端添加消息总线⽀持</li></ol><p><img src="https://pic4.zhimg.com/80/v2-7d8e4965360cc36882756a6ed62ffbf3_720w.webp" alt="img"></p><ol start="2"><li>ConfigServer添加配置连接RabbitMq</li></ol><p><img src="/posts/30414/assets/3c5b93717edf71d56ca9fee5b5232cb9.webp" alt="img"></p><ol start="3"><li>微服务暴露端口</li></ol><p><img src="https://pic3.zhimg.com/80/v2-38bb7be029177aa2a7d86a96ad8620b2_720w.webp" alt="img"></p><ol start="4"><li>重启各个服务，更改配置之后，向配置中⼼服务端发送post请求<a href="http://localhost:9003/actuator/bus-refresh%EF%BC%8C%E5%90%84%E4%B8%AA%E5%AE%A2%E6%88%B7%E7%AB%AF%E9%85%8D%E7%BD%AE%E5%8D%B3%E5%8F%AF%E2%BE%83%E5%8A%A8%E5%88%B7%E6%96%B0%EF%BC%8C%E4%B9%9F%E6%94%AF%E6%8C%81%E5%AE%9A%E5%90%91%E5%88%B7%E6%96%B0%EF%BC%8C%E8%B7%9F%E6%9C%8D%E5%8A%A1%E5%90%8D:%E7%AB%AF%E5%8F%A3%E5%8F%B7%E5%8D%B3%E5%8F%AF%E3%80%82">http://localhost:9003/actuator/bus-refresh，各个客户端配置即可⾃动刷新，也支持定向刷新，跟服务名:端口号即可。</a></li></ol><h3 id="Stream消息驱动组件"><a href="#Stream消息驱动组件" class="headerlink" title="Stream消息驱动组件"></a>Stream消息驱动组件</h3><p>Spring Cloud Stream 消息驱动组件帮助我们更快速，更⽅便，更友好的去构建消息驱动微服务的。Spring Cloud Stream进⾏了很好的上层抽象，可以让我们与具体消息中间件解耦合，屏蔽掉了底层具体MQ消息中间件的细节差异，就像Hibernate屏蔽掉了具体数据库（Mysql&#x2F;Oracle⼀样）。</p><p>本质：屏蔽掉了底层不同MQ消息中间件之间的差异，统⼀了MQ的编程模型，降低了学习、开发、维护MQ的成本。</p><p>Spring Cloud Stream 是⼀个构建消息驱动微服务的框架。应⽤程序通过inputs（相 当于消息消费者consumer）或者outputs（相当于消息⽣产者producer）来与 Spring Cloud Stream中的binder对象交互，⽽Binder对象是⽤来屏蔽底层MQ细节 的，它负责与具体的消息中间件交互。对于我们来说，只需要知道如何使⽤Spring Cloud Stream与Binder对象交互即可。</p><p><img src="/posts/30414/assets/1994fd0e4b47b19fdc46acb9097c73e9.webp" alt="img"></p><p><strong>Binder绑定器</strong></p><p>通过它来屏蔽底层不同MQ消息中间件的细节差异，当需要更换为其他消息中间件时，我们需要做的就是更换对应的Binder绑定器。</p><p>Stream中的消息通信⽅式遵循了发布—订阅模式。当⼀条消息被投递到消息中间件之后，它会通过共享的Topic 主题进⾏⼴播，消息消费者在订阅的 主题中收到它并触发⾃身的业务逻辑处理。</p><p><img src="/posts/30414/assets/89f013d10d5df6ce78a7a6fe85518931.webp" alt="img"></p><h3 id="常见问题及解决方案"><a href="#常见问题及解决方案" class="headerlink" title="常见问题及解决方案"></a>常见问题及解决方案</h3><p><strong>Eureka 服务发现慢的原因</strong></p><p>Eureka 服务发现慢的原因主要有两个，⼀部分是因为服务缓存导致的，另⼀部分是 因为客户端缓存导致的。</p><p><img src="/posts/30414/assets/d06512fcd8c631f76d848197bf45a979.webp" alt="img"></p><p><strong>服务端缓存</strong></p><p>服务注册到注册中⼼后，服务实例信息是存储在内存中，为了提高响应效率，Eureta内部加了两层缓存结构，一二级缓存之间会进行数据同步，默认30S，当Client获取服务实例数据时，会先从⼀级缓存中获取，如果⼀级缓存中不存在，再从⼆级缓存中获取，如果⼆级缓存也不存在，会触发缓存的加载，从存储层拉取数据到缓存中，然后再返回给Client，服务下线、过期、注册、状态变更等操作都会清除二级缓存中的数据，基于Guava，默认过期180S，因此产生的弊端也出现了，同步时间有30S，会导致服务发现慢的问题，解决办法要么缩短更新时间，要么禁用一级缓存。</p><p><strong>客户端缓存</strong></p><p>Eureka Client负责跟Eureka Server进⾏交互，默认30S拉取一次数据，也可以缩短拉取时间。</p><p>Ribbon会从Eureka Client中获取服务信息，默认也是30S，也可以缩短定时更新时间。</p><p><strong>Spring Cloud 各组件超时，通过设置超时时间解决</strong></p><p>Ribbon 如果采⽤的是服务发现⽅式，就可以通过服务名去进⾏转发，需要配置 Ribbon的超时，Hystrix的超时时间要⼤于Ribbon的超时时间，因为Hystrix将请求包装了起来，特别需要注意的是，如果Ribbon开启了重试机制，⽐如 重试3 次，Ribbon 的超时为 1 秒，那么 Hystrix 的超时时间应该⼤于 3 秒，否则就 会出现 Ribbon 还在重试中，⽽Hystrix已经超时的现象。</p><p>Feign Feign本身也有超时时间的设置，如果此时设置了Ribbon的时间就以Ribbon的时间为准，如果没设置Ribbon的时间但配置了Feign的时间，就以Feign的时间为准。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;一、Spring-Cloud基础知识&quot;&gt;&lt;a href=&quot;#一、Spring-Cloud基础知识&quot; class=&quot;headerlink&quot; title=&quot;一、Spring Cloud基础知识&quot;&gt;&lt;/a&gt;一、Spring Cloud基础知识&lt;/h3&gt;&lt;h3 id=&quot;微</summary>
      
    
    
    
    <category term="基础知识" scheme="https://itingyu.github.io/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    <category term="spring cloud" scheme="https://itingyu.github.io/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/spring-cloud/"/>
    
    
    <category term="基础知识" scheme="https://itingyu.github.io/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    <category term="spring cloud" scheme="https://itingyu.github.io/tags/spring-cloud/"/>
    
  </entry>
  
  <entry>
    <title>dubbo框架知识</title>
    <link href="https://itingyu.github.io/posts/2661b4f7/"/>
    <id>https://itingyu.github.io/posts/2661b4f7/</id>
    <published>2023-06-17T10:59:26.000Z</published>
    <updated>2023-06-17T11:00:40.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、Dubbo架构和实战"><a href="#一、Dubbo架构和实战" class="headerlink" title="一、Dubbo架构和实战"></a>一、Dubbo架构和实战</h2><h3 id="架构演变过程"><a href="#架构演变过程" class="headerlink" title="架构演变过程"></a>架构演变过程</h3><p><strong>单体架构</strong></p><p>单体架构所有模块和功能都集中在一个项目中 ，部署时也是将项目所有功能整体部署到服务器中。</p><p><strong>垂直架构</strong></p><p>根据业务把项目垂直切割成多个项目。</p><p><strong>分布式架构（SOA）</strong></p><p>在垂直划分的基础上,将每个项目拆分出多个具备松耦合的服务,一个服务通常以独立的形式存在于操作系统进程中。</p><p>Dubbo三大核心能力：面向接口的远程方法调用，智能容错和负载均衡，以及服务自动注册和发现。</p><p>基于垂直结构进行分层：</p><p>应用层: 距离用户最近的一层也称之为接入层，使用tomcat作为web容器接收用户请求使用下游的dubbo提供的接口来返回数据并且该层禁止访问数据库。</p><p>业务服务层：根据具体的业务场景 演变而来的模块 比如 简历投递 职位搜索 职位推荐等。</p><p>基础业务层：招聘业务的核心 账号 简历 公司 职位。</p><p>基础服务层：这一层是与业务无关的模块是一些通用的服务，比如发短信，发邮件等等，这类服务请求量大但是逻辑简单。</p><p>存储层:不同的存储类型Mysql、Mongodb。</p><p>分级：二八定律，80%的流量在核心功能上，优先保证核心服务的稳定。</p><p>隔离：不同性质、不同重要业务要进行隔离，比如各种中间件。</p><p>优点：服务以接口为粒度，屏蔽远程调用底层细节，只关心结果，而且采用此业务分层架构清晰，模块职责单一，扩展性强，保证系统稳定且安全。</p><p>缺点：粒度控制复杂，模块越多可能引发超时，分布式事务问题，可能引发接口爆炸，版本升级兼容困难，调用链路长。</p><p><strong>微服务架构</strong></p><p>将单个应用程序作为一套小型服务开发的方法，每种应用程序都在其自己的进程中独立运行，并使用轻量级机制(通常是HTTP资源的API)进行通信。这些服务的集中化管理非常少，它们可以用不同的编程语言编写，并使用不同的数据存储技术。微服务是在SOA上做的升华 , 粒度更加细致，微服务架构强调的一个重点是业务需要彻底的组件化和服务化。</p><h3 id="Dubbo基础知识"><a href="#Dubbo基础知识" class="headerlink" title="Dubbo基础知识"></a>Dubbo基础知识</h3><p>Apache Dubbo是一款高性能的Java RPC框架。</p><p><img src="/posts/2661b4f7/assets/77a6e374003d0f20358ccbbacd1f732b.webp" alt="img"></p><p>面向接口的远程方法调用：提供高性能的基于代理的远程调用能力，服务以接口为粒度，为开发者屏蔽远程调用底层细节。</p><p>智能容错和负载均衡：内置多种负载均衡策略，智能感知下游节点健康状况，显著减少调用延迟，提高系统吞吐量。</p><p>服务自动注册和发现：支持多种注册中心服务，服务实例上下线实时感知。</p><p>Dubbo服务治理：，企业为了确保项目顺利完成而实施的过程，包括最佳实践、架构原则、治理规程、规律以及其他决定性的因素。</p><p><strong>Dubbo处理流程</strong></p><p><img src="/posts/2661b4f7/assets/7c2fa66ab6aeb68279ee2fc07ba9de35.webp" alt="img"></p><p><img src="/posts/2661b4f7/assets/fdef3523e35dbabb28a2060e5c526a3a.webp" alt="img"></p><p>调用过程：</p><p>\1. 服务提供者在服务容器启动时向注册中心注册自己提供的服务。</p><p>\2. 服务消费者在启动时向注册中心订阅自己所需的服务。</p><p>\3. 注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心会基于长连接推送数据给消费者。</p><p>\4. 服务消费者从提供者地址列表中，基于软负载均衡算法选一台提供者进行调用，如果调用失败，重新选择。</p><p>\5. 服务提供者和服务消费者在内存中的调用次数和时间，定时每分钟发送给监控中心。</p><h3 id="Dubbo配置方式"><a href="#Dubbo配置方式" class="headerlink" title="Dubbo配置方式"></a>Dubbo配置方式</h3><p>1.注解: 基于注解可以快速的将程序配置，无需多余的配置信息，包含提供者和消费者。弊端是根据配置信息无法快速定位。</p><p>\2. XML:和Spring做结合，相关的Service和Reference均使用Spring集成后的。通过这样的方式可以很方便的通过几个文件进行管理整个集群配置。可以快速定位也可以快速更改。</p><p>3.基于代码方式: 基于代码方式的对上述配置进行配置。</p><h3 id="dubbo-application配置"><a href="#dubbo-application配置" class="headerlink" title="dubbo:application配置"></a>dubbo:application配置</h3><p>代表当前应用的信息</p><p>\1. name: 当前应用程序的名称，在dubbo-admin中我们也可以看到，这个代表这个应用名称。我们在真正时是时也会根据这个参数来进行聚合应用请求。</p><p>\2. owner: 当前应用程序的负责人，可以通过这个负责人找到其相关的应用列表，用于快速定位到责任人。</p><p>\3. qosEnable : 是否启动QoS 默认true</p><p>\4. qosPort : 启动QoS绑定的端口 默认22222</p><p>\5. qosAcceptForeignIp: 是否允许远程访问 默认是false</p><p>注解方式</p><p><img src="https://pic2.zhimg.com/80/v2-1acff69e625ede63ce08ef174fefec65_720w.webp" alt="img"></p><p>XML方式</p><p><img src="https://pic3.zhimg.com/80/v2-3dc3de900d5b2e0d6ea12f46b45f3caa_720w.webp" alt="img"></p><h3 id="dubbo-registry配置"><a href="#dubbo-registry配置" class="headerlink" title="dubbo:registry配置"></a>dubbo:registry配置</h3><p>代表该模块所使用的注册中心</p><p>\1. id : 当前服务中provider或者consumer中存在多个注册中心时，则使用需要增加该配置。在一 些公司，会通过业务线的不同选择不同的注册中心，所以一般都会配置该值。</p><p>\2. address : 当前注册中心的访问地址。</p><p>\3. protocol : 当前注册中心所使用的协议是什么。也可以直接在 address 中写入，比如使用 zookeeper，就可以写成 zookeeper:&#x2F;&#x2F;xx.xx.xx.xx:2181</p><p>\4. timeout : 当与注册中心不再同一个机房时，大多会把该参数延长。</p><h3 id="dubbo-protocol配置"><a href="#dubbo-protocol配置" class="headerlink" title="dubbo:protocol配置"></a>dubbo:protocol配置</h3><p>指定服务在进行数据传输所使用的协议</p><p>\1. id : 在大公司，可能因为各个部门技术栈不同，所以可能会选择使用不同的协议进行交互。这里 在多个协议使用时，需要指定。</p><p>\2. name : 指定协议名称。默认使用 dubbo 。</p><h3 id="dubbo-service配置"><a href="#dubbo-service配置" class="headerlink" title="dubbo:service配置"></a>dubbo:service配置</h3><p>指定当前需要对外暴露的服务信息</p><p>\1. interface : 指定当前需要进行对外暴露的接口是什么。</p><p>\2. ref : 具体实现对象的引用，一般我们在生产级别都是使用Spring去进行Bean托管的，所以这里面 一般也指的是Spring中的BeanId。</p><p>\3. version : 对外暴露的版本号。不同的版本号，消费者在消费的时候只会根据固定的版本号进行消 费。</p><h3 id="dubbo-reference配置"><a href="#dubbo-reference配置" class="headerlink" title="dubbo:reference配置"></a>dubbo:reference配置</h3><p>消费者的配置</p><p>\1. id : 指定该Bean在注册到Spring中的id。</p><p>\2. interface: 服务接口名</p><p>\3. version : 指定当前服务版本，与服务提供者的版本一致。</p><p>\4. registry : 指定所具体使用的注册中心地址。这里面也就是使用上面在dubbo:registry中所声明的id。</p><h3 id="dubbo-consumer设置"><a href="#dubbo-consumer设置" class="headerlink" title="dubbo:consumer设置"></a>dubbo:consumer设置</h3><p>\1. mock: 用于在方法调用出现错误时，当做服务降级来统一对外返回结果，后面我们也会对这个方 法做更多的介绍。</p><p>\2. timeout: 用于指定当前方法或者接口中所有方法的超时时间。我们一般都会根据提供者的时长来 具体规定。比如我们在进行第三方服务依赖时可能会对接口的时长做放宽，防止第三方服务不稳定 导致服务受损。</p><p>\3. check: 用于在启动时，检查生产者是否有该服务。我们一般都会将这个值设置为false，不让其进 行检查。因为如果出现模块之间循环引用的话，那么则可能会出现相互依赖，都进行check的话， 那么这两个服务永远也启动不起来。</p><p>\4. retries: 用于指定当前服务在执行时出现错误或者超时时的重试机制，重试次数。</p><p>\1. 注意提供者是否有幂等，否则可能出现数据一致性问题</p><p>\2. 注意提供者是否有类似缓存机制，如出现大面积错误时，可能因为不停重试导致雪崩</p><p>\5. executes: 用于在提供者做配置，来确保最大的并行度，熔断处理。</p><p>\1. 可能导致集群功能无法充分利用或者堵塞</p><p>\2. 但是也可以启动部分对应用的保护功能</p><p>\3. 可以不做配置，结合后面的熔断限流使用</p><h3 id="dubbo-method配置"><a href="#dubbo-method配置" class="headerlink" title="dubbo:method配置"></a>dubbo:method配置</h3><p>XML中独有，指定具体方法级别在进行RPC操作时候的配置。</p><p>\1. name : 指定方法名称，用于对这个方法名称的RPC调用进行特殊配置。</p><p>\2. async: 是否异步 默认false</p><h2 id="二、Dubbo高级应用"><a href="#二、Dubbo高级应用" class="headerlink" title="二、Dubbo高级应用"></a>二、Dubbo高级应用</h2><h3 id="SPI"><a href="#SPI" class="headerlink" title="SPI"></a>SPI</h3><p>JDK内置的一种服务提供发现机制，使用SPI机制的优势是实现解耦， 使得第三方服务模块的装配控制逻辑与调用者的业务代码分离。</p><p><img src="https://pic3.zhimg.com/80/v2-7e6ad2826337df99bfc91a38212d7536_720w.webp" alt="img"></p><p><strong>SPI约定</strong></p><p>1） 当服务提供者提供了接口的一种具体实现后，在META-INF&#x2F;services目录下创建一个以“接口全 限定名”为命名的文件，内容为实现类的全限定名。</p><p>2） 接口实现类所在的jar包放在主程序的classpath中。</p><p>3） 主程序通过java.util.ServiceLoader动态装载实现模块，它通过扫描META-INF&#x2F;services目录下 的配置文件找到实现类的全限定名，把类加载到JVM。</p><p>4） SPI的实现类必须携带一个无参构造方法。</p><p><strong>Dubbo中的SPI</strong></p><p>dubbo中大量的使用了SPI来作为扩展点，通过实现同一接口的前提下，可以进行定制自己的实现类。 比如比较常见的协议，负载均衡，都可以通过SPI的方式进行定制化，自己扩展。</p><p>优点：</p><p>\1. JDK 标准的 SPI 会一次性实例化扩展点所有实现，如果有扩展实现初始化很耗时，但如果没用上也加载，会很浪费资源。</p><p>\2. 如果有扩展点加载失败，则所有扩展点无法使用。</p><p>\3. 提供了对扩展点包装的功能(Adaptive)，并且还支持通过set的方式对其他的扩展点进行注入。</p><p><strong>Adaptive功能</strong></p><p>Dubbo中的Adaptive功能，主要解决的问题是如何动态的选择具体的扩展点。通过 getAdaptiveExtension 统一对指定接口对应的所有扩展点进行封装，通过URL的方式对扩展点来进行 动态选择。</p><p><img src="/posts/2661b4f7/assets/bc2cb48585c1d2a2d9831048f04f7dc6.webp" alt="img"></p><p><strong>Dubbo过滤器</strong></p><p>Dubbo的Filter机制，是专门为服务提供方和服务消费方调用过程进行拦截设计的，每次远程方法执行，该拦截都会被执行。这样就为开发者提供了非常方便的扩展性，比如为dubbo接口实现ip白名单功 能、监控功能 、日志记录等。</p><p><img src="/posts/2661b4f7/assets/62ef2e899499c84e03d9054e980a52dc.webp" alt="img"></p><h3 id="负载均衡策略"><a href="#负载均衡策略" class="headerlink" title="负载均衡策略"></a>负载均衡策略</h3><p>负载均衡（Load Balance）, 其实就是将请求分摊到多个操作单元上进行执行，从而共同完成工作任务。负载均衡策略主要用于客户端存在多个提供者时进行选择某个提供者。在集群负载均衡时，Dubbo 提供了多种均衡策略（包括随机、轮询、最少活跃调用数、一致性 Hash），dubbo默认为随机调用。</p><p><img src="https://pic3.zhimg.com/80/v2-83806ef061b1d2930e45612f0e1300f6_720w.webp" alt="img"></p><p><strong>自定义负载均衡器开发</strong></p><p>1） 自定义负载均衡器</p><p>2） 配置负载均衡器 META-INF&#x2F;dubbo</p><p>3） 在服务提供者工程实现类中编写用于测试负载均衡效果的方法，启动不同端口时，方法返回的信息不同。</p><p>4） 启动多个服务 要求他们使用同一个接口注册到同一个注册中心 但是他们的dubbo通信端口不同</p><p>5） 在服务消费方指定自定义负载均衡器</p><h3 id="异步调用"><a href="#异步调用" class="headerlink" title="异步调用"></a>异步调用</h3><p>Dubbo不只提供了堵塞式的的同步调用，同时提供了异步调用的方式。这种方式主要应用于提供者接口</p><p>响应耗时明显，消费者端可以利用调用接口的时间去做一些其他的接口调用,利用 Future 模式来异步等待和获取结果即可。</p><p><img src="https://pic2.zhimg.com/80/v2-4a8a66ba39d42150125f8998f1950e69_720w.webp" alt="img"></p><h3 id="线程池"><a href="#线程池" class="headerlink" title="线程池"></a>线程池</h3><p>Dubbo两种线程池</p><p>1） fix: 表示创建固定大小的线程池。Dubbo默认的使用方式，默认创建的执行线程数为200，并且是没有任何等待队列的。大量操作同步执行可能阻塞。</p><p>2） cache: 创建非固定大小的线程池，当线程不足时，会自动创建新的线程。高TPS（每秒请求数）请求下，对系统CPU和负载压力大。</p><p>自定义线程池</p><p>真实的使用过程中可能会因为使用fix模式的线程池，导致具体某些业务场景因为线程池中的线程数量不足而产生错误，而很多业务研发是对这些无感知的，只有当出现错误的时候才会去查看告警或者通过客户反馈出现严重的问题才去查看，结果发现是线程池满了。所以可以在创建线程池的时，通过某些手段对这个线程池进行监控，这样就可以进行及时的扩缩容机器或者告警。</p><p><img src="/posts/2661b4f7/assets/7aae2bd0a0466e411a1cc4eef60e05fe.webp" alt="img"></p><p><img src="/posts/2661b4f7/assets/bd49f180b2f90f0152100405b396a5a1.webp" alt="img"></p><h3 id="路由规则"><a href="#路由规则" class="headerlink" title="路由规则"></a>路由规则</h3><p>路由是决定一次请求中需要发往目标机器的重要判断，通过对其控制可以决定请求的目标机器。我们可以通过创建这样的规则来决定一个请求会交给哪些服务器去处理。</p><p><img src="/posts/2661b4f7/assets/f45011d46fc7a2ad56698e36c4aa46ef.webp" alt="img"></p><p>规则详解：</p><p>route:&#x2F;&#x2F; 表示路由规则的类型，支持条件路由规则和脚本路由规则，可扩展，必填。</p><p>0.0.0.0 表示对所有 IP 地址生效，如果只想对某个 IP 的生效，请填入具体 IP，必填。</p><p>com.lagou.service.HelloService 表示只对指定服务生效，必填。</p><p>category&#x3D;routers 表示该数据为动态配置类型，必填。</p><p>dynamic : 是否为持久数据，当指定服务重启时是否继续生效。必填。</p><p>runtime : 是否在设置规则时自动缓存规则，如果设置为true则会影响部分性能。</p><p>… &#x3D;&gt; … 在这里 &#x3D;&gt; 前面的就是表示消费者方的匹配规则，可以不填(代表全部)。 &#x3D;&gt; 后方则必 须填写，表示当请求过来时，如果选择提供者的配置。</p><h3 id="服务降级"><a href="#服务降级" class="headerlink" title="服务降级"></a>服务降级</h3><p>服务降级，当服务器压力剧增的情况下，根据当前业务情况及流量对一些服务有策略的降低服务级别， 以释放服务器资源，保证核心任务的正常运行。使用服务降级，这是防止分布式服务发生雪崩效应，当一个请求发生超时，一直等待着服务响应，那么在高并发情况下，很多请求都是因为这样一直等着响应，直到服务资源耗尽产生宕机，而宕机之后会导致分布式其他服务调用该宕机的服务也会出现资源耗尽宕机， 这样下去将导致整个分布式服务都瘫痪，这就是雪崩。</p><p>降级方式：</p><p>1） 在 dubbo 管理控制台配置服务降级，屏蔽和容错。</p><p>2） 指定返回简单值或者null</p><p>3） 使用java代码 动态写入配置中心</p><p>4） 整合hystrix</p><h3 id="三、Dubbo源码剖析"><a href="#三、Dubbo源码剖析" class="headerlink" title="三、Dubbo源码剖析"></a>三、Dubbo源码剖析</h3><h3 id="Dubbo调用过程"><a href="#Dubbo调用过程" class="headerlink" title="Dubbo调用过程"></a>Dubbo调用过程</h3><p><img src="/posts/2661b4f7/assets/3f1f8209307394fdaec90abf277561b8.webp" alt="img"></p><p>调用四部分</p><p>1）Provider: 暴露服务的服务提供方</p><p>Protocol 负责提供者和消费者之间协议交互数据</p><p>Service 真实的业务服务信息 可以理解成接口 和 实现</p><p>Container Dubbo的运行环境</p><p>2）Consumer: 调用远程服务的服务消费方</p><p>Protocol 负责提供者和消费者之间协议交互数据</p><p>Cluster 感知提供者端的列表信息</p><p>Proxy 可以理解成 提供者的服务调用代理类 由它接管 Consumer中的接口调用逻辑</p><p>3）Registry: 注册中心，用于作为服务发现和路由配置等工作，提供者和消费者都会在这里进行注册</p><p>4）Monitor: 用于提供者和消费者中的数据统计，比如调用频次，成功失败次数等信息。</p><p>启动和执行流程</p><p>1）提供者端启动 容器负责把Service信息加载 并通过Protocol 注册到注册中心</p><p>2）消费者端启动 通过监听提供者列表来感知提供者信息 并在提供者发生改变时 通过注册中心及时通知消费端</p><p>3）消费方发起 请求 通过Proxy模块</p><p>4）利用Cluster模块 来选择真实的要发送给的提供者信息</p><p>5）交由Consumer中的Protocol 把信息发送给提供者</p><p>6）提供者同样需要通过 Protocol 模块来处理消费者的信息</p><p>7）最后由真正的服务提供者 Service 来进行处理</p><h3 id="整体调用链路"><a href="#整体调用链路" class="headerlink" title="整体调用链路"></a>整体调用链路</h3><p><img src="/posts/2661b4f7/assets/64a44eaed767d33cb4fb979da5d99943.webp" alt="img"></p><p>1）消费者通过Interface进行方法调用 统一交由消费者端的 Proxy 通过ProxyFactory 来进行代理 对象的创建 使用到了 jdk javassist技术</p><p>2）交给Filter 这个模块 做一个统一的过滤请求 在SPI案例中涉及过</p><p>3）接下来会进入最主要的Invoker调用逻辑</p><p>通过Directory 去配置中新读取信息 最终通过list方法获取所有的Invoker</p><p>通过Cluster模块 根据选择的具体路由规则 来选取Invoker列表</p><p>通过LoadBalance模块 根据负载均衡策略 选择一个具体的Invoker 来处理我们的请求</p><p>如果执行中出现错误 并且Consumer阶段配置了重试机制 则会重新尝试执行</p><p>4） 继续经过Filter进行执行功能的前后封装 Invoker 选择具体的执行协议 、</p><p>5） 客户端 进行编码和序列化然后发送数据</p><p>6） 到达Consumer中的Server在这里进行反编码和反序列化的接收数据</p><p>7） 使用Exporter选择执行器</p><p>8） 交给Filter 进行一个提供者端的过滤到达 Invoker 执行器</p><p>9） 通过Invoker 调用接口的具体实现然后返回</p><h3 id="URL规则和服务本地缓存"><a href="#URL规则和服务本地缓存" class="headerlink" title="URL规则和服务本地缓存"></a>URL规则和服务本地缓存</h3><p>Dubbo中的URL与java中的URL差异</p><p>1） 这里提供了针对于参数的 parameter 的增加和减少(支持动态更改)</p><p>2） 提供缓存功能，对一些基础的数据做缓存</p><p>服务本地缓存</p><p>频繁往从ZK获取信息，肯定会存在单点故障问题，所以dubbo提供了将提供者信息缓存在本地的方法，主要实现就是创建一个properties文件，通过构造方法从远程一拿到配置信息就存储到本地进行缓存。</p><h3 id="Dubbo服务消费过程"><a href="#Dubbo服务消费过程" class="headerlink" title="Dubbo服务消费过程"></a>Dubbo服务消费过程</h3><p><img src="https://pic3.zhimg.com/80/v2-9916b50dd80c1fe5226288ad2da843f6_720w.webp" alt="img"></p><p>1）通过ReferenceConfig 类的Protocol 调用 refer 方法让远程对象生成 Invoker 实例。</p><p>2）接着通过ProxyFactory的getProxy方法生成ref代理对象对远程服务进行处理。</p><h3 id="Adaptive功能实现原理"><a href="#Adaptive功能实现原理" class="headerlink" title="Adaptive功能实现原理"></a>Adaptive功能实现原理</h3><p>Adaptive的主要功能是对所有的扩展点进行封装为一个类，通过URL传入参数的时动态选择需要使用的扩展点。其底层的实现原理就是动态代理。</p><h3 id="集群容错分析"><a href="#集群容错分析" class="headerlink" title="集群容错分析"></a>集群容错分析</h3><p><img src="https://pic3.zhimg.com/80/v2-9d8219c67027330bc038ac2dd92e1bfa_720w.webp" alt="img"></p><p>Dubbo 主要提供了这样几种容错方式</p><p>Failover Cluster - 失败自动切换 失败时会重试其它服务器</p><p>Failfast Cluster - 快速失败请求失败后快速返回异常结果不重试</p><p>Failsafe Cluster - 失败安全出现异常 直接忽略 会对请求做负载均衡</p><p>Failback Cluster - 失败自动恢复请求失败后 会自动记录请求到失败队列中</p><p>Forking Cluster - 并行调用多个服务提供者 其中有一个返回则立即返回结果</p><h3 id="信息缓存接口Directory"><a href="#信息缓存接口Directory" class="headerlink" title="信息缓存接口Directory"></a>信息缓存接口Directory</h3><p>Directory是Dubbo中的一个接口，主要用于缓存当前可以被调用的提供者列表信息。我们在消费者进 行调用时都会通过这个接口来获取所有的提供者列表，再进行后续处理。</p><h3 id="负载均衡实现原理"><a href="#负载均衡实现原理" class="headerlink" title="负载均衡实现原理"></a>负载均衡实现原理</h3><p>通过LoadBalance 接口进行定义，默认使用的是随机算法，这随机算法的负载，其内部的实现其实就是一个权重概念，通过不同权重来选取不同机器。权重相同直接随机，权重不同通过总工权重来随机分配。</p><h3 id="网络通信原理剖析"><a href="#网络通信原理剖析" class="headerlink" title="网络通信原理剖析"></a>网络通信原理剖析</h3><p>dubbo协议采用固定长度的消息头和不定长度的消息体来进行数据传输。请求、响应的 header 一致。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、Dubbo架构和实战&quot;&gt;&lt;a href=&quot;#一、Dubbo架构和实战&quot; class=&quot;headerlink&quot; title=&quot;一、Dubbo架构和实战&quot;&gt;&lt;/a&gt;一、Dubbo架构和实战&lt;/h2&gt;&lt;h3 id=&quot;架构演变过程&quot;&gt;&lt;a href=&quot;#架构演变过程&quot;</summary>
      
    
    
    
    <category term="基础知识" scheme="https://itingyu.github.io/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    <category term="dubbo" scheme="https://itingyu.github.io/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/dubbo/"/>
    
    
    <category term="基础知识" scheme="https://itingyu.github.io/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    <category term="dubbo" scheme="https://itingyu.github.io/tags/dubbo/"/>
    
  </entry>
  
  <entry>
    <title>zookeeper相关知识</title>
    <link href="https://itingyu.github.io/posts/26268/"/>
    <id>https://itingyu.github.io/posts/26268/</id>
    <published>2023-06-17T10:58:01.000Z</published>
    <updated>2023-06-17T10:58:35.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、Zookeeper基础"><a href="#一、Zookeeper基础" class="headerlink" title="一、Zookeeper基础"></a>一、Zookeeper基础</h2><h3 id="Zookeeper定位"><a href="#Zookeeper定位" class="headerlink" title="Zookeeper定位"></a>Zookeeper定位</h3><p>分布式系统是同时跨越多个物理主机，独⽴运⾏的多个软件所组成系统，而ZooKeeper主要的使⽤场景，就是作为分布式系统的分布式协同服务。分布式系统的协调⼯作就是通过某种⽅式，让每个节点的信息能够同步和共享，这依赖于服务进程之间的通信。</p><p>两种通信方式：通过网络进行信息共享、通过共享储存（Zookeeper）。</p><p><img src="https://pic2.zhimg.com/80/v2-d75675da81f6deb6d4b551e45118ac09_720w.webp" alt="img"></p><h3 id="Zookeeper基本概念"><a href="#Zookeeper基本概念" class="headerlink" title="Zookeeper基本概念"></a>Zookeeper基本概念</h3><p>Zookeeper是⼀个典型的分布式数据⼀致性的解决⽅案，分布式应⽤程序可以基于它实现诸如数据订阅&#x2F;发布、负载均衡、命名服务、集群管理、分布式锁和分布式队列等功能。</p><p><strong>集群角色</strong>：Zookeeper没用传统的主备模式，即Master&#x2F;Slave模式，而是引⼊了Leader、Follower、Observer三种⻆⾊，Leader通过选举产生，所有机子都可能成为Leader，Follower就是跟随者，Observer也相当于跟随者，但是没有投票权，Observer的意义在于不参与选举，减低投票压力，因为投票者越少，选出Leader越快，并且不参与写操作的过半写策略，提高集群性能。</p><p><img src="/posts/26268/assets/cecff32374a776223d86ba45cccaa1c8.webp" alt="img"></p><p><strong>会话</strong>：Session指客户端会话，⼀个客户端连接是指客户端和服务端之间的⼀个TCP⻓连接，通过心跳机制来保持有效会话。</p><p><strong>数据节点</strong>（Znode）: 构成集群的机器，我们称之为机器节点，数据模型中的数据单元，数据节点——ZNode，他是一颗树状的数据模型。</p><p><strong>版本</strong>：每个ZNode，Zookeeper都会为其维护⼀个叫作Stat的数据结构，Stat记录了这个ZNode的三个数据版本，分别是version（当前ZNode的版本）、cversion（当前ZNode⼦节点的版本）、aversion（当前ZNode的ACL版本）。</p><p><strong>Watcher（事件监听器）</strong>：就是特定的事件监听机制，进行特殊化通知某个服务器协同处理某些逻辑。</p><p><strong>ACL策略</strong>：用于权限控制，五种分类权限：　</p><p>1）CREATE：创建⼦节点的权限。</p><p>2）READ：获取节点数据和⼦节点列表的权限。</p><p>3）WRITE：更新节点数据的权限。</p><p>4）DELETE：删除⼦节点的权限。</p><p>5）ADMIN：设置节点ACL的权限。</p><h3 id="Zookeeper环境搭建"><a href="#Zookeeper环境搭建" class="headerlink" title="Zookeeper环境搭建"></a>Zookeeper环境搭建</h3><p><img src="https://pic4.zhimg.com/80/v2-b8a42e6fb0140cdd33d8cd158f9a2343_720w.webp" alt="img"></p><p><img src="/posts/26268/assets/e7d4a741e3f0e11744f8179b4883b824.webp" alt="img"></p><p>伪集群搭建注意事项，当前zookeeper的节点配置不能写ip地址，要写成0.0.0.0</p><h3 id="Znode系统模型"><a href="#Znode系统模型" class="headerlink" title="Znode系统模型"></a>Znode系统模型</h3><p>ZNode 是Zookeeper 中最⼩数据单位，在 ZNode 下面又可以再挂 ZNode，这样⼀层层下去就形成了⼀个层次化</p><p>命名空间 ZNode 树，我们称为 ZNode Tree，它采用类似⽂件系统的层级树状结构进行管理。</p><p><img src="/posts/26268/assets/56bfb824b83b1637c3c6367c6e2c9374.webp" alt="img"></p><p>Znode类型：持久性节点（创建后一直存在，除非主动删除）、临时性节点（会自动被清理）、顺序性节点（带顺序的持久或者临时节点）</p><p>事务：每个事务请求，ZooKeeper都会为其分配⼀个全局唯⼀的事务ID，⽤ZXID来表示，通常是⼀个64位的数字，</p><p>每⼀个ZXID对应⼀次更新操作，通过他来知道执行顺序，从而保证事务执行。</p><p><img src="/posts/26268/assets/b0209bc4f091a2708e4bdf2f290a92ef.webp" alt="img"></p><h3 id="Watcher系统模型"><a href="#Watcher系统模型" class="headerlink" title="Watcher系统模型"></a>Watcher系统模型</h3><p>ZooKeeper 允许客户端向服务端注册⼀个 Watcher 监听，当服务端的⼀些指定事件触发了这个 Watcher，那么就会向指定客户端发送⼀个事件通知来实现分布式的通知功能。</p><p>Watcher机制：客户端线程、客户端WatcherManager、Zookeeper服务器。</p><p><img src="https://pic3.zhimg.com/80/v2-b44d917871121fe5270c941081c0653e_720w.webp" alt="img"></p><p>客户端在向Zookeeper服务器注册的同时，会将Watcher对象存储在客户端的WatcherManager当中。当Zookeeper服务器触发Watcher事件后，会向客户端发送通知，客户端线程从WatcherManager中取出对应的Watcher对象来执⾏回调逻辑。</p><h3 id="ACL系统模型"><a href="#ACL系统模型" class="headerlink" title="ACL系统模型"></a>ACL系统模型</h3><p>ACL权限控制机制用来保障数据的安全，这部分数据就是内部存储的分布式系统运⾏时状态的元数据。</p><p>ACL机制三部分：权限模式（Scheme）、授权对象（ID）、权限（Permission）</p><p>权限模式：权限验证的检验策略，分Ip（IP地址模式）、Digest（常用模式，即用户名：密码模式）、World（开放模式）、Super（超级管理员模式）</p><p>授权对象：权限赋予的⽤户或⼀个指定实体，例如 IP 地址或是机器等。</p><p>权限：通过权限检查后可以被允许执⾏的操作，也就是前面提到的那五种分类权限。</p><h2 id="二、Zookeeper应用"><a href="#二、Zookeeper应用" class="headerlink" title="二、Zookeeper应用"></a>二、Zookeeper应用</h2><h3 id="数据发布-x2F-订阅"><a href="#数据发布-x2F-订阅" class="headerlink" title="数据发布&#x2F;订阅"></a>数据发布&#x2F;订阅</h3><p>ZooKeeper是⼀个典型的发布&#x2F;订阅模式的分布式数据管理与协调框架，我们可以使⽤它来进⾏分布式数据的发布与订阅。另⼀⽅⾯，通过对ZooKeeper中丰富的数据节点类型进⾏交叉使⽤，配合Watcher事件通知机制，可以⾮常⽅便的构建⼀系列分布式应⽤中都会涉及的核⼼功能，如数据发布&#x2F;订阅、命名服务、集群管理、Master选举、分布式锁和分布式队列等。</p><p>数据发布&#x2F;订阅（Publish&#x2F;Subscribe）系统，即所谓的配置中⼼，顾名思义就是发布者将数据发布到ZooKeeper的⼀个或⼀系列节点上，供订阅者进⾏数据订阅，进⽽达到动态获取数据的⽬的，实现配置信息的集中式管理和数据的动态更新。</p><p>两种设计模式：推（Push）模式和拉（Pull）模式。</p><p>推模式：服务端主动将数据更新发送给所有订阅的客户端。</p><p>拉模式：客户端主动发起请求来获取最新数据，常用轮询方式。</p><p>ZooKeeper 采⽤的是推拉相结合的⽅式：客户端向服务端注册⾃⼰需要关注的节点，⼀旦该节点的数据发⽣变更，那么服务端就会向相应客户端发送Watcher事件通知，客户端接收到这个消息通知之后，需要主动到服务端获取最新的数据。</p><p>比如通过zookeeper配置数据库连接信息，通过zookeeper的watcher事件通知机制，在集群环境下，当集群中的每台机子初始化阶段，就会从配置节点上读取数据库配置信息，并通过在该节点注册的watcher监听，一旦数据发生改变，所有订阅的客户端都能获取到变更通知，然后重新读取最新配置信息。</p><h3 id="命名服务"><a href="#命名服务" class="headerlink" title="命名服务"></a>命名服务</h3><p>命名服务就是集群中的机器、提供的服务地址或远程对象等等一系列的名称，通过使⽤命名服务，客户端应⽤能够根据指定名字来获取资源的实体、服务地址和提供者的信息等，比如RPC中的服务地址列表。</p><p>比如创建全局唯一ID，首先客户端会根据任务类型创建一个顺序节点，如job-0000000001，前缀是任务类型，接着客户端拿到这个值后还会拼接上type类型，最终形成一个全局唯一ID，如type-job-0000000001。</p><h3 id="集群管理"><a href="#集群管理" class="headerlink" title="集群管理"></a>集群管理</h3><p>集群管理，包括集群监控与集群控制两⼤块，前者侧重对集群运⾏时状态的收集，后者则是对集群进⾏操作与控制。</p><p>集群管理主要干的事：统计多少台机器、获取上下线机器情况、监控每台机器运行时状况。</p><p>传统集群管理基于Agent进行分布式集群管理，在每台机子上部署一个Agent，每个 Agent 主动向指定的⼀个监控中⼼系统汇报自己所在机器的状态，但是具有局限性，只能监控大局观上的内容，比如负载、CPU使用率、吞吐量等等，至于内部的一些业务状态，任务执行情况等等没办法监控。</p><p><strong>Zookeeper实现集群管理（分布式日志收集系统）</strong></p><p>特点</p><p>1）客户端如果对Zookeeper的数据节点注册Watcher监听，那么当该数据节点的内容或是其⼦节点列表发⽣变更时，Zookeeper服务器就会向订阅的客户端发送变更通知。</p><p>2）对在Zookeeper上创建的临时节点，如果客户端与服务器之间的会话失效，那么临时节点也会被⾃动删除。</p><p>实现</p><p>1） 注册收集器机器：创建一个节点作为收集器根节点，其他机器纷纷在这个主节点下创建自己的子节点。</p><p>2） 任务分发：系统根据收集器节点下面的数量，进行分组，然后组内的机器日志都写到当前组下面创建的子节点上。</p><p>3） 状态汇报：每个收集器还要创建一个状态节点，这个节点是持久节点，因为临时节点在服务器挂掉后会被自动删除，按时写入状态信息，日志系统定时，也就是主动轮询策略根据状态节点信息更新时间来判断该节点是否存活，类似于心跳机制检测，如果采用Watcher，通知量会很高，因为一更新就会触发，对于检测来说没必要。</p><p>4） 动态分配：当收集器集群机器存在扩展或者挂掉，第一种方式就是全局动态分配，即重新开始分组，影响较大，风险较高。第二种局部动态分配，这也是为什么要分组的原因，当某组的某台机器挂掉或者扩容，对当前组进行重新分配，把挂掉机器的任务分配到其他负载低的机器上或者新加进来的机器分担一些负载高机器的任务。</p><h3 id="Master选举"><a href="#Master选举" class="headerlink" title="Master选举"></a>Master选举</h3><p>所有集群机器通过选举产生一个主机器，成为Master，他的作用就是对其他集群机器进行协调，就最大控制权，同时一些重要业务逻辑和读写分离的写操作由Master执行，Zookeeper是通过所有机器同时创建一个相同的节点，这个节点是临时节点，谁创建成功，谁就是Master的机制进行选举，当确定了Master之后，其他机器就在Master节点后面创建子节点，对Master进行Watcher进行监听，当Master服务器挂了，那么 Master创建的临时节点也会被删除，通过Watcher机制其他集群机器就马上知道了结果，于是重新选举。</p><h3 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h3><p>分布式锁是控制分布式系统之间同步访问共享资源的⼀种⽅式，其实就是对共享资源的访问保持一致性。</p><p><strong>排他锁</strong></p><p>排他锁又称写锁或独占锁，是⼀种基本的锁类型。就是事务1对资源1加了锁，那么只有事务1能对他进行操作，直到他释放了锁之后，其他事务才能操作。</p><p>Zookeeper中排他锁实现：</p><p>1） 定义锁：定义一个lock锁节点</p><p>2） 获取锁：所有客户端都尝试在这个lock节点下创建临时子节点，当谁成功创建临时子节点，就是谁持有了排他锁，其他机器在lock注册监听，监听临时子节点变化。</p><p>3） 释放锁：当临时子节点被删除，也就是当前获取锁客户端宕机或者已经完成操作，其他机器监听到了子节点状态变化，过来争抢创建临时子节点，进行锁的获取。</p><p><img src="/posts/26268/assets/5ffa44a74b8409bb1925c82ca34a2ed8.webp" alt="img"></p><p><strong>共享锁</strong></p><p>共享锁又称为读锁，同样是一种基本锁类型，和排他锁不一样，事务1对资源1加了共享锁，但是资源1对其他事务也可见，资源1是共享的，如果是读，资源2也可以加共享锁获取数据，也就是可以并行读，如果是写，就需要排斥。</p><p>Zookeeper中共享锁实现：</p><p>1） 定义锁：定义一个lock锁节点</p><p>2） 获取锁：所有客户端都往这个锁节点创建子节点，并往lock锁注册watcher事件监听，这时候就不是只允许一个创建了，是大家都可以创建，不过创建的是临时顺序节点，并且读、写请求的别名不一样，分别是R、W。当读节点前面都是读，那么就可以进行读，当读前面有写，那就等待，当写前面有读，等读完，直到自己是第一顺位写再执行。</p><p>3） 释放锁：因为都是临时顺序节点，宕机和执行完都会被删除，然后被监听的其他节点获取，相当于就完成了锁的交替。</p><h3 id="羊群效应"><a href="#羊群效应" class="headerlink" title="羊群效应"></a>羊群效应</h3><p>当集群规模扩大，这种watcher监听事件通知就会消耗很大的资源。如果第一个是读请求，第二个是写请求，只需要通知第二个节点即可，而通过watcher监听，通知的是所有集群机器，所以就造成了不必须的资源浪费。</p><p>改进：很简单，不对lock进行注册事件监听，只需要对当前节点的前面一个节点，也就是序号比自己小的前一位注册watcher事件监听，来监听前面的节点是读还是写请求，并且监听节点的状态变化。</p><p><img src="https://pic2.zhimg.com/80/v2-a254c8c41249ce1c944295e545a4e80d_720w.webp" alt="img"></p><h3 id="分布式队列"><a href="#分布式队列" class="headerlink" title="分布式队列"></a>分布式队列</h3><p>分布式队列可以简单分为两⼤类：⼀种是常规的FIFO先⼊先出队列模型，还有⼀种是等待队列元素聚集后统⼀安排处理执⾏的Barrier模型。</p><p><strong>FIFO先入先出队列</strong></p><p>先进⼊队列的请求操作先完成后，才会开始处理后⾯的请求。</p><p>Zookeeper实现FIFO队列：跟前面的共享锁类似，在一个主节点下面按顺序创建临时顺序子节点，第二个子节点在第一个子节点注册Watcher事件监听，监听前一个子节点变化，当第一个子节点消失，也就是执行完毕，马上执行，这样按顺序挂接下去，实现FIFO。</p><p><strong>Barrier分布式屏障</strong></p><p>FIFO的增强，同样的在主节点下面创建子节点，并注册监听到主节点中，通过getData判断子节点创建的数量是否到达10，如果到达了10个就解除屏障，进行事务处理，未达到就等待，对资源集中处理利用的一种方式。</p><h3 id="ZAB协议"><a href="#ZAB协议" class="headerlink" title="ZAB协议"></a>ZAB协议</h3><p>ZAB协议其实就是一种算法，跟Paxos算法一样，作为数据⼀致性的核⼼算法，不过ZAB协议是zookeeper专⻔设计的⼀种⽀持崩溃恢复的原子广播协议，内部实现的是主备模型。即主进程来接收并处理客户端的所有事务请求，并采⽤ZAB的原⼦⼴播协议，以事务 Proposal的形式广播给所有副本进程，处理大量并发请求。</p><p>ZAB核心：定义了对于那些会改变Zookeeper服务器数据状态的事务请求的处理⽅式，所有事务请求必须由⼀个全局唯⼀的服务器来协调处理，这样的服务器被称为Leader服务器，余下的服务器则称为Follower服务器，通过广播进行调度，并且根据反馈的ACK命令，以半数原则来判断是否可以下达提交命令。</p><p>ZAB协议分两种基本的模式：崩溃恢复和消息⼴播</p><p>崩溃恢复模式：即Leader服务器出现⽹络中断、崩溃退出或重启等异常情况，重新选举新的Leader</p><p>消息⼴播模式：过半的Follower服务器完成了和Leader服务器的状态同步，进入消息广播模式，这时新加入到集群的服务器会自觉进入数据恢复模式，即和Leader服务器数据进行同步，并加入到消息广播模式中。</p><p><strong>消息广播</strong></p><p>ZAB协议的消息⼴播过程使⽤原⼦⼴播协议，类似于⼀个⼆阶段提交过程，针对客户端的事务请求，Leader服务器会为其⽣成对应的事务Proposal，并将其发送给集群中其余所有的机器，这是是基于FIFO队列发送，然后再分别收集各⾃的选票，最后进⾏事务提交。当时ZAB协议移除了中断机制，也就是不需要等每台机子响应，只要过半机子响应了就执行提交事务，而数据不一致的问题就通过崩溃恢复模式来解决了。</p><p><strong>崩溃恢复</strong></p><p>选举算法：能够确保提交已经被 Leader 提交的事务 Proposal，同时丢弃已经被跳过的事务 Proposal。针对这个要求，如果让Leader选举算法能够保证新选举出来的Leader服务器拥有集群中所有机器最⾼编号（即ZXID最⼤）的事务Proposal，那么就可以保证这个新选举出来的Leader⼀定具有所有已经提交的提案。更为重要的是，如果让具有最⾼编号事务Proposal 的机器来成为 Leader，就可以省去 Leader 服务器检查Proposal的提交和丢弃⼯作的这⼀步操作了。</p><p>数据同步：Leader服务器会为每⼀个Follower服务器都准备⼀个队列，并将那些没有被各Follower服务器同步的事务以Proposal消息的形式逐个发送给Follower服务器， 并在每⼀个Proposal消息后⾯紧接着再发送⼀个Commit消息，以表示该事务已经被提交。等到 Follower服务器将所有其尚未同步的事务 Proposal 都从 Leader 服务器上同步过来并成功应⽤到本地数据库中后，Leader服务器就会将该Follower服务器加⼊到真正的可⽤Follower列表中，并开始之后的其他流程。</p><p><strong>运行时分析</strong></p><p>ZAB协议的三种状态：LOOKING：Leader选举阶段、FOLLOWING：Follower服务器和Leader服务器保持同步状态、LEADING：Leader服务器作为主进程领导状态。</p><p>所有进程初始状态都是LOOKING状态，此时不存在Leader，接下来，进程会试图选举出⼀个新的 Leader，之后如果进程发现已经选举出新的Leader了，那么它就会切换到FOLLOWING状态，并开始 和Leader保持同步，处于FOLLOWING状态的进程称为Follower，LEADING状态的进程称为Leader，当 Leader崩溃或放弃领导地位时，其余的Follower进程就会转换到LOOKING状态开始新⼀轮的Leader选举。</p><h3 id="运行流程"><a href="#运行流程" class="headerlink" title="运行流程"></a>运行流程</h3><p><strong>单机模式</strong></p><p>1、注册jmx</p><p>2、解析ServerConfig配置对象</p><p>3、根据配置对象，运⾏单机zk服务</p><p>4、创建管理事务⽇志和快照FileTxnSnapLog对象，zookeeperServer对象，并设置zkServer的统计对象</p><p>5、设置zk服务钩⼦，原理是通过设置CountDownLatch，调⽤ZooKeeperServerShutdownHandler的 handle⽅法，可以将触发shutdownLatch.await⽅法继续执⾏，即调⽤shutdown关闭单机服务</p><p>6、基于jetty创建zk的admin服务</p><p>7、创建连接对象cnxnFactory和secureCnxnFactory（安全连接才创建该对象），⽤于处理客户端的请求</p><p>8、创建定时清除容器节点管理器，⽤于处理容器节点下不存在⼦节点的清理容器节点⼯作等</p><p><img src="/posts/26268/assets/7b57651ea4e65f5ce57d68716372d449.webp" alt="img"></p><p><strong>集群模式</strong></p><p>集群模式执行流程跟单机也是差不多的，只是在单机集群判断不同而已。</p><p><img src="/posts/26268/assets/7ee0b7751eeb1ae4de7317ce40eb97df.webp" alt="img"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、Zookeeper基础&quot;&gt;&lt;a href=&quot;#一、Zookeeper基础&quot; class=&quot;headerlink&quot; title=&quot;一、Zookeeper基础&quot;&gt;&lt;/a&gt;一、Zookeeper基础&lt;/h2&gt;&lt;h3 id=&quot;Zookeeper定位&quot;&gt;&lt;a href=</summary>
      
    
    
    
    <category term="基础知识" scheme="https://itingyu.github.io/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    <category term="zookeeper" scheme="https://itingyu.github.io/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/zookeeper/"/>
    
    
    <category term="基础知识" scheme="https://itingyu.github.io/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    <category term="zookeeper" scheme="https://itingyu.github.io/tags/zookeeper/"/>
    
  </entry>
  
  <entry>
    <title>tomcat相关知识</title>
    <link href="https://itingyu.github.io/posts/2320/"/>
    <id>https://itingyu.github.io/posts/2320/</id>
    <published>2023-06-17T10:56:09.000Z</published>
    <updated>2023-06-17T10:57:22.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、-Tomcat系统架构和原理剖析"><a href="#一、-Tomcat系统架构和原理剖析" class="headerlink" title="一、 Tomcat系统架构和原理剖析"></a>一、 Tomcat系统架构和原理剖析</h2><h3 id="浏览器访问服务器的流程"><a href="#浏览器访问服务器的流程" class="headerlink" title="浏览器访问服务器的流程"></a>浏览器访问服务器的流程</h3><p><img src="https://pic3.zhimg.com/80/v2-bcc32c3b6cb7a2ba6b1a272b2c0c3fe2_720w.webp" alt="img"></p><p>浏览器访问服务器使⽤的是Http协议，Http是应⽤层协议，⽤于定义数据通信的格式，具体的数据传输使⽤的是TCP&#x2F;IP协议。</p><h3 id="Tomcat-系统总体架构"><a href="#Tomcat-系统总体架构" class="headerlink" title="Tomcat 系统总体架构"></a>Tomcat 系统总体架构</h3><p><strong>Tomcat的两个身份：</strong></p><p>1）http服务器</p><p>2）Tomcat是⼀个Servlet容器</p><p>Tomcat是⼀个Http服务器，HTTP 服务器接收到请求之后把请求交给Servlet容器来处理，Servlet 容器通过Servlet接⼝调⽤业务类，避免tomcat和业务类耦合在一起。Servlet接⼝和Servlet容器这⼀整套内容就是Servlet规范。</p><p><strong>Tomcat Servlet容器处理流程：</strong></p><p>1）HTTP服务器会把请求信息使⽤ServletRequest对象封装起来</p><p>2）进⼀步去调⽤Servlet容器中某个具体的Servlet</p><p>3）Servlet容器拿到请求后，根据URL和Servlet的映射关系，找到相应的Servlet</p><p>4）如果Servlet还没有被加载，就⽤反射机制创建这个Servlet，并调⽤Servlet的init⽅法来完成初始化</p><p>5）接着调⽤这个具体Servlet的service⽅法来处理请求，请求处理结果使⽤ServletResponse对象封装</p><p>6）把ServletResponse对象返回给HTTP服务器，HTTP服务器会把响应发送给客户端</p><p><img src="/posts/2320/assets/efdb8b714f44fe0c3fd8bf488fee0013.webp" alt="img"></p><p>总结：Tomcat主要干两个事情</p><p>1）和客户端浏览器进⾏交互，进⾏socket通信，将字节流和Request&#x2F;Response等对象进⾏转换</p><p>2）Servlet容器处理业务逻辑</p><p><img src="/posts/2320/assets/36379b79999327337f7d8db2092f7e15.webp" alt="img"></p><p>Tomcat设计了两个核心组件：连接器（Connector）和容器（Container）来干上面的两个事情</p><p>连接器，负责对外交流： 处理Socket连接，负责⽹络字节流与Request和Response对象的转化</p><p>容器，负责内部处理：加载和管理Servlet，以及具体处理Request请求</p><h3 id="Tomcat-两大组件之连接器组件-Coyote"><a href="#Tomcat-两大组件之连接器组件-Coyote" class="headerlink" title="Tomcat 两大组件之连接器组件 Coyote"></a>Tomcat 两大组件之连接器组件 Coyote</h3><p>客户端通过Coyote与服务器建⽴连接、发送请求并接受响应：</p><p>（1）Coyote 封装了底层的⽹络通信（Socket 请求及响应处理）</p><p>（2）Coyote 使Catalina 容器（Container容器组件）与具体的请求协议及IO操作⽅式完全解 耦</p><p>（3）Coyote 将Socket 输⼊转换封装为 Request 对象，进⼀步封装后交由Catalina 容器进⾏处理，处理请求完成后, Catalina 通过Coyote 提供的Response 对象将结果写⼊输出流。</p><p>（4）Coyote 负责的是具体协议（应⽤层）和IO（传输层）相关内容</p><p><img src="/posts/2320/assets/4e70d4e3313490b56a509f95cf7674bb.webp" alt="img"></p><p><img src="https://pic3.zhimg.com/80/v2-18b84208b91eb96c8a86e3321d88819a_720w.webp" alt="img"></p><p>注意： 8.0 之前 ，Tomcat 默认采⽤的I&#x2F;O⽅式为 BIO，之后改为 NIO。 ⽆论 NIO、NIO2 还是 APR， 在性能⽅⾯均优于以往的BIO。 如果采⽤APR， 甚⾄可以达到 Apache HTTP Server 的影响性能。</p><p><strong>Coyote 的内部组件及流程</strong></p><p><img src="https://pic4.zhimg.com/80/v2-39c0a3f4f15e3145b027642fe58b18a7_720w.webp" alt="img"></p><p><img src="/posts/2320/assets/812f5fcc102346c63adbb4878f7e0d0c.webp" alt="img"></p><h3 id="Tomcat-两大组件之Servlet容器组件Catalina"><a href="#Tomcat-两大组件之Servlet容器组件Catalina" class="headerlink" title="Tomcat 两大组件之Servlet容器组件Catalina"></a>Tomcat 两大组件之Servlet容器组件Catalina</h3><p>Tomcat是由⼀系列可配置（conf&#x2F;server.xml）的组件构成的Web容器，⽽Catalina是Tomcat的servlet容器。</p><p>Tomcat 本质上就是⼀款 Servlet 容器， 因此Catalina 才是 Tomcat 的核⼼ ， 其他模块都是为Catalina 提供⽀撑的。 ⽐如 ： 通过 Coyote 模块提供链接通信，Jasper 模块提供 JSP 引擎，Naming 提供JNDI 服务，Juli 提供⽇志服务。</p><p><img src="/posts/2320/assets/3f8eef762783307fcfdc98394ce3d108.webp" alt="img"></p><p>整个Tomcat就是⼀个Catalina实例，一个Catalina实例有一个Server实例，一个Server实例可以有多个Service实例, 每⼀个Service实例下可以有多个Connector实例和⼀个Container实例。</p><p><img src="/posts/2320/assets/9ca9f4221d6c8bdc1d0ffdaacca6b5c6.webp" alt="img"></p><p><strong>Catalina</strong></p><p>负责解析Tomcat的配置⽂件（server.xml） , 以此来创建服务器Server组件并进⾏管理</p><p><strong>Server</strong></p><p>服务器表示整个Catalina Servlet容器以及其它组件，负责组装并启动Servlaet引擎,Tomcat连接器。Server通过实现Lifecycle接⼝，提供了⼀种优雅的启动和关闭整个系统的⽅式</p><p><strong>Service</strong></p><p>服务是Server内部的组件，⼀个Server包含多个Service。它将若⼲个Connector组件绑定到⼀个</p><p><strong>Container</strong></p><p>Container容器，负责处理⽤户的servlet请求，并返回对象给web⽤户的模块</p><p>Container组件下有四种具体的组件，分别是Engine、Host、Context和Wrapper，他们是层级关系。</p><p>Engine：表示整个Catalina的Servlet引擎，⽤来管理多个虚拟站点，⼀个Service最多只能有⼀个Engine，但是⼀个引擎可包含多个Host。</p><p>Host：代表⼀个虚拟主机，或者说⼀个站点，可以给Tomcat配置多个虚拟主机地址，⽽⼀个虚拟主机下可包含多个Context。</p><p>Context：表示⼀个Web应⽤程序， ⼀个Web应⽤可包含多个Wrapper。</p><p>Wrapper：表示⼀个Servlet，Wrapper 作为容器中的最底层，不能包含⼦容器。</p><h3 id="Tomcat-服务器核⼼配置Server标签"><a href="#Tomcat-服务器核⼼配置Server标签" class="headerlink" title="Tomcat 服务器核⼼配置Server标签"></a>Tomcat 服务器核⼼配置Server标签</h3><p><img src="/posts/2320/assets/989b041079ee1ef1ac6b3efb2f74e238.webp" alt="img"></p><h3 id="Tomcat-服务器核⼼配置Service标签"><a href="#Tomcat-服务器核⼼配置Service标签" class="headerlink" title="Tomcat 服务器核⼼配置Service标签"></a>Tomcat 服务器核⼼配置Service标签</h3><p><img src="/posts/2320/assets/a02b581b3cfabcecdfd66e3a9cb2800d.webp" alt="img"></p><h3 id="Tomcat-服务器核⼼配置Executor标签"><a href="#Tomcat-服务器核⼼配置Executor标签" class="headerlink" title="Tomcat 服务器核⼼配置Executor标签"></a>Tomcat 服务器核⼼配置Executor标签</h3><p><img src="/posts/2320/assets/c8bd3a4cdc0b64c68670e1781ca51472.webp" alt="img"></p><h3 id="Tomcat-服务器核⼼配置Connector标签"><a href="#Tomcat-服务器核⼼配置Connector标签" class="headerlink" title="Tomcat 服务器核⼼配置Connector标签"></a>Tomcat 服务器核⼼配置Connector标签</h3><p>Connector 标签⽤于创建链接器实例默认情况下，server.xml 配置了两个链接器，⼀个⽀持HTTP协议，⼀个⽀持AJP协议</p><p>⼤多数情况下，我们并不需要新增链接器配置，只是根据需要对已有链接器进⾏优化.</p><p><img src="https://pic2.zhimg.com/80/v2-73127870fcce3df98ba75cf41be8b951_720w.webp" alt="img"></p><p>共享线程池:配置共享线程池，多个connector共用，节约资源。</p><p><img src="/posts/2320/assets/6bc951d9c7f6fe1b47a7b59924d803ea.webp" alt="img"></p><h3 id="Tomcat-服务器核⼼配置Engine标签"><a href="#Tomcat-服务器核⼼配置Engine标签" class="headerlink" title="Tomcat 服务器核⼼配置Engine标签"></a>Tomcat 服务器核⼼配置Engine标签</h3><p>Engine 表示 Servlet 引擎</p><p><img src="/posts/2320/assets/3cf4f30992c15107f56a39e739fa1723.webp" alt="img"></p><h3 id="Tomcat-服务器核⼼配置Host标签"><a href="#Tomcat-服务器核⼼配置Host标签" class="headerlink" title="Tomcat 服务器核⼼配置Host标签"></a>Tomcat 服务器核⼼配置Host标签</h3><p><img src="/posts/2320/assets/6cb5ba980d6886fc1fa34b04f5d7c970.webp" alt="img"></p><h3 id="Tomcat-服务器核⼼配置Context标签"><a href="#Tomcat-服务器核⼼配置Context标签" class="headerlink" title="Tomcat 服务器核⼼配置Context标签"></a>Tomcat 服务器核⼼配置Context标签</h3><p><img src="https://pic4.zhimg.com/80/v2-f3e5efed8367c39cabf0763d86b89587_720w.webp" alt="img"></p><h2 id="二、手写实现Tomcat服务器与源码剖析"><a href="#二、手写实现Tomcat服务器与源码剖析" class="headerlink" title="二、手写实现Tomcat服务器与源码剖析"></a>二、手写实现Tomcat服务器与源码剖析</h2><h3 id="手写实现Tomcat服务器需求及实现步骤"><a href="#手写实现Tomcat服务器需求及实现步骤" class="headerlink" title="手写实现Tomcat服务器需求及实现步骤"></a>手写实现Tomcat服务器需求及实现步骤</h3><p>1）提供服务，接收请求（Socket通信）</p><p>2）请求信息封装成Request对象（Response对象）</p><p>3）客户端请求资源，资源分为静态资源（html）和动态资源（Servlet）</p><p>4）资源返回给客户端浏览器</p><p>\1. 创建一个启动类Bootstrap，通过main方法调用启动start方法</p><p><img src="/posts/2320/assets/a694ff087aab0a04a5dcc99668fd39e1.webp" alt="img"></p><p><img src="/posts/2320/assets/84c07c550e2553cd4ce3e75400409228.webp" alt="img"></p><p>\2. 通过dom4j加载解析web.xml存入map集合中，此map存储的是地址和自定义的HttpServlet类</p><p><img src="/posts/2320/assets/0f16d95069dd71d57c9ef884f4769cad.webp" alt="img"></p><p>\3. 定义端口号，创建一个ServerSocket，通过accept获取Socket类,把Socket和map集合传入多线程处理类。</p><p><img src="https://pic2.zhimg.com/80/v2-d556554d799b10a0728b275749d59b89_720w.webp" alt="img"></p><p>\4. 通过Socket获取输入流封装Request对象</p><p><img src="/posts/2320/assets/6bf49db3da69c7b16bb079a327089255.webp" alt="img"></p><p>\5. 通过Socket获取输出流封装Response对象。</p><p><img src="/posts/2320/assets/1da87bffb7ba9d23b198a9b97fa252d2.webp" alt="img"></p><p>\6. 根据请求查询map集合是否为空判断静态资源，静态资源处理</p><p><img src="https://pic2.zhimg.com/80/v2-c7ef8d1509d33955578f6d48fcc34af5_720w.webp" alt="img"></p><p>\7. 动态资源处理，调用自定义的LgServlet继承HttpServlet重写doGet和doPost进行输出</p><p><img src="/posts/2320/assets/ae9c0cf3fddd9576185fd4fdd4dc0662.webp" alt="img"></p><p>\8. 关闭socket，获取已经创建好的多线程类，放入调用定义线程池threadPoolExecutor中调用execute执行。</p><p><img src="/posts/2320/assets/54ed60b1539016fe66ef12ad2b951b43.webp" alt="img"></p><h3 id="Tomcat启动流程"><a href="#Tomcat启动流程" class="headerlink" title="Tomcat启动流程"></a>Tomcat启动流程</h3><p>从脚本start.sh找到Bootstap类的main方法从父容器开始把组件一个个初始化再逐级启动</p><p><img src="/posts/2320/assets/3422109b0992b60d7987996e724c7462.webp" alt="img"></p><h3 id="Tomcat请求流程"><a href="#Tomcat请求流程" class="headerlink" title="Tomcat请求流程"></a>Tomcat请求流程</h3><p>请求处理流程分析图</p><p><img src="https://pic2.zhimg.com/80/v2-46cdf77a7c957192ef2582e542453829_720w.webp" alt="img"></p><p>Mapper组件体系结构</p><p><img src="/posts/2320/assets/623e79a5cb86319afca419593816352b.webp" alt="img"></p><p>请求处理流程示意图</p><p><img src="https://pic2.zhimg.com/80/v2-95e2ba7c2cd2061adcdd10a058081169_720w.webp" alt="img"></p><h3 id="三、Tomcat类加载机制剖析"><a href="#三、Tomcat类加载机制剖析" class="headerlink" title="三、Tomcat类加载机制剖析"></a>三、Tomcat类加载机制剖析</h3><p>类加载过程：Java类（.java）文件被编译成字节码文件（.class），然后通过类加载器（classloader）加载到jvm内存中。</p><h3 id="JVM类加载机制"><a href="#JVM类加载机制" class="headerlink" title="JVM类加载机制"></a>JVM类加载机制</h3><p>Jvm内置了⼏种类加载器，包括：引导类加载器、扩展类加载器、系统类加载器，他们之间形成⽗⼦关系，通过 Parent 属性来定义这种关系，最终可以形成树形结构，同时我们自己也可以自定义类加载器。</p><p><img src="/posts/2320/assets/09484d20f46241fd81f0ee06dfdb9016.webp" alt="img"></p><p><img src="/posts/2320/assets/84be9f837ec2ea4c779b39d580cc02a2.webp" alt="img"></p><p>⽤户可以⾃定义类加载器（Java编写，⽤户⾃定义的类加载器，可加载指定路径的 class ⽂件）当 JVM 运⾏过程中，⽤户⾃定义了类加载器去加载某些类时，会按照下⾯的步骤（⽗类委托机制）</p><p>1） ⽤户⾃⼰的类加载器，把加载请求传给⽗加载器，⽗加载器再传给其⽗加载器，⼀直到加载器树的顶层</p><p>2 ）最顶层的类加载器⾸先针对其特定的位置加载，如果加载不到就转交给⼦类</p><p>3 ）如果⼀直到底层的类加载都没有加载到，那么就会抛出异常 ClassNotFoundException</p><p>因此，按照这个过程可以想到，如果同样在 classpath 指定的⽬录中和⾃⼰⼯作⽬录中存放相同的class，会优先加载 classpath ⽬录中的⽂件。</p><h3 id="JVM双亲委派机制"><a href="#JVM双亲委派机制" class="headerlink" title="JVM双亲委派机制"></a>JVM双亲委派机制</h3><p>当某个类加载器需要加载某个.class⽂件时，它⾸先把这个任务委托给他的上级类加载器，递归这个操作，如果上级的类加载器没有加载，⾃⼰才会去加载这个类。</p><p><strong>作用：</strong></p><p>防⽌重复加载同⼀个.class。通过委托去向上⾯问⼀问，加载过了，就不⽤再加载⼀遍。保证数据安全。</p><p>保证核⼼.class不能被篡改。通过委托⽅式，不会去篡改核⼼.class，即使篡改也不会去加载，即使加载也不会是同⼀个.class对象了。不同的加载器加载同⼀个.class也不是同⼀个.class对象。这样保证了class执⾏安全（如果⼦类加载器先加载，那么我们可以写⼀些与java.lang包中基础类同名的类， 然后再定义⼀个⼦类加载器，这样整个应⽤使⽤的基础类就都变成我们⾃⼰定义的类了）。</p><h3 id="Tomcat类加载机制"><a href="#Tomcat类加载机制" class="headerlink" title="Tomcat类加载机制"></a>Tomcat类加载机制</h3><p>Tomcat 的类加载机制相对于 Jvm 的类加载机制做了⼀些改变<strong>，</strong>因为如果同时存在两个应用，然后他们有相同的全限定类名，如果遵循双亲委派机制，tomcat加载了应用1的全限定类之后就不会再加载应用2的类，但是这两个类虽然全限定类名相同，里面的逻辑却是不同的，所以JVM的双亲委派机制就不适合Tomcat了。因此在原来Jvm类加载机制上做了扩展和改变。增加了Commons、Catalina、Shared、WebApp类加载器。</p><p><img src="/posts/2320/assets/1b43c97cc74a951249792cd6722db1ac.webp" alt="img"></p><p><img src="/posts/2320/assets/9e68caf918a0c2a4981a729c6de4759a.webp" alt="img"></p><p>引导类加载器 和 扩展类加载器 的作⽤不变。</p><p>系统类加载器正常情况下加载的是 CLASSPATH 下的类，但是 Tomcat 的启动脚本并未使⽤该变量，⽽是加载tomcat启动的类，⽐如bootstrap.jar，通常在catalina.bat或者catalina.sh中指定，位于CATALINA_HOME&#x2F;bin下。</p><p>Common 通⽤类加载器加载Tomcat使⽤以及应⽤通⽤的类，位于CATALINA_HOME&#x2F;lib下，⽐如servlet-api.jar。</p><p>Catalina ClassLoader ⽤于加载服务器内部可⻅类，这些类应⽤程序不能访问。</p><p>Shared ClassLoader ⽤于加载应⽤程序共享类，这些类服务器不会依赖。</p><p>Webapp ClassLoader，每个应⽤程序都会有⼀个独⼀⽆⼆的Webapp ClassLoader，他⽤来加载本应⽤程序 &#x2F;WEB-INF&#x2F;classes 和 &#x2F;WEB-INF&#x2F;lib 下的类。</p><p><strong>加载顺序：</strong></p><p>⾸先从 Bootstrap Classloader加载指定的类-&gt;</p><p>如果未加载到，则从 &#x2F;WEB-INF&#x2F;classes加载-&gt;</p><p>如果未加载到，则从 &#x2F;WEB-INF&#x2F;lib&#x2F;*.jar 加载-&gt;</p><p>如果未加载到，则依次从 System、Common、Shared 加载（在这最后⼀步，遵从双亲委派机制）</p><h2 id="四、Tomcat-对-Https-的支持及-Tomcat-性能优化策略"><a href="#四、Tomcat-对-Https-的支持及-Tomcat-性能优化策略" class="headerlink" title="四、Tomcat 对 Https 的支持及 Tomcat 性能优化策略"></a>四、Tomcat 对 Https 的支持及 Tomcat 性能优化策略</h2><h3 id="Tomcat-对-HTTPS-的支持"><a href="#Tomcat-对-HTTPS-的支持" class="headerlink" title="Tomcat 对 HTTPS 的支持"></a>Tomcat 对 HTTPS 的支持</h3><p>Https是⽤来加强数据传输安全的。Http超⽂本传输协议，明⽂传输 ，传输不安全，https在传输数据的时候会对数据进⾏加密，也就是在http的基础上增加了ssl协议。</p><p><strong>HTTPS和HTTP的主要区别：</strong></p><p>HTTPS协议使⽤时需要到电⼦商务认证授权机构（CA）申请SSL证书。</p><p>HTTP默认使⽤8080端⼝，HTTPS默认使⽤8443端⼝。</p><p>HTTPS则是具有SSL加密的安全性传输协议，对数据的传输进⾏加密，效果上相当于HTTP的升级版。</p><p>HTTP的连接是⽆状态的，不安全的；HTTPS协议是由SSL+HTTP协议构建的可进⾏加密传输、身份认证的⽹络协议，⽐HTTP协议安全。</p><p><strong>HTTPS⼯作原理：</strong></p><p><img src="/posts/2320/assets/4467bfc76f7470191ecf6c775665d63f.webp" alt="img"></p><p>使用：生成秘钥库文件xx.keystore，把绝对路径地址配置到conf&#x2F;server.xml即可。</p><h3 id="JVM内存调优"><a href="#JVM内存调优" class="headerlink" title="JVM内存调优"></a>JVM内存调优</h3><p>系统性能的衡量指标，主要是响应时间和吞吐量。</p><p>1）响应时间：执行某个操作的耗时；</p><ol start="2"><li>吞吐量：系统在给定时间内能够⽀持的事务数量，单位为TPS（Transactions PerSecond的缩写，也就是事务数&#x2F;秒，⼀个事务是指⼀个客户机向服务器发送请求然后服务器做出反应的过程。</li></ol><p>Java 虚拟机的运⾏优化主要是内存分配和垃圾回收策略的优化</p><p>1）内存直接影响服务的运⾏效率和吞吐量</p><p>2）垃圾回收机制会不同程度地导致程序运⾏中断（垃圾回收策略不同，垃圾回收次数和回收效率都是不同的）</p><p><img src="/posts/2320/assets/c281e5618ddac033e359f214ddc8d5d3.webp" alt="img"></p><p>JVM内存模型</p><p><img src="/posts/2320/assets/67070137f7139efc792e161736b51bb4.webp" alt="img"></p><p><strong>使用：配置在catalina.sh的脚本</strong></p><p><img src="/posts/2320/assets/ce94e1800948882bd1d16675bd91917e.webp" alt="img"></p><h3 id="JVM垃圾收集策略"><a href="#JVM垃圾收集策略" class="headerlink" title="JVM垃圾收集策略"></a>JVM垃圾收集策略</h3><p>垃圾回收性能指标</p><p>吞吐量：⼯作时间（排除GC时间）占总时间的百分⽐， ⼯作时间并不仅是程序运⾏的时间，还包含内存分配时间。</p><p>暂停时间：由垃圾回收导致的应⽤程序停⽌响应次数&#x2F;时间。</p><p><strong>垃圾收集器：</strong></p><p>串⾏收集器（Serial Collector）</p><p>单线程执⾏所有的垃圾回收⼯作， 适⽤于单核CPU服务器⼯作进程—–|（单线程）垃圾回收线程进⾏垃圾收集|—⼯作进程继续</p><p>并⾏收集器（Parallel Collector）</p><p>⼯作进程—–|（多线程）垃圾回收线程进⾏垃圾收集|—⼯作进程继续⼜称为吞吐量收集器（关注吞吐量）， 以并⾏的⽅式执⾏年轻代的垃圾回收， 该⽅式可以显著降低垃圾回收的开销(指多条垃圾收集线程并⾏⼯作，但此时⽤户线程仍然处于等待状态)。适⽤于多处理器或多线程硬件上运⾏的数据量较⼤的应⽤</p><p>并发收集器（Concurrent Collector）</p><p>以并发的⽅式执⾏⼤部分垃圾回收⼯作，以缩短垃圾回收的暂停时间。适⽤于那些响应时间优先于吞吐量的应⽤， 因为该收集器虽然最⼩化了暂停时间(指⽤户线程与垃圾收集线程同时执⾏,但不⼀定是并⾏的，可能会交替进⾏)， 但是会降低应⽤程序的性能</p><p>CMS收集器（Concurrent Mark Sweep Collector）</p><p>并发标记清除收集器， 适⽤于那些更愿意缩短垃圾回收暂停时间并且负担的起与垃圾回收共享处理器资源的应⽤</p><p>G1收集器（Garbage-First Garbage Collector）</p><p>适⽤于⼤容量内存的多核服务器， 可以在满⾜垃圾回收暂停时间⽬标的同时， 以最⼤可能性实现⾼吞吐量(JDK1.7之后)</p><p><strong>垃圾回收器参数：</strong></p><p><img src="/posts/2320/assets/0ab38bc46cd9530bf692ea205e26757c.webp" alt="img"></p><p><strong>使用：配置在catalina.sh的脚本</strong></p><p><img src="/posts/2320/assets/ac69ae4d989337259f071c78559a266d.webp" alt="img"></p><h3 id="Tomcat调优"><a href="#Tomcat调优" class="headerlink" title="Tomcat调优"></a>Tomcat调优</h3><p>Tomcat优化从两个⽅⾯进⾏</p><p>1）JVM虚拟机优化（优化内存模型）</p><p>2）Tomcat⾃身配置的优化（⽐如是否使⽤了共享线程池？IO模型？）</p><p><strong>优化一调整线程池</strong></p><p><img src="/posts/2320/assets/c6a7877eaa145326ae23fb02807c1266.webp" alt="img"></p><p><strong>优化二调整tomcat的连接器：调整tomcat&#x2F;conf&#x2F;server.xml 中关于链接器的配置可以提升应⽤服务器的性能。</strong></p><p><img src="/posts/2320/assets/b7b7a9eec83d5f000ea2c775963fed3b.webp" alt="img"></p><p><strong>优化三禁用 AJP 连接器</strong></p><p><img src="https://pic2.zhimg.com/80/v2-00461d1c0704ebb062852639a0f3b97d_720w.webp" alt="img"></p><p><strong>优化四调整 IO 模式</strong></p><p>Tomcat8之前的版本默认使⽤BIO（阻塞式IO），对于每⼀个请求都要创建⼀个线程来处理，不适合⾼并发；Tomcat8以后的版本默认使⽤NIO模式（⾮阻塞式IO）</p><p><img src="/posts/2320/assets/2e3803931a16d4e5b980188d399a126f.webp" alt="img"></p><p>当Tomcat并发性能有较⾼要求或者出现瓶颈时，我们可以尝试使⽤APR模式，APR（Apache PortableRuntime）是从操作系统级别解决异步IO问题，使⽤时需要在操作系统上安装APR和Native（因为APR原理是使⽤使⽤JNI技术调⽤操作系统底层的IO接⼝）</p><p><strong>优化五动静分离</strong></p><p>可以使⽤Nginx+Tomcat相结合的部署⽅案，Nginx负责静态资源访问，Tomcat负责Jsp等动态资源访问处理（因为Tomcat不擅⻓处理静态资源）。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、-Tomcat系统架构和原理剖析&quot;&gt;&lt;a href=&quot;#一、-Tomcat系统架构和原理剖析&quot; class=&quot;headerlink&quot; title=&quot;一、 Tomcat系统架构和原理剖析&quot;&gt;&lt;/a&gt;一、 Tomcat系统架构和原理剖析&lt;/h2&gt;&lt;h3 id=&quot;浏</summary>
      
    
    
    
    <category term="基础知识" scheme="https://itingyu.github.io/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    <category term="tomcat" scheme="https://itingyu.github.io/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/tomcat/"/>
    
    
    <category term="基础知识" scheme="https://itingyu.github.io/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    <category term="tomcat" scheme="https://itingyu.github.io/tags/tomcat/"/>
    
  </entry>
  
  <entry>
    <title>集群模式相关知识</title>
    <link href="https://itingyu.github.io/posts/45764/"/>
    <id>https://itingyu.github.io/posts/45764/</id>
    <published>2023-06-17T10:53:29.000Z</published>
    <updated>2023-06-17T10:55:34.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、一致性Hash算法"><a href="#一、一致性Hash算法" class="headerlink" title="一、一致性Hash算法"></a>一、一致性Hash算法</h2><h3 id="分布式和集群"><a href="#分布式和集群" class="headerlink" title="分布式和集群"></a>分布式和集群</h3><p>分布式一定是集群，但是集群不一定是分布式，集群是多个实例一起工作，分布式是将一个系统拆分成多个，就是多个实例，而集群的满足条件不一定是系统拆分，也可以是复制，相同服务多部署，提高程序性能。</p><p><img src="https://pic3.zhimg.com/80/v2-8f1d0598d0f2c6d78a99a9310d5cb45e_720w.webp" alt="img"></p><p>理解：比如一个电商网站，里面的业务复杂，于是就进行了拆分，把每个模块拆成了一个个子系统，然后一起协调工作运行，这就是分布式，而集群呢，可以是另一种，当一个服务器已经不能满足访问要求的时候，我可以这个用户子系统，我复制部署在多个服务器，通过Nginx进行负载均衡，可以对用户请求进行分流，这就没有拆分系统，所以他只能是集群。</p><h3 id="Hash算法简介"><a href="#Hash算法简介" class="headerlink" title="Hash算法简介"></a>Hash算法简介</h3><p>Hash算法应用广泛，如加密算法MD5、SHA，数据储存和查找的Hash表等，而平常我们接触最多的就是Hash表，比如有一个数组，需要对他的数据进行查找，常用的一些查找法比如顺序查找、二分查找，如果是数据量大了，效率就非常低下，因此又有一种直接寻址法，把数组下标和值直接绑定在一起，通过下标来直接查找，但是如果两个值中间值差大，对空间又非常浪费；接着又有开放寻址法，对每一个数据进行取模，然后放入对应的下标中，但是如果是相同的取模值，就会产生hash冲突，他就把冲突值往前或后移，但是也有问题，无法扩展，长度为5的数组只能放5个值，因此数组加链表的Hash表就出现了，也就是我们常用的HashMap的设计结构。</p><p>数组：数组存储空间是连续的，占用内存严重，空间复杂度大，二分法时间复杂度小，查找容易，插入和删除困难。</p><p>链表：链表存储空间离散，占用内存比较宽松，空间复杂度小，时间复杂度大，查找困难，插入和删除简单。</p><p>Hash表又称为哈希表：由数组和链表构成，既满足了数据查找方便，又不用占用太多内存，通过key获取hashcode值，再取模的规则存储到数组中。Hashmap是一个线性数组实现，里面实现了一个静态内部类entry(键值对对象)，其重要属性有key、value、next，从属性key、value就可以看出来entry是hashmap键值对实现的一个继承bean(类)。这个线性数组被保存在entry[]中。</p><p><img src="https://pic2.zhimg.com/80/v2-d5fc9255b227cd28141e2c222251fee1_720w.webp" alt="img"></p><h3 id="Hash算法应用场景"><a href="#Hash算法应用场景" class="headerlink" title="Hash算法应用场景"></a>Hash算法应用场景</h3><p>Hash算法在分布式集群架构Redis、Hadoop、ElasticSearch，Mysql分库分表，Nginx负载均衡都有应用。</p><p>主要应用场景</p><p>1）请求的负载均衡（如Nginx的Ip_hash策略）</p><p>Nginx的Ip_hash策略可以在客户端ip不变的情况下，将其发出的请求始终路由到同⼀个⽬标服务器上，实现会话粘滞（会话保持），避免处理多服务器之间的session共享问题，</p><p>如果没有Ip_hash策略就需要自己维护一张映射表，存储客户端IP或者sessionid与具体目标服务器的映射关系。</p><p>缺点：</p><p>针对大体量级系统，客户端众多，这个映射表需要储存的数据就非常多，浪费内存空间。</p><p>客户端上下线，目标服务器上下线都会导致重新维护映射表，维护成本高。</p><p><img src="https://pic3.zhimg.com/80/v2-bdee8eeac3176add6174a1726916fcd6_720w.webp" alt="img"></p><p>如果使用hash算法，可以直接对ip地址或者sessionid进行计算哈希值，哈希值与服务器数量进行取模运算，得到的值就是当前请求应该被路由到的服务器编号，如此，一个客户端ip发送的请求就可以路由到同一个目标服务器，实现会话粘带。</p><p>2）分布式存储</p><p>以分布式内存数据库Redis为例,集群中有redis1，redis2，redis3 三台Redis服务器，在数据储存时，&lt;key,value&gt;数据，根据key进行hash处理，hash(key)%3&#x3D;index，使用余数来锁定存储的具体服务节点。</p><h3 id="一致性Hash算法"><a href="#一致性Hash算法" class="headerlink" title="一致性Hash算法"></a>一致性Hash算法</h3><p>普通hash算法存在一个问题，如果服务器宕机了，服务器的数量就会减少，之前的所有求模运算都将重新来，缩容和扩容也是一样的，大量用户的请求都将被重新分发，原来服务器会话都会丢失，因此诞生了一致性hash算法。</p><p><img src="https://pic3.zhimg.com/80/v2-c9b19735268cdd69b785a235cf37cc7a_720w.webp" alt="img"></p><p>一致性hash算法实现原理</p><p><img src="/posts/45764/assets/80fe252f8440877b5c711366d04f4510.webp" alt="img"></p><p>首先有一条直线，他的开头和结尾分别定为为0和2的32次⽅减1，对应IP地址的长度，服务器的IP地址是32位，所以是2^32-1次方的数值空间，对于这样⼀条线，弯过来构成⼀个圆环形成闭环，这样的⼀个圆环称为hash环。我们把服务器的ip或者主机名求hash值然后对应到hash环上，那么针对客户端⽤户，也根据它的ip进⾏hash求值，对应到环上某个位置。客户端路由服务器就按照顺时针找离他最近的服务器节点。</p><p><img src="/posts/45764/assets/80b00074f4541d37be6e88bec33e3a24.webp" alt="img"></p><p>如果某台服务器宕机或者需要进行扩容之类，客户端就按照顺时针接着往下顺延或者缩短定位最近服务器节点。</p><p><img src="https://pic3.zhimg.com/80/v2-7e8c1503450ff632a55d1e288d7a8b82_720w.webp" alt="img"></p><p><img src="https://pic4.zhimg.com/80/v2-c5c4014a81b335b35fd31993e6a3371b_720w.webp" alt="img"></p><p>每台服务器负责⼀段，⼀致性哈希算法对于节点的增减都只需重定位环空间中的⼀⼩部分数据，具有较好的容错性和可扩展性。但是，⼀致性哈希算法在服务节点太少时，容易因为节点分部不均匀⽽造成数据倾斜问题。例如系统中只有两台服务器，其环分布如下，节点2只能负责⾮常⼩的⼀段，⼤量的客户端请求落在了节点1上，这就是<strong>数据（请求）倾斜问题</strong></p><p>为了解决这种数据倾斜问题，⼀致性哈希算法引⼊了虚拟节点机制，即对每⼀个服务节点计算多个哈希，每个计算结果位置都放置⼀个此服务节点，称为虚拟节点。</p><p>具体实现：以在服务器ip或主机名的后面增加编号来实现。⽐如，可以为每台服务器计算三个虚拟节点，于是可以分别计算 “节点1的ip#1”、“节点1的ip#2”、“节点1的ip#3”、“节点2的ip#1”、“节点2的ip#2”、“节点2的ip#3”的哈希值，于是形成六个虚拟节点，当客户端被路由到虚拟节点的时候其实是被路由到该虚拟节点所对应的真实节点。</p><p><img src="/posts/45764/assets/604ce8e9a7e291121b77e264073c7172.webp" alt="img"></p><h3 id="手写三种一致性hash算法"><a href="#手写三种一致性hash算法" class="headerlink" title="手写三种一致性hash算法"></a>手写三种一致性hash算法</h3><p>普通hash算法实现</p><p><img src="/posts/45764/assets/b7106c145f555c3d2c1df8beff64975a.webp" alt="img"></p><p>一致性hash算法实现 不含虚拟节点</p><p><img src="https://pic3.zhimg.com/80/v2-c76785187cc1eeee70b36c31bd63cca2_720w.webp" alt="img"></p><p><img src="/posts/45764/assets/80e72d545366ff5f74f2959ff1f14b20.webp" alt="img"></p><p>一致性hash算法实现 含虚拟节点（就在前面的基础上引入虚拟节点就好了）</p><p><img src="/posts/45764/assets/85b990f630504a1a439ff53a4fdbb28f.webp" alt="img"></p><h3 id="Nginx配置一致性Hash负载均衡策略"><a href="#Nginx配置一致性Hash负载均衡策略" class="headerlink" title="Nginx配置一致性Hash负载均衡策略"></a>Nginx配置一致性Hash负载均衡策略</h3><p>ngx_http_upstream_consistent_hash 模块是⼀个负载均衡器，使⽤⼀个内部⼀致性hash算法来选择合适的后端节点。</p><p>1） github下载nginx⼀致性hash负载均衡模块 <a href="https://link.zhihu.com/?target=https://github.com/replay/ngx_http_consistent_hash">https://github.com/replay/ngx_http_consistent_hash</a></p><p>2） 将下载的压缩包上传到nginx服务器，并解压</p><p>3） 进⼊nginx的源码⽬录，顺序执⾏如下命令.&#x2F;configure —add-module&#x3D;&#x2F;root&#x2F;ngx_http_consistent_hash-master</p><p>è Make</p><p>è make install</p><p>4） Nginx就可以使⽤啦，在nginx.conf⽂件中配置</p><p><img src="https://pic3.zhimg.com/80/v2-b10a19847f5302777fc2563903222942_720w.webp" alt="img"></p><h2 id="二、集群时钟同步问题"><a href="#二、集群时钟同步问题" class="headerlink" title="二、集群时钟同步问题"></a>二、集群时钟同步问题</h2><h3 id="时钟不同步导致的问题"><a href="#时钟不同步导致的问题" class="headerlink" title="时钟不同步导致的问题"></a>时钟不同步导致的问题</h3><p>时钟此处指服务器时间，如果集群中各个服务器时钟不⼀致势必导致⼀系列问题。电商⽹站业务中，新增⼀条订单，那么势必会在订单表中增加了⼀条记录，该条记录中应该会有“下单时间”这样的字段，往往我们会在程序中获取当前系统时间插⼊到数据库或者直接从数据库服务器获取时间。那我们的订单子系统是集群部署，或者我们的数据库也是分库分表的集群部署，然⽽他们的系统时钟不⼀致，比如有⼀台服务器的时间是昨天，那么这个时候下单时间就成了昨天，那我们的数据将会混乱。</p><p><img src="https://pic3.zhimg.com/80/v2-01ed630f00d542e20d3b67107671aafe_720w.webp" alt="img"></p><h3 id="集群时钟同步配置"><a href="#集群时钟同步配置" class="headerlink" title="集群时钟同步配置"></a>集群时钟同步配置</h3><p>第一种：分布式集群中各个服务器节点都可以连接互联网直接通过互联网国家授时中心获取正确时间并制定定时计划，按时间计划进行刷新同步。</p><p><img src="/posts/45764/assets/9e15e6e18fe1aac695f912d84570afe6.webp" alt="img"></p><p>操作⽅式：</p><p><img src="/posts/45764/assets/53ccda2508e83713f5921724be51d64a.webp" alt="img"></p><p>第二种：只有一台服务器可以连接互联网或者所有服务器都不能连接互联网。</p><p>选取一台服务器作为时间服务器，整个集群时间从这台服务器同步，如果这台服务器能够访问互联⽹，可以让这台服务器和⽹络时间保持同步，如果不能就⼿动设置⼀个时间。</p><p><img src="/posts/45764/assets/19f982c487ed2e65da9da81056fd05ac.webp" alt="img"></p><p>实现步骤：</p><p>1）设置服务器的时间</p><p>2）把当前服务器设置为时间服务器（修改&#x2F;etc&#x2F;ntp.conf文件）</p><p><img src="/posts/45764/assets/f0e056c37cbdb7abf8a34a95b5ca4616.webp" alt="img"></p><p>3）集群中其他节点通过命令从A服务器同步时间</p><p><img src="/posts/45764/assets/1f711f3e3dac493b3c1a28b10390851f.webp" alt="img"></p><h2 id="三、分布式DI解决方案"><a href="#三、分布式DI解决方案" class="headerlink" title="三、分布式DI解决方案"></a>三、分布式DI解决方案</h2><h3 id="需求场景"><a href="#需求场景" class="headerlink" title="需求场景"></a>需求场景</h3><p>当单表已经不能满足数据储存要求的时候，就需要对单表进行分表，以Mysql为准，单表储存量最佳500万，超过性能就会慢慢下降，因此搭建Mysql集群进行分表就势在必行，而分表带来了一个无法回避的问题，多表之间数据的唯一序列号该如何处理。</p><p><img src="/posts/45764/assets/576250bec0c5c044b4326c5d8715d829.webp" alt="img"></p><h3 id="UUID解决方案"><a href="#UUID解决方案" class="headerlink" title="UUID解决方案"></a>UUID解决方案</h3><p>UUID 是指Universally Unique Identifier，翻译为中文是通⽤唯⼀识别码，他的生成规则客户端地址+时间戳+一个随机数，重复的概率是非常低的，不过他有一个缺点，没有规律，作为主键建立索引的话，查询效率不高。</p><p><img src="https://pic3.zhimg.com/80/v2-c1b4f7a56c281059b9300da149a3538a_720w.webp" alt="img"></p><h3 id="独立数据库的自增ID解决方案"><a href="#独立数据库的自增ID解决方案" class="headerlink" title="独立数据库的自增ID解决方案"></a>独立数据库的自增ID解决方案</h3><p>创建⼀个Mysql数据库，在这个数据库中创建⼀张表，这张表的ID设置为⾃增，其他地⽅需要全局唯⼀ID的时候，就模拟向这个Mysql数据库的这张表中模拟插⼊⼀条记录，此时ID会⾃增，然后我们可以通过Mysql的select last_insert_id() 获取到刚刚这张表中⾃增⽣成的ID。</p><p><img src="/posts/45764/assets/88174b749d16f77bc0a20aab3685a7b7.webp" alt="img"></p><p>缺点：性能和可靠性都不够好，因为你需要代码连接到数据库才能获取到id，性能⽆法保障，另外mysql数据库实例挂掉了，那么就⽆法获取分布式id了。</p><h3 id="SnowFlake-雪花算法解决方案"><a href="#SnowFlake-雪花算法解决方案" class="headerlink" title="SnowFlake 雪花算法解决方案"></a>SnowFlake 雪花算法解决方案</h3><p>雪花算法是Twitter（推特）推出的⼀个⽤于⽣成分布式ID的策略。</p><p>雪花算法是⼀个算法，基于这个算法可以⽣成ID，⽣成的ID是⼀个long型，那么在Java中⼀个long型是8个字节，算下来是64bit，由符号位加时间戳（毫秒级）加机器id最后拼接一个随机序列号（一毫秒产生四千多个不重复得序列号，）生成，换算成秒也就是一秒内能产生四百万个不重复id，而且在一台机子上可以运行七十多年生成不重复得ID，可靠性非常高。</p><p><img src="https://pic4.zhimg.com/80/v2-42e7c3322b15345e23f0614cbeb9626b_720w.webp" alt="img"></p><p>雪花算法原理理解：机器ID给了10位，而在实现得时候，拆分成了两部分，一部分集群编号占5位，另一部分集群机器编号占5位，组合起来拼接成完整的机器ID，接着获取当前得时间戳，如果获取当前时间戳小于上次时间戳，违背雪花算法核心原则，直接抛出异常，不能生成ID。如果当前时间戳等于当前时间戳，就代表当前请求还在同一毫秒内，进入同一毫秒生成规则，但是里面有一个限制，一毫秒内最大生成唯一ID数量是4095，进行位与运算判断，如果超了4095边界，就等待，里面有一个方法在疯狂刷新时间戳，当下个时间戳到来，取下一毫秒的时间戳来生成唯一ID，这一毫秒又可以生成4095个唯一ID.</p><p><img src="/posts/45764/assets/c60135385d414859196fd4174fec4c71.webp" alt="img"></p><p><img src="https://pic2.zhimg.com/80/v2-3aaed5ac88afbd765b43e06b0f15fae1_720w.webp" alt="img"></p><h3 id="Redis的Incr命令获取全局唯⼀ID解决方案"><a href="#Redis的Incr命令获取全局唯⼀ID解决方案" class="headerlink" title="Redis的Incr命令获取全局唯⼀ID解决方案"></a>Redis的Incr命令获取全局唯⼀ID解决方案</h3><p>Redis Incr 命令将 key 中储存的数字值增⼀。如果 key 不存在，那么 key 的值会先被初始化为 0，然后再执⾏ INCR 操作。</p><p><img src="/posts/45764/assets/64862b3a056cf515007d4ea7e8e88869.webp" alt="img"></p><p>Redis安装</p><p>1）官⽹下载redis-3.2.10.tar.gz <a href="https://link.zhihu.com/?target=http://download.redis.io/releases/redis-3.2.10.tar.gz">http://download.redis.io/releases/redis-3.2.10.tar.gz</a></p><p>2）上传到linux服务器解压 tar -zxvf redis-3.2.10.tar.gz</p><p>3）cd 解压⽂件⽬录，对解压的redis进⾏编译</p><p>4）make</p><p>5）然后cd 进⼊src⽬录，执⾏make install</p><p>6）修改解压⽬录中的配置⽂件redis.conf，关掉保护模式</p><p><img src="/posts/45764/assets/13152d1b46bf7ff44ca2e4e8a0112261.webp" alt="img"></p><p><img src="https://pic2.zhimg.com/80/v2-f33c5a6b5b3b47facce30ac24e83088d_720w.webp" alt="img"></p><p>7）在src⽬录下执⾏ .&#x2F;redis-server ..&#x2F;redis.conf 启动redis服务</p><p><img src="/posts/45764/assets/9470aec670fd673e1257d4dcfa11a8ae.webp" alt="img"></p><h2 id="四、分布式调度问题解决方案"><a href="#四、分布式调度问题解决方案" class="headerlink" title="四、分布式调度问题解决方案"></a>四、分布式调度问题解决方案</h2><h3 id="定时任务的场景"><a href="#定时任务的场景" class="headerlink" title="定时任务的场景"></a>定时任务的场景</h3><p>调度—&gt;定时任务，分布式调度—&gt;在分布式集群环境下定时任务</p><p>定时任务就是每隔一段时间或者特定时间执行</p><p>比如：订单审核、物流信息推送、日志监控、定时备份数据、报表数据分析、数据积压检测等等</p><h3 id="分布式调度"><a href="#分布式调度" class="headerlink" title="分布式调度"></a>分布式调度</h3><p>1） 运行在分布式集群环境下的调度任务（多个实例同时运行，但是同一时间只有一个实例生效，比如统计报表定时任务多实例部署，调用的时候只需要一个就行了，另外一个相当于备用）</p><p>2） 分布式调度-&gt;进行任务的分布式-&gt;定时任务拆分（比如我一个单体应用有很多定时任务，我对他进行拆分，为了提高性能，进行集群部署，比如拆分出来的统计报表定时任务，数据备份定时任务等等，执行的时候应该是一起执行，而不是一个个执行）</p><p><img src="https://pic4.zhimg.com/80/v2-da2c24ba09e41234f3468d02f9425c17_720w.webp" alt="img"></p><h3 id="定时任务与消息队列的区别"><a href="#定时任务与消息队列的区别" class="headerlink" title="定时任务与消息队列的区别"></a>定时任务与消息队列的区别</h3><p><strong>共同点</strong></p><p>1）异步处理：比如注册、下单事件，比如下单完成后台只是做了一个标记，并不是同步就完成了整个订单的处理流程，你看到的订单完成只是显示的一个标记状态，如果是消息队列，后台就按消息顺序处理这些订单，而定时任务的话，就按间隔时间去扫描订单表，获取标记进行订单处理。</p><p>2）应用解耦：定时任务和MQ都可以作为两个应用之间的齿轮实现应用解耦，比如两个系统需要数据交互，就可以通过mq当做中转；定时任务的话，就是把数据存储到一张中间表，进行定时扫描获取数据。</p><p>3）流量削峰：双十一的时候，流量很大，定时任务作业和MQ都可以用来扛流量，如果直接全部发送到后台，后台是处理不过来的，会直接崩掉，有了他们，后台就可以根据服务能力定时处理订单或者从MQ抓取订单事件触发处理，而前端用户看到的结果是下单成功。</p><p><strong>本质不同</strong></p><p>定时任务是时间驱动，消息队列是事件驱动</p><p>时间驱动不可代替，比如金融系统每日利息结算，不是利息到来事件就算一下，而是批量处理，所以定时任务作业更倾向于批量处理，MQ倾向于逐条处理。</p><h3 id="定时任务Quartz实现方式"><a href="#定时任务Quartz实现方式" class="headerlink" title="定时任务Quartz实现方式"></a>定时任务Quartz实现方式</h3><p>定时任务的实现⽅式有多种。早期没有定时任务框架的时候，我们会使⽤JDK中的Timer机制和多线程机制（Runnable+线程休眠）来实现定时或者间隔⼀段时间执⾏某⼀段程序；后来有了定时任务框架，⽐如Quartz任务调度框架，使⽤时间表达式（包括：秒、分、时、⽇、周、年）配置某⼀个任务什么时间去执⾏。</p><p>引入Quartz的jar包</p><p><img src="/posts/45764/assets/a3c5ae263770ad1c893e05192f1747d6.webp" alt="img"></p><p>编写定时任务作业主调度程序分为四步：</p><p>1）创建任务调度器 如公交调度站</p><p><img src="https://pic3.zhimg.com/80/v2-1d0c517391da7f45fcf1499a42794d0a_720w.webp" alt="img"></p><p>2）创建一个任务 如公交车出行</p><p><img src="/posts/45764/assets/304db9ca5d08a1e36c4cdf03d49dd360.webp" alt="img"></p><p><img src="https://pic2.zhimg.com/80/v2-82bd804deb650dd5596608a1e66663b1_720w.webp" alt="img"></p><p>3）创建任务的时间触发器 如公交车出行时间表</p><p><img src="/posts/45764/assets/9949e6119df4353fdf2aad686fb191fe.webp" alt="img"></p><p>cron表达式由七个位置组成，空格分隔</p><p>* 1、Seconds（秒） 0~59</p><p>* 2、Minutes（分） 0~59</p><p>* 3、Hours（⼩时） 0~23</p><p>* 4、Day of Month（天）1~31,注意有的⽉份不⾜31天</p><p>* 5、Month（⽉） 0~11,或者JAN,FEB,MAR,APR,MAY,JUN,JUL,AUG,SEP,OCT,NOV,DEC</p><p>* 6、Day of Week(周) 1~7,1&#x3D;SUN或者 SUN,MON,TUE,WEB,THU,FRI,SAT</p><p>* 7、Year（年）1970~2099 可选项</p><p>4）使用任务调度器根据时间触发器执行我们的任务</p><p><img src="https://pic2.zhimg.com/80/v2-a20d5e62780ba0e9d8583d61746b51f9_720w.webp" alt="img"></p><h3 id="Elastic-Job简介"><a href="#Elastic-Job简介" class="headerlink" title="Elastic-Job简介"></a>Elastic-Job简介</h3><p>Elastic-Job是当当⽹开源的⼀个分布式调度解决⽅案，基于Quartz⼆次开发的，由两个相互独⽴的⼦项⽬Elastic-Job-Lite和Elastic-Job-Cloud组成，Elastic-Job-Lite，它定位为轻量级⽆中⼼化解决⽅案，使⽤Jar包的形式提供分布式任务的协调服务，⽽Elastic-Job-Cloud⼦项⽬需要结合Mesos以及Docker在云环境下使⽤。</p><p>主要功能：</p><p>1）分布式调度协调：在分布式环境中，任务能够按指定的调度策略执⾏，并且能够避免同⼀任务多实例重复执⾏。</p><p>2）丰富的调度策略：基于成熟的定时任务作业框架Quartz cron表达式执⾏定时任务</p><p>3）弹性扩容缩容：当集群中增加某⼀个实例，它应当也能够被选举并执⾏任务；当集群减少⼀个实例时，它所执⾏的任务能被转移到别的实例来执⾏。</p><p>4）失效转移：某实例在任务执⾏失败后，会被转移到其他实例执⾏</p><p>5）错过执⾏作业重触发：若因某种原因导致作业错过执⾏，⾃动记录错过执⾏的作业，并在上次作业完成后⾃动触发。</p><p>6）⽀持并⾏调度：⽀持任务分⽚，任务分⽚是指将⼀个任务分为多个⼩任务项在多个实例同时执⾏。</p><p>7）作业分⽚⼀致性：当任务被分⽚后，保证同⼀分⽚在分布式环境中仅⼀个执⾏实例。</p><h3 id="安装Zookeeper"><a href="#安装Zookeeper" class="headerlink" title="安装Zookeeper"></a>安装Zookeeper</h3><p>Elastic-Job依赖于Zookeeper进⾏分布式协调，Zookeeper的本质功能：存储+通知。</p><p>1）我们使⽤3.4.10版本，在linux平台解压下载的zookeeper-3.4.10.tar.gz</p><p>2）进⼊conf⽬录，cp zoo_sample.cfg zoo.cfg</p><p>3）修改目录地址dataDir&#x3D;&#x2F;usr&#x2F;local&#x2F;zookeeper-3.4.10&#x2F;data</p><ol start="4"><li>进⼊bin⽬录，启动zk服务</li></ol><p>启动 .&#x2F;zkServer.sh start</p><p>停⽌ .&#x2F;zkServer.sh stop</p><p>查看状态 .&#x2F;zkServer.sh status</p><p><img src="/posts/45764/assets/99161a2920bc009e5ff34ee4317a44f1.webp" alt="img"></p><h3 id="Elastic-job应用"><a href="#Elastic-job应用" class="headerlink" title="Elastic-job应用"></a>Elastic-job应用</h3><p>需求：每隔两秒钟执⾏⼀次定时任务（resume表中未归档的数据归档到resume_bak表中，每次归档1条记录）</p><p>1） 定义定时任务业务逻辑处理类ArchivieJob实现SimpleJob接口，重写execute方法，封装核心逻辑</p><p><img src="/posts/45764/assets/556ba8cfd4bd13428e08292ce5f59f50.webp" alt="img"></p><p>2）配置注册中心，连接云主机上的zookeeper，进行任务配置（时间事件10秒执行、调用定时任务逻辑处理类、任务调度器开启任务）</p><p><img src="/posts/45764/assets/0de39d1cb286b09dba849bd14e9fa95c.webp" alt="img"></p><p>3）测试结果，每隔十秒执行一次逻辑处理，完成单例定时任务执行。如果多个应用启动，多个实例同时创建一个leader节点，谁创建了谁就是领导者，其他就不能创建了，而当前领导者就负责执行对应实例定时任务，另外的相当于备份，当集群服务扩容或者缩减，zookeeper的领导者leader会重新选举，找出新的执行者。</p><p><img src="https://pic4.zhimg.com/80/v2-675a15c9b4401a525f9b713e9741009b_720w.webp" alt="img"></p><h3 id="Elastic-job轻量级和去中⼼化"><a href="#Elastic-job轻量级和去中⼼化" class="headerlink" title="Elastic-job轻量级和去中⼼化"></a>Elastic-job轻量级和去中⼼化</h3><p>轻量级：</p><p>不需要引入或安装其他服务或者组件，把jar包引入调用即可。</p><p>不需要独立部署，就是一个jar程序。</p><p>去中心化：</p><p>执行节点对等。</p><p>定时调度自触发，不需要中心节点分配，谁该执行什么任务等等。</p><p>服务自发现，通过注册中心服务发现。</p><p>主节点非固定，通过leader选举产生。</p><p><img src="https://pic2.zhimg.com/80/v2-18c41d9459623532de69643913485d3d_720w.webp" alt="img"></p><h3 id="Elastic-job任务分片及扩容"><a href="#Elastic-job任务分片及扩容" class="headerlink" title="Elastic-job任务分片及扩容"></a>Elastic-job任务分片及扩容</h3><p>ElasticJob可以把作业分为多个的task（每⼀个task就是⼀个任务分⽚），每⼀个task交给具体的⼀个机器实例去处理（⼀个机器实例是可以处理多个task的），但是具体每个task执⾏什么逻辑由我们⾃⼰来指定，比如把批量处理的数据按类型分开，然后多个实例各自执行不同类型的数据，提高并发处理效率。</p><p><img src="https://pic3.zhimg.com/80/v2-4d1c6fb313edbc5452e6f8af2470cc16_720w.webp" alt="img"></p><p>设置3个分片，设置3个分片对应逻辑参数</p><p><img src="/posts/45764/assets/e1d2096b049a567e1538cc4f550580c6.webp" alt="img"></p><p>获取参数，在业务逻辑类进行处理</p><p><img src="https://pic4.zhimg.com/80/v2-c4128f5582cda72b419946a006cbaf53_720w.webp" alt="img"></p><p><strong>扩容：</strong></p><p>新增加⼀个运⾏实例，它会⾃动注册到注册中⼼，注册中⼼发现新的服务上线，注册中⼼会通知ElasticJob 进⾏重新分⽚，总分⽚项有多少，就可以搞多少个实例机器。</p><p>1）分⽚项也是⼀个JOB配置，修改配置，重新分⽚，在下⼀次定时运⾏之前会重新调⽤分⽚算法，那么这个分⽚算法的结果就是：哪台机器运⾏哪⼀个分⽚，这个结果存储到zk中的，主节点会把分⽚给分好放到注册中⼼去，然后执⾏节点从注册中⼼获取信息(执⾏节点在定时任务开启的时候获取相应的分⽚)。</p><p>2）如果所有节点挂掉只剩下⼀个节点时，所有分⽚都会指向剩下的⼀个节点，这就是ElasticJob的⾼可⽤。</p><h2 id="五、Session共享问题"><a href="#五、Session共享问题" class="headerlink" title="五、Session共享问题"></a>五、Session共享问题</h2><h3 id="Session问题原因分析"><a href="#Session问题原因分析" class="headerlink" title="Session问题原因分析"></a>Session问题原因分析</h3><p>Session共享及Session保持或者叫做Session⼀致性</p><p>http协议是无状态的协议，而页面具有动态的内容，就需要有状态，保持http状态的技术就是cookie和session，但是客户端和服务器又不会把会话数据保留，因此当nginx进行集群tomcat登录请求的时候，由于nginx的轮询策略，就会产生第一次登录请求分发到第一台tomcat服务器，登录成功，当前服务器session保存了当前登录信息，第二次请求来了，获取业务数据，跳转数据列表，对页面渲染，但是第二次缺请求到了第二台服务器，而第二台服务器是没得session的，于是又重定向到了登录界面。</p><p><img src="/posts/45764/assets/6c8768104405205c82c4190ce3561471.webp" alt="img"></p><p><img src="/posts/45764/assets/8db622412d2e87d459f34e2a12224998.webp" alt="img"></p><h3 id="解决Session⼀致性的⽅案"><a href="#解决Session⼀致性的⽅案" class="headerlink" title="解决Session⼀致性的⽅案"></a>解决Session⼀致性的⽅案</h3><p><strong>Nginx的 IP_Hash 策略</strong></p><p>前面Nginx有讲述，同一个客户端的IP的请求都会被路由到同一个目标服务器，也叫会话保持。</p><p>优点：</p><p>配置简单，不⼊侵应⽤，不需要额外修改代码</p><p>缺点：</p><p>服务器重启Session丢失</p><p>存在单点负载⾼的⻛险</p><p>单点故障问题</p><p><strong>Session复制</strong></p><p><img src="/posts/45764/assets/ecb2559801fefd3e6859f8aa0faa3014.webp" alt="img"></p><p>优点：</p><p>不侵入应用</p><p>便于服务器水平扩展</p><p>能适应各种负载均衡策略</p><p>服务器重启或者宕机不会造成session丢失</p><p>缺点：</p><p>性能低</p><p>内存消耗</p><p>不能存储太多数据，数据越多性能越低</p><p>延迟性</p><p><strong>Session共享，Session集中储存</strong></p><p><img src="/posts/45764/assets/3ad49724208e579fa8f2e7442a6304b7.webp" alt="img"></p><p>优点</p><p>能适应各种负载均衡策略</p><p>服务器重启或者宕机不会造成session丢失</p><p>扩展能力强</p><p>适合大集群数量使用</p><p>缺点</p><p>对应用有入侵，引入了和Redis的交互代码</p><p><img src="https://pic2.zhimg.com/80/v2-d03322ded558347c9b3c5fdf83129d7d_720w.webp" alt="img"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、一致性Hash算法&quot;&gt;&lt;a href=&quot;#一、一致性Hash算法&quot; class=&quot;headerlink&quot; title=&quot;一、一致性Hash算法&quot;&gt;&lt;/a&gt;一、一致性Hash算法&lt;/h2&gt;&lt;h3 id=&quot;分布式和集群&quot;&gt;&lt;a href=&quot;#分布式和集群&quot; cla</summary>
      
    
    
    
    <category term="基础知识" scheme="https://itingyu.github.io/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    <category term="集群模式知识总结" scheme="https://itingyu.github.io/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="基础知识" scheme="https://itingyu.github.io/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    <category term="集群模式知识总结" scheme="https://itingyu.github.io/tags/%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>分布式架构知识总结</title>
    <link href="https://itingyu.github.io/posts/8228/"/>
    <id>https://itingyu.github.io/posts/8228/</id>
    <published>2023-06-17T10:50:55.000Z</published>
    <updated>2023-06-17T10:52:47.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、分布式理论"><a href="#一、分布式理论" class="headerlink" title="一、分布式理论"></a>一、分布式理论</h2><h3 id="分布式系统概念和存在的问题"><a href="#分布式系统概念和存在的问题" class="headerlink" title="分布式系统概念和存在的问题"></a>分布式系统概念和存在的问题</h3><p>分布式系统，就是一个业务拆分成多个子业务，分布在不同的服务器节点，共同构成的系统称为分布式系统。</p><p>集群：多个人在一起作同样的事。</p><p>分布式：多个人在一起作不同的事。</p><p><img src="https://pic2.zhimg.com/80/v2-825769041326e65e785019cfb3ef0f79_720w.webp" alt="img"></p><p>特点：分布性、对等性、并发性、缺乏全局时钟、故障总数会发生</p><p><img src="/posts/8228/assets/17d252b2506be21c0448b64f4100851b.webp" alt="img"></p><p><strong>分布式系统存在的问题</strong></p><p>通信异常：网络不确定性导致分布式系统无法顺利进行一次网络通信</p><p>网络分区：整个系统网络被切分，导致分布式系统出现局部小集群，小集群要完成整个分布式系统的功能。</p><p>节点故障：组成分布式系统的某个服务器出现宕机</p><p>三态：每次请求都存在的三种状态，失败、成功、超时。超时通常是发送过程中丢失或者响应过程中丢失。</p><h3 id="分布式理论：一致性"><a href="#分布式理论：一致性" class="headerlink" title="分布式理论：一致性"></a>分布式理论：一致性</h3><p>数据在多份副本中存储时，各副本中的数据是一致的。</p><p>数据的ACID四原则：原子性、一致性、隔离性、持续性。</p><p><strong>一致性分类</strong></p><p>强一致性：要求系统写入什么，读出来的也会是什么，对系统性能影响最大，难实现。</p><p>弱一致性：约束了系统在写入成功后，不承诺立即可以读到写入的值，也不承诺多久之后数据能够达到一致， 但会尽可能地保证到某个时间级别（比如秒级别）后，数据能够达到一致状态。</p><p><img src="https://pic3.zhimg.com/80/v2-c9a718da2208703fb9aba49e76a3aeea_720w.webp" alt="img"></p><p>弱一致性之读写一致性：用户读取自己写入结果的一致性，保证用户永远能够第一时间看到自己更新的内容，也就是写到了主库，但是读却走了从库，导致读写可能不一致，通过设定时间戳，让更新后一段时间都从主库读来实现。</p><p>弱一致性之单调读一致性：本次读到的数据不能比上次读到的旧，也就是第一次读主库最新值，第二次读从库还是旧值，通过根据用户ID计算一个hash值，再通过hash值映射到机器，让用户每次都访问一台机子来实现。</p><p>弱一致性之因果一致性：节点 A 在更新完某个数据后通知了节点 B，那么节点 B 之后对该数据的访问和修改都是基于 A 更新后的值。</p><p>弱一致性之最终一致性：最弱一致性模型，不考虑所有的中间状态的影响，只保证当没有新的更新之后，经过一段时间之后，最终系统内所有副本的数据是正确的。它最大程度上保证了系统的并发能力，在高并发的场景下，它也是使用最广的一致性模型。</p><h3 id="分布式理论：CAP定理"><a href="#分布式理论：CAP定理" class="headerlink" title="分布式理论：CAP定理"></a>分布式理论：CAP定理</h3><p>一个分布式系统不可能同时满足一致性（C:Consistency)，可用性（A: Availability）和分区容错性（P：Partition tolerance）这三个基本需求，最多只能同时满足其中的2个。</p><p><img src="https://pic4.zhimg.com/80/v2-fb12a3fafa88ab9bc0fef88938019b5f_720w.webp" alt="img"></p><p><img src="https://pic2.zhimg.com/80/v2-5493bff9d6f30e539d3949fd45a7a87d_720w.webp" alt="img"></p><p><strong>一致性</strong></p><p>目标：</p><p>1.商品服务写入主数据库成功, 则想从数据库查询数据也成功</p><p>2.商品服务写入主数据库失败,则向从数据库查询也失败</p><p>实现：</p><p>1.写入主数据库后要数据同步到从数据库，同步有一定延迟。</p><p>2.写入主数据库后,在向从数据库同步期间要将从数据库锁定, 等待同步完成后在释放锁,以免在写新数据后,向从数据库查询到旧的数据。</p><p><strong>可用性</strong></p><p>目标：</p><p>1.从数据库接收到数据库查询的请求则立即能够响应数据查询结果</p><p>2.从数据库不允许出现响应超时或错误</p><p>实现：</p><p>1.写入主数据库后要将数据同步到从数据</p><p>2.由于要保证数据库的可用性,不可以将数据库中资源锁定</p><p>3.即使数据还没有同步过来,从数据库也要返回查询数据, 哪怕是旧数据,但不能返回错误和超时.</p><p><strong>分区容错性</strong></p><p>目标：</p><p>1.主数据库想从数据库同步数据失败不影响写操作</p><p>2.其中一个节点挂掉不会影响另一个节点对外提供服务</p><p>实现：</p><p>1.尽量使用异步取代同步操作,如使用异步方式将数据从主数据库同步到从数据库, 这样节点之间能有效的实现松 耦合;</p><p>2.添加数据库节点,其中一个从节点挂掉,由其他从节点提供服务。</p><p><img src="https://pic2.zhimg.com/80/v2-7e8a4c084879e9ee10f8477fb3420ff9_720w.webp" alt="img"></p><h3 id="分布式理论：BASE理论"><a href="#分布式理论：BASE理论" class="headerlink" title="分布式理论：BASE理论"></a>分布式理论：BASE理论</h3><p>BASE：全称：Basically Available(基本可用)，Soft state（软状态）,和 Eventually consistent（最终一致性）</p><p>对CAP中一致性和可用性权衡的结果，即无法做到强一致性，但每个应用都可以根据自身业务特点，采用适当的方式来使系统达到最终一致性。</p><p>Basically Available(基本可用)：</p><p>分布式系统在出现不可预知故障的时候，允许损失部分可用性，比如12306抢票，他给你延时查询，响应非常久，又比如双十一抢购，订单付款时内部出现某种错误，网页这边提示你数据加载失败，让你重试，即不失败也不成果，进入降级处理。</p><p>Soft state（软状态）：允许系统中的数据存在中间状态，并认为该状态不影响系统的整体可用性，即允许系统在多个不同节点的数据副本之间进行数据同步的过程中存在延迟。</p><p>Eventually consistent（最终一致性）：最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性。</p><h3 id="分布式理论：一致性协议2PC"><a href="#分布式理论：一致性协议2PC" class="headerlink" title="分布式理论：一致性协议2PC"></a>分布式理论：一致性协议2PC</h3><p>两阶段提交协议，是将整个事务流程分为两个阶段，准备阶段（Preparephase）、提交阶段（commit phase），2是指两个阶段，P是指准备阶段，C是指提交阶段。</p><p>准备阶段（Prepare phase）：</p><p>事务管理器给每个参与者发送Prepare消息，每个数据库参与者在本地执行事务，并写本地的Undo&#x2F;Redo日志，此时事务没有提交。（Undo日志是记录修改前的数据，用于数据库回滚， Redo日志是记录修改后的数据，用于提交事务后写入数据文件）</p><p>提交阶段（commit phase）：</p><p>如果事务管理器收到了参与者的执行失败或者超时消息时，直接给每个参与者发送回滚(Rollback)消息；否则，发送提交(Commit)消息；参与者根据事务管理器的指令执行提交或者回滚操作，并释放事务处理过程中使用的锁资源。</p><p><img src="https://pic2.zhimg.com/80/v2-a2fe571e0d5960121295a0aa87676e89_720w.webp" alt="img"></p><p><strong>缺点</strong></p><p>同步阻塞：他需要等第一阶段所有节点全部完成之后才能执行第二阶段。</p><p>单点问题：严重依赖于事务管理协调者，一旦协调者出现问题导致整个流程无法完成。</p><p>数据不一致：第二阶段事务管理器逐个向资源节点发生提交请求，当发送到一半，事务管理器宕机了，前面的资源节点会提交，后面的回滚，导致数据不一致。而且当资源节点出现问题无法向协调者发送响应信息，事务管理者只能依赖超时机制进行事务中断。</p><h3 id="分布式理论：一致性协议3PC"><a href="#分布式理论：一致性协议3PC" class="headerlink" title="分布式理论：一致性协议3PC"></a>分布式理论：一致性协议3PC</h3><p>将 2PC 的提交阶段过程一分为三，形成了由 CanCommit、PreCommit和doCommit三个阶段组成的事务处理协议。</p><p><img src="/posts/8228/assets/cf14e333d87432fc903682fc4859957e.webp" alt="img"></p><p>CanCommit：协调者给参与者发送事务响应等待全部回应。</p><p>PreCommit：协调者收到全部参与者响应，yes发送执行事务预提交，并反馈ACK，如果有一个参与者未反馈或者反馈no，中断事务。</p><p>doCommit：协调者收到所有参数值ACK反馈，向所有参与者发送提交指令，参与者完成之后向协调者发送ACK响应，但是有一个问题，也就是进入第三阶段，如果协调者因宕机等原因没有向参与者发送提交doCommit请求或回滚abort请求，参与者到达超时时间自动提交，也就是如果是要准备回滚的话，就出现了问题。</p><p><strong>2PC对比3PC</strong></p><p>1） 协调者和参与者都设置了超时机制，降低了整个事务的阻塞时间和范围，解决了之前的同步阻塞。</p><p>2） 通过CanCommit、PreCommit、DoCommit三个阶段的设计，相较 于2PC而言，多设置了一个缓冲阶段保证了在最后提交阶段之前各参与节点的状态是一致的。</p><p>3） 3PC协议并没有完全解决数据不一致问题。</p><h3 id="分布式理论：一致性算法Paxos"><a href="#分布式理论：一致性算法Paxos" class="headerlink" title="分布式理论：一致性算法Paxos"></a>分布式理论：一致性算法Paxos</h3><p>此算法用于解决分布式系统一致性问题。</p><p><img src="https://pic2.zhimg.com/80/v2-75228427b192b012289ab4266f6f0cf9_720w.webp" alt="img"></p><p>当出现多个参与者，要保证数据事务一致性，就引入了3PC进行协调，协调者也可能宕机，所以协调者也做了集群，当每个参与者发送了不同的指令给协调者，协调者就必须有一个真正的决策者来保证数据的一致性。</p><p><strong>提案（Proposal）</strong></p><p>提案 (Proposal)：Proposal信息包括提案编号 (Proposal ID) 和提议的值 (Value)，最终要达成一致的value就在提案里。</p><p><strong>Paxos算法的角色</strong></p><p>Client：客户端向分布式系统发出请求 ，并等待响应。</p><p>Proposer：提案发起者提倡客户请求，试图说服Acceptor对此达成一致，并在发生冲突时充当协调者以推动协议向前发展。</p><p>Acceptor：决策者可以接受（accept）提案；如果某个提案被选定（chosen），那么该提案里的value就被选定了。</p><p>Learners：最终决策学习者充当该协议的复制因素。</p><p><strong>一致性算法的保证</strong></p><p>1）在这些被提出的提案中，只有一个会被选定 。</p><p>2）如果没有提案被提出，就不应该有被选定的提案。</p><p>3）当一个提案被选定后，那么所有进程都应该能学习（learn）到这个被选定的value。</p><p><strong>Paxos算法提案规则</strong></p><p><img src="/posts/8228/assets/a713bcc972f3dab5210a8abd9c0d0027.webp" alt="img"></p><p>总结：提案规则P2c &#x3D;&gt;P2b&#x3D;&gt;P2a&#x3D;&gt;P2，通过P2和P1来保证一致性，概括就是决策者必须接受收到的第一个提案，当只有一个决策者，那么第一个提案就是最终提案，当多个决策者，以半数以上决策者接收的提案为最终提案，当决策者选定了一个提案，后续提案只能增长序列编号，不能更改提案的值。</p><p><strong>Proposer生成提案规则-&gt;Acceptor接受提案规则</strong></p><p>Proposer生成提案之前，应该先去『学习』已经被选定或者可能被选定的value，然后以 该value作为自己提出的提案的value。如果没有value被选定，Proposer才可以自己决定value的值。</p><p><img src="/posts/8228/assets/62ec5a19727a9ce3880ca0dfbeb03823.webp" alt="img"></p><p>理解：提案者1先发送一个prepare给决策者，并携带一个map，这个map只有key，编号n，value是null，当决策者接受了这个提案，就把当做了最终提案保存了下来，并返回了一个空value回来，这里有一个规则，如果决策者是多个，需要超过半数返回才行，如果没有超过半数，重新提交prepare给决策者，接着提案者1再往map里面放入值，提交给决策者，决策者就把这个map替换了之前的空null的map，并返回ack，如果超过半数返回了ack，此value就被确定，否则重新提交prepare给决策者，当完成后如果又有另一个提案者2提交了提案，他的编号是n+1，决策者接收了，但是决策者已经有最终提案了，这时候他会把value返回给提案者2，让提案者2学习，把自己map集合的value值替换成决策者返回的值，提案者学习完毕，再次提交，这时候决策者就接受了提案者2的提案，把之前的提案进行了替换，而且编号低于n+1的提案会被决策者直接拒绝，这样值没变，保证了数据的一致性，还可以通过编号实现对不符合规则的提案过滤。</p><p><img src="/posts/8228/assets/d370978be464f7cf8a32327443a9ea37.webp" alt="img"></p><p><strong>Learner学习被选定的value</strong></p><p>当决策者接受了一个提案，就会把这个提案发给所有学习者，来保证数据一致性。</p><p><img src="https://pic4.zhimg.com/80/v2-82dd45dd395ea215e2eebfd003a41c7f_720w.webp" alt="img"></p><p><strong>保证Paxos算法的活性</strong></p><p>两个Proposer依次提出了一系列编号递增的提案，但是每次根据响应塞值提交又因为编号不一致，被另一个提案者编号给递增，导致又恢复到最开始提交prepare，最终陷入死循环，没有value被选定。</p><p>解决：通过选取主Proposer，并规定只有主Proposer才能提出议案。这样一来只要主Proposer和过半的Acceptor能够正常进行网络通信，那么只能是主Proposer提出一个编号更高的提案，该提案终将会被批准，这样通过选择一个主 Proposer，整套Paxos算法就能够保持活性。</p><h3 id="分布式理论：一致性算法Raft"><a href="#分布式理论：一致性算法Raft" class="headerlink" title="分布式理论：一致性算法Raft"></a>分布式理论：一致性算法Raft</h3><p>Raft算法分为两个阶段，首先是选举过程，然后在选举出来的领导人带领进行正常操作，主要用于管理复制日志的一致性算法。</p><p>Raft算法三模块：领导人选举、日志复制、安全性。</p><p><strong>领导人Leader选举</strong></p><p>Raft通过选举一个领导人，然后给予他全部的管理复制日志的责任来实现一致性。</p><p>三个角色(任何服务器都可以当三个角色之一)：</p><p>领导者(leader)：处理客户端交互，日志复制等动作，一般一次只有一个领导者</p><p>候选者(candidate)：候选者就是在选举过程中提名自己的实体，一旦选举成功，则成为领导者</p><p>跟随者(follower)：类似选民，完全被动的角色，这样的服务器等待被通知投票</p><p><img src="/posts/8228/assets/245c625665ef3048b3beb44397944a4a.webp" alt="img"></p><p>理解：当服务启动的时候，所有服务器follower都是初始状态，每个服务器都有一个定时器，超时时间为election timeout（一般为150-300ms），当某个服务器达到超时时间，他就成为了候选者，先给自己投上一票，然后发送消息给其他服务器，当其他服务器超过半数收到了他的消息，相当于获取到了选票，他就成了领导者，而其他服务器全部成了跟随者，这时候领导者就开始根据间隔时间向跟随者发送心跳检测包，证明我还活在，也就是心跳机制，而跟随者每次接受到消息，就初始化自己内部的定时器，当某个服务器定时器达到超时时间，没有收到领导者的消息，那么跟随者会觉得领导者挂了，他就摇身一变称为候选者，开始篡位，重复之前的过程，成为领导者，当他成为领导者之后，当前任领导者就算回来了，也只能变成跟随者。</p><p>特殊情况：四个服务器，当其中两个服务器同时达到超时成为候选者，并且每个服务器拿到自己一票，另外一个服务器一票，这时候的机制就是这两个服务器重新定时，先达到超时的服务器成为候选者，并发送通知进一步成为选举者。</p><p><strong>日志复制（保证数据一致性）</strong></p><p>Leader选出后，就开始接收客户端的请求。Leader把请求作为日志条目（Log entries）加入到它的日志中，然后并行的向其他服务器发起 AppendEntries RPC复制日志条目。当这条日志被复制到大多数服务器上，Leader将这条 日志应用到它的状态机并向客户端返回执行结果。</p><p><img src="https://pic3.zhimg.com/80/v2-bb308fb5ccc46915f0cb13a9875bcc4e_720w.webp" alt="img"></p><p>1）客户端的每一个请求都包含被复制状态机执行的指令。</p><p>2）leader把这个指令作为一条新的日志条目添加到日志中，然后并行发起 RPC 给其他的服务器，让他们复制这条 信息。</p><p>3）跟随者响应ACK,如果 follower 宕机或者运行缓慢或者丢包，leader会不断的重试，直到所有的 follower 最终都 复制了所有的日志条目。</p><p>4）通知所有的Follower提交日志，同时领导人提交这条日志到自己的状态机中，并返回给客户端。</p><h2 id="二、分布式系统设计策略"><a href="#二、分布式系统设计策略" class="headerlink" title="二、分布式系统设计策略"></a>二、分布式系统设计策略</h2><p>分布式常用设计策略：如何检测当前节点还活着？ 如何保障高可用？ 容错处理？ 负载均衡？</p><h3 id="心跳检测机制"><a href="#心跳检测机制" class="headerlink" title="心跳检测机制"></a>心跳检测机制</h3><p>心跳顾名思义，就是以固定的频率向其他节点汇报当前节点状态的方式。收到心跳，一般可以认为一个节点和现在的网络拓扑是良好的。心跳汇报时，一般也会携带一些附加的状态、元数据信息，以便管理。</p><p><img src="/posts/8228/assets/99869867adcf1e9c0d04f78eb39766e0.webp" alt="img"></p><p>理解：Client请求Server，Server转发请求到具体的Node获取请求结果。Server需要与三个Node节点保持心跳连接，确保Node可以正常工作，若Server没有收到Node3的心跳时，Server认为Node3失联，当Node3不一定是宕机了，可能是网络中断、任务繁忙导致检测超时等等，通过周期检测心跳机制、累计失效检测机制来判断节点是否挂掉，如果真正挂掉，从集群中移除，等恢复后再加进来。</p><h3 id="高可用设计"><a href="#高可用设计" class="headerlink" title="高可用设计"></a>高可用设计</h3><p>系统架构设计中必须考虑的因素之一，通常是指经过设计来减少系统不能提供服务的时间。</p><p><img src="https://pic3.zhimg.com/80/v2-3ddfce4f1f68ac247e09773ad7f6b842_720w.webp" alt="img"></p><p>系统高可用性的常用设计模式包括三种：主备（Master-SLave）、互备（Active-Active）和集群（Cluster）模式。</p><p><strong>主备模式</strong></p><p>最常用的模式，当主机宕机时，备机接管主机的一切工作，待主机恢复正常后，按使用者的设定以自动（热备）或手动（冷备）方式将服务切换到主机上运行，数据库称为MS模式，MySQL、Redis就采用MS模式实现主从复制，保证高可用。</p><p><img src="/posts/8228/assets/0257db1d7bd7cc77087ad7feb659507a.webp" alt="img"></p><p>master中所有操作都会以“事件”的方式记录在二进制日志中，也就是bin-log，其他数据库作为slave通过一个I&#x2F;O线程与主服务器保持通信，并监控master的二进制日志文件的变化，如果发现master二进制日志文件发生变化，则会把变化复制到自己的relay-log日志中，然后slave的一个SQL线程会把相关的“事件”执行到自己的数据库中，以此实现从数据库和主数据库的一致性，也就实现了主从复制。</p><p><strong>互备模式</strong></p><p>两台主机同时运行各自的服务工作且相互监测情况，开启互相备份同步，只有对写要求较高，需要多台数据库服务器存储写入数据，比如微博之类的网站。</p><p><img src="/posts/8228/assets/224d8b97ccf1f29cc5c12e6fb820bccf.webp" alt="img"></p><p><strong>集群模式</strong></p><p>集群模式是指有多个节点在运行，同时可以通过主控节点分担服务请求。如Zookeeper。集群模式需要解决主控节 点本身的高可用问题，一般采用主备模式来把某个节点当做master。</p><h3 id="容错性设计"><a href="#容错性设计" class="headerlink" title="容错性设计"></a>容错性设计</h3><p>提高系统对于错误包容的能力，保障分布式环境下相应系统的高可用或者健壮性，也提升了系统的安全性。</p><p>比如Redis的缓存穿透。</p><p><img src="https://pic3.zhimg.com/80/v2-67c70a7596cfd5981cae1e002baa944a_720w.webp" alt="img"></p><p>当一个请求进来时，从缓存中查询不到，这时候就会进去数据库查，如果是一个恶意的请求，比如id为-1，这个值根本不存在，制造大量请求进行攻击，越过缓存，数据库服务器可能就会承受不住压力而宕机，这时候就需要一个容错性设计来保证数据库的安全，可以通过布隆过滤器或者在第一次请求，为null时仍然返回一个值存储缓存，并设置一定的过期时间，再次请求就会直接经过缓存返回，来保证系统的高可用。</p><h3 id="负载均衡策略"><a href="#负载均衡策略" class="headerlink" title="负载均衡策略"></a>负载均衡策略</h3><p>使用多台集群服务器共同分担计算任务，把网络请求及计算分配到集群可用的不同服务器节 点上，从而达到高可用性及较好的用户操作体验。</p><p><img src="/posts/8228/assets/2755df4de6155f8cc3dfcffc6b99e7dc.webp" alt="img"></p><p>负载均衡器有硬件解决方案F5，也有软件解决方案Nginx、LVS等等。</p><p>负载均衡策略：</p><p>1） 轮询：默认就是轮询，根据Nginx配置文件中的顺序，依次把客户端的Web请求分发到不同的后端服务器。</p><p>2） 最少连接：当前谁连接最少，分发给谁。</p><p>3） IP地址哈希：确定相同IP请求可以转发给同一个后端节点处理，以方便session保持。</p><p>4） 基于权重的负载均衡：配置Nginx把请求更多地分发到高配置的后端服务器上，把相对较少的请求分发到低配服务器。</p><h3 id="三、分布式架构网络通信"><a href="#三、分布式架构网络通信" class="headerlink" title="三、分布式架构网络通信"></a>三、分布式架构网络通信</h3><h3 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h3><p>网络通信就是将流从一台计算机传输到另外一台计算机，基于传输协议和网络IO来实现，其中传输协议比较出名的有tcp、udp等等，tcp、udp都是在基于Socket概念上为某类应用场景而扩展出的传输协议，网络IO，主要有bio、nio、aio三种方式。其实就是使用不同的传输协议和IO技术实现服务器之间的远程方法调用。</p><p>TCP:面向连接的协议，速度不快，安全，因为他要经过三次握手，安全性要求更高四次握手。</p><p>UDP:广播协议，面向无连接，速度快，不安全，就是相当于广播一样只管发出去就完事了。</p><p>BIO:阻塞IO NIO:非阻塞IO AIO:非阻塞IO</p><p><img src="/posts/8228/assets/20298a2b0fe0ebb1b1fab5f5f13b7d79.webp" alt="img"></p><h3 id="RPC基本概念"><a href="#RPC基本概念" class="headerlink" title="RPC基本概念"></a>RPC基本概念</h3><p>RPC远程过程调用，核心模块就是通讯和序列化，他不是具体的技术，而是指整个网络远程调用过程，常用RPC实现框架Dubbo、Hessian、HSF等等。</p><p>RPC四个核心的组件，分别是Client，Client Stub，Server以及Server Stub，即客户端、客户端存根、服务端、服务端存根。</p><p><img src="/posts/8228/assets/6706f62e50bf4bffe3a18aaf097ff8eb.webp" alt="img"></p><p>1） 客户端以接口方式调用客户端存根。</p><p>2） 客户端存根收到调用后，把方法、参数等封装成消息体进行序列化成二进制文件，从而在网络中传输。</p><p>3） 客户端存根将请求发送给服务器存根。</p><p>4） 服务器存根收到消息后对消息体进行反向序列化。</p><p>5） 服务端存根根据解码结果调用本地服务端。</p><p>6） 服务端进行服务处理，即执行方法并返回结果。</p><p>7） 服务端存根收到结果，将结果封装成消息体，并进行序列化成二进制文件。</p><p>8） 服务端存根返回消息给客户端存根。</p><p>9） 客户端存根收到消息后对消息体进行反序列化解码。</p><p>10）客户端存根返回解码结果，客户端得到最终结果。</p><p>RPC的目标是要把2、3、4、7、8、9这些步骤都封装起来。</p><h3 id="RMI远程方法调用"><a href="#RMI远程方法调用" class="headerlink" title="RMI远程方法调用"></a>RMI远程方法调用</h3><p>远程方法调用 (Remote Method Invocation)，是java原生支持的远程调用 ,采用JRMP（Java Remote Messageing protocol）作为通信协议，纯java版本的分布式远程调用解决方案。</p><p><strong>客户端</strong></p><p>1）存根&#x2F;桩(Stub)：远程对象在客户端上的代理。</p><p>2）远程引用层(Remote Reference Layer)：解析并执行远程引用协议。</p><p>3）传输层(Transport)：发送调用、传递远程方法参数、接收远程方法执行结果。</p><p><strong>服务端</strong></p><p>1） 骨架(Skeleton)：读取客户端传递的方法参数，调用服务器方的实际对象方法，并接收方法执行后的返回值。</p><p>2） 远程引用层(Remote Reference Layer)：处理远程引用后向骨架发送远程方法调用。</p><p>3） 传输层(Transport)：监听客户端的入站连接，接收并转发调用到远程引用层。</p><p><strong>注册表</strong></p><p>URL形式注册远程对象，并向客户端回复对远程对象的引用。</p><p><img src="https://pic4.zhimg.com/80/v2-a023b13a3f2a2acee0cd6b76b0e3d8ff_720w.webp" alt="img"></p><p>运行过程：首先启动server服务端，向注册表发布对象，再启动客户端，客户端就从注册表获取远程对象引用，接着客户端生成对应的代理对象，也就是Stub桩对象，他和远程对象具有相同的接口和方法列表，接着通过远程引用层Remote Reference Layer进行转化成远程引用对象，传递给传输层Transport，由传输层发送TCP协议到服务端的传输层Transport，接着服务端的传输层调用远程引用层Remote Reference Layer，把远程引用对象转化成服务端本地对象，然后传递给骨架Skeleton，骨架根据请求去调用服务端进行对应方法执行，并获取返回结果，接着骨架Skeleton又一层一层往回返，最终客户端获取结果。</p><h3 id="同步、异步、阻塞、非阻塞"><a href="#同步、异步、阻塞、非阻塞" class="headerlink" title="同步、异步、阻塞、非阻塞"></a>同步、异步、阻塞、非阻塞</h3><p>同步：用户进程触发IO操作等待或者轮训的方式查看IO操作是否就绪。</p><p>异步：当一个异步进程调用发出之后，调用者不会立刻得到结果。而是在调用发出之后，被调用者通过状态、通知来通知调用者，或者通过回调函数来处理这个调用。</p><p>阻塞：当一个线程需要获取一把锁，一直等待这个锁释放。</p><p>非阻塞：当一个线程需要获取一把锁，并不会一直等待，他跑去做其他事，等通知者告知他锁被释放，他在回来获取锁接着干事。</p><h3 id="BIO"><a href="#BIO" class="headerlink" title="BIO"></a>BIO</h3><p>同步阻塞IO，B代表blocking，jdk1.4之前唯一IO模型。</p><p>一个连接一个线程，即客户端有连接请求时服务器端就启动一个线程进行处理，如果这个连接不做任何事情会造成不必要的线程开销，可以通过线程池改善，但是同样的无法避免大量线程的创建，并发请求效率低。</p><p><img src="https://pic3.zhimg.com/80/v2-c49b9904811043869f760deb25e9a00a_720w.webp" alt="img"></p><h3 id="NIO"><a href="#NIO" class="headerlink" title="NIO"></a>NIO</h3><p>同步非阻塞IO，JDK 1.4 及以上版本。</p><p>一个请求一个通道，即客户端发送的连接请求都会注册到多路复用器上，多路复用器（也称为选择器）轮询到连接有IO请求时才启动一个线程进行处理。</p><p><strong>通道（Channels）</strong></p><p>NIO 新引入的最重要的抽象是通道的概念。Channel数据连接的通道。 数据可以从Channel读到Buffer，也可以从buffer写到Channel中。</p><p><strong>缓冲区（Buffer）</strong></p><p>就是存数据的地方，通过缓冲区提高读写效率，通道channel可以向缓冲区Buffer中写数据，也可以向buffer中存数据。</p><p><strong>选择器（Selector）</strong></p><p>使用选择器，借助单一线程，就可对数量庞大的活动 I&#x2F;O 通道实时监控和维护。</p><p><img src="/posts/8228/assets/5be940a3a3ebdcbc4424d7e56bbc1598.webp" alt="img"></p><p>BIO模型中，一个连接来了，会创建一个线程，对应一个while死循环，死循环的目的就是不断监测这条连接上是否有数据可以读，而NIO他创建了一个多路复用器selector，连接来了之后现进多路复用器，通过检查这个selector，不需要再批量死循环，就可以批量监测出有数据可读的连接，进而读取数据。</p><h3 id="AIO"><a href="#AIO" class="headerlink" title="AIO"></a>AIO</h3><p>异步非阻塞IO，JDK7开始支持。</p><p>当有流可以读时，操作系统会将可以读的流传入read方法的缓冲区，并通知应用程序，对于写操作，OS将write方法的流写入完毕，操作系统会主动通知应用程序。因此read和write都是异步的，完成后调用回调函数通知。</p><p><img src="/posts/8228/assets/4fe1c55e37c5db64306430736de9a429.webp" alt="img"></p><h3 id="Netty"><a href="#Netty" class="headerlink" title="Netty"></a>Netty</h3><p>Netty 是由 JBOSS 提供一个异步的、 基于事件驱动的网络编程框架。</p><p><img src="/posts/8228/assets/074088ee1e34c9f2bd888afb8ffe948e.webp" alt="img"></p><p><strong>NIO缺点</strong></p><p>1）NIO 的类库和 API 繁杂，使用麻烦。</p><p>2）可靠性不强，开发工作量和难度都非常大。</p><p>3）NIO 的 Bug。例如 Epoll Bug，它会导致 Selector 空轮询，最终导致 CPU 100%。</p><p><strong>Netty优点</strong></p><p>1）对各种传输协议提供统一的API 。</p><p>2）高度可定制的线程模型——单线程模型、一个或多个线程池模型。</p><p>3）更好的吞吐量，更低的等待延迟 。</p><p>4）更少的资源消耗 。</p><p>5）最小化不必要的内存拷贝。</p><p><strong>netty模型</strong></p><p><img src="/posts/8228/assets/60d57f2ad955e3b6cc9ebda3ac7a49db.webp" alt="img"></p><p>Netty 抽象出两组线程池， BossGroup 专门负责接收客 户端连接， WorkerGroup 专门负责网络读写操作。 NioEventLoop 表示一个不断循环执行处理 任务的线程， 每个 NioEventLoop 都有一个 selector， 用于监听绑定在其 上的 socket 网络通道。 NioEventLoop 内部采用串行化设计， 从消息的读取-&gt;解码-&gt;处理-&gt;编码-&gt;发送， 始终由 IO 线 程 NioEventLoop 负责。</p><p><strong>Netty核心组件</strong></p><p><strong>ChannelHandler</strong> 接口及其实现类，相当于之前NIO里面的accept、read、write方法。</p><p><img src="/posts/8228/assets/f442f97b1077c350c5e73eb7cb1cfc48.webp" alt="img"></p><p><strong>ChannelPipeline</strong> 是一个Handler的集合，它负责处理和拦截 inbound 或者 outbound 的事件和操作，相当于一个 贯穿 Netty 的链。</p><p><img src="/posts/8228/assets/479a6a071d89e7c6f06d68189e733c0f.webp" alt="img"></p><p><strong>ChannelHandlerContext</strong>这是事件处理器上下文对象，Pipeline链中的实际处理节点。每个处理节点ChannelHandlerContext中包含一个 具 体 的 事 件 处 理 器 ChannelHandler ， 同 时 ChannelHandlerContext 中也绑定了对应的 pipeline 和 Channel 的信息，方便对 ChannelHandler 进行调用。</p><p><img src="https://pic3.zhimg.com/80/v2-f0113e80cba78bd225fd01ac135936c2_720w.webp" alt="img"></p><p><strong>ChannelFuture</strong> 核心，表示Channel 中异步 I&#x2F;O 操作的结果，在 Netty 中所有的 I&#x2F;O 操作都是异步的， I&#x2F;O 的调用会直接返回，调用者并不能立刻获得结果，但是可以通过 ChannelFuture 来获取 I&#x2F;O 操作的处理状态，结果要等执行完毕后获取。</p><p><img src="https://pic3.zhimg.com/80/v2-c713b674238ea17647fe98e5603d29e6_720w.webp" alt="img"></p><p><strong>EventLoopGroup</strong> 和其实现类 <strong>NioEventLoopGroup</strong>，EventLoopGroup(最上面模型中的Boss Group) 是一组 EventLoop（可以理解成一个线程，最上面模型中的NIOEventLoop） 的抽象， Netty 为了更好的利用多核 CPU 资源， 一般会有多个 EventLoop 同时工作，每个EventLoop 维护着一个Selector实例，线程池一般是两个，一次处理连接，一次进行操作。</p><p><img src="https://pic2.zhimg.com/80/v2-2b4ed67d6478e7bb894465e305733c3d_720w.webp" alt="img"></p><p><strong>ServerBootstrap</strong> 和 <strong>Bootstrap</strong> ServerBootstrap 是 Netty 中的服务器端启动助手，通过它可以完成服务器端的各种配置；Bootstrap是Netty 中的客户端启动助手，通过它可以完成客户端的各种配置。</p><p><img src="/posts/8228/assets/9aa26083ccbc1d39cbc89e2a9c510804.webp" alt="img"></p><p><img src="/posts/8228/assets/cbe67b6d982e45077c2a20bc7638c910.webp" alt="img"></p><p><img src="https://pic2.zhimg.com/80/v2-ea9c3edc34aea7630b9e304f0a849a1d_720w.webp" alt="img"></p><p><img src="https://pic3.zhimg.com/80/v2-2177b146d9ac635cd8a6415db8055f5e_720w.webp" alt="img"></p><h3 id="基于Netty自定义RPC"><a href="#基于Netty自定义RPC" class="headerlink" title="基于Netty自定义RPC"></a>基于Netty自定义RPC</h3><p><strong>两种常用远程调用</strong></p><p>1）是基于HTTP的restful形式的广义远程调用，以spring could的feign和restTemplate为代表，采用的协议是HTTP的7层 调用协议，并且协议的参数和响应序列化基本以JSON格式和XML格式为主。</p><p>2）是基于TCP的狭义的RPC远程调用，以阿里的Dubbo为代表，主要通过netty来实现4层网络协议，NIO来异步传输， 序列化也可以是JSON或者hessian2以及java自带的序列化等，可以配置。</p><p><strong>运转实现图</strong></p><p><img src="/posts/8228/assets/97e8a3a4f77cc6dd2a3982ce29254d5a.webp" alt="img"></p><p><strong>服务端</strong></p><p>1） 通过main方法启动服务器，设定ip和端口，调用实现类的startServer方法。</p><p><img src="/posts/8228/assets/487973472fcf60679a238ee9dc027d1a.webp" alt="img"></p><p>2） 在startServer方法创建启动引导类并监听要做的事，通过自定义UserServiceHandler来实现自定义逻辑的监听来并加到启动引导类的通道中。</p><p><img src="/posts/8228/assets/aacde7e949aaf3f2e4b07a5340107354.webp" alt="img"></p><p>3） 当有读操作出现，就会进入自定义处理器，执行相应逻辑并返回结果，最后把结果写回客户端。</p><p><img src="/posts/8228/assets/e9bc75420cc5eb1a9d709fc942645b95.webp" alt="img"></p><p><strong>客户端</strong></p><p>1） 通过main方法启动服务器，首先调用createProxy，传递接口类和参数，进行代理对象的构造。</p><p><img src="/posts/8228/assets/d284e8c3aaba979c45fd2e8529626d7a.webp" alt="img"></p><p>2） 当代理对象创建之后，调用代理对象对应的方法时，就会进去JDK动态代理的invoke拦截方法内部进行客户端初始化。</p><p><img src="https://pic4.zhimg.com/80/v2-390e6740d34cfff45c3c2dbb554c82eb_720w.webp" alt="img"></p><p>3） 初始完毕之后，开始设置参数，即最开始定义参数拼接方法传递参数</p><p><img src="https://pic3.zhimg.com/80/v2-20d2d079e377020a25f4a57c4a696f3a_720w.webp" alt="img"></p><p>4） 当参数也设置完毕之后就可以通过线程池对call方法进行调度，进行写操作，写完阻塞，等待服务器返回数据之后唤醒继续写，这是通过互斥锁来实现读写交替。</p><p><img src="/posts/8228/assets/eee427888435f493800477a0cb3c9bb2.webp" alt="img"></p><p>5） 最后返回结果给客户端。</p><p><img src="/posts/8228/assets/7741999f36dcf4c21e3fb86e99e333a6.webp" alt="img"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一、分布式理论&quot;&gt;&lt;a href=&quot;#一、分布式理论&quot; class=&quot;headerlink&quot; title=&quot;一、分布式理论&quot;&gt;&lt;/a&gt;一、分布式理论&lt;/h2&gt;&lt;h3 id=&quot;分布式系统概念和存在的问题&quot;&gt;&lt;a href=&quot;#分布式系统概念和存在的问题&quot; class</summary>
      
    
    
    
    <category term="基础知识" scheme="https://itingyu.github.io/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    <category term="分布式架构设计" scheme="https://itingyu.github.io/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"/>
    
    
    <category term="基础知识" scheme="https://itingyu.github.io/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    <category term="分布式架构设计" scheme="https://itingyu.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"/>
    
  </entry>
  
</feed>
